<html><head></head><body><div class="part" title="Part&#xA0;IV.&#xA0;The Big Picture"><div class="titlepage"><div><div><h1 class="title"><a id="the_big_picture"/>Part IV. The Big Picture</h1></div></div></div><div class="partintro" title="The Big Picture" id="id2821058"><div/><div class="epigraph"><p><span class="emphasis"><em>Our legal department advised us not to say “the network is the computer” here</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div></div></div>
<div class="chapter" title="Chapter&#xA0;16.&#xA0;Parasitic Computing, or How Pennies Add Up"><div class="titlepage"><div><div><h1 class="title"><a id="parasitic_computing_comma_or_how_pennies"/>Chapter 16. Parasitic Computing, or How Pennies Add Up</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where the old truth that having an army of minions is better than doing the job yourself is once again confirmed</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>I hope you’ve enjoyed the ride so far. I’ve discussed a number of fancy problems that affect the security and privacy of information from its input at the keyboard to its ultimate destination hundreds or thousands of miles away. But it is too early for either of us to throw a party; something is missing from the picture—something far bigger than what we have discussed so far. The dark matter.</p><p>The problem with our story so far is simple: communications do not occur in a void. Although the process of exchanging data is usually limited to two systems and a dozen or so intermediate ones, the grand context of all events simply cannot be ignored; the properties of the surrounding environment can shape the reality of a chitchat between endpoints in profound ways. We cannot ignore the relevance of systems that are not directly involved in communications or the importance of all the tiny, seemingly isolated bits of individually trivial events that data meets along its path. It can be fatal to focus only on what appears relevant to a specific application or a particular case, as I hope this book has shown you thus far.</p><p>Rather than fall into this shortsighted trap, I’ve chosen to embrace the grand scheme of things in all its glory. Thus, the fourth and last part of this book focuses exclusively on the security of networking as a whole and discusses the Internet as an ecosystem, instead of a collection of systems accomplishing specific tasks. We pay tribute to the seemingly inert matter that binds the world together.</p><p>This part of the book begins with an analysis of a concept that appears to be the most appropriate way to make the transition. For many computer geeks, this concept, called parasitic computing, has revolutionized the way we think of the Internet.</p><div class="sect1" title="Nibbling at the CPU"><div class="titlepage"><div><div><h1 class="title"><a id="nibbling_at_the_cpu"/>Nibbling at the CPU</h1></div></div></div><p>A humble research paper published in letters to <span class="emphasis"><em>Nature</em></span> by Albert-Laszlo Barabasz, Vincent W. Freeh, Hawoong Jeong, and Jay B. Brochman in 2001<sup>[<a href="apb.html#ftn.CHP-16-BIB-1" class="footnoteref">108</a>]</sup> could easily have gone unnoticed. At first glance, this letter did not seem worthy of much attention; in fact, it posed a seemingly laughable proposition. The authors suggest that traffic could be created within well-established network protocols such as TCP/IP that would pose (as a message) a trivial arithmetic challenge—a problem to be solved—to a remote computer; the remote system would unwittingly solve the problem while parsing the message and preparing a response. But why would anyone waste time casting riddles at emotionless machines? What could one gain from this? Wouldn’t it be as much fun to solve them yourself? Of course, the answer is quite interesting.<a id="IDX-CHP-16-0710" class="indexterm"/><a id="IDX-CHP-16-0711" class="indexterm"/><a id="IDX-CHP-16-0712" class="indexterm"/><a id="IDX-CHP-16-0713" class="indexterm"/><a id="IDX-CHP-16-0714" class="indexterm"/><a id="IDX-CHP-16-0715" class="indexterm"/><a id="IDX-CHP-16-0716" class="indexterm"/><a id="IDX-CHP-16-0717" class="indexterm"/></p><p>First, there is a business to solving puzzles with a computer: much of today’s cryptography is based on the relative difficulty of solving a set of so-called non-polynomial<sup>[<a id="CHP-16-FN-1" href="#ftn.CHP-16-FN-1" class="footnote">33</a>]</sup> (NP) problems. NP-complete problems seem to take pleasure in crashing every codebreaker’s party at the least opportune times. The ability to solve them efficiently—whether with enormous computing power, clever algorithms, or both—would likely take a lucky inventor one step closer to world domination. There’s the incentive, then, but how would one do it?</p><p>The method proposed in the research is quite novel. The paper first states that many NP problems in mathematics can be easily expressed in terms of Boolean satisfiability (SAT) equations. SAT equations represent these problems as Boolean logic operations, effectively constructing a sequence of parameters and variables (a Boolean formula). A classic example of an SAT formula might be<a id="IDX-CHP-16-0719" class="indexterm"/><a id="IDX-CHP-16-0720" class="indexterm"/><a id="IDX-CHP-16-0718" class="indexterm"/></p><table border="0" summary="Simple list" class="simplelist"><tr><td>P = (x<sub>1</sub> XOR x<sub>2</sub>) AND (~x<sub>2</sub> AND x<sub>3</sub>)</td></tr></table><p>Here, <span class="emphasis"><em>P</em></span> is the formula (problem) itself, and <span class="emphasis"><em>x</em></span><sub>1</sub>to <span class="emphasis"><em>x</em></span><sub>3</sub> are binary inputs, or parameters.</p><p>Although there are 2<sup>3</sup> possible combinations of values for x<sub>1</sub>, x<sub>2</sub>, and x<sub>3</sub>, only one of them makes <span class="emphasis"><em>P</em></span> true: x<sub>1</sub> = 1, x<sub>2</sub> = 0, x<sub>3</sub> = 1. Hence, we say that only this triplet is a solution to <span class="emphasis"><em>P</em></span>. Finding solutions to SAT problems boils down to determining a set of values for all variables in the equation, for which the whole formula that incorporates those variables has a logic value of truth. Although trivial SAT problems like the one shown earlier are easy to solve, even without invoking any solving mechanism other than trial and error, more complex multivariable cases are indeed NP complete, and, consequently, other NP problems can be reduced to SAT problems in polynomial (meaning sane) time.</p><p>And here lies the problem. We can formulate a hard NP problem in terms of SAT, but this does not buy us much. As of this writing, when it comes to a non-trivial equation, even the best SAT-solving algorithms known aren’t much more effective than a brute-force search whereby all possibilities are tried, and the value of the formula is evaluated for each possibility. This means that if we have a SAT problem and enough computing power to even consider approaching it, attempting a solution using brute force is not such an insane approach, and we would not get much further by with a more sophisticated one. Anyway, there’s not much to lose by trying.</p><p>And here’s the revelation that binds SAT problems and TCP/IP networking. The basic observation made by the researchers is fairly obvious (or should be, if you subscribe to <span class="emphasis"><em>Nature</em></span>): the checksumming algorithm of TCP (or IP), as discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>, although in principle designed for a wholly different purpose than solving equations, is nothing more than a set of Boolean operations subsequently performed on bits of the input message. After all, at the low level, the algorithm boils down to pure Boolean logic carried out on words of the transmitted packet. They conclude that, by providing specific contents of the packet (“input”), the remote system can thus be forced to carry out a set of arithmetic operations and then evaluate its correctness—its agreement with the checksum declared in the TCP or IP header.</p><p>Although the operation performed by the remote system during the checksumming process is in every single iteration exactly the same, it has a functionality sufficient to serve as a universal logic gate, a mechanism we remember from <a class="xref" href="ch02.html" title="Chapter 2. Extra Efforts Never Go Unnoticed">Chapter 2</a>. By interleaving the actual tested input with carefully chosen “control” words that invert or otherwise alter the partial checksum computed thus far, it is possible to carry out any Boolean operation.</p><p>This, in turn, means that SAT logic can be easily re-created using a specific sequence control and “input” bits in a packet once the data is exposed to a checksumming algorithm; equation variables (chosen this or the other way) are interleaved with fixed words that are used to transmogrify the current checksum value so that the outcome of the next operation mimics a specific Boolean operator. The final result—the value to which a packet sums—denotes the final outcome: the logic value of a formula to be evaluated.</p><p>Thus, the satisfiability test is quite accidentally carried out by the remote recipient when, upon arrival, it attempts to validate the checksum. If the checksum comes out as 1 (or as some other value that in our SAT computation system corresponds to an SAT statement evaluating true), it passes the satisfiability test for the variable values chosen for this particular packet (and the traffic is passed to higher layers and acted upon). If the checksum fails, the formula has not been satisfied, and the packet is dropped silently. In other words, if our input bits denoted a specific hypothesis, the recipient had either verified it or proved it wrong, taking different actions depending on the outcome.</p><p>Further, a party wanting to solve an SAT problem quickly can prepare a set of all possible combinations of variable values (inputs) for a given formula, interleave it with information that causes the inputs to combine with others in the most desirable way, stuff this information into TCP packets, and send them out (nearly in parallel) to a large number of hosts around the globe. The checksum for a packet would be set manually to a value we know the “hypothesis” would produce if proven true, instead of actually calculating it. Only hosts that receive packets with variable values for which the formula evaluates to the desired value would respond to the traffic; other systems would simply disregard such traffic as corrupted due to the checksum mismatch. The sender can thus determine the correct solution without performing massive computations and can simply look up the set of values used in packets sent to those hosts that replied to a request.</p><p>The research goes further and reports on a successful attempt to solve an NP problem using real-world hosts across the globe, thus providing not only theoretical background, but also actual confirmation of the approach.</p><p>The impact of this technique is quite subtle, but also important: it proves that it is possible to effectively “outsource” computations to unaware and unwilling remote parties on the network, including sets of operations needed to solve real-world computing problems, without actually attacking these systems, taking them over, installing malicious software, or otherwise interfering with legitimate tasks. One person can thus, effectively, divide a specific computational task among a large number of systems. In the process, they can consume only a tiny and negligible fraction of a system’s computing power that could nevertheless add up to the equivalent of a decent supercomputer, when millions of systems work on a problem together.</p><p>World domination at hand? Not so fast.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-16-FN-1" href="#CHP-16-FN-1" class="para">33</a>] </sup>In complexity theory, polynomial problems can be solved by a Turing machine in time that is polynomially proportional to input length (number or size of variables for which the answer must be found). This means that the time needed to solve a polynomial problem corresponds directly to the input length raised to a constant exponent, which can be zero (causing the time not to depend on input length at all, as with testing for parity). Non-polynomial (NP) problems have no known solutions of this nature and may require dramatically more time to solve as the input length increases, exhibiting, for example, exponential dependency. A subset of NP problems, known as NP complete, are proven to have no polynomial time solutions. NP problems are generally regarded as “hard” for nontrivial inputs, whereas P problems are less expensive to solve.</p></div></div></div>
<div class="sect1" title="Practical Considerations"><div class="titlepage"><div><div><h1 class="title"><a id="practical_considerations"/>Practical Considerations</h1></div></div></div><p>. . . or, perhaps, not just yet. The approach suggested in the aforementioned research is revolutionary and interesting, but not necessarily a particularly practical way to build a supercomputer by stealing from the rich. The amount of bandwidth needed to sustain a reasonable computing rate, and the amount of computations needed to prepare trivia for other systems to solve, is quite high. As a result, this scheme is not efficient enough to outsource the solving of complex mathematical problems to a global supercluster of unwilling victims.<a id="IDX-CHP-16-0721" class="indexterm"/><a id="IDX-CHP-16-0722" class="indexterm"/></p><p>In the scheme outlined earlier, the requirement of exponential computing power is exchanged for the requirement of exponential bandwidth. This is not necessarily a decent trade-off, particularly because only relatively simple tests can be pushed out, considering the packet size limitations of most networks. (All of them could likely be solved in the time it takes to transmit this data over Ethernet.) This technique proves that the attack is possible and provides a truly universal venue to facilitate it, but using more specific attack scenarios might yield much more useful results.</p><p>Other ways of stealing negligible amounts of individual computing power are perhaps more interesting as ways to achieve impressive computing power at a low cost. For example, certain types of client software (such as web browsers) can be easily used to execute even fairly complex algorithms in a relatively trivial way. One such example, a “Chinese lottery” computing scheme detailed in RFC 3607,<sup>[<a href="apb.html#ftn.CHP-16-BIB-2" class="footnoteref">109</a>]</sup> is used by a tiny Java applet that Jean-Luc Cooke’s <a class="ulink" href="http://md5crk.com">md5crk.com</a> website encourages webmasters to add to their web pages. Once this applet is added to a site, every visitor to it can execute the applet on their system, borrowing a negligible amount of CPU cycles in order to contribute them to a project aimed at finding MD5 shortcut function collisions. (Collisions are two different messages that produce the same shortcut. They are elusive and anecdotal, although most definitely possible,<sup>[<a id="CHP-16-FN-2" href="#ftn.CHP-16-FN-2" class="footnote">34</a>]</sup> beings that can allow us to better understand the weaknesses of shortcut functions and could empirically prove and demonstrate that MD5 is too weak to be a match for today’s computers.)</p><p>Java applets are small pieces of machine-independent programs that are by default executed by web browsers in special, restricted “sandbox” environments. They have no access to local disk storage and (only in theory) no ability to do any harm, though they can use limited network connectivity to perform computations and to add certain visual elements to a web page. They are most commonly used to enhance websites with additional features, such as interactive games, visual effects, and so on. But Jean-Luc used these applets to do something else: to find likely candidates for collisions using the joint computing power of hundreds or thousands of systems around the world, simultaneously.<a id="IDX-CHP-16-0723" class="indexterm"/><a id="IDX-CHP-16-0724" class="indexterm"/></p><p>The principle behind the applet’s operation was trivial: The applet was executed on client systems worldwide whenever a cooperating website was visited; then, once launched, the applet tried to calculate MD5 shortcuts for different randomly chosen messages. This continued until a shortcut that matched a certain arbitrarily chosen and fixed masking pattern was found. Such a pattern could be “any shortcut with zero for the last four bytes” or something similar. The pattern was chosen so that it does not take too long to find a suitable shortcut by trial and error (so that the person does not have to leave the web page and stop the code before it is found), but so that only a small fraction of all possible shortcuts would match the rule.</p><p>Once a suitable message was found, the program “phoned home” with the candidate. The author could then examine the submissions. The applet had already examined and rejected a number of collision candidates, and only submitted those that matched a predefined condition (ones that were partly identical). Because much less variation is possible in the data collected this way, the likelihood of a collision in a chunk of <span class="emphasis"><em>n</em></span> entries is considerably higher than for purely random data. By analogy, the likelihood of running into two visually indistinguishable apples in an amount of fruit we are capable of going through within one day is higher if we order for delivery only those apples that have nearly the same weight and color, as opposed to purchasing a wagon of arbitrary fruit.</p><p>Although somewhere in the gray area of cyber-ethics, this ingenious approach first openly deployed by <a class="ulink" href="http://md5crk.com">md5crk.com</a> really worked and provided a good demonstration of how parasitic computing can be both quite effective and stealthy. It appears that the ability to steal processor cycles originally intended to be used for “rightful” purposes is well within reach, and perhaps used more often that we want it to be. And this possibility is here to stay.</p><p>But, a cranky skeptic continues, can parasitic computing do more than just nibble tiny bits of CPU power to facilitate cracking encryption schemes, a task few of us are truly interested in?</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-16-FN-2" href="#CHP-16-FN-2" class="para">34</a>] </sup>While this book was being prepared for printing, a team of Chinese researchers from Shandong University—Xiaoyun Wang, Dengguo Feng, Xuejia Lai, and Hongbo Yu—advised of a technique for finding and provided samples of MD4, MD5, HAVAL-128, and RIPEMD-128 collisions. This is one of the more important bits of news in modern cryptography, and confirmation that those functions are inadequate for some security-related applications. While the <a class="ulink" href="http://md5crk.com">md5crk.com</a> project has closed down, its contributions to exploring the field of parasitic computing remain valid.</p></div></div></div>
<div class="sect1" title="Parasitic Storage: The Early Days"><div class="titlepage"><div><div><h1 class="title"><a id="parasitic_storage_colon_the_early_days"/>Parasitic Storage: The Early Days</h1></div></div></div><p>When you shout, acoustic waves move through the air, gradually losing energy and dispersing in all directions. However, if they encounter a solid obstacle along the way they will likely bounce, and, if the angle is just right, they will bounce back to you. The audible result is that a split second after shouting you will hear an echo of your own voice.<a id="IDX-CHP-16-0725" class="indexterm"/></p><p>But what happens when an information theory geek reads their code aloud standing on the top of a mountain, directing their words toward a rocky valley? I thought you’d never ask. In such case, they cannot help but make a clever observation: if they read it fast and then immediately forget about what they just recited (because they become preoccupied with other matters), they can still eventually recover the information he when it bounces back off the bottom of the valley and is echoed back. Voilà—a convenient data storage mechanism.</p><p>Sounds ridiculous? Maybe we are just too young. Early types of computer memory modules used a similar acoustic technique that allowed the processor to store some information “offline” and recover it later. Instead of using air (through which waves spread a bit too fast to provide reasonable storage capacities without building extremely large memory units), a mercury-filled drum was used (an environment in which acoustic waves propagate much more slowly). The principle remained the same, however, and even gave an interesting meaning to the term <span class="emphasis"><em>memory leak</em></span>. Such a device, <span class="emphasis"><em>mercury delay line memory</em></span>, was used, for example, in the famous UNIVAC I.<sup>[<a id="CHP-16-FN-3" href="#ftn.CHP-16-FN-3" class="footnote">35</a>]</sup><a id="IDX-CHP-16-0727" class="indexterm"/><a id="IDX-CHP-16-0728" class="indexterm"/><a id="IDX-CHP-16-0726" class="indexterm"/></p><p>Naturally, this slow, bulky, dangerous, and inconvenient sort of memory was dropped in favor of other solutions as soon as the technology matured. However, the invention itself had some charm to it, and wouldn’t fade into oblivion that easily. A short presentation by Saqib A. Khan at the DefCON conference in Las Vegas in 2002 revived it and gave us the first hints about how to use the properties of a large-scale network to construct similar types of momentary storage using the Internet as a medium. But this time, the description of acoustic memory did not sound ridiculously primitive, but rather unbelievably cool to all hackers and geeks watching this short slide show. Acoustic memory had made its comeback in style.<a id="IDX-CHP-16-0729" class="indexterm"/></p><p>Because the round-trip times for packets (the time needed for a message to arrive at a remote system, and for a response to come back) are nonzero, a certain amount of data can always be kept “on the wire” by repeatedly sending out and receiving portions of it and waiting for it to echo back. Saqib used ICMP (Internet Control Message Protocol) “echo request” (ping) packets to achieve this effect; most systems on the Internet respond to such packets with “echo reply,” quoting the original payload they received.</p><p>This seemed like a cool trick. However, it was also far from practical for any reasonable application, because it required frequent retransmissions of portions of data. Because ICMP “echo reply” is sent back nearly immediately after the “echo request” is received, only a small amount of data could be pushed out before being sent back and needing to be recovered off the wire. As a result, the amount of data that could be stored this way could be no larger than the amount that the user could push out in, at best, a couple of seconds (and more commonly, under a tenth of a second).</p><p>Ah, but parasitic storage could be improved.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-16-FN-3" href="#CHP-16-FN-3" class="para">35</a>] </sup>Perhaps it is worth noting that a low-capacity, analog delay line memory was also used in early implementations of SECAM (Séquentiel Couleur avec Mémoire, or Sequential Color with Memory) TV receivers. Unlike NTSC or PAL, the SECAM signal uses a reduced color resolution; red and blue chrominance components are transmitted alternatively, never both at once. The other component must be taken from the preceeding line to determine how a specific pixel should look. To make this possible, a memory device needed to be implemented.</p></div></div></div>
<div class="sect1" title="Making Parasitic Storage Feasible"><div class="titlepage"><div><div><h1 class="title"><a id="making_parasitic_storage_feasible"/>Making Parasitic Storage Feasible</h1></div></div></div><p>In 2003, Wojciech Purczynski and I coauthored a paper called “Juggling with Packets: Parasitic Data Storage.” We took the concept of parasitic storage a bit further and considered a number of methods that could be used to dramatically extend the Internet’s storage capacity, while conserving the bandwidth needed to sustain the information. Our research focused on several other ways to store data on remote systems and classified them based on the properties of the storage medium (its visibility, volatility, and reliability). We also included a detailed discussion of the hypothetical storage capacities for each of the techniques.<a id="IDX-CHP-16-0734" class="indexterm"/><a id="IDX-CHP-16-0735" class="indexterm"/><a id="IDX-CHP-16-0736" class="indexterm"/><a id="IDX-CHP-16-0737" class="indexterm"/><a id="IDX-CHP-16-0738" class="indexterm"/><a id="IDX-CHP-16-0739" class="indexterm"/><a id="IDX-CHP-16-0740" class="indexterm"/><a id="IDX-CHP-16-0741" class="indexterm"/><a id="IDX-CHP-16-0742" class="indexterm"/><a id="IDX-CHP-16-0730" class="indexterm"/><a id="IDX-CHP-16-0731" class="indexterm"/><a id="IDX-CHP-16-0732" class="indexterm"/><a id="IDX-CHP-16-0733" class="indexterm"/></p><p>The paper was quite short and—I hope—refreshing and humorous, and it’s included here.</p><a id="I_programlisting1_d1e9750"/><pre class="programlisting">==============================================
 Juggling with packets: floating data storage
==============================================

  "Your dungeon is built on an incline. Angry monsters can't play marbles!"

  Wojciech Purczynski &lt;cliph@isec.pl&gt;
  Michal Zalewski &lt;lcamtuf@coredump.cx&gt;

1) Juggle with oranges!
------------------------
  Most of us, including the authors of this paper, have attempted to juggle
 with three or more apples, oranges, or other fragile ballistic objects. The
 effect is usually rather pathetic, but most adept juggler padawans sooner or
 later learn to do it without inflicting excessive collateral damage.

  A particularly bright juggler trainee may notice that, as long as he
 continues to follow a simple procedure, at least one of the objects is in the
 air at all times and that he has to hold at most two objects in his hands at
 once. Yet, each and every apple goes through his hands every once in a while,
 and he can recover it at will.

  After some fun with juggling, he may decide that the entire process is
 extremely boring and go back to his computer. While checking his e-mail, an
 educated juggler might notice that a typical network service has but one duty:
 to accept and process data coming from a remote system and take whatever steps
 it deems appropriate based on its interpretation of the data. Many of those
 services do their best to behave robustly, to be fault tolerant, and to supply
 useful feedback about the transaction.

  In some cases, the mere fact that a service is attempting to process the
 data and reply according to protocol can be used in ways that the authors
 never dreamed of. One of the more spectacular examples of this, which our
 fellow juggler might be familiar with, is research done at the University of
 Notre Dame, titled "Parasitic Computing" and published in letters to "Nature."

  Nevertheless, our hero concludes that such attempts are quite impractical in
 the real world. The cost of preparing and delivering trivia to be solved far
 exceeds any eventual gain since the sender has to perform operations of
 comparable computational complexity simply to deliver the request. "The
 computing power of such a device is puny!" he says.

  A real juggler would focus on a different kind of outsourced data
 processing, one that is much closer to his domain of expertise. Why not
 implement a distributed fruit-based data storage? What if I write a single
 letter on every orange and then start juggling? I can then store more orange
 bytes than my physical capacity (the number of oranges I can hold in my
 hands)! How brilliant. . . . But, but, would it work without oranges?

2) The same, without oranges
-----------------------------

  This paper is based on the observation that for all network communications,
 there is a nonzero (and often considerable) delay between sending information
 and receiving a reply--a result of the physical constrains of the medium and
 the time it takes to process data on all computer equipment.

  Like an orange with a message written on it, a packet used to store a piece
 of data travels for a period of time before returning to the source, and for
 this period of time we can safely forget its message without losing data. As
 such, the Internet has a nonzero momentary data storage capacity, and it is
 possible to push out a piece of information and effectively have it stored
 until echoed back. By establishing a mechanism for the cyclic transmission and
 reception of chunks of data to and from a number of remote hosts, it is
 possible to maintain an arbitrary amount of data constantly 'on the wire,'
 thus establishing a high-capacity, volatile medium.

  This medium can be used for memory-expensive operations, either as regular
 storage or for certain types of sensitive data for which one does not want to
 have leave a physical trail on a hard disk or other nonvolatile media.

  Since it is not considered bad programming practice to return as much
 relevant information to the sender as the sender sends to the service, and
 because many services or stacks maintain a high level of verbosity, our
 juggling experience tells us that it is not only possible, but also feasible,
 to establish this kind of storage, even over a low-end network hookup. Unlike
 traditional methods of parasitic data storage (such as P2P abuse, open FTP
 servers, binary Usenet postings, and so on), this particular method may or may
 not leave a trail of data (depending on how we implement it), and it does not
 put any single system under a noticeable load. Therefore, unlike the
 traditional methods, this technique is less likely to be detected and
 considered an abuse. Hence, the possibility of the data being intercepted and
 purposefully discarded is much less a problem.

3) Class A data storage: memory buffers
----------------------------------------

  Class A data storage uses the capacity inherent in communication delays
 during the transmission and processing of live data as it travels across
 networks between two endpoints. The information stored herein remains cached
 in the memory of a remote machine and is not likely to be swapped out to a
 disk device.

  Examples of class A memory are a variety of schemes that rely on sending a
 message that is known to result in partial or full echo of the original
 request, including the following:

    - SYN+ACK, RST+ACK responses to SYN packets, and other bounces

    - ICMP echo replies

    - DNS lookup responses and cache data. It is possible to store some
      information in a lookup request and have it bounce back with an NXDomain
      reply or to store data in an NS cache.

    - Cross-server chat network message relaying. Relaying text messages
      across IRC servers and so on can exhibit considerable latency.

    - HTTP, FTP, web proxy, or SMTP error or status replies.

  The most important properties of class A storage are:

    - Low latency (milliseconds to minutes), which makes it more useful for
       near random access memory applications.

    - Lower per-system capacity (usually kilobytes), which makes it less
       suitable for massive storage.

    - Only one chance to receive or few retransmits which make it less
       reliable in case of a network failure.

    - Lower likelihood of permanent recording. The data is not likely to be
       stored on a nonvolatile medium or swapped out, increasing privacy and
       deniability.

  In particular, when using higher-level protocols, additional features appear
that might solve some of the low-capacity and short- recovery window problems
 shared by various types of class A storage. For example, it is possible to
 establish a connection to a service such as SMTP, FTP, HTTP, or any other
 text-based service and send a command that is known to result in an
 acknowledgment or error message being echoed along with part of the original
 data. We do not, however, send a fully formatted message; we leave some
 necessary characters unsent. In most cases, end-of-line characters are
 required in order to complete the command. In this state, our data is already
 stored on remote service waiting for a complete command or until connection
 time-out occurs. To prevent time-outs, either on TCP or at the application
 level, no-op packets need to be sent periodically. A \0 character interpreted
 as an empty string has no effect on many services but is sufficient to reset
 TCP and service time-out timers. A prominent example of an application
 vulnerable to this attack is Microsoft Exchange.

  The attacker can sustain the connection for an arbitrary amount of time,
 with a piece of data already stored at the other end. To recover the
 information, the command must be completed with the missing \r\n, and then the
 response is sent to the client.

  A good example is the SMTP VRFY command:

  220 inet-imc-01.redmond.corp.microsoft.com Microsoft.com ESMTP Server
  Thu, 2 Oct 2003 15:13:22 −0700
  VRFY AAAA...
  252 2.1.5 Cannot VRFY user, but will take message for
  &lt;AAAA...@microsoft.com&gt;

  It is possible to store just over 300 bytes, including nonprintable
 characters, this way--and have it available almost instantly. More data can be
 stored if the HTTP TRACE method is used with data passed in arbitrary HTTP
 headers, depending on the server software. Sustained connections can give us
 arbitrarily high latency, thus creating large storage capacity.

  This type of storage is naturally more suited for privacy-critical
 applications or low-latency lower to medium capacity storage (immediate RAM-
extending storage for information that should leave no visible traces). The
 storage is not suitable for critical data that should be preserved at all
 costs, due to the risk of data being lost on network failure.


4) Class B data storage: disk queues
-------------------------------------

  Class B data storage uses "idle" data queues that store information for an
 extended period of time (often on the disk). For example, MTA systems can
 queue e-mail messages for as many as 7 days (or more, depending on the
 configuration). This feature can give us a long delay between sending data to
 store on the remote host and receiving it. Because a typical SMTP server
 prevents the relay of e-mail from the client to itself, e-mail bounces can be
 used to have data returned after a long period of time.

  For example, consider this potential attack scenario:

  1. The user builds a list of SMTP servers (perhaps servers that provide a
      reasonable expectation of being beyond the reach of their foes).

  2. The user blocks (with block/drop, not reject) all incoming connections to
      their port 25.

  3. For each server, the attacker has to confirm its delivery time-outs and
      the IP from which the server connects back while trying to return a
      bounce. This is done by sending an appropriate probe to an address local
      to the server (or requesting a DSN notification for a valid address) and
      checking to see how long the server tries to connect back before giving
      up. The server does not have to be an open relay.

  4. After confirming targets, the attacker starts sending data at a pace
      chosen so that the process is spread evenly over the period of one week.
      The data should be divided so that there is one chunk per each server.
      Every chunk is sent to a separate server to immediately generate a bounce
      back to the sender.

  5. The process of maintaining the data boils down to accepting an incoming
      connection and receiving the return at most a week from the initial
      submission, just before the entry is about to be removed from the queue.
      This is done by allowing this particular server to go through the
      firewall. Immediately after the chunk is received it is relayed back.

  6. To access any portion of data, the attacker looks up which MTA is holding
      this specific block and then allows this IP to connect and deliver the
      bounce. Three scenarios are possible:

     - If the remote MTA supports the ETRN command, the delivery can be
        induced immediately.

     - If the remote MTA was in the middle of a three-minute run in an attempt
        to connect to a local system (keeps retrying thanks to the fact its SYN
        packets are dropped, not rejected with RST+ACK), the connection can be
        established in a matter of seconds.

     - Otherwise, it is necessary to wait from five minutes to one hour,
        depending on the queue settings.

  This scheme can be enhanced using DNS names instead of IPs for users on
 dynamic IP or to provide additional protection (or when it is necessary to cut
 the chain immediately).

  The important properties of class B storage are:

    - High per-system capacity (megabytes), making it a perfect solution for
       storing large files and so on

    - Higher access latency (minutes to hours), likening it to a tape device,
       not RAM (with the exception of SMTP hosts that accept the ETRN command
       to immediately reattempt delivery)

    - Very long lifetime, increasing per-user capacity and reliability

    - Plenty of delivery attempts, making it easy to recover the data even
       after temporary network or hardware problems

    - Likely to leave a trace on the storage devices, making it a less-useful
       solution for fully deniable storage (although it would still require
       examining a number of foreign systems, which does not have to be
       feasible)

  Class B storage is suitable for storing regular file archives, large append-
only buffers, encrypted resources (with a proper selection of hosts, it
 remains practically deniable), etc.

5) Discreet class A storage
----------------------------

  In certain situations, it might be necessary to devise a solution for
 discreet data storage that does not reside on the machine itself and that
 makes it possible to deny the presence of this information anywhere.

  The basic requirement is that the data is:

    - Not returned until a special key sequence is sent

    - Permanently discarded without leaving any record on any nonvolatile
       storage media in the absence of keep-alive requests

  It is possible to use class A storage to implement this functionality using
 the sustained command method discussed earlier. The proper TCP sequence number
 is necessary to release the data, and until this sequence is delivered, the
 data is not returned or disclosed to any party. If the client node goes
 offline, the data is discarded and likely overwritten.

  The sequence number is thus the key to the stored information, and, if the
 lifetime of the data is fairly short when keep-alive \0s stop coming, it is
 often adequate protection.

6) User-accessible capacity
----------------------------

  In this section, we attempt to estimate the storage capacity available to a
 single user.

  In order to maintain a constant amount of data "outsourced" to the network,
 we must be able to receive and send it back on a regular basis.

  The amount of time that data can be stored remotely is constrained by the
 maximum lifetime Tmax of a single packet (including packet queuing and
 processing delays). The maximum amount of data that can be sent is limited by
 maximum available network bandwidth (L). Thus, the maximum capacity
 can be defined as:

    Cmax [bytes] = L [bytes/second] * Tmax [seconds] / Psize * Dsize

where:

    Dsize - The size of a packet required to store an initial portion of data
 on a remote host

Psize - The size of a packet required to sustain the information stored on
 a remote host

  Psize and Dsize are equal and thus can be omitted whenever the entire chunk
 of data is bounced back and forth; they differ only for "sustained command"
 scenarios. The smallest TCP/IP packet to accomplish this has 41 bytes. The
 maximum amount of data that can be sustained using HTTP headers is about 4096 bytes.

  That all, in turn, gives us the following chart:

            Bandwidth  | Class A | Class B
           -----------+---------+---------
            28.8 kbps |  105 MB |    2 GB
             256 kbps |  936 MB |   18 GB
               2 Mbps |  7.3 GB |  147 GB
             100 Mbps |  365 GB |    7 TB

7) Internet as a whole
-----------------------

  In this section, we attempt to estimate the theoretical momentary capacity
 of the Internet as a whole.

  Class A

    To estimate the theoretical class A storage capacity of the Internet, we
     assume the following:

      - ICMP messages offer the best balance between storage capacity and
         preserving a remote system's resources.

      - An average operating system has a packet input queue capable of
         holding at least 64 packets.

      - The default PMTU is approximately 1500 (the most common MTU).

    As an estimate of the number of hosts on the Internet we use an ISC survey
     for 2003, which lists 171,638,297 systems with reverse DNS entries
     (although not all IPs with reverse DNS have to be operational). To take
     this into account, we used the ICMP echo response ratio calculated from
     the last survey that performed such a test (in 1999). The data then
     suggested that approximately 20 percent of visible systems were alive,
     which, in turn, sets the number of systems ready to respond to ICMP
     requests at roughly 34,000,000.

    By multiplying the number of systems that reply to ICMP echo requests by
     the average packet cache size and maximum packet size (minus headers), we
     estimate the total theoretical momentary capability for class A ICMP
     storage to be approximately 3 TB.

Class B:

    To estimate theoretical class B storage capacity, we use the example of
     MTA software. There is no upper cap for the amount of data we feed to a
     single host. Although it is safe to assume that only messages under
     approximately 1 MB will not cause noticeable system load and other
     undesirable effects, we assume that the average maximum queue size is
     500 MB.

    Our own research suggests that roughly 15 percent of systems that respond
     to ping requests have port 25 open. We thus estimate the population of
     SMTP servers to be 3 percent (15 percent of 20 percent) of the total host
     count, or just over 5,000,000 hosts.

    This gives a total storage space capacity of 2500 TB.</pre></div>
<div class="sect1" title="Applications, Social Considerations, and Defense"><div class="titlepage"><div><div><h1 class="title"><a id="applications_comma_social_considerations"/>Applications, Social Considerations, and Defense</h1></div></div></div><p>But what now? What is the benefit of having practical parasitic computing and storage schemes, if the benefits are still not nearly good enough to make it a tempting alternative to just getting more hardware?<a id="IDX-CHP-16-0743" class="indexterm"/><a id="IDX-CHP-16-0744" class="indexterm"/></p><p>Despite advances in the practical exploitation of parasitic computing, applications that aim to extend the sheer computing power or storage space of a traditional system may appear pointless when we consider the abundance of cheap memory and gigahertz processors.</p><p>The unseen potential of this technology may, however, lie in a wholly different set of applications: <span class="emphasis"><em>volatile computing</em></span>. The ability to build usable distributed computers that can disperse at will, leaving no physical traces and storing no meaningful data at any one location, might be a powerful privacy tool and also pose some challenges for forensics and law enforcement. The ability to build volatile store-and-keep memory that collapses shortly after taking a single node offline, but that does not involve frequent retransmissions of data, might provide a good level of deniability for an offender (or an oppressed entity, for that matter) and require many common evidence collection procedures to change quite dramatically.<a id="IDX-CHP-16-0745" class="indexterm"/></p><p>Furthermore, imagine volatile systems that could, once bootstrapped and initialized, sustain themselves for extended periods of time, living in the Internet and taking no localized physical presence. Two designs are possible for volatile, distributed computer systems, and neither is that absurd:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Systems can be designed so that they complete a complex task by finding a solution in parallel (already largely accomplished by the SAT computing scheme discussed previously). The disadvantage of such systems is that the computation result must be retrieved and the next iteration of processing must be initiated manually by occasionally “reseeding” the entire system from some location. Solutions that rely on low-level properties of protocols such as TCP would likely fall into this category.</p></li><li class="listitem"><p>Systems can be designed so that they execute subsequent iterations of distributed computing themselves. All types of abuse of higher-level features (such as embedded document-rendering algorithms) and of some network services might be used to facilitate this type of activity.</p></li></ul></div><p>In each case, the consequences can be quite profound. For example, how do you take down a redundant self-repairing machine that uses no single system, but rather borrows tiny bits of memory and processing power from others for fractions of a second—and uses no vulnerabilities to do so or clearly distinguishable traffic that can be filtered out? And isn’t it also a bit disconcerting to realize that we would not be able to immediately discern the goals of such a distributed computer? Bowing respectfully to the masters of bad science fiction, I believe the domination of computers is imminent and want to welcome our new machine overlords.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id11"/>Food for Thought</h1></div></div></div><p>Defense against parasitic computing is generally extremely difficult. The ability to store data or to cause the other party to perform certain trivial computations is often bound to the fundamental functionality of network protocols. This is a characteristic that we cannot conceive of removing without wiping out the Internet as we know it and introducing a host of new problems more serious than the one remedied.</p><p>Protecting a single system against becoming a node for parasitic computing is also fairly difficult, because the number of resources stolen from a system is often a negligible fraction of the idle CPU time and memory and, hence, might easily go unnoticed.</p><p>Chances are good that parasitic computing has yet to show its full potential and that the threat—irrelevant or nonexistent for single systems but significant for the net as a whole—is here to stay.</p></div>
<div class="chapter" title="Chapter&#xA0;17.&#xA0;Topology of the Network"><div class="titlepage"><div><div><h1 class="title"><a id="topology_of_the_network"/>Chapter 17. Topology of the Network</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>On how the knowledge of the world around us may help track down friends and foes</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>What is the shape of the Internet? No committee oversees it or decides where, how, and why it should expand or how new and existing systems should be organized or managed. The Internet grows in all directions in ways that are equally driven by demand, economics, politics, technology, and blind luck.</p><p>Yet the Internet is not a shapeless blob: there are planned, locally governed hierarchies of autonomous systems, with core routers surrounded by lesser nodes, with links configured by automatic mechanisms or carefully designed by humans. The Internet is a spectacular mesh, a complex and fragile cobweb covering the entire industrialized and developing world. The task of capturing this ever-changing topology appears challenging, but also tempting, especially when we realize how we can benefit from the information collected.</p><p>In this chapter, I’ll first discuss two notable attempts to map the Internet’s topology, and then I’ll moralize once more on the potential uses for the information gathered this way to do things that our ancestors could not even dream of.</p><div class="sect1" title="Capturing the Moment"><div class="titlepage"><div><div><h1 class="title"><a id="capturing_the_moment"/>Capturing the Moment</h1></div></div></div><p>The most comprehensive attempt to map the Internet was undertaken by the Cooperative Association for Internet Data Analysis (CAIDA), an organization funded, among others, by federal research agencies (NSF, DHS, DARPA) and the industry (Cisco, Sun). The organization was formed to come up with traffic and infrastructure analysis and tools for the common benefit of the Internet community, in hopes of making it better, more reliable, more resilient, and more robust.<a id="IDX-CHP-17-0746" class="indexterm"/><a id="IDX-CHP-17-0747" class="indexterm"/><a id="IDX-CHP-17-0748" class="indexterm"/><a id="IDX-CHP-17-0749" class="indexterm"/><a id="IDX-CHP-17-0750" class="indexterm"/><a id="IDX-CHP-17-0751" class="indexterm"/><a id="IDX-CHP-17-0752" class="indexterm"/></p><p>Since 2000, one of CAIDA’s flagship public projects has been the creation and maintenance of the autonomous system core network map (aka “Skitter”). As of this publication, their most recent capture represents data for 12,517 major autonomous systems, corresponding to 1,134,634 IP addresses and 2,434,073 links (logical paths) between them.</p><p>Despite sounding astonishingly arcane, the CAIDA Internet map was created with only publicly accessible router BGP configuration data, empirical network testing results (traceroute), and WHOIS records for network blocks. This map is organized using polar coordinates. Points representing each system are located at an angle corresponding to the physical location of a network’s declared headquarters location and the radius corresponding to the “peering relevance” of this particular autonomous system. The latter parameter is derived by calculating the number of other autonomous systems observed to accept traffic from this particular node. Thus, massive core systems are located toward the center of the map, whereas systems that have direct contact with only a couple of nodes are located near the outer perimeter. Lines in the graph simply correspond to peering relations between routers.<a id="IDX-CHP-17-0753" class="indexterm"/></p><div class="note" title="Note"><h3 class="title">Note</h3><p>Quite regrettably, we were not allowed to use a graphical representation of CAIDA Skitter graphics in the book free of charge. I encourage you, however, to see this stunning picture online at <a class="ulink" href="http://www.caida.org/analysis/topology/as_core_network/pics/ascoreApr2003.gif">http://www.caida.org/analysis/topology/as_core_network/pics/ascoreApr2003.gif</a> where it is available to the general public at no cost.</p></div><p>Another noteworthy attempt to map the network used an approach that relied on analyzing distances to various networks, as seen from a particular location (in this case, from Bell Laboratories), to build a treelike structure quite unlike the complex mesh created by CAIDA. Conducted by Bill Cheswick in 2000,<sup>[<a href="apb.html#ftn.CHP-17-BIB-1" class="footnoteref">110</a>]</sup> this analysis resulted in the map shown in <a class="xref" href="ch17.html#bill_cheswickas_map_of_the_internet" title="Figure 17-1. Bill Cheswick’s map of the Internet">Figure 17-1</a>. This structure does not parametrize the graph depending on the physical or administrative location of a system; the relative distance from the center corresponds to the number of hops between that node and Bell Labs, however.</p><p>Although the two attempts appear to involve massive data collection and analysis, it is not prohibitively difficult for an amateur to attempt to map the network on even a fairly low-end link. Probing all publicly routable subnets with a single packet might require generating only a couple of gigabytes of traffic—the equivalent of a couple of hours to one day on a typical DSL connection. The only risk is that of upsetting some system administrators, but with the proliferation of computer worms and automated attacks, very few have a sensitivity threshold that low. Mapping the observed structure of the Internet is possible, and it can be rewarding, especially because it can tell us a lot about how the worldwide network is organized.</p><div class="figure"><a id="bill_cheswickas_map_of_the_internet"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9869"/><img src="httpatomoreillycomsourcenostarchimages1138106.png.jpg" alt="Bill Cheswick’s map of the Internet"/></div></div><p class="title">Figure 17-1. Bill Cheswick’s map of the Internet</p></div><p>But, as it turns out, the data, such as the information acquired by CAIDA, Bill Cheswick, or just about any proficient user of the Net, can also be successfully used to better understand the nature and better examine the origin of a mysterious traffic we might one day stumble upon.</p></div></div>
<div class="sect1" title="Using Topology Data for Origin Identification"><div class="titlepage"><div><div><h1 class="title"><a id="using_topology_data_for_origin_identific"/>Using Topology Data for Origin Identification</h1></div></div></div><p>Spoofed traffic is one of the Internet’s major problems—or, at the very least, one of its more annoying woes. Blindly spoofed packets with bogus or specially chosen but deceptive source addresses can be used to abuse trust relationships between computers, inject malicious contents (such as unsolicited bulk mailings) without leaving conclusive traces and legitimate origin information, and so forth. Blind spoofing can also be used to hide the identity of an attacker conducting system probes (“decoy scanning” discussed earlier in <a class="xref" href="ch13.html" title="Chapter 13. Smoke and Mirrors">Chapter 13</a>). The worst plague of all is, however, spoofing used to carry out Denial of Service (DoS) attacks.<a id="IDX-CHP-17-0754" class="indexterm"/><a id="IDX-CHP-17-0755" class="indexterm"/><a id="IDX-CHP-17-0756" class="indexterm"/><a id="IDX-CHP-17-0757" class="indexterm"/><a id="IDX-CHP-17-0758" class="indexterm"/><a id="IDX-CHP-17-0759" class="indexterm"/><a id="IDX-CHP-17-0760" class="indexterm"/><a id="IDX-CHP-17-0761" class="indexterm"/><a id="IDX-CHP-17-0762" class="indexterm"/><a id="IDX-CHP-17-0763" class="indexterm"/><a id="IDX-CHP-17-0764" class="indexterm"/><a id="IDX-CHP-17-0765" class="indexterm"/></p><p>In a typical DoS attack, the administrator is given a chance to see the origin of malicious traffic directed against one of their services (and presumably intended to bring it down and cause inconvenience or loss to the operator). It is possible to randomly spoof offending packets, however, and in such cases the administrator is left helpless, unable to filter out the traffic coming from the attacker without cutting off other users. Their only hope is to work with the upstream provider to investigate the actual origin of the traffic on the link layer and pass the information to the offender’s ISP; this, however, takes time, and lots of it. It also requires convincing all parties, without a court order, that the case is worthy of investigation (and their time and money). This situation makes it particularly important for the system administrator to be equipped with tools and methods to differentiate between spoofed and legitimate traffic.</p><p>When I used to live and work in the United States (I live in Poland these days), my colleague Mark Loveless decided to implement an idea originally proposed by Donald McLachlan: He would measure time to live (TTL) on network traffic between him and the presumed sender of a packet to automatically determine whether an incoming packet had been spoofed. The challenge of identifying the origin of a network packet in a world where the information cannot be trusted is important, and the ability to do so, even if only in a specific subset of cases, would greatly benefit many analytic and administrative tasks, for the reasons mentioned earlier.</p><p>To understand Donald and Mark’s idea, consider that the remote system, from which we are seeing traffic, is at a specific logical distance from us, separated by a given number of network devices. Thus, all packets legitimately sent by this system exhibit a certain TTL on arrival, corresponding to the default initial TTL configured on that system, minus the number of intermediate systems the packet has gone through (as discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>). However, for spoofed traffic that presumably originates on a wholly different network, the initial TTL and the distance is most likely different than the aforementioned observation would suggest. Mark’s tool, despoof,<sup>[<a href="apb.html#ftn.CHP-17-BIB-2" class="footnoteref">111</a>]</sup> compares the TTLs observed on specially induced and previously received traffic in order to distinguish between legitimate and falsified traffic.</p><p>However, although this method might work well in individual cases when used against unsuspecting attackers, at least two problems are associated with it:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A paranoid attacker can measure distances before the attack and choose a TTL that matches the expected value. Although possible, this trick is a bit difficult to implement. For one thing, the attacker might be physically unable to set TTL high enough to achieve a specific value that would match the expected value of a real packet once the packet reaches its destination. This attacker’s plan could be thwarted if the system that he is trying to impersonate uses a default TTL at or near 255 (the maximum possible) and he is farther from the target than the system he is trying to impersonate (hence it is very much impossible for him to send a packet that would, upon arrival at the destination, have the desired TTL). Of course, few systems use the highest possible TTL, and it is rare for an attacker to want to impersonate a specific system to begin with.</p><p>The attacker’s second challenge is that he might not be able to determine the exact distance between his victim and the impersonated system if he is nowhere near them and does not know the routing specifics between these hosts. But if the victim uses despoof to dynamically implement filtering rules to cut off malicious packets, the attacker might just try various TTLs from various sources until he sees that the victim is no longer capable of making the distinction. (This would be obvious: the system targeted would begin to exhibit the effects of a successful attack, such as a performance impact.)</p></li><li class="listitem"><p>Each time a suspicious packet is received, the recipient must start an investigation and then wait for the results to arrive. This makes it impractical to use despoof as a basis for an automatic defense, especially in response to DoS attacks. However, this method is still quite useful for determining the actual origin of a “decoy scan.”</p></li></ul></div><p>Without the knowledge of a specific network’s topology, it is difficult to do any better than with despoof; the TTL analysis technique implemented by this tool is good enough to recognize and stop many common probes and individual attacks, but what next?</p><p>Combine Mark’s tool with real-time data on the network structure, and apply passive fingerprinting to determine the initial TTL of a system that sends specific requests, and this technique becomes much more powerful. This additional data allows us to perform an initial passive assessment of incoming traffic by comparing observed and initial TTLs with the expected distance indicated by the network map. <sup>[<a id="CHP-17-FN-1" href="#ftn.CHP-17-FN-1" class="footnote">36</a>]</sup> Because the distance we should be seeing can be determined without initiating any active probe of the network topology data, we can instantly distinguish between legitimate and malicious traffic without much effort. This, in turn, makes it possible to react to massive incidents quite reliably and to detect individual low-profile probes without alerting the attacker that a spoofing detection system is in place.</p><p>Obviously, there is plenty to be gained from taking the structure of a network into account when considering peer-to-peer relations. But spoofing detection is only the beginning.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-17-FN-1" href="#CHP-17-FN-1" class="para">36</a>] </sup>In such an approach, the comparison of TTLs must be performed with a certain error margin, because there can be several additional hops within internal networks. Too, some routes are asymmetric, and their lengths can differ slightly depending on the direction in which the traffic is being exchanged.</p></div></div></div>
<div class="sect1" title="Network Triangulation with Mesh-Type Topology Data"><div class="titlepage"><div><div><h1 class="title"><a id="network_triangulation_with_mesh-type_top"/>Network Triangulation with Mesh-Type Topology Data</h1></div></div></div><p>Network triangulation is a considerably more interesting application of network topology mesh-type data for the purpose of traffic analysis. We can use network triangulation to determine the approximate location of an attacker who sends spoofed packets without the help of those operating the underlying routing backbone, as soon as they choose to attack more than one target at once or in succession—truly, happiness in misery.</p><p>Well, to be correct: although triangulation works best when the attacker chooses several targets, in some scenarios, it may work quite well even if they choose to attack only one service. In particular, we might be able to observe the same attack from different viewpoints when the object attacked has several IP addresses and the service is being served from several physical locations in order to distribute the load and make the entire structure fault tolerant (as is common with web services). In all other scenarios, we can get a range of data on an attack when system administrators notice that more than one system is being targeted by an attacker and share their data about the incident.</p><p>Regardless of the case, once data believed to come from a single source is seen at more than one destination, we can triangulate. For each destination at which the traffic is seen, only a specific set of networks are at a distance that can be determined by observing the distance through which the offending packet has traveled (again, possible to find out by examining TTL<sup>[<a id="CHP-17-FN-2" href="#ftn.CHP-17-FN-2" class="footnote">37</a>]</sup>). An intersection of all those sets for every observation point would yield a smaller set—or, often, only a single network—from which the attack could originate, as shown in <a class="xref" href="ch17s04.html#a_naive_network_triangulation_colon_only" title="Figure 17-2. A naive network triangulation: only one origin is consistent with all observations. The attacker may be spoofing source addresses, but can’t fool the victims.">Figure 17-2</a>.</p><p>The ability to perform the trace on our own frees us from unconditional dependence on ISPs and helps to precisely pinpoint who is attacking or probing our network—and perhaps find out why.</p><p>Although this approach is much more difficult to thwart than traditional despoofing, a clever attacker might still be able to fool an observer by randomizing a different TTL (or range of TTLs) to be used for every target. True, we know of no tools to do this at present, but this might change.</p><p>The battle is lost? Nope—there is a way to keep perpetrators from fooling us that way.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-17-FN-2" href="#CHP-17-FN-2" class="para">37</a>] </sup>Even if the tool uses random TTLs, it is possible to judge the distance by using the maximum TTL observed if a number of packets can be observed at each destination (which is almost always the case). For example, if the scan tool randomizes initial TTLs in the range of 32 to 255, but for several thousand packets received at the destination, none had a TTL higher than 247, the host is quite likely to be 255 – 247 = 8 systems away.</p></div></div></div>
<div class="sect1" title="Network Stress Analysis"><div class="titlepage"><div><div><h1 class="title"><a id="network_stress_analysis"/>Network Stress Analysis</h1></div></div></div><p>The solution, dubbed “network stress analysis,” comes in the form of a fine piece of research presented by Hal Brunch and Bill Cheswick at the LISA conference in 2000.<sup>[<a href="apb.html#ftn.CHP-17-BIB-3" class="footnoteref">112</a>]</sup> Brunch and Cheswick proposed an interesting use for tree-type network topology data (similar to the graph shown earlier in <a class="xref" href="ch17.html#bill_cheswickas_map_of_the_internet" title="Figure 17-1. Bill Cheswick’s map of the Internet">Figure 17-1</a>) obtained for a specific location. They came up with a way to use the data to detect the origin of a particular type of spoofed traffic: Denial of Service. The approach itself is fairly trivial and is based on the assumption that such an attack would stress not only the system against which it is being carried out, but also interim routers, and that this stress could be externally measured by the victim and used to—almost literally—go back and find a yarn by pulling the wire.<a id="IDX-CHP-17-0766" class="indexterm"/><a id="IDX-CHP-17-0767" class="indexterm"/><a id="IDX-CHP-17-0768" class="indexterm"/><a id="IDX-CHP-17-0769" class="indexterm"/><a id="IDX-CHP-17-0770" class="indexterm"/><a id="IDX-CHP-17-0771" class="indexterm"/><a id="IDX-CHP-17-0772" class="indexterm"/><a id="IDX-CHP-17-0773" class="indexterm"/><a id="IDX-CHP-17-0774" class="indexterm"/><a id="IDX-CHP-17-0775" class="indexterm"/></p><div class="figure"><a id="a_naive_network_triangulation_colon_only"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e10045"/><img src="httpatomoreillycomsourcenostarchimages1138108.png.jpg" alt="A naive network triangulation: only one origin is consistent with all observations. The attacker may be spoofing source addresses, but can’t fool the victims."/></div></div><p class="title">Figure 17-2. A naive network triangulation: only one origin is consistent with all observations. The attacker may be spoofing source addresses, but can’t fool the victims.</p></div><p>The job of stress-testing network links is achieved by first building or obtaining a tree of links from your location to all networks on the Internet and then going through subsequent branches of this tree structure when an attack occurs. For each branch (which, in reality, denotes a connection to a higher-order router), we can iteratively measure network load on this node by sending test traffic to or through the router associated with it. (In this particular paper, a UDP [User Datagram Protocol] chargen is used, but ICMP requests or any other type of messages could be also used.) We choose a more loaded node as a potential candidate for the incoming traffic and then list and test all branches that spawn from this node until we trace the traffic back to the origin.</p><p><a class="xref" href="ch17s04.html#recursive_attack_backtrace_using_network" title="Figure 17-3. Recursive attack backtrace using network topology data and stress testing">Figure 17-3</a> illustrates a simple trace-back scenario. In the first phase, the attacked system attempts to measure the performance of the three nearest Internet routers when an attack occurs; it concludes that the first (topmost) router is the most saturated.</p><p>Based on this information, the victim chooses to test only those routers directly connected (peering) with this device. In this particular figure, only three devices are to be tested (the remaining six are not to be tested because they do not peer with this device), and, again, the first one is the most loaded. The process continues until a router that is directly connected to a specific network, for which a physical location and owner information can be discovered through public databases, is determined to be the final endpoint.</p><div class="figure"><a id="recursive_attack_backtrace_using_network"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e10060"/><img src="httpatomoreillycomsourcenostarchimages1138110.png.jpg" alt="Recursive attack backtrace using network topology data and stress testing"/></div></div><p class="title">Figure 17-3. Recursive attack backtrace using network topology data and stress testing</p></div><p>A potential problem arises: some devices might be heavily loaded for reasons other than handling DoS traffic; other devices might have plenty of spare CPU cycles and would not be considerably affected by relaying malicious traffic.</p><p>To solve this issue, the research proposes putting an artificial short-term load on the router (by generating additional traffic) and then observing how this test affects the bandwidth and latency of the DoS requests; if this particular device is indeed involved in relaying malicious packets, the attack rate should drop when we put load on the device (again, likely by generating additional bogus TCP, UDP, or ICMP requests, designed more to consume a device’s CPU power than to congest its interfaces). Hence, there should be a correlation only on those branches that are involved in servicing the malicious traffic.</p><p>This brilliant and simple scheme had been successfully used in test environments. However, because it involves interacting with routers and placing an additional load on them, certain ethical considerations come into play when we consider using it in the real world.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id12"/>Food for Thought</h1></div></div></div><p>The main difficulty in using the techniques discussed in this chapter for tracking down attackers is that we need to construct and update network maps for each location. It is not immediately clear how often such maps should be refreshed, and what methods would prove most reliable and least intrusive.</p><p>Another possible issue is that much of the core Internet infrastructure is redundant. Some alternative routes may be chosen only when the primary route fails or is saturated, though in some cases the switch may occur as a part of load balancing. Thus, some empirical maps may become obsolete in a matter of minutes or hours—although such cases are not very common.</p><p>In the end, although private, individual uses of various despoofing tactics may prove very successful, there are many open questions that need to be answered before we can deploy such techniques on a large scale—and some of the questions are not as much about technical issues.</p></div>
<div class="chapter" title="Chapter&#xA0;18.&#xA0;Watching the Void"><div class="titlepage"><div><div><h1 class="title"><a id="watching_the_void"/>Chapter 18. Watching the Void</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>When looking down the abyss, what does not kill us makes us stronger</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>We have looked at many ways to discover information and intercept data by observing the communications between two systems or by watching the side effects of such communications. The story does not end here, however. Sometimes, by averting our eyes from the target we hope to probe, we can see even more.</p><p>An entire set of methods commonly referred to as “black-hole monitoring” is dedicated to observing and analyzing unwanted or unsolicited traffic that arrives accidentally, erroneously, or in mangled form at a specific destination. These methods most often include simply running a packet dump utility and then painstakingly analyzing and theorizing about every single observance.<a id="IDX-CHP-18-0776" class="indexterm"/></p><p>Although in a perfect world, we should gain nothing by looking for data where we are not supposed to find it, in reality we can use these methods to gather abundant bits of information and invaluable hints as to the condition of a network as a whole. Even though the information is mostly random and we cannot choose who we listen to, we can still benefit from the effort.</p><div class="sect1" title="Direct Observation Tactics"><div class="titlepage"><div><div><h1 class="title"><a id="direct_observation_tactics"/>Direct Observation Tactics</h1></div></div></div><p>One application of black-hole monitoring lies in detecting and analyzing global attack trends. Many black hat hackers in possession of new attack techniques often simply scan large blocks of network addresses to find vulnerable targets that can be compromised and ultimately used for illicit activities (presumably to collect skip hosts<sup>[<a id="CHP-18-FN-1" href="#ftn.CHP-18-FN-1" class="footnote">38</a>]</sup> or to build attack drone networks for automated attacks). We can use black-hole monitoring to alert us to new vulnerabilities being exploited in the wild by simply observing increased standard network scan activity from various sources.<a id="IDX-CHP-18-0779" class="indexterm"/><a id="IDX-CHP-18-0780" class="indexterm"/><a id="IDX-CHP-18-0781" class="indexterm"/><a id="IDX-CHP-18-0777" class="indexterm"/><a id="IDX-CHP-18-0778" class="indexterm"/></p><p>Many network administrators deploy black-hole monitoring. They sometimes combine it with honeypots (in which a fake “lure” system is put out on the network to catch attackers and intercept their tools and identify their techniques<sup>[<a href="apb.html#ftn.CHP-18-BIB-1" class="footnoteref">113</a>]</sup>) to produce an advance warning system that will allow them to be the first to know about impeding breakouts of worms and other malware. (You can also use black-hole traffic to calibrate “noise levels” and detect targeted attacks against your servers more efficiently, without picking up automated, indiscriminate malicious activity.)</p><p>Researchers such as Dug Song and Jose Nazario (Jose most recently in his book <span class="emphasis"><em>Defense and Detection Strategies against Internet Worms</em></span><sup>[<a href="apb.html#ftn.CHP-18-BIB-2" class="footnoteref">114</a>]</sup>) have attempted to analyze black-hole activity during massive outbreaks of network worms. Their goal is to better understand and model the distribution (initial propagation and reinfection) dynamics of the network and to test the efficiency and persistence of the worms’ infection algorithms. Their research will help us to devise future defenses against massive, distributed threats, while providing valuable insight into the state of the network today. Some examples of their findings are shown in <a class="xref" href="ch18.html#windows_worm_propagation_characteristics" title="Figure 18-1. Windows worm propagation characteristics">Figure 18-1</a> through <a class="xref" href="ch18s02.html#worm_persistence_over_time._note_that_th" title="Figure 18-4. Worm persistence over time. Note that there is no trivial spike-falloff pattern for CodeRed and that the model behaves like a biological population model.">Figure 18-4</a>.</p><p><a class="xref" href="ch18.html#windows_worm_propagation_characteristics" title="Figure 18-1. Windows worm propagation characteristics">Figure 18-1</a> shows how a worm propagates during an outbreak. The data is based on the number of observed attack attempts on TCP port 137, a part of the Windows NetBIOS implementation, which is installed by default on all Windows computers and targeted by many types of self-propagating malware. Notice in this figure how, after a week of initial propagation—when both the number of infected sites (sources) and systems attacked on the observed black-hole network were steadily and rapidly increasing—a stabilization period suddenly stretches for over a month with dramatic peaks and valleys. Such a propagation footprint is highly unique to a worm and the network conditions in which it operates; it also reflects the subtleties of the target selection and infection algorithms used by the author.</p><p><a class="xref" href="ch18.html#sqlsnake_worm_target_selection_algorithm" title="Figure 18-2. SQLSnake worm target selection algorithm histogram; note the nonuniform but generally continuous coverage of the address space">Figure 18-2</a> shows a different aspect of the worm propagation algorithm and depicts the properties of the target selection algorithm. In this case, a popular worm that targeted Microsoft SQL servers appears to have fairly continuous coverage of the address space (although addresses with octets between about 200 and 225 are chosen considerably more often, and the worm appears to skip values over 225 altogether).</p><div class="figure"><a id="windows_worm_propagation_characteristics"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject3_d1e10150"/><img src="httpatomoreillycomsourcenostarchimages1138112.png" alt="Windows worm propagation characteristics"/></div></div><p class="title">Figure 18-1. Windows worm propagation characteristics</p></div><div class="figure"><a id="sqlsnake_worm_target_selection_algorithm"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject3_d1e10158"/><img src="httpatomoreillycomsourcenostarchimages1138114.png" alt="SQLSnake worm target selection algorithm histogram; note the nonuniform but generally continuous coverage of the address space"/></div></div><p class="title">Figure 18-2. SQLSnake worm target selection algorithm histogram; note the nonuniform but generally continuous coverage of the address space</p></div><p><a class="xref" href="ch18.html#the_slapper_worm_target_selection_algori" title="Figure 18-3. The Slapper worm target selection algorithm histogram. This shows a far more uniform distribution, but noncontinuous coverage with gaps suggesting that the least significant bits of each of the “random” addresses are constant—perhaps due to a programming glitch.">Figure 18-3</a> shows the same graph for a different network worm, Slapper. This worm targeted Linux systems, exploiting a flaw in a popular OpenSSL encryption library. The algorithm appears to offer considerably more uniform, but much less continuous coverage, with gaping holes across certain values.<a id="IDX-CHP-18-0782" class="indexterm"/></p><div class="figure"><a id="the_slapper_worm_target_selection_algori"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject3_d1e10172"/><img src="httpatomoreillycomsourcenostarchimages1138116.png" alt="The Slapper worm target selection algorithm histogram. This shows a far more uniform distribution, but noncontinuous coverage with gaps suggesting that the least significant bits of each of the “random” addresses are constant—perhaps due to a programming glitch."/></div></div><p class="title">Figure 18-3. The Slapper worm target selection algorithm histogram. This shows a far more uniform distribution, but noncontinuous coverage with gaps suggesting that the least significant bits of each of the “random” addresses are constant—perhaps due to a programming glitch.</p></div><p><a class="xref" href="ch18s02.html#worm_persistence_over_time._note_that_th" title="Figure 18-4. Worm persistence over time. Note that there is no trivial spike-falloff pattern for CodeRed and that the model behaves like a biological population model.">Figure 18-4</a> shows worm persistence patterns over time. For example, some worms appear to die off steadily as systems are patched and disinfected, while others use algorithms that cause sudden and recurring rise and fall patterns (familiar to anyone who has experimented with population or epidemiology models based on natural phenomena).<a id="IDX-CHP-18-0783" class="indexterm"/></p><p>As Jose and his colleagues strive to demonstrate, black-hole monitoring may not be only a routine and perhaps completely needless activity, but also a great way to discover the secret life of all things malicious. Alas, the story does not end there. By observing only the traffic we consider aimed at us, we miss the most interesting bits of data.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-18-FN-1" href="#CHP-18-FN-1" class="para">38</a>] </sup>Skip host is a system used as an intermediate hop for carrying out further attacks or other illicit activity (such as sending spam). This technique makes it more difficult to track the ultimate offender, because their origin is not directly known, and a number of administrators or jurisdictions must cooperate to find them.</p></div></div></div>
<div class="sect1" title="Attack Fallout Traffic Analysis"><div class="titlepage"><div><div><h1 class="title"><a id="attack_fallout_traffic_analysis"/>Attack Fallout Traffic Analysis</h1></div></div></div><p>The other application of black-hole monitoring relies on observing traffic that was never aimed at us in the first place, but which is merely a side effect of other activity.<a id="IDX-CHP-18-0784" class="indexterm"/><a id="IDX-CHP-18-0785" class="indexterm"/><a id="IDX-CHP-18-0786" class="indexterm"/><a id="IDX-CHP-18-0787" class="indexterm"/><a id="IDX-CHP-18-0788" class="indexterm"/><a id="IDX-CHP-18-0789" class="indexterm"/><a id="IDX-CHP-18-0790" class="indexterm"/><a id="IDX-CHP-18-0791" class="indexterm"/><a id="IDX-CHP-18-0792" class="indexterm"/><a id="IDX-CHP-18-0793" class="indexterm"/></p><div class="figure"><a id="worm_persistence_over_time._note_that_th"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject3_d1e10238"/><img src="httpatomoreillycomsourcenostarchimages1138118.png.jpg" alt="Worm persistence over time. Note that there is no trivial spike-falloff pattern for CodeRed and that the model behaves like a biological population model."/></div></div><p class="title">Figure 18-4. Worm persistence over time. Note that there is no trivial spike-falloff pattern for CodeRed and that the model behaves like a biological population model.</p></div><p>Here we can see how a number of common reconnaissance and attack schemes use address spoofing to conceal an attacker’s identity. The assumption is that an administrator will have difficulty differentiating decoy traffic from bogus addresses from the attacker’s actual probes. Although as I’ve shown in previous chapters, this approach does not guarantee the attacker complete anonymity; in order to successfully “despoof” the traffic, an administrator must implement extensive logging and additional measures at the time of the attack. Because these procedures are not always implemented, attackers can often spoof their attacks quite effectively and remain out of the spotlight.</p><p>Whether packets are spoofed or not, the attacked system will in good faith respond to all requests including those allegedly coming from made-up addresses. However, only the responses to packets with a proper source address arrive back at the sender; all other probes generate responses that are scattered all around the Internet, and we can often catch them.</p><p>Although it may seem unlikely that we will receive such a misdirected packet, remember that a considerable number of SYN+ACK, RST+ACK, and RST packets are generated in response to decoy scans or SYN flood attacks. The Internet address space appears vast, with millions of packets typically involved in such attacks, but it is quite likely that over time, some will reach every single network block. Although the likelihood of a single, randomly generated spoofed packet bouncing back to a specific address is only 1 in 4,294,967,296 (1 to 2<sup>32</sup>), assuming that a typical small subnet assigned to a small company or organization usually consists of 256 addresses (class C network or equivalent), this probability is increased to 1 in 16,777,216 (1 to 2<sup>24</sup>). This can be further improved by ruling out address ranges that are known to be reserved for special purposes or which are otherwise not noteworthy and thus excluded in certain types of attacks.</p><p>Because the face of a single SYN packet is about 40 bytes (and compresses well in bulk) and a typical network link available to a casual attacker has a throughput of approximately 10 to 150 kilobytes per IP layer per second (low-end DSL and T1 line, respectively), he can push out 250 to nearly 3,000 packets in this time frame—or 900,000 to circa 10,000,000 packets per hour.<sup>[<a id="CHP-18-FN-2" href="#ftn.CHP-18-FN-2" class="footnote">39</a>]</sup></p><p>For a typical DoS attack to produce any noticeable results and cause major inconvenience to the victim, it usually has to be carried out for several hours or days. (The attacker wants to inconvenience their victim for as long as possible.) As a result, dozens to hundreds of millions of packets are sent, generating a similar number of SYN+ACK or RST+ACK replies.</p><p>Due to this huge amount of traffic, it’s quite reasonable to expect that even a relatively small entity could notice the fallout of a small SYN flood attack as it happens, even if the recipient host drops many attack packets. Furthermore, administrators able to monitor class B equivalent networks (65,356 addresses, usually owned by larger companies, ISPs, research institutions, and so forth) would be able to pick up much smaller events quickly.</p><p>Because all the fallout replies in a spoofed DoS attack include certain details of the messages fabricated by the attacker to trigger those responses in the first place (such as port and sequence numbers, timing information, and so forth), we can use these replies to extract important information about the type and scale of attack. We can use these replies to determine whether a specific service has been targeted, how many systems have been targeted, the bandwidth available to the attacker, and the tool used to perform the attack (by examining source port selection, chosen sequence numbers, and “random” IP patterns<sup>[<a id="CHP-18-FN-3" href="#ftn.CHP-18-FN-3" class="footnote">40</a>]</sup>).</p><p>Finally, by analyzing the sources of these ricochet responses, we might notice that a particular network segment is under attack or be able to identify global “hostility trends,” perhaps to better prepare if a specific industry or business is being targeted. We can also use this information to learn about attacks that are being covered up by the victim or to identify false claims of attacks. (Claims that certain targets are being attacked by cyber-terrorists are sometimes made as a PR stunt to justify financial losses or to push a specific political agenda. Of recent, some experts accused SCO of taking their servers off-line and pretending to be a victim of a coordinated DoS attack to discredit the Linux users community.)</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-18-FN-2" href="#CHP-18-FN-2" class="para">39</a>] </sup>Note that determined, seasoned attackers proficient in Denial of Service attacks often have dozens or hundreds of “zombie” nodes at their command, thus increasing this estimate dramatically.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-18-FN-3" href="#CHP-18-FN-3" class="para">40</a>] </sup>For example, some tools only “spoof” packets from even or odd IP addresses due to coding flaws. Analyses similar to those conducted by Jose Nazario and others typically prove to be as good at pinpointing attack tools as they do at identifying worms.</p></div></div></div>
<div class="sect1" title="Detecting Malformed or Misdirected Data"><div class="titlepage"><div><div><h1 class="title"><a id="detecting_malformed_or_misdirected_data"/>Detecting Malformed or Misdirected Data</h1></div></div></div><p>This application for monitoring black holes relies on monitoring traffic that does not seem to make any sense, but that still appears to reach a specific destination. To better illustrate the problem, allow me this digression.<a id="IDX-CHP-18-0794" class="indexterm"/><a id="IDX-CHP-18-0795" class="indexterm"/><a id="IDX-CHP-18-0796" class="indexterm"/></p><p>In 1999, a group of friends, colleagues in Poland, and I began a humble after-hours project. Our goals were to track down a hard-to-explain set of RST+ACK packets that we had noticed arriving at networks we maintained and to monitor unusual and unsolicited traffic patterns arriving at unused network segments in general. It was great fun, and, as you might imagine, it resulted in a good deal of speculation when we tried to reasonably explain some of the most unusual cases. Our research also enabled us to learn more about the world around us as we encountered some exceedingly bizarre and seemingly inexplicable traffic that, once properly analyzed, provided more insight into the vast conspiraces of our wired world.</p><p>Although formally abandoned, this project ended up in my private “Museum of Broken Packets,”<sup>[<a href="apb.html#ftn.CHP-18-BIB-3" class="footnoteref">115</a>]</sup> a semihumorous web page dedicated to tracking down, documenting, and explaining packets that should never have reached their destination or that should never have looked the way they did. The stated purpose of the museum was as follows:</p><div class="blockquote"><blockquote class="blockquote"><p>The purpose of this museum is to provide a shelter for strange, unwanted, malformed packets—abandoned and doomed freaks of nature—as we, mere mortals, meet them on the twisted paths of our grand journey called life. Our exhibits—or, if you wish, inhabitants—are often just a shadow of what they used to be before they met a hostile, faulty router. Some of them were born deformed in the depth of a broken IP stack implementation. Others were normal packets, just like their friends (you or me), but got lost looking for the ultimate meaning of their existence and arrived where we should never have seen them. In every case, we try to discover the unique history of each packet’s life, and to help you understand how difficult it is to be a sole messenger in the hostile universe of bits and bytes.</p></blockquote></div><p>And this is what the last type of black-hole monitoring boils down to. Although the task can appear pointless at first, it is foolish to assume so. The museum made it possible to passively uncover dark secrets about various proprietary devices and well-protected networks, and running such an experiment elsewhere would undoubtedly result in the same or greater accomplishments.</p><p>Some of the exhibits in my museum include marvels such as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Packets originating from networks with a specific type of web accelerator, router, or firewall; the device appends, strips, or otherwise mangles some of the data. A good example is a flaw in certain Nortel CVX devices that is responsible for the occasional stripping of TCP headers from packets (as discussed in <a class="xref" href="ch11.html" title="Chapter 11. In Recognition of Anomalies">Chapter 11</a>). The uniqueness of this flaw enables us to learn a good deal about a number of remote networks without having to actually go out and probe them.</p></li><li class="listitem"><p>Several line noise exhibits, showing packets containing either utter garbage or data that certainly did not belong to a specific connection. One of the most surprising exhibits is unsolicited traffic containing data that appears to be a dump of .de DNS zone contents (a listing of all domains in Germany). The traffic could not have originated just anywhere, because mere mortals have no rights to obtain such a list. Instead, it must have originated at an authorized party able to obtain and transfer this data and must have been mangled either by the sender or by a device somewhere along the way. Although all cases shed little light on the nature of mishaps on the network, cases such as this one often enrich the observer with unexpected—and often valuable—findings.</p></li></ul></div><p>Other noteworthy exhibits included cases of apparent espionage camouflaged to appear as regular traffic and many other coding or networking hiccups. But enough bragging—if you feel compelled to find out more, visit <a class="ulink" href="http://lcamtuf.coredump.cx/mobp/">http://lcamtuf.coredump.cx/mobp/</a>.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id13"/>Food for Thought</h1></div></div></div><p>Many regard black-hole monitoring as just another way to detect attacks against their systems (and perhaps an expensive way, given the scarcity of public IP space resources). But the real value of this technique is that it makes it possible to not only identify known attacks (something that can be done just as well in many other locations, without wasting IP space), but also detect and analyze subtle patterns that would otherwise be lost below the “noise level” in an extensively used network.</p><p>Naturally, performing this type of black-hole monitoring is not easy and remains expensive. It takes time to learn how to find that needle in the haystack of the usual worm and black hat activity that, in a sufficiently extensive network, usually bears no significance beyond statistical reporting.</p><p>Yet, for the joy of finally finding the needle, it is often worth a try.</p></div></body></html>