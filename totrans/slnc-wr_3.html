<html><head></head><body><div class="part" title="Part&#xA0;III.&#xA0;Out in the Wild"><div class="titlepage"><div><div><h1 class="title"><a id="out_in_the_wild"/>Part III. Out in the Wild</h1></div></div></div><div class="partintro" title="Out in the Wild" id="id2806829"><div/><div class="epigraph"><p><span class="emphasis"><em>Once you are on the Internet, it gets dirty</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div></div></div>
<div class="chapter" title="Chapter&#xA0;9.&#xA0;Foreign Accent"><div class="titlepage"><div><div><h1 class="title"><a id="foreign_accent"/>Chapter 9. Foreign Accent</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Passive fingerprinting: subtle differences in how we behave can help others tell who we are</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>On the Internet, the network of networks, information sent to a remote party is beyond the sender’s control and supervision. Unlike on a local Ethernet, which is usually a safe harbor for packets until a stranger wanders in, once data is out in the wild it is no longer possible to estimate and effectively manage threats that it is likely to face, as no single person can control the data’s path or determine the intentions of all parties involved in communications, let alone determine how they approach security. On such a complex network, the likelihood of a middle party becoming malicious is neither negligible nor easy to assess. In fact, even the person with whom you are establishing legitimate communications may have a hidden agenda or simply be a bit curious.<a id="IDX-CHP-9-0362" class="indexterm"/></p><p>Unsolicited data acquisition attempts, so to speak, are also different when carried out over the Internet for a couple other reasons. Most important, they do not have to be targeted, and they are not limited to a specific segment of physical infrastructure. Because they require so little effort on the part of an attacker, they become a viable route for acquiring potentially interesting data even prior to determining a precise way to profit or otherwise benefit from this knowledge. Too, the line between good and bad becomes even more fuzzy: the attacker can be your best friend. The profitability of general espionage and surveillance for the purposes of marketing reconnaissance and profiling is too tempting for many to resist; the world of service provisioning is not black and white, and flexible ethics is simply a viable business model for many people.</p><p>This part of the book focuses on the threats inherent in the open design of the Internet and on the ability of others to obtain way more information about you than you might expect—and more than would ever be needed in order for them to provide you a service such as an interesting website or an enjoyable network-based game. Once on the Internet, the enemy is no longer a lone madman sitting across the street, watching LEDs on the switch through a high-tech telezoom lens. The exposures covered here make it possible to carry out massive profiling, tracking, information gathering, industrial espionage, network reconnaissance, and preattack analysis—and are far more real than the scenarios described previously.</p><p>You need to understand the threats in order to maintain an informed level of privacy protection or perhaps to deploy effective monitoring whether of your users or of complete strangers, as they approach your systems. Understanding is also the key to maintaining sanity in a world where the line between being concerned about privacy and becoming clinically paranoid is fairly thin.</p><p>I’ll begin with an examination of a set of core network protocols used over the Internet and their privacy implications. Shall we?</p><div class="sect1" title="The Language of the Internet"><div class="titlepage"><div><div><h1 class="title"><a id="the_language_of_the_internet"/>The Language of the Internet</h1></div></div></div><p>The official language of the Internet is called the <span class="emphasis"><em>Internet Protocol</em></span>, and the most popular dialect is labeled version 4. The protocol, specified in RFC793,<sup>[<a href="apb.html#ftn.CHP-9-BIB-1" class="footnoteref">74</a>]</sup> provides a way to implement a standardized method for transmitting data over vast distances and a variety of networks with as little effort as possible. IP packets constitute the third layer in the OSI model discussed previously and consist of a header that contains the information necessary to deliver a portion of data to its ultimate destination—the <span class="emphasis"><em>remote endpoint</em></span>—and a payload constructed of higher-layer information that immediately follows the header data.<a id="IDX-CHP-9-0363" class="indexterm"/><a id="IDX-CHP-9-0364" class="indexterm"/></p><p>The routing information furnished by the sender within the IP packet prior to sending it out consists of the source and destination address and a set of parameters that simplifies the process of data transfer or improves its reliability and performance. When a machine on the local network wants to communicate with a remote party that is not directly reachable over the wire—at least not according to the host’s knowledge—it forwards an IP packet with the ultimate recipient’s destination address, encapsulated in a lower-layer frame addressed to a local machine that is believed to be a gateway to and of the network the sender resides at. The gateway machine is nothing more than a multihomed device—one that has a presence in more than one network, serving as a connection point between them. The gateway is expected to know how to route the packet to the outside world, what to do with the packet, and who should get the data next if there must be more parties involved before the data reaches the recipient.</p><p>Systems involved in routing traffic, from the local gateway through to the destination network, read the information provided on the IP layer to decide how to relay the data farther down its path, based on their knowledge of how to reach certain networks. (In this context, a network is defined as a pool of network addresses residing at a specific location.)</p><div class="sect2" title="Naive Routing"><div class="titlepage"><div><div><h2 class="title"><a id="naive_routing"/>Naive Routing</h2></div></div></div><p>In its basic form, a router uses a fixed routing table with which it distinguishes between a set of local networks (to which it can deliver traffic directly) and the outside world, which is unknown. Thus, all traffic destined for outside the local network must be relayed to a higher-order router that presumably has a better idea of where to deliver the data.<a id="IDX-CHP-9-0365" class="indexterm"/><a id="IDX-CHP-9-0366" class="indexterm"/></p><p><a class="xref" href="ch09.html#a_naive_wide_area_network_routing_scheme" title="Figure 9-1. A naive wide area network routing scheme">Figure 9-1</a> shows an example routing structure. The sender (shown at left) attempts to send a packet to a system whose address belongs to network C, a network that the sender knows nothing about. To facilitate delivery, the guy sends the traffic to the local gateway, hoping that it will know where to look for the recipient. However, this system, router 1, can only reach the sender’s own network and network A, another network that has nothing to do with C. Because the target is not on their local network, the router decides it would be best to just send the packet to a higher-rank WAN router (router 2), which it happens to be able to reach locally.</p><div class="figure"><a id="a_naive_wide_area_network_routing_scheme"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5086"/><img src="httpatomoreillycomsourcenostarchimages1138052.png.jpg" alt="A naive wide area network routing scheme"/></div></div><p class="title">Figure 9-1. A naive wide area network routing scheme</p></div><p>This device also has no immediate connection with network C; it can only directly reach hosts on networks B and D. However, it knows that router 3 is serving the destination address and thus would surely know what to do. Therefore, the packet is forwarded there, and router 3 can now deliver the traffic locally to the ultimate recipient, at which point all can rejoice and celebrate another success.</p></div><div class="sect2" title="Routing in the Real World"><div class="titlepage"><div><div><h2 class="title"><a id="routing_in_the_real_world"/>Routing in the Real World</h2></div></div></div><p>In practice, networks are often highly redundant and do not have a strictly linear architecture. They have a complex treelike structure that makes selecting the optimal and most economical path difficult if we were to use a static configuration. (Never mind the challenge of staying up-to-date with all the infrastructure changes as the network grows.)<a id="IDX-CHP-9-0367" class="indexterm"/><a id="IDX-CHP-9-0368" class="indexterm"/><a id="IDX-CHP-9-0369" class="indexterm"/><a id="IDX-CHP-9-0370" class="indexterm"/></p><p>As such, a more reasonable routing strategy is implemented once the traffic reaches a <span class="emphasis"><em>backbone router</em></span>. Run by a network operator, a backbone router is a dedicated WAN device that binds many networks controlled by a particular provider into a complex being called an <span class="emphasis"><em>autonomous system</em></span>. Back-bone routers are typically equipped with interfaces to other large routers and use an advanced path-discovery algorithm and a sizable “phone book” of network blocks and their whereabouts, controlled dynamically by a Boundary Gateway Protocol, to find the best way to route the data to the destination system, without blindly handing out the job of delivering the traffic to some system in hopes that it will be able to relay it properly.</p></div><div class="sect2" title="The Address Space"><div class="titlepage"><div><div><h2 class="title"><a id="the_address_space"/>The Address Space</h2></div></div></div><p>This process would, of course, be quite impractical if destination networks consisted simply of a set of addresses arbitrarily assigned to devices around the world. A definition of an autonomous system would have to list all the addresses and might easily grow to enormous size. To solve this problem, continuous blocks of address space are assigned to backbone service providers instead; providers later lease smaller blocks to end users or lesser service providers. Routing to the provider’s network is based on a lookup of the destination IP within the address ranges assigned to this entity and then within the network based on additional lookup in more detailed routing tables. An autonomous system can thus be defined as a range of IPv4 addresses (or a set of such ranges), using a netmask method.<a id="IDX-CHP-9-0371" class="indexterm"/></p><p>The single IPv4 address used to uniquely identify an endpoint system in all Internet Protocol communications has a fairly simple structure, consisting of 32 bits, divided for convenience into 4 bytes, a total of 4,294,967,296 possible addresses. The address is traditionally written as four 8-bit values between 0 and 255, with each value separated by dots. For example, 195.117.3.59 corresponds to a 32-bit integer value of 3241036664.</p><p>Continuous IP address blocks are the basis for packet routing. They are defined on top of IPv4 addressing by defining the part of the IP address that is fixed and constant for all systems belonging to an autonomous system, as well as the part of the address that will be set to various values by the owner of a network in order to give computers unique identifiers.</p><p>When defining a network, a set of more significant bits of an IP—theoretically, anywhere from 1 to 31; practically, 8 to 24—is reserved as a <span class="emphasis"><em>network address</em></span>. The fixed part of this address is shared by all addresses belonging to (and presumably routed to) this particular network. The less significant remainder bits can be set at will to assign addresses to systems within the network.</p><p>Historically (per RFC796<sup>[<a href="apb.html#ftn.CHP-9-BIB-2" class="footnoteref">75</a>]</sup>), the size of a network or the number of significant locked bits was a function of the address and could be determined from the network address itself. Based on the most important bits of each address alone, addresses were grouped to constitute class A networks (in which the 8 most significant bits are fixed, yielding more than 16 million possible user addresses), class B networks (in which 16 bits are fixed, yielding more than 65,000 hosts), or class C networks (with 24 bits fixed, and 256 possible hosts). Therefore, if your system has an IP address beginning with the number 1, you can tell that yours is a class A network and that all other systems with this prefix are next to your box.</p><p>Although this seemed handy at the time, the IPv4 address space shrank significantly once the initial implementers (the U.S. Army, Xerox, IBM, and other behemoths) were assigned a handful of class A network addresses in the early days of the Internet, and seemed not to be very keen on giving them up, despite not using even a fraction of the space they got for public infra-structure. Too, once the Internet became commercial, and IP addresses became a resource that users had to pay for, users demanded chunks of address space that would better fit their requirements; some folks only wanted four addresses, whereas others wanted a continuous space of 8,000. Users began to resell or otherwise partition their Internet space.<a id="IDX-CHP-9-0372" class="indexterm"/></p><p>The result is that the current address space is partitioned in bizarre ways, often with tiny bits of address space excluded and rerouted from larger, otherwise continuous blocks, with general disregard for the original partitioning scheme. Each network address is now accompanied by a net-mask specification, because it is no longer possible to tell which network a system is on based merely by the IP itself. The netmask has its bits set at positions that should be fixed in the network address and zeroed for positions that can be freely manipulated within a network.</p><p>As shown in <a class="xref" href="ch09.html#network_addressing_rules" title="Figure 9-2. Network addressing rules">Figure 9-2</a>, by fixing 24 bits on 195.117.3.0 network, we end up with 8 trailing bits that can be changed. This allows us to create 256 addresses between 195.117.3.0 and 195.117.3.255 that belong to this network (albeit some implementations would force the first and the last address to be reserved for special purposes, leaving only 254 possible hosts). With such a relatively simple specification of a network of addresses, it is easy to determine which addresses belong to this network and thus which should be delivered to a system that is its gateway (and which should not).</p><p>Although this addressing scheme may appear confusing and needlessly complicated, it is successful: it lets us associate pools of addresses with specific systems and differentiate between systems with minimum computational effort. The Internet, in all its complexity, usually succeeds in finding a system in a really short period of time, without much maintenance.</p><div class="figure"><a id="network_addressing_rules"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5161"/><img src="httpatomoreillycomsourcenostarchimages1138054.png.jpg" alt="Network addressing rules"/></div></div><p class="title">Figure 9-2. Network addressing rules</p></div></div><div class="sect2" title="Fingerprints on the Envelope"><div class="titlepage"><div><div><h2 class="title"><a id="fingerprints_on_the_envelope"/>Fingerprints on the Envelope</h2></div></div></div><p>We know how the data makes it from point A to point B—but what happens on the way is more interesting than how the path is determined. Let’s then look more closely at what is being exchanged between the routers and our endpoint systems. Although you might think that the actual data payload inside the packets sent over the Internet contains the most interesting information (considering all the private email and bizarre contents being exchanged around the world every second), there is more than meets the eye.<a id="IDX-CHP-9-0373" class="indexterm"/></p><p>The format of IP packets used for routing the data, and the layer four information used to encapsulate the actual application-level data, is defined by the RFCs fairly strictly and with surprisingly little ambiguity. However, even with a competent TCP stack implementation, the underlying information can provide considerably and consistently more value to the recipient than the actual payload data it receives. The disclosure on this level is inadvertent and unexpected, but to learn more about it we need to take a closer look at the design of the underlying protocols.<a id="IDX-CHP-9-0374" class="indexterm"/></p></div></div></div>
<div class="sect1" title="Internet Protocol"><div class="titlepage"><div><div><h1 class="title"><a id="internet_protocol"/>Internet Protocol</h1></div></div></div><p>First, the foundations. The Internet Protocol provides a universal long-distance delivery mechanism on the third layer of the OSI model. It contains a set of parameters that were meant to be interpreted and eventually modified by intermediate systems. The header is shown in <a class="xref" href="ch09s02.html#the_ip_header_structure" title="Figure 9-3. The IP header structure">Figure 9-3</a>.</p><div class="figure"><a id="the_ip_header_structure"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5193"/><img src="httpatomoreillycomsourcenostarchimages1138056.png.jpg" alt="The IP header structure"/></div></div><p class="title">Figure 9-3. The IP header structure</p></div><div class="sect2" title="Protocol Version"><div class="titlepage"><div><div><h2 class="title"><a id="protocol_version"/>Protocol Version</h2></div></div></div><p>This is a four-bit value that is fixed to 4 (0100) in all IPv4 packets. IPv4 is the standard (and, in many cases, the only supported) layer three protocol over the Internet. Attempts to move toward a more advanced implementation, IPv6, have not been particularly successful so far—the author is willing to speculate this is perhaps because the new, extended IP address format is much more difficult for a typical system administrator to memorize.<a id="IDX-CHP-9-0375" class="indexterm"/><a id="IDX-CHP-9-0376" class="indexterm"/><a id="IDX-CHP-9-0377" class="indexterm"/></p></div><div class="sect2" title="The Header Length Field"><div class="titlepage"><div><div><h2 class="title"><a id="the_header_length_field"/>The Header Length Field</h2></div></div></div><p>This is a four-bit value that specifies the total length of the IP header itself, expressed as a count of 4-byte blocks (making it possible to express lengths from 0 to 60 bytes using the 16 values of field). This parameter tells the implementation where to stop parsing the IP header (which may have a variable length due to extra “options” that can be appended at the end of the header and immediately before any higher layer contents). It also makes it possible to skip some of the IP header without having to look at the options or understand them completely, and go directly to the data.</p><p>Because IP options aren’t commonly used for anything other than diagnostics (they do things like make it possible to force a particular packet route and not much more), almost all IP packets seen in the wild are 20 bytes long (meaning this field is set to 5), which is the length of the fixed part of the header. Values less than 20 are, naturally, erroneous, and such a packet is not honored by a sane implementation. (Sanity, however, is not a rule of thumb.)</p></div><div class="sect2" title="The Type of Service Field (Eight Bits)"><div class="titlepage"><div><div><h2 class="title"><a id="the_type_of_service_field_open_parenthes"/>The Type of Service Field (Eight Bits)</h2></div></div></div><p>The significance of this field is usually fairly marginal. It provides an honor-based routing priority description in which the sender is trusted to act in good faith and allowed to specify whether this traffic is of particular importance or otherwise requires special treatment. This value is sometimes used in local installations, where this level of trust can be exercised, but it is often ignored over the open Internet.<a id="IDX-CHP-9-0378" class="indexterm"/><a id="IDX-CHP-9-0379" class="indexterm"/><a id="IDX-CHP-9-0380" class="indexterm"/><a id="IDX-CHP-9-0381" class="indexterm"/><a id="IDX-CHP-9-0382" class="indexterm"/></p><p>This field consists of three segments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The first three bits specify the priority.</p></li><li class="listitem"><p>The next four denote the desired routing method (using abstract concepts such as “high reliability” or “low latency” and letting the router interpret this).</p></li><li class="listitem"><p>The last part, a single bit, is reserved and shall be set to 0 (yeah, right).</p></li></ul></div></div><div class="sect2" title="The Total Packet Length (16 Bits)"><div class="titlepage"><div><div><h2 class="title"><a id="the_total_packet_length_open_parenthesis"/>The Total Packet Length (16 Bits)</h2></div></div></div><p>This 2-byte field specifies the total length of this IP packet, including its payload. Although the highest possible value is 65,535, the maximum size of a packet is often limited to a much smaller value by the restraints of the lower-level protocol. For example, Ethernet has a maximum transmission unit (MTU) of 1,500 bytes; as such, a system connected to Ethernet will not send packets larger than this limit. MTUs greater than approximately 16 to 18 kilobytes are practically unheard of; values between 576 and 1,500 bytes are the most common.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Fun fact: The size limit of an IP packet, N bytes (resulting of the MTU parameter), also imposes the minimum bandwidth overhead limit for any IP traffic: there will always be at least 20 bytes of header added per N-20 bytes to be sent on a higher level.</p></div></div><div class="sect2" title="The Source Address"><div class="titlepage"><div><div><h2 class="title"><a id="the_source_address"/>The Source Address</h2></div></div></div><p>This 32-bit value—an IP address in the format discussed in the previous section—should represent the originating endpoint of the communications. Because the IP packet is prepared by the sender, and there is very little incentive for anyone to check the correctness of this parameter at the perimeter of the originating network, this value alone cannot really be trusted. It does provide a good hint as to who to talk back to, though—and if we have a reason to trust this hint, we can use it to talk back to the sender. The act of forging this value intentionally is commonly referred to as <span class="emphasis"><em>IP spoofing</em></span>.</p></div><div class="sect2" title="The Destination Address"><div class="titlepage"><div><div><h2 class="title"><a id="the_destination_address"/>The Destination Address</h2></div></div></div><p>This 32-bit value specifies the ultimate destination of the traffic. Like all other IP parameters, it is chosen at the sender’s discretion and used by intermediate systems to direct the packet appropriately.<a id="IDX-CHP-9-0383" class="indexterm"/><a id="IDX-CHP-9-0384" class="indexterm"/><a id="IDX-CHP-9-0385" class="indexterm"/><a id="IDX-CHP-9-0386" class="indexterm"/><a id="IDX-CHP-9-0387" class="indexterm"/></p></div><div class="sect2" title="The Fourth Layer Protocol Identifier"><div class="titlepage"><div><div><h2 class="title"><a id="the_fourth_layer_protocol_identifier"/>The Fourth Layer Protocol Identifier</h2></div></div></div><p>This is an eight-bit value that specifies what is carried as a payload of the IP packet—TCP, UDP, ICMP, or more exotic options we will talk about in more detail in a moment.</p></div><div class="sect2" title="Time to Live (TTL)"><div class="titlepage"><div><div><h2 class="title"><a id="time_to_live_open_parenthesis_ttl_close"/>Time to Live (TTL)</h2></div></div></div><p>TTL is an eight-bit “kill counter” for IP traffic. To avoid endless loops when something goes horribly awry with routing tables, the counter is decreased by one every time it passes an interim system, or stays in the transmit queue for a period of time. When the counter reaches zero, the packet is discarded, and the sender may be mercifully notified via an ICMP packet. The TTL value, like all others, is chosen at the sender’s discretion, but, by virtue of its bit width, cannot be more than 255.</p><p>An interesting side effect of the TTL counter is that it can be used to map the route to a remote system: A message with a TTL of 1 expires on the first router it encounters on its way to the specified destination (and the sender receives an ICMP message from the router); a message with TTL set to 2 expires on the next hop, and so on. By sending packets with gradually increasing TTLs and monitoring the origin of ICMP “time-to-live exceeded” responses, it is possible to map the set of routers and other IP-enabled devices en route to the destination. The technique is called <span class="emphasis"><em>traceroute</em></span> and is a common method for diagnosing routing problems and performing preattack analysis.</p><p>The usefulness to the attacker lies in the fact that some effects can be achieved without actually compromising the intended victim: to compromise <a class="ulink" href="http://www.microsoft.com">www.microsoft.com</a> you might instead target the router of the network that hosts this server, or routers of their ISPs, hoping to intercept all its traffic and return forged responses. This would effectively cut off the actual server and, by impersonating it, make it appear to the outside world as if the site at <a class="ulink" href="http://www.microsoft.com">www.microsoft.com</a> had been changed. Naturally, this is just an example.</p></div><div class="sect2" title="Flags and Offset Parameters"><div class="titlepage"><div><div><h2 class="title"><a id="flags_and_offset_parameters"/>Flags and Offset Parameters</h2></div></div></div><p>These 16-bit values control an interesting—and perhaps most flawed—aspect of IP packet routing. These parameters are used whenever a large packet must be forwarded by an intermediate system over a link with an MTU lower than the size of the packet. In such a case, the packet does not “fit” into the medium as is.<a id="IDX-CHP-9-0388" class="indexterm"/><a id="IDX-CHP-9-0389" class="indexterm"/><a id="IDX-CHP-9-0390" class="indexterm"/><a id="IDX-CHP-9-0391" class="indexterm"/><a id="IDX-CHP-9-0392" class="indexterm"/><a id="IDX-CHP-9-0393" class="indexterm"/><a id="IDX-CHP-9-0394" class="indexterm"/><a id="IDX-CHP-9-0395" class="indexterm"/><a id="IDX-CHP-9-0396" class="indexterm"/></p><p>As an arbitrary example, a sender connected to Ethernet can send a packet up to 1,500 bytes in size and often will do so. However, if the first router the packet hits bridges the local LAN with a DSL modem, a problem arises: A common MTU for a DSL link (itself usually a bizarre combination of encapsulations over other protocols) is 1,492. As such, a 1,500-byte packet will simply not fit.</p><p>Given the large variety of links that make the Internet work, this is a serious problem. It is dealt with by splitting <span class="emphasis"><em>(fragmenting)</em></span> the IP packet or, more precisely, its payload into several separate IP packets and adding information that makes it possible for the recipient to reassemble the payload before passing it to higher layers. The result is a new set of packets that fit over this particular link. An offset specified on each fragment indicates how each part of the payload should be inserted when the ultimate recipient attempts to reassemble the original packet.</p><p>All fragments but the last also have a special more fragments (MF) flag set in their headers. When the destination system receives a packet with an MF flag, or a packet with chunk offset set but no MF flag (which indicates the last chunk of a split packet), the destination system knows to allocate a scratch memory area to facilitate the reassembly of the original packet and to wait for all other remaining chunks before processing the packet any further.</p><p><a class="xref" href="ch09s02.html#the_packet_fragmentation_and_reassembly" title="Figure 9-4. The packet fragmentation and reassembly process">Figure 9-4</a> shows the process of fragmentation and reassembly, in which an oversized packet is first split into two chunks and then completely reassembled by the recipient, despite chunks arriving out of order.</p><p>Although this process works, it is somewhat inefficient. It takes time for the systems to fragment and reassemble the traffic, and the trailing chunks often carry little payload—only the few bytes that do not fit over a different type of a link. It is better, of course, for the sender to be able to determine the lowest MTU between their location and the destination (also called path MTU, or PMTU for short) and construct their packets accordingly. Unfortunately, IP does not offer a flexible and clean way to implement this, but this has not stopped researchers from coming up with a clever hack.</p><p>According to this hack, a system that implements PMTU discovery sets a special flag, DF (don’t fragment), on all outgoing traffic. If a router cannot forward a DF packet without fragmenting it, it should drop it instead and send an appropriate ICMP message that reads “fragmentation required, but DF set.” The sender, upon receipt of such a message, can adjust their expectations accordingly, cache the finding, and continue with more appropriate packet sizes.</p><div class="figure"><a id="the_packet_fragmentation_and_reassembly"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5382"/><img src="httpatomoreillycomsourcenostarchimages1138058.png.jpg" alt="The packet fragmentation and reassembly process"/></div></div><p class="title">Figure 9-4. The packet fragmentation and reassembly process</p></div><div class="note" title="Note"><h3 class="title">Note</h3><p>This practice, specified in RFC1191,<sup>[<a href="apb.html#ftn.CHP-9-BIB-3" class="footnoteref">76</a>]</sup> assumes that the single expense of resending the dropped packet is better than the constant performance loss caused by the need for fragmentation. The technique, however, is also quite controversial, because not all devices send proper ICMP notifications and, historically, there was no such requirement. Hence, enabling PMTUD (PMTU discovery) can result in a sender being unable to talk to some sites or in stalled file transfers that are extremely difficult to diagnose.<a id="IDX-CHP-9-0397" class="indexterm"/></p></div></div><div class="sect2" title="Identification Number"><div class="titlepage"><div><div><h2 class="title"><a id="identification_number"/>Identification Number</h2></div></div></div><p>The identification number (ID) is a 16-bit value that differentiates IP packets when fragmentation occurs. Without IP IDs, if two packets are fragmented at once, reassembly would severely mangle, interchange, or otherwise damage fragments of two packets that were fragmented simultaneously.<a id="IDX-CHP-9-0398" class="indexterm"/></p><p>IP IDs uniquely identify several reassembly buffers for different packets. The value used for this purpose is often chosen simply by incrementing a counter with every packet sent; the first packet sent by a system has an IP ID of 0, the second an Internet Protocol of ID 1, and so on.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>On systems with PMTUD enabled, unique IPIDs are not needed, because in theory fragmentation does not occur, and the value is often set to 0 (although, arguably, not particularly wisely, because some fairly popular devices tend to ignore the DF flag).</p></div></div><div class="sect2" title="Checksum"><div class="titlepage"><div><div><h2 class="title"><a id="checksum"/>Checksum</h2></div></div></div><p>The checksum is a 16-bit number that provides a trivial error detection method. The checksum must be recomputed on every hop (because parameters such as TTL change) and is thus designed to use a fast algorithm, which is not particularly reliable. Although in today’s world, “checksum” is a sum only by name (using algorithms such as CRC32 or cryptographically safe shortcut functions), the IP checksum is in fact a sum, or a variant thereof, with a couple of bitwise negations<sup>[<a id="CHP-9-FN-1" href="#ftn.CHP-9-FN-1" class="footnote">15</a>]</sup> thrown in to confuse opponents (and, on a more serious note, to make it less likely for checksum to remain correct when common transmission errors occur).<a id="IDX-CHP-9-0400" class="indexterm"/><a id="IDX-CHP-9-0401" class="indexterm"/><a id="IDX-CHP-9-0399" class="indexterm"/></p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-1" href="#CHP-9-FN-1" class="para">15</a>] </sup>Technically speaking, although it bears no particular importance for the discussion, IP check-sum is based on 16-bit 1’s complement of a sum of 1’s complements of the checksummed data.</p></div></div></div>
<div class="sect1" title="Beyond Internet Protocol"><div class="titlepage"><div><div><h1 class="title"><a id="beyond_internet_protocol"/>Beyond Internet Protocol</h1></div></div></div><p>One consequence of many of the design decisions made when devising IPv4 is the lack of a reasonable reliability guarantee, even if the network itself is behaving reliably. Although IP ID numbers are intended to minimize the risk of reassembly collisions, their relatively small 16-bit size (which allows for 65,536 possible values) permits problems to arise occasionally when two packets with identical IP IDs are reassembled at the same time. Also, IP header checksums are simply insufficient to provide reliable integrity protection; although unlikely, a random change in a packet could still give an identical checksum. Too, if the network actually failed, there is no way to find out what data has gone missing, even if the failure is due to something as straightforward as a brief overload of a single network component.</p><p>Finally, the Internet Protocol does not provide any way to verify the sender of a message, simply trusting that the real sender is the one listed in the IP header. It is left to higher-level protocols to provide some of the integrity and reliability assurance functionality as necessary—and more often than not, this is necessary. As such, higher-level protocols on top of IP are needed.</p><p>TCP, and to a lesser extent, UDP, not only provide much-needed protection for traffic, but also enable the user to specify the recipient (or sender) on a level beyond pointing at a certain system.</p><p>Whereas the IP header simply contains enough information to route traffic between two systems, and not enough to decide to which application the information should be delivered, UDP and TCP take things a step further: they move in the realm of the endpoint system, telling the recipient to which application they should direct incoming data.<a id="IDX-CHP-9-0402" class="indexterm"/><a id="IDX-CHP-9-0403" class="indexterm"/></p></div>
<div class="sect1" title="User Datagram Protocol"><div class="titlepage"><div><div><h1 class="title"><a id="user_datagram_protocol"/>User Datagram Protocol</h1></div></div></div><p>As defined in RFC768,<sup>[<a href="apb.html#ftn.CHP-9-BIB-4" class="footnoteref">77</a>]</sup> UDP provides a minimal superset of IP functionality. UDP adds a mechanism for the local delivery of data, but keeps close to the level of unreliability of the underlying layer (as well as its low overhead). The use of UDP for communications can be likened to a phone service in which words sometimes get swapped or are dropped out of sentences, and there is no reliable caller ID—but the cost of a call is low, and your calls are answered quickly.<a id="IDX-CHP-9-0406" class="indexterm"/><a id="IDX-CHP-9-0407" class="indexterm"/><a id="IDX-CHP-9-0404" class="indexterm"/><a id="IDX-CHP-9-0405" class="indexterm"/></p><p>The UDP header (<a class="xref" href="ch09s04.html#the_udp_header_structure" title="Figure 9-5. The UDP header structure">Figure 9-5</a>) has a minimal set of features and is relatively simple. It introduces a small set of parameters that can be interpreted by the destination system and used to route a packet to a specific application or to verify that packet payload was not mangled down the road.</p><div class="figure"><a id="the_udp_header_structure"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5485"/><img src="httpatomoreillycomsourcenostarchimages1138060.png.jpg" alt="The UDP header structure"/></div></div><p class="title">Figure 9-5. The UDP header structure</p></div><p>UDP is used for single queries, in other situations in which maintaining state information is unnecessary, and when performance and low overhead are more important than reliability. For example, UDP is commonly used for domain name system (DNS) name resolution, trivial network boot and autoconfiguration protocols (BOOTP), streaming media technologies, network file system sharing, and so on.</p><div class="sect2" title="Introduction to Port Addressing"><div class="titlepage"><div><div><h2 class="title"><a id="introduction_to_port_addressing"/>Introduction to Port Addressing</h2></div></div></div><p>UDP introduces the notion of source and destination ports in addition to source and destination addresses, a concept that it shares with TCP (a more advanced layer four protocol that I will cover next). A <span class="emphasis"><em>port</em></span> is a certain 16-bit number, either chosen by an endpoint application willing to send or receive data or assigned to it by the operating system (called an <span class="emphasis"><em>ephemeral port</em></span>).</p><p>A port serves as a means to route data to a specific application or service on a multitasking system so that simultaneous communications can occur between programs. For example, a name server process can decide to listen on port 53 for incoming queries, whereas a system logger facility can listen to traffic addressed to port 514. Ports make it possible for clients to talk to these processes at the same time. Too, when the implementation supports a proper separation of source and destination port pairs, it is possible for two clients using different ephemeral source ports to talk to the same service (say, port 514) at once, without causing major confusion as to which client application should get which response from the remote service.</p><p>In order for the destination system to differentiate between communications addressed to a particular application and deliver them as expected, the sender must specify the destination port number in all their traffic. The sender specifies a different source port for every client application so that once the server replies, the answer is delivered to the correct component.</p><p>In this port addressing scheme, a quadruplet of values—source host, source port, destination host, and destination port—is used to ensure proper traffic separation and session management for simultaneous connections originating or terminating at a specific system. The design means that as many as 65,535<sup>[<a id="CHP-9-FN-2" href="#ftn.CHP-9-FN-2" class="footnote">16</a>]</sup> clients from a single IP address can connect to the outside world and that no more than 65,535 services can listen on a single IP address at any one time; that is, without some clever hacks. (We are not likely to suffer terrible consequences of this limitation any time soon.)</p></div><div class="sect2" title="UDP Header Summary"><div class="titlepage"><div><div><h2 class="title"><a id="udp_header_summary"/>UDP Header Summary</h2></div></div></div><p>The UDP header shown in <a class="xref" href="ch09s04.html#the_udp_header_structure" title="Figure 9-5. The UDP header structure">Figure 9-5</a> earlier follows the IP header and precedes the actual user-space data in UDP packets. It consists of few fields: source and destination ports (16 bits each), packet length, and a 16-bit checksum for the purpose of additional integrity verification.<a id="IDX-CHP-9-0408" class="indexterm"/><a id="IDX-CHP-9-0409" class="indexterm"/></p><p>And now, for something completely different, it’s . . .</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-2" href="#CHP-9-FN-2" class="para">16</a>] </sup>Technically, that’s 65,536; port number 0 should not be used, however. The operating system and its applications may allow this, naturally, and be in violation of the standard.</p></div></div></div>
<div class="sect1" title="Transmission Control Protocol Packets"><div class="titlepage"><div><div><h1 class="title"><a id="transmission_control_protocol_packets"/>Transmission Control Protocol Packets</h1></div></div></div><p>TCP (RFC793<sup>[<a href="apb.html#ftn.CHP-9-BIB-5" class="footnoteref">78</a>]</sup>), the header of which is shown in <a class="xref" href="ch09s05.html#the_tcp_header_structure" title="Figure 9-6. The TCP header structure">Figure 9-6</a>, aims to provide a reliable, stream-based method for establishing a meaningful conversation between two systems. TCP is more suitable than UDP for use with all applications except those that must exchange more than simple, short messages and single shouts.<a id="IDX-CHP-9-0410" class="indexterm"/><a id="IDX-CHP-9-0411" class="indexterm"/></p><p>Although technically implemented using separate IP datagrams traversing the network, the established TCP connection—a virtual channel, from an application’s perspective—allows for a communications mode much like a regular phone conversation. Unlike with UDP traffic, when using TCP you can be sure that the recipient always receives the data as sent (or that, if error recovery is not possible, the conversation is dropped entirely). Under normal conditions, you can also be sure of the caller’s identity, but this convenience comes at a higher price and with lower performance.</p><div class="figure"><a id="the_tcp_header_structure"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5557"/><img src="httpatomoreillycomsourcenostarchimages1138062.png.jpg" alt="The TCP header structure"/></div></div><p class="title">Figure 9-6. The TCP header structure</p></div><p>In TCP, two endpoints first initiate a connection using a so-called three-way handshake algorithm. Using special, as a general rule, empty packets (ones with only headers and no actual data payload), the parties agree on the intent, confirm each other’s identity, and agree on initial sequence and acknowledgment numbers. These numbers (a set of 32-bit values) ensure reliable and seamless transmission because they are increased as the data is sent. This, in turn, allows the recipient to queue incoming packets in the correct order and to determine whether any portion of the data is missing.</p><div class="sect2" title="Control Flags: The TCP Handshake"><div class="titlepage"><div><div><h2 class="title"><a id="control_flags_colon_the_tcp_handshake"/>Control Flags: The TCP Handshake</h2></div></div></div><p>A TCP session begins when a remote system expresses a desire to connect to a specific port on a destination machine. The remote system sends the destination an empty packet with a SYN flag (meaning a designated bit is set in the header) and an initial sequence number set in the headers. Following receipt of this packet, any response to a packet must quote the sequence number in order to be honored. If the destination machine does not send the correct response in a reasonable time frame, the packet is sent again, until either the delivery succeeds or the sender concludes that enough time has passed and drops the connection.<a id="IDX-CHP-9-0412" class="indexterm"/><a id="IDX-CHP-9-0413" class="indexterm"/><a id="IDX-CHP-9-0414" class="indexterm"/><a id="IDX-CHP-9-0415" class="indexterm"/><a id="IDX-CHP-9-0416" class="indexterm"/><a id="IDX-CHP-9-0417" class="indexterm"/><a id="IDX-CHP-9-0418" class="indexterm"/></p><p>The sequence number ensures that the response to the packet is from the actual recipient, not from an outsider who knows that a communication will be occurring and who intends to capture it. The sequence number also ensures that the response is not a lost, misguided packet from a previous session that finally made its way home, but a response to this particular request from the sender. (With 32-bit numbers and 4,294,967,296 possible values, the likelihood of a collision is considerably less than with 16 bits used in IP IDs, making both an accidental mishap and a successful guess by an outsider quite unlikely.)</p><p>The recipient is expected to respond to a SYN request with a similar packet addressed to the sender and source port they used. This packet should have an RST flag set (again, another bit in the headers) to indicate that they are not willing to establish a session. (No program is ready to answer connections on this endpoint.) This packet must also quote the original sequence number along with the response. Alternatively, in the unusual case that the recipient is actually willing to establish a connection and chat with the stranger, they should reply with a similarly constructed response, but with both SYN and ACK flags set, indicating acceptance of the request. They should also include the sequence number they expect from now on in all responses pertaining to this session.</p><p>As the last part of the handshake, the sender exchanges a single ACK packet just to make sure that both parties know each other’s sequence and acknowledgment numbers exchanged earlier, and that they are on the same page in regard to the transaction. Assuming that their communication has reached this point, both endpoints can assume, with reasonable certainty, that both sender and receiver are who they claim to be. Why? Because each can observe the traffic addressed to their address. Otherwise, if one endpoint were just spoofing its IP address to establish a bogus connection in the name of somebody else, it would have no idea what number to include in its response to the other party. (And the other party would be quite surprised to find someone attempting to send them unsolicited SYN+ACK or ACK packets.)</p><p>This handshake protocol eliminates the chance of an outsider simply spoofing the traffic, but does not eliminate the possibility of a hostile privileged party on a legitimate path between the systems (though such an incident is unlikely, compared with the blind spoofing scenario).</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Needless to say, although the problem of using initial sequence numbers that are difficult to predict was not considered a problem, and many systems used designs such as a simple incremental generator, the possibility of either blindly establishing a session by spoofing a TCP handshake from a particular source or injecting data into alreadyestablished connections by an outsider has become a bit problematic with time.<sup>[<a id="CHP-9-FN-3" href="#ftn.CHP-9-FN-3" class="footnote">17</a>]</sup> Careful selection of TCP initial sequence numbers so that a bystander cannot predict what your system is going to reply with in response to a forthcoming packet is now considered a necessity, and several approaches have been devised to address this issue.<sup>[<a href="apb.html#ftn.CHP-9-BIB-6" class="footnoteref">79</a>]</sup></p></div><p>Once a handshake is completed, the parties can exchange data, mutually acknowledging their sequence numbers each time; packets on which a mismatch of sequence numbers larger than an allowed “window” occurs are simply ignored. These numbers are from now on also steadily increased to reflect the amount of data sent up to that point, which makes it possible to process packets in the correct order at the destination, even if they arrive out of order. To ensure reliability, if a portion of data is not acknowledged within a reasonable time frame, a retransmission of the packet (or packets) must occur.</p><p>The termination of a session occurs when a FIN packet with a proper acknowledgment number is received by any of the parties. If, at any point, one of the systems gets quite agitated and wants to abruptly terminate the session (perhaps because, from their perspective, there is nothing to talk about, the session timed out, or their party severely violated the convention), an RST packet is sent.</p><p>A successful legitimate TCP handshake is shown in <a class="xref" href="ch09s05.html#a_complete_tcp_handshake_and_a_failure_o" title="Figure 9-7. A complete TCP handshake and a failure of a common spoofing attempt">Figure 9-7</a> (on the left). A failure of a typical IP spoofing attack intended to create a session in the name of an innocent bystander who does not intend to exchange any data with the target is shown on the right. The attacker cannot see or predict the response sent to the system it tries to act on behalf of and thus cannot complete the handshake, let alone perform any actual data exchange within the TCP session.</p><p>As suggested, TCP provides reasonable protection against network reliability problems and is more suitable for ordered session-based communications. But the price is extra overhead that comes from the need to complete a handshake, as well as for both endpoints to maintain control information for the connection. Maintenance of this state exacts a heavy toll because it becomes necessary for every connection to track sequence numbers and current status of the stream (handshake stages, data exchange stage, closing stages), keep a copy of all sent but not yet acknowledged data in case it needs to be re-sent, and so on.</p><p>Because of their memory and performance costs, TCP stack implemen-tations are a common denial-of-service attack vector.</p><div class="figure"><a id="a_complete_tcp_handshake_and_a_failure_o"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5630"/><img src="httpatomoreillycomsourcenostarchimages1138064.png.jpg" alt="A complete TCP handshake and a failure of a common spoofing attempt"/></div></div><p class="title">Figure 9-7. A complete TCP handshake and a failure of a common spoofing attempt</p></div></div><div class="sect2" title="Other TCP Header Parameters"><div class="titlepage"><div><div><h2 class="title"><a id="other_tcp_header_parameters"/>Other TCP Header Parameters</h2></div></div></div><p>Other TCP header parameters also control important aspects of packet interpretation and delivery. These will come in handy later when we attempt to gain information about the sender by just looking at the packet data they provide. <a class="xref" href="ch09s05.html#the_tcp_header_structure" title="Figure 9-6. The TCP header structure">Figure 9-6</a>, shown earlier in this chapter, provides a complete listing of the TCP fields.<a id="IDX-CHP-9-0419" class="indexterm"/><a id="IDX-CHP-9-0420" class="indexterm"/><a id="IDX-CHP-9-0421" class="indexterm"/><a id="IDX-CHP-9-0422" class="indexterm"/><a id="IDX-CHP-9-0423" class="indexterm"/><a id="IDX-CHP-9-0424" class="indexterm"/><a id="IDX-CHP-9-0425" class="indexterm"/><a id="IDX-CHP-9-0426" class="indexterm"/><a id="IDX-CHP-9-0427" class="indexterm"/><a id="IDX-CHP-9-0428" class="indexterm"/></p><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>Source and destination ports</strong></span></span></dt><dd><p>These 16-bit values identify the logical origin and endpoint on source and destination machines. They are similar to the source and destination port parameters used in UDP, although the UDP and TCP port space is kept separate on the system level—meaning one application can listen on UDP port 1234, and another application can listen on the same port number in the TCP space. The traffic is directed according to the protocol specification in the IP headers.</p></dd><dt><span class="term"><span class="strong"><strong>Sequence and acknowledgment numbers</strong></span></span></dt><dd><p>These 32-bit values ensure session integrity. A sequence number is the value the sender expects to have echoed back. An acknowledgment number is the value echoed back to the sender and will only be meaningful if the ACK flag is set.</p></dd><dt><span class="term"><span class="strong"><strong>Data offset (not to be confused with IP fragment offset parameter)</strong></span></span></dt><dd><p>The information in this field indicates where in the packet the header ends and the payload starts. As with IP headers, the length of the TCP header can vary if certain variable-length settings were appended at its end. This information makes it easy to just skip to the actual data, without having to go through all the header information.</p></dd><dt><span class="term"><span class="strong"><strong>Flags</strong></span></span></dt><dd><p>These eight-bit values define special properties of a packet. Each of the designated bits of this field represents a unique flag and can be turned on or off independently; as such, TCP flags can be recombined arbitrarily. <span class="emphasis"><em>Primary flags</em></span> (SYN, ACK, RST, and FIN) define the way the packet should be interpreted in terms of a TCP session, as discussed earlier; <span class="emphasis"><em>secondary flags</em></span> control certain aspects of payload delivery and other extended features, such as congestion notification, but are not used to change the state of a connection itself.</p></dd></dl></div><div class="note" title="Note"><h3 class="title">Note</h3><p>Although flags can be combined as you please, many possible combinations are simply illegal or bogus. (For example, SYN+RST has no meaning and is, formally speaking, not allowed.) Only some combinations are meaningful for the handshake and normal data processing. Various systems respond in different ways to illegal flag combinations, and so sending bogus packets with unusual flags is a popular active operating system detection mechanism.</p></div><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>Window size</strong></span></span></dt><dd><p>This 16-bit value controls the maximum amount of data that can be sent without waiting for an acknowledgment packet. A higher value allows more data to be sent at once, without having to wait for an acknowledgment receipt, but can penalize performance if a portion of the data is lost in transfer or is not acknowledged and has to be resent.</p></dd><dt><span class="term"><span class="strong"><strong>Checksum</strong></span></span></dt><dd><p>This trivial 16-bit method protects the integrity of the layer four data, similar to the packet checksumming mechanism used in UDP and IP headers.</p></dd><dt><span class="term"><span class="strong"><strong>Urgent pointer</strong></span></span></dt><dd><p>This field is interpreted only by the recipient when one of the secondary flags, URG, is set in a packet. If URG is not set, the value specified in this region of the header is simply disregarded. This flag indicates that the sender is asking the recipient to relay a certain message to the application processing the traffic, presumably due to an “urgent” situation, so that the packet is inserted in the logical stream at a position earlier than it would otherwise belong to; the exact offset is controlled by the urgent pointer value. This mechanism is seldom used in normal communications.</p></dd></dl></div></div><div class="sect2" title="TCP Options"><div class="titlepage"><div><div><h2 class="title"><a id="tcp_options"/>TCP Options</h2></div></div></div><p>The variable-length options block at the end of the header can specify additional settings or parameters for the packet. In some cases, it will be empty (zero length), but it is more commonly used to implement additional extensions for the protocol that were designed later on, without disrupting old implementations that cannot understand them. The options block is designed so that systems that do not recognize a specific option can safely ignore it. The most popular options include the following.<a id="IDX-CHP-9-0429" class="indexterm"/><a id="IDX-CHP-9-0430" class="indexterm"/><a id="IDX-CHP-9-0431" class="indexterm"/><a id="IDX-CHP-9-0432" class="indexterm"/><a id="IDX-CHP-9-0433" class="indexterm"/></p><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>Maximum Segment Size (MSS)</strong></span></span></dt><dd><p>This 16-bit value equals the maximum transfer unit on the sender’s network, minus the size of lower-layer headers. It represents the maximum packet length that can be sent back to the recipient without causing fragmentation en route. The sender uses the MSS setting to ensure optimal performance whenever the recipient returns large portions of data that would otherwise require fragmentation and associated bandwidth overhead. Unfortunately, the MSS option is set by the endpoint system according to its best knowledge of the size of the packets their immediate network neighborhood can handle; it does nothing to avoid a common problem of midway fragmentation that occurs on intermediate systems (and hence the need to implement PMTU discovery on IP level, as discussed previously).</p></dd><dt><span class="term"><span class="strong"><strong>Window scaling</strong></span></span></dt><dd><p>This eight-bit value described in RFC1232<sup>[<a href="apb.html#ftn.CHP-9-BIB-7" class="footnoteref">80</a>]</sup> extends the range of the window size field originally specified in the TCP header. With experience we have seen that acknowledging every 64 kilobytes of data (the maximum value expressed by the 16-bit window size parameter) can create a performance bottleneck when transferring large amounts of data, such as multimedia files, over high-bandwidth but high-latency links. Window scaling is a method to extend window size to allow more data to be sent without waiting for an acknowledgment. This speeds up data transfer but can also require more data to be retransmitted when a single packet is missing.</p></dd><dt><span class="term"><span class="strong"><strong>Selective acknowledgment options (RFC2018<sup>[<a href="apb.html#ftn.CHP-9-BIB-8" class="footnoteref">81</a>]</sup>)</strong></span></span></dt><dd><p>When using larger window sizes, losing a single packet requires retransmitting the entire group of data not yet acknowledged, a terrible waste of bandwidth. To prevent this, a mechanism for selective acknowledgment of chunks of data was devised. Endpoints first declare their ability and willingness to implement this functionality by specifying a Selective ACK Permitted option and then, eventually, acknowledge noncontinuous blocks of data using the actual Selective Acknowledgment option in the headers. Implementing this technique can significantly boost performance, but at the cost of certain memory and data processing overhead.</p></dd><dt><span class="term"><span class="strong"><strong>The time-stamp option (two 32-bit values)</strong></span></span></dt><dd><p>This is another high-performance extension suggested in RFC1232. This mechanism for sending and echoing back time stamps (which are typically chosen to correspond to system time or uptime in one way or another) provides a method for each endpoint to estimate round-trip times for the traffic. The main advantage of this option is that the sender can measure the typical time a packet needs to reach its destination and proceed with a TCP retransmission sooner if there is no response. An additional application of the time-stamp option is preventing sequence number collisions (PAWS, Protection Against Wrapped Sequence [Numbers]), for example, when a long-gone packet makes its way to the destination after several gigabytes of data have been exchanged and after the sequence number counter has wrapped around.</p></dd><dt><span class="term"><span class="strong"><strong>EOL</strong></span></span></dt><dd><p>This option should be interpreted as the end of options; it tells the recipient not to process any trailing data as a part of the header. Because the TCP header size is defined in units longer than a single byte, some unused space can remain after placing all relevant options before the beginning of the data, but before the payload data begins (which is only possible on a full four-byte boundary). The EOL option can be used to prevent the recipient from attempting to analyze this data.</p></dd><dt><span class="term"><span class="strong"><strong>The NOP option</strong></span></span></dt><dd><p>This option means “do nothing,” and is quite simply ignored by the recipient. The sender may and should use NOPs in a packet to pad it to ensure proper alignment of some multibyte options (which must be aligned due to performance and architecture constraints on some processors<sup>[<a id="CHP-9-FN-4" href="#ftn.CHP-9-FN-4" class="footnote">18</a>]</sup>).</p></dd><dt><span class="term"><span class="strong"><strong>T/TCP (Transactional TCP)</strong></span></span></dt><dd><p>This esoteric extension provides support for separate virtual sessions (transactions) within an established TCP session. This makes it possible to avoid the overhead caused by the need to complete a handshake every time you want to perform a specific operation with one-shot services—an approach that is more common if an application wants to process a number of separate transactions with a server. This extension is rarely used, and it is most useful for certain database systems (see RFC1644<sup>[<a href="apb.html#ftn.CHP-9-BIB-9" class="footnoteref">82</a>]</sup>).</p></dd></dl></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-3" href="#CHP-9-FN-3" class="para">17</a>] </sup>Kevin Mitnick, one of the most famous and controversial black hat hackers, compromised Tsutomu Shimomura’s computer by impersonating one of their trusted workstations using TCP spoofing—an act that quite upset Mr. Tsutomu and, according to most accounts, did not really help Kevin in the long run.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-4" href="#CHP-9-FN-4" class="para">18</a>] </sup>“Must” as in “are required to be in order to ensure proper handling.” Some processors have significant performance penalties when accessing multibyte data structures that are not aligned to 32 or 64 bits; others simply require them to be aligned this way or else cause a fatal exception (execution trap) and refuse to perform an operation. Naturally, a naughty sender can purposefully place misaligned data in the buffer and hope that recipient’s system will go down in flames upon receiving such a packet. Of course, a sane operating system checks for this first or attempts to copy the option data to a properly aligned region before processing it. The sanity of a system need not to be taken for granted, though.</p></div></div></div>
<div class="sect1" title="Internet Control Message Protocol Packets"><div class="titlepage"><div><div><h1 class="title"><a id="internet_control_message_protocol_packet"/>Internet Control Message Protocol Packets</h1></div></div></div><p>ICMP packets (see RFC792<sup>[<a href="apb.html#ftn.CHP-9-BIB-10" class="footnoteref">83</a>]</sup>) are used to send diagnostic information and notifications for other protocol types. Logically considered part of layer three, ICMP packets are carried as a payload of IP packets and, as such, are no different from the layer four payload. ICMP does not carry any new user-space data between endpoints and provides a trivial signaling method for IP instead. <a class="xref" href="ch09s06.html#the_icmp_header_structure" title="Figure 9-8. The ICMP header structure">Figure 9-8</a> shows the ICMP header structure.<a id="IDX-CHP-9-0434" class="indexterm"/><a id="IDX-CHP-9-0435" class="indexterm"/><a id="IDX-CHP-9-0436" class="indexterm"/><a id="IDX-CHP-9-0437" class="indexterm"/><a id="IDX-CHP-9-0438" class="indexterm"/><a id="IDX-CHP-9-0439" class="indexterm"/></p><div class="figure"><a id="the_icmp_header_structure"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e5875"/><img src="httpatomoreillycomsourcenostarchimages1138066.png.jpg" alt="The ICMP header structure"/></div></div><p class="title">Figure 9-8. The ICMP header structure</p></div><p>A variety of messages are sent using ICMP in response to TCP or UDP traffic, usually indicating that a particular packet cannot be delivered, expired in transfer, or was rejected for some reason. Several types of ICMP can be sent spontaneously, such as router advertisements, echo requests (ping), and so on.</p><p>As with UDP packets, the ICMP header is simple. It consists of the following fields.</p><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>Message type</strong></span></span></dt><dd><p>This eight-bit field lists a general category of the event that caused this packet to be sent (such as “destination unreachable”). This field can also carry a stand-alone message, though that use is infrequent.</p></dd><dt><span class="term"><span class="strong"><strong>Message code</strong></span></span></dt><dd><p>This eight-bit value describes the exact problem, if applicable. It depends on the message type and might describe the condition in more detail (“network unreachable,” “host unreachable,” “port unreachable,” “communication administratively prohibited”). The distinction between the level of detail that should be included in the message type field versus what should be left to the message code is unclear.<a id="IDX-CHP-9-0440" class="indexterm"/></p></dd><dt><span class="term"><span class="strong"><strong>A checksum of the packet</strong></span></span></dt><dd><p>This field verifies that the packet was not damaged (as with UDP and TCP).</p></dd></dl></div><p>The header of an ICMP packet is fairly simple and itself does not provide enough information to successfully troubleshoot the issue it attempts to report on or to identify what kind of traffic generated this message. This information is conveyed in the packet payload instead and immediately follows the header of a packet.</p><p>Although the payload of an ICMP packet depends on the message, it typically quotes the beginning of the packet that triggered the response. This makes it possible for the recipient to determine the communications to which the message applies and which application should be notified of the problem. It can also be used to ensure that the sender of the ICMP packet is actually somewhere on the legitimate network route between the two machines, rather than outside them. Otherwise, the sender would not be able to see the actual data being exchanged. (In particular, they would not be able to determine the exact sequence number in TCP packets.) This prevents malicious bystanders from sending bogus messages announcing connectivity problems and forcing one of the endpoints to drop a connection—or at least in theory. Naturally, it can be quite difficult to tell the good from the bad since some systems are notorious for mangling or misquoting the original data.</p></div>
<div class="sect1" title="Enter Passive Fingerprinting"><div class="titlepage"><div><div><h1 class="title"><a id="enter_passive_fingerprinting"/>Enter Passive Fingerprinting</h1></div></div></div><p>How does the design of this protocol relate to user privacy? The answer is a bit bizarre: although the design of IP, TCP, UDP, and ICMP packets is generally fairly strict, and the information transmitted in these headers is not particularly verbose, differences in the way various operating systems add information to these packets makes it possible to tell not only the type of operating system in use but even the specific version of an instance of a machine. The differences are particularly evident when dealing with traffic that is not clearly and appropriately discussed in the specification or that is not analyzed during normal quality assurance routines (say, an incoming packets with an illegal combination of flags such as SYN+RST).<a id="IDX-CHP-9-0441" class="indexterm"/></p><p>Intensive research into differentiating systems by stress-testing their implementations has shown that it is safe to conclude that no two IP suite implementations in operating systems are the same. It is often possible to use sophisticated analysis to distinguish between the same system running on slightly different platforms or between slightly different versions of a system. Active analysis tools such as Fyodor’s NMAP, a TCP/UDP fingerprinter and port scanner, and Ofir Arkin’s Xprobe, an ICMP fingerprinter, exploit the flaws or oddities in every system and identify operating system genre and version by sending various types of malformed or unusual packets and then measuring and analyzing the responses they trigger.</p><div class="sect2" title="Examining IP Packets: The Early Days"><div class="titlepage"><div><div><h2 class="title"><a id="examining_ip_packets_colon_the_early_day"/>Examining IP Packets: The Early Days</h2></div></div></div><p>But the techniques of system fingerprinting do not stop here. In fact, poking the remote system by sending suspicious and easily detectable data is perhaps the least subtle way to approach this problem.<a id="IDX-CHP-9-0442" class="indexterm"/></p><p>In early 2000, two folks at Subterrain Security Group, identified only by the nicknames <span class="emphasis"><em>bind</em></span> and <span class="emphasis"><em>aempirei</em></span>, demonstrated that it is often possible to get information about a distant entity on a network without conducting any intrusive communications with the remote party or, for that matter, without initiating any communications at all. (Their code and findings were first presented at DefCON 8, a slightly overrated hacker trade show of sorts, back in 2000.) Their technique, today called <span class="emphasis"><em>passive fingerprinting</em></span>, involves passively (duh) observing casual legitimate traffic originating from a remote system. Although the metrics this technique uses are much more subtle and limited than those deployed by Fyodor and his predecessors, a good dose of research (to which I am proud to have made several contributions) has provided enough observations to achieve a fairly amazing level of precision.</p><p>To better understand what can be told from a single packet received over the network, let’s take a look at the metrics upon which we can base passive fingerprinting and examine what they can tell us about the other party. This exploration is based on dissecting the most popular type of traffic on the Internet—a legitimate TCP packet in IP wrapping.</p></div><div class="sect2" title="Initial Time to Live (IP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="initial_time_to_live_open_parenthesis_ip"/>Initial Time to Live (IP Layer)</h2></div></div></div><p>Recall that the TTL field controls the number of systems through which a packet can pass before being discarded as undeliverable. The packet’s TTL value is decreased each time it passes a router, until TTL reaches zero, at which point the packet is discarded.<a id="IDX-CHP-9-0445" class="indexterm"/><a id="IDX-CHP-9-0446" class="indexterm"/><a id="IDX-CHP-9-0443" class="indexterm"/><a id="IDX-CHP-9-0444" class="indexterm"/></p><p>Because there is no strict requirement as to how this field should be set by the sender, many IP stack developers just roll the dice when determining the default for their pet system. Although a passive bystander cannot determine the packet’s exact initial value without additional tests (because the packet would have surely crossed several routers before being observed), they know that its initial value must have been higher than the actual observed state. Too, the average distance to a remote computer on the Internet usually does not exceed 15 hops, and it is unusual for two systems to be more than 30 hops apart. As such, you can safely assume that the original value lies somewhere between the observed TTL and the observed TTL + 30 (but is less than 256, of course).</p><p>Because we know the initial values used by popular operating systems, we can hone in on the operating system genre the sender is likely running. (Linux and BSD-derived systems usually stick with 64; Windows developers use 128, and some true Unix descendants use 255.) Then, once we determine the operating system that sent the packet, based on this and other factors, we might also be able to determine how far the sender is from the observation point by subtracting the observed TTL from the value known to be used initially. By correlating this value with the actual previously observed or otherwise known distance to his network, we might then be able to draw some conclusions about the organization of the sender’s internal network.</p></div><div class="sect2" title="The Don’t Fragment Flag (IP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="the_donat_fragment_flag_open_parenthesis"/>The Don’t Fragment Flag (IP Layer)</h2></div></div></div><p>The DF flag says, “If this packet does not fit over a specific network link, don’t fragment it; just discard it.” By observing whether this flag is set, we can determine whether the system uses the PMTUD mechanism described previously, which gives us yet another hint as to the operating system in use. This also distinguishes between two sizable groups of systems: only newer IP implementations use this technique, and all others have no interest in enabling this flag in packets they send out.</p></div><div class="sect2" title="The IP ID Number (IP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="the_ip_id_number_open_parenthesis_ip_lay"/>The IP ID Number (IP Layer)</h2></div></div></div><p>As mentioned earlier (in the discussion of the shortcomings of packet fragmentation), certain PMTUD-enabled systems set the IP ID number to zero on some (or all) outgoing traffic, because they assume that the traffic will not be fragmented and because of security concerns about displaying IP ID numbers (as you’ll see in <a class="xref" href="ch13.html" title="Chapter 13. Smoke and Mirrors">Chapter 13</a>). Consequently, we can identify those systems by examining whether incoming packets have the IP ID number set to zero.<a id="IDX-CHP-9-0447" class="indexterm"/><a id="IDX-CHP-9-0448" class="indexterm"/></p><p>However, there is a catch. Although some PMTUD-enabled operating systems always set the IP ID to zero, some other systems can also set IP IDs to zero at some point, simply because there aren’t that many IP ID possibilities to choose from. In other words, if you see a packet with an IP ID that is nonzero, it is safe to assume this is not a system that uses zero values for all outgoing communications. However, if you see a zero value in a packet, you might be seeing a particular species of PMTUD-enabled system, but you could also be seeing a “regular” system that has simply chosen zero for this packet, by chance.</p><p>Although the probability of this occurring is low, it is not quite negligible either. You might either want to take zero IP ID cases with a grain of salt (and only use nonzero IP ID observations to narrow down the set of possible operating systems) or to conduct several observations for the same source to confirm that zero values are always used.</p></div><div class="sect2" title="Type of Service (IP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="type_of_service_open_parenthesis_ip_laye"/>Type of Service (IP Layer)</h2></div></div></div><p>By design, this field should be chosen to correspond to the priority and type of the traffic in order to give interim systems a hint as to how to handle the packet, but it almost never is. Most operating systems set this field to an arbitrary fixed value because developers can set the value as they want without, in practice, affecting the operations of TCP networking. Depending on the developer’s ego, they may merely default this parameter to zero or consider it appropriate to tag all communications originating from their system as “low latency,” “high reliability,” or some other setting using a combination of bits in this field.<sup>[<a id="CHP-9-FN-5" href="#ftn.CHP-9-FN-5" class="footnote">19</a>]</sup></p><p>This should give us an advantage—by knowing the default values for particular systems, we can once again narrow down the number of possible systems the sender might be using. To add to the confusion, however, the value of this field is sometimes changed for all outgoing traffic by certain naughty DSL operators and other ISPs. Their hope is that some remote routers on the other side of the globe will fall for the trick, trust that their traffic, tagged as “high priority,” deserves expedited handling, and prioritize it over other connections, thus providing this ISP’s clients with faster browsing (doubtfully so).</p><p>As is the case with operating systems, the ISP’s choice of Type of Service parameters is rather arbitrary. (For example, one Swedish provider uses a fairly unique and interesting combination of priority bits set to a value of 3 and uses Type of Service bits set to “high throughput.”) This practice, in turn, makes it quite easy to detect traffic originating from particular ISPs by spotting their unique selection of Type of Service bits, without the need to perform active analysis such as WHOIS Registry lookups for the source IP.</p></div><div class="sect2" title="Nonzero Unused and Must Be Zero Fields (IP and TCP Layers)"><div class="titlepage"><div><div><h2 class="title"><a id="nonzero_unused_and_must_be_zero_fields_o"/>Nonzero Unused and Must Be Zero Fields (IP and TCP Layers)</h2></div></div></div><p>The specification for IP and TCP calls for a number of fields to be reserved for future use. All current systems should set these fields to zero so that a special meaning can be assigned to nonzero values at these positions in a packet in the future.<a id="IDX-CHP-9-0449" class="indexterm"/><a id="IDX-CHP-9-0450" class="indexterm"/><a id="IDX-CHP-9-0451" class="indexterm"/></p><p>Needless to say, these are not zeroed in some implementations prior to sending, as they ought to be. This problem is not likely to be caught in the quality assurance stage because it causes no noticeable problems—other systems assume it is better safe than sorry and do not reject packets just because of this nuisance—and as such, this flaw can persist for ages (perhaps until those bits are actually used as a part of some TCP extension, causing it to fail spectacularly while talking to those broken systems). Once again, the ability to examine those values is a precious source of information that can lead us to a more accurate identification of the sender operating system.</p></div><div class="sect2" title="Source Port (TCP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="source_port_open_parenthesis_tcp_layer_c"/>Source Port (TCP Layer)</h2></div></div></div><p>The source port identifies the party to a connection on the sender’s side. Each system has a different policy for assigning so-called ephemeral (originating) ports for outgoing connections, and by examining the observed port number, it is often possible to determine the source operating system. Moreover, systems that perform masquerading commonly use a fairly specific range of ports for this purpose. (Masquerading, or many-to-one network address translation, involves rewriting outgoing traffic from a private network so that all connections appear to originate from the masquerading system and all responses are translated back and delivered to the actual sender when received by the system.)</p><p>Masquerading is commonly used by both corporate and home networks in order to preserve address space. The internal network can use a large pool of addresses that, technically speaking, are not assigned to them and that are not routed there (or anywhere else) from the Internet. However, systems using those addresses can still access the Internet by forwarding their outgoing connections through an agent box that uses its own, legitimate public address to reach the remote system in the name of the initiator. This approach also protects internal systems, making it impossible for an outsider to initiate a direct unsolicited connection to the system, while allowing only insiders to connect to the outside.</p><p>Examining the range of source ports chosen by the other party makes it possible to both make a better guess at the operating system the sender is using and (once the range is correlated with other observations) determine whether the sender is in a private network using address translation (in which case, source port ranges expected for the system and actually observed would most likely not match). If the sender’s network is using address translation, it is also possible to draw certain conclusions as to the type of the address translation device, because various products use distinct ranges.</p></div><div class="sect2" title="Window Size (TCP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="window_size_open_parenthesis_tcp_layer_c"/>Window Size (TCP Layer)</h2></div></div></div><p>Recall that the window size setting determines the amount of data that can be sent without acknowledgment. The specific setting is often chosen according to the developer’s personal voodoo rules and other religious beliefs. The two most popular approaches say the value should be either a multiple of the MTU minus protocol headers (a value referred to as Maximum Segment Size, or MSS) or simply something sufficiently high and “round.” Older versions of Linux (2.0) used values that were powers of 2 (for example, 16,384). Linux 2.2 switched to a multiple of MSS (11 or 22 times MSS, for some reason), and newer versions of Linux commonly use 2 to 4 times MSS. The Sega Dreamcast, a network-enabled console, uses a value of 4,096, and Windows often uses 64,512.<a id="IDX-CHP-9-0452" class="indexterm"/><a id="IDX-CHP-9-0453" class="indexterm"/><a id="IDX-CHP-9-0454" class="indexterm"/><a id="IDX-CHP-9-0455" class="indexterm"/><a id="IDX-CHP-9-0456" class="indexterm"/><a id="IDX-CHP-9-0457" class="indexterm"/><a id="IDX-CHP-9-0458" class="indexterm"/><a id="IDX-CHP-9-0459" class="indexterm"/></p><p>An application can sometimes change the window size value set by the operating system in order to boost performance, but it seldom is. (The presence of a value that does not match the default value that we would expect for an operating system is a good way to detect a specific application; one of the few examples of such applications is Opera, a moderately popular web browser.)</p></div><div class="sect2" title="Urgent Pointer and Acknowledgment Number Values (TCP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="urgent_pointer_and_acknowledgment_number"/>Urgent Pointer and Acknowledgment Number Values (TCP Layer)</h2></div></div></div><p>The values specified in the urgent pointer (16 bits) and acknowledgment number (32 bits) fields are used only when a corresponding TCP flag—URG or ACK—is set in the packet. If these flags are not set, the values should be zeroed, but they often are not. Some systems simply initialize them to something nonzero, which causes no real problem: because the values will not be interpreted if an appropriate flag is not set, they simply serve to identify a particular system.</p><p>In some cases, however, these values are not initialized at all and are simply copied from whatever is found in the buffer being used to construct the TCP packet at the moment. I observed this behavior with Windows 2000 and XP stack implementations while working on passive operating system fingerprinting: whenever two TCP sessions occurred at once, these values leaked some of the information from a previous session to the current one (a case we will return to in <a class="xref" href="ch11.html" title="Chapter 11. In Recognition of Anomalies">Chapter 11</a>). This tells you that the person is doing something else in the background and discloses some of the information transferred to another party. Hallelujah!</p></div><div class="sect2" title="Options Order and Settings (TCP Layer)"><div class="titlepage"><div><div><h2 class="title"><a id="options_order_and_settings_open_parenthe"/>Options Order and Settings (TCP Layer)</h2></div></div></div><p>The exact ordering and selection of options in a packet is unique to each system. Because there are no rules governing how options should be ordered in a packet, there are certain “signature” combinations. For example, Windows uses a characteristic sequence of “MSS, NOP, NOP, Selective ACK Permitted” options on SYN packets; Linux usually sticks with “MSS, Selective ACK Permitted, Timestamp, NOP, Window scale.” Naturally, this once again serves as an excellent way of telling systems apart.<a id="IDX-CHP-9-0460" class="indexterm"/><a id="IDX-CHP-9-0461" class="indexterm"/><a id="IDX-CHP-9-0462" class="indexterm"/><a id="IDX-CHP-9-0463" class="indexterm"/></p></div><div class="sect2" title="Window Scale (TCP Layer, Option)"><div class="titlepage"><div><div><h2 class="title"><a id="window_scale_open_parenthesis_tcp_layer"/>Window Scale (TCP Layer, Option)</h2></div></div></div><p>A scaling factor for the window size is usually set to zero. However, some systems either default to a higher value or permanently increase the parameter for a specific type of traffic when they conclude that it is reasonable to do so, for example, if the user just fetched a pirated movie from a P2P network or completed an extensive download of a different kind (the latter is naturally a bit less likely).</p></div><div class="sect2" title="Maximum Segment Size (TCP Layer, Option)"><div class="titlepage"><div><div><h2 class="title"><a id="maximum_segment_size_open_parenthesis_tc"/>Maximum Segment Size (TCP Layer, Option)</h2></div></div></div><p>This field is fixed to a specific value on some systems; on others, it indicates the type of direct network hookup of the device. Different network types have different MTUs, making it possible to tell whether a person uses a high-speed DSL link or a puny modem line.</p></div><div class="sect2" title="Time-Stamp Data (TCP Layer, Option)"><div class="titlepage"><div><div><h2 class="title"><a id="time-stamp_data_open_parenthesis_tcp_lay"/>Time-Stamp Data (TCP Layer, Option)</h2></div></div></div><p>Since this value often corresponds to system uptime, it is often possible to determine it by observing the time-stamp option. Furthermore, given a set of operating systems, it is possible to differentiate them and track each one by checking time-stamp variations in incoming traffic: different systems will have different uptimes (and are quite unlikely to have identical boot-up times), whereas the same computer would maintain a continuously increasing time-stamp parameter value.</p><p>This comes in quite handy in two situations. The first is when a set of systems acts under a single IP, as with masquerading. In such a case, a curious webmaster can determine how many unique users from corporation X visited their page and the whereabouts of each visitor to the websites they operate, even if all requests originate from one address and appear to be indistinguishable at first.</p><p>The other application is for tracking a single user who, for whatever reason, hops IP addresses. Why would one bother, and why would the other party want to determine if the user is doing it? For example, they might be switching between a pool of dynamic IP addresses assigned to a dial-up line (by disconnecting and connecting again), in hopes that their attack attempts will appear to be a set of meaningless, uncorrelated activities, rather than a well-planned, extensive probe. Or they might want to bypass interaction restrictions on a web forum, in an online poll or voting contest (with some old-fashioned ballot stuffing), and so on. All are common pastimes of the new generation.</p><p>The time-stamp option’s measurement of time is usually precise, because it is based on a clock that most commonly ticks at 100 or 1,000 Hz (although some systems use 64 or 1,024 Hz, and values in between). This precision is enough to differentiate even similar boxes that were all booted up nearly at once after a power failure, and thus it provides extreme accuracy.</p></div><div class="sect2" title="Other Passive Fingerprinting Venues"><div class="titlepage"><div><div><h2 class="title"><a id="other_passive_fingerprinting_venues"/>Other Passive Fingerprinting Venues</h2></div></div></div><p>In this chapter, we have looked at the most common metrics used to determine the operating system of a remote host (and to track its users) without their ever knowing. But many exciting, yet lesser explored aspects of communications beyond these basics can be used to achieve the same ends, and more.<a id="IDX-CHP-9-0464" class="indexterm"/><a id="IDX-CHP-9-0465" class="indexterm"/><a id="IDX-CHP-9-0466" class="indexterm"/><a id="IDX-CHP-9-0467" class="indexterm"/><a id="IDX-CHP-9-0468" class="indexterm"/></p><p>For example, an interesting variant of fingerprinting is related not to examining the packets themselves, but to measuring the timing and response rates for certain ICMP messages, TCP retransmissions, and similar features. The values used for all the time-out and retransmission count settings provide a good way to precisely and uniquely fingerprint a system. A CRONOS project, based on the research by Franck Veysset, Olivier Courtay, and Olivier Heen of the Intranode Research Team, aims at providing an active fingerprinting tool based on this set of metrics, but passive fingerprinting applications are just as tempting.<a id="IDX-CHP-9-0469" class="indexterm"/></p><p>Another promising lead is the effort to combine and measure many other anomalies or uncommon settings, such as a sender’s use of specific time-stamp values, sequence numbers identical to acknowledgment numbers, or unusual flags, as well as data payload in control packets, the use of the EOL option, and so on. These characteristics can also be used to differentiate between operating systems, although these characteristics are often specific to a small set of implementations. (The algorithm used for choosing initial sequence numbers is often a valuable source of information, as you will see in the next chapter.)</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-5" href="#CHP-9-FN-5" class="para">19</a>] </sup>Some developers even choose to set the Must Be Zero bit of this parameter—which should never be set in a legitimate application—presumably just to make a style statement.</p></div></div></div>
<div class="sect1" title="Passive Fingerprinting in Practice"><div class="titlepage"><div><div><h1 class="title"><a id="passive_fingerprinting_in_practice"/>Passive Fingerprinting in Practice</h1></div></div></div><p>These metrics make it possible to precisely identify operating systems and their configuration as well as network parameters and to track users efficiently and silently. Although it may seem difficult to believe that this is possible, a tool I have authored, p0f, implements most of the techniques to gather and analyze the information based on the analysis of SYN, SYN+ACK, and RST packets in a completely passive manner, with a high rate of success.<a id="IDX-CHP-9-0470" class="indexterm"/><a id="IDX-CHP-9-0471" class="indexterm"/></p><p>Let’s look at an example packet to see the effectiveness of this approach. Following is a set of important parameters extracted from an actual TCP packet captured on the network. What can this tell us about the sender’s operating system?</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/></colgroup><tbody><tr><td style="text-align: left" colspan="2" valign="top"><p><span class="strong"><strong>Internet Protocol (Version 4)</strong></span></p></td></tr><tr><td style="text-align: left" valign="top"><p>Source host</p></td><td style="text-align: left" valign="top"><p>nimue (10.3.0.1)</p></td></tr><tr><td style="text-align: left" valign="top"><p>Destination host</p></td><td style="text-align: left" valign="top"><p>nightside (10.3.0.3)</p></td></tr><tr><td style="text-align: left" valign="top"><p>Flags</p></td><td style="text-align: left" valign="top"><p>DF</p></td></tr><tr><td style="text-align: left" valign="top"><p>Time to live</p></td><td style="text-align: left" valign="top"><p>57</p></td></tr><tr><td style="text-align: left" valign="top"><p>Identification number</p></td><td style="text-align: left" valign="top"><p>4428</p></td></tr><tr><td style="text-align: left" valign="top"><p>No IP options (packet size = 20)</p></td><td style="border-bottom: 0.5pt solid ; "> </td></tr><tr><td style="text-align: left" colspan="2" valign="top"><p><span class="strong"><strong>Transmission Control Protocol</strong></span></p></td></tr><tr><td style="text-align: left" valign="top"><p>Source port</p></td><td style="text-align: left" valign="top"><p>3803</p></td></tr><tr><td style="text-align: left" valign="top"><p>Destination port</p></td><td style="text-align: left" valign="top"><p>80 (HTTP)</p></td></tr><tr><td style="text-align: left" valign="top"><p>Flags</p></td><td style="text-align: left" valign="top"><p>SYN</p></td></tr><tr><td style="text-align: left" valign="top"><p>Sequence number</p></td><td style="text-align: left" valign="top"><p>1418000073</p></td></tr><tr><td style="text-align: left" valign="top"><p>Acknowledgment number</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr><tr><td style="text-align: left" valign="top"><p>Window size</p></td><td style="text-align: left" valign="top"><p>32120</p></td></tr><tr><td style="text-align: left" colspan="2" valign="top"><p><span class="strong"><strong>TCP Options</strong></span></p></td></tr><tr><td style="text-align: left" valign="top"><p>#1 Maximum Segment Size</p></td><td style="text-align: left" valign="top"><p>1460</p></td></tr><tr><td style="text-align: left" valign="top"><p>#2 Selective ACK Permitted</p></td><td style="border-bottom: 0.5pt solid ; "> </td></tr><tr><td style="text-align: left" valign="top"><p>#3 Timestamp</p></td><td style="text-align: left" valign="top"><p>170330930</p></td></tr><tr><td style="text-align: left" valign="top"><p>#4 Window scale</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr></tbody></table></div><p>A lot. Here’s what we can infer from these observations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Because the DF flag in IP headers is set, the system must use path MTU discovery. Matching systems that use path MTU discovery are newer versions of Linux, FreeBSD, OpenBSD, Solaris, and Windows. We can rule out IRIX, AIX, many commercial firewalls,<sup>[<a id="CHP-9-FN-6" href="#ftn.CHP-9-FN-6" class="footnote">20</a>]</sup> and other systems that do not implement PMTUD for reliability reasons.</p></li><li class="listitem"><p>The time to live of the packet is 57. We know that the initial TTL value could not have been lower because it might only be decreased in transit, and it is unlikely that the value exceeds 87 (that would be a system really far away). We can match this with many Unixes (all of which use an initial TTL of 64) but we rule out Windows (with an initial TTL 128), versions of Solaris prior to 8 (255), and several network appliances (32).</p></li><li class="listitem"><p>The identification number of the packet is nonzero. This rules out Linux 2.4 and newer versions, as well as several recent releases of other popular operating systems.</p></li><li class="listitem"><p>The source port falls in the most commonly used range (1,024 to 4,095). Although this alone doesn’t help us to exclude any systems, we can safely assume that the system had established more than 2,700 connections before this one and is unlikely to be behind a masquerade.</p></li><li class="listitem"><p>The option selection and ordering (MSS, Selective ACK, Timestamp, Window scaling) is specific to Linux 2.2 and newer.</p></li><li class="listitem"><p>The window size is a multiple of MSS, that is MSS*22. The only system that matches this is Linux 2.2.</p></li><li class="listitem"><p>There are no observed anomalies, RFC violations, or other quirks in the packet, which confirms the hypothesis that Linux is the system being run.</p></li><li class="listitem"><p>The Maximum Segment Size indicates an Ethernet or modem PPP connection (MTU of 1,500).</p></li><li class="listitem"><p>The system’s uptime is approximately 19 days, and it is located 7 systems away.</p></li></ul></div><p>Certainly, single metrics can be modified by applications or user tweaks. (For example, users tend to modify TTL or enable or disable certain settings after reading network optimization guides or running “system doctor” applications.) However, by drawing a series of conclusions based on our observations we come up with a reliable way to determine the machine’s operating system by identifying the system that appears to be the best match in most categories.</p><p>In this case, we have good reasons to believe that the system in question is Linux 2.2 and that the sender is connected to the Internet via Ethernet or dial-up modem. Based on this assumption, we can also conclude that the system is 7 hops away (64–57, where 64 is the initial TTL for Linux systems) and that its uptime is close to 20 days. If more users are hiding behind this particular IP, we can easily count them and differentiate their sessions based on their system characteristics and time-stamp data, if available.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-6" href="#CHP-9-FN-6" class="para">20</a>] </sup>A firewall is essentially a filtering router, often also capable of understanding and making decisions based on higher-layer traffic characteristics.</p></div></div></div>
<div class="sect1" title="Exploring Passive-Fingerprinting Applications"><div class="titlepage"><div><div><h1 class="title"><a id="exploring_passive-fingerprinting_applica"/>Exploring Passive-Fingerprinting Applications</h1></div></div></div><p>When observed by either the recipient or a bystander (such as an ISP between the sender and the recipient), network traffic can provide information beyond the actual data exchanged, including certain parameters of the sender’s system. As suggested previously, the exposure is important and quite interesting because, unlike the data transmitted by applications, it is not necessarily obvious, and the disclosure is often beyond any user’s control. Although users can change their browser settings and those of other applications in order to prevent being monitored, identified, and tracked, the disclosure that occurs on the lower IP or TCP layer can easily undermine this effort by revealing to the observer just as much about the victim as the victim is trying to hide. It can also carry data of more fundamental significance to the security of the infrastructure, including some useful hints about how the victim’s network is constructed and protected.<a id="IDX-CHP-9-0472" class="indexterm"/></p><p>That said, short of privacy invasion, passive fingerprinting can also be useful for quite legitimate reconnaissance tasks. The set of practical (and commonly deployed) applications of passive fingerprinting extends through the entire ethical spectrum, from malice to rightful defense.</p><div class="sect2" title="Collecting Statistical Data and Incident Logging"><div class="titlepage"><div><div><h2 class="title"><a id="collecting_statistical_data_and_incident"/>Collecting Statistical Data and Incident Logging</h2></div></div></div><p>One of the more legitimate uses for passive fingerprinting is that of monitoring the network to perform noninvasive and objective analysis of the platforms and network environments used, to ensure that users receive service that is optimized for their software, and to guarantee that no sizable group of users is neglected in some way. Too, gathering data about potential attackers or other unauthorized activity can be greatly enhanced by the use of passive fingerprinting. Indeed, passive fingerprinting is particularly popular in the field of honeypot research.<a id="IDX-CHP-9-0473" class="indexterm"/><a id="IDX-CHP-9-0474" class="indexterm"/><a id="IDX-CHP-9-0475" class="indexterm"/><a id="IDX-CHP-9-0476" class="indexterm"/><a id="IDX-CHP-9-0477" class="indexterm"/><a id="IDX-CHP-9-0478" class="indexterm"/><a id="IDX-CHP-9-0479" class="indexterm"/></p><div class="note" title="Note"><h3 class="title">Note</h3><p>Honeypots are a concept aggressively promoted and researched by Lance Spitzner of Sun Microsystems.<sup>[<a href="apb.html#ftn.CHP-9-BIB-11" class="footnoteref">84</a>]</sup> The goal is to let the owner learn about their opponents and their goals, using devices (honeypots) whose value lies in their unauthorized and illicit use and that have no actual significance for the infrastructure, although they are designed to appear as if they do.<a id="IDX-CHP-9-0480" class="indexterm"/></p></div></div><div class="sect2" title="Content Optimization"><div class="titlepage"><div><div><h2 class="title"><a id="content_optimization"/>Content Optimization</h2></div></div></div><p>One active application for passive fingerprinting relies on providing services optimized for a specific recipient based on an immediate analysis of the setup they are using to access the server. I consider it my duty to include a shameless plug here for one of my aforementioned tools, p0f. p0f offers a method for querying it about the parameters of recent incoming connections from other applications, which makes the task of content optimization much easier: a web script does not have to know a lot about TCP and IP, can simply ask p0f, “Hey, who is that guy I am talking with?” and then get a useful response.</p></div><div class="sect2" title="Policy Enforcement"><div class="titlepage"><div><div><h2 class="title"><a id="policy_enforcement"/>Policy Enforcement</h2></div></div></div><p>The detection and eventual blocking of obsolete or noncompliant systems (say, devices that violate a corporate policy or pose a security risk) or infestations of unauthorized network hookups is another interesting application for passive fingerprinting. Since version 3.4, OpenBSD has provided a method for routing and redirecting traffic based on the operating system detection results, hence making policy enforcement based on remote operating system characteristics quite viable. The same functionality is now provided as a part of Linux netfilter patch-o-matic code. Both implementations are closely inspired by or based on p0f.</p></div><div class="sect2" title="Poor Man’s Security"><div class="titlepage"><div><div><h2 class="title"><a id="poor_manas_security"/>Poor Man’s Security</h2></div></div></div><p>Passive fingerprinting can also be used to minimize certain types of exposure. Although with some effort it is possible to fool the fingerprinting technique, fingerprinting might be used to prevent certain types of clients (such as Windows systems, a platform most commonly infested with spyware, backdoors, and worms and often used for unsolicited mass email distribution or attack hops) from using certain underlying services on the network, while allowing “less suspect” entities to access them.<a id="IDX-CHP-9-0481" class="indexterm"/><a id="IDX-CHP-9-0482" class="indexterm"/><a id="IDX-CHP-9-0483" class="indexterm"/><a id="IDX-CHP-9-0484" class="indexterm"/><a id="IDX-CHP-9-0485" class="indexterm"/></p></div><div class="sect2" title="Security Testing and Preattack Assessment"><div class="titlepage"><div><div><h2 class="title"><a id="security_testing_and_preattack_assessmen"/>Security Testing and Preattack Assessment</h2></div></div></div><p>Active fingerprinting is often stopped in its tracks by firewalls and other solutions that carefully filter and analyze IP traffic. Passive fingerprinting, however, can examine even aggressively protected systems and can map networks without triggering any alerts.</p><p>The approach to security testing and assessment using passive fingerprinting is twofold. First, it can be used to analyze incoming traffic. Although the observer must wait for the remote party to connect to their systems, such a connection can be quite easily induced without triggering suspicion. In fact, it is often sufficient to send a specific email or a link to a website to the victim behind even the most sophisticated packet-filtering solution. Second, passive fingerprinting can be used to analyze the responses to legitimate traffic to an available service in order to determine the remote party’s parameters. If a black-hat hacker knows how to compromise an internal network, but wants to know more about its internals in order to minimize the risk of being detected prematurely, passive fingerprinting can come in handy. The same can be said about legitimate security testing for which one is paid by the entity that undergoes the test.</p></div><div class="sect2" title="Customer Profiling and Privacy Invasion"><div class="titlepage"><div><div><h2 class="title"><a id="customer_profiling_and_privacy_invasion"/>Customer Profiling and Privacy Invasion</h2></div></div></div><p>Many companies go to great lengths to gather and sell valuable information about people’s habits, preferences, and behavior. Although this information is usually used for marketing purposes, it could—in theory—be used against a specific person. The ability to track users by correlating fingerprinting results from several locations that they have visited, whether to map internal networks and software used, track individuals, or gather other valuable statistical data, can be a source of information that might either have considerable value by itself or be used to enhance the attractiveness of other not-quite-ethical offerings.</p></div><div class="sect2" title="Espionage and Covert Reconnaissance"><div class="titlepage"><div><div><h2 class="title"><a id="espionage_and_covert_reconnaissance"/>Espionage and Covert Reconnaissance</h2></div></div></div><p>The ability to gather additional information about a competitor’s network architecture and user behavior and preferences is often quite tempting. Though this may sound like bad science-fiction, it is simply a more targeted type of the profiling discussed above.</p></div></div>
<div class="sect1" title="Prevention of Fingerprinting"><div class="titlepage"><div><div><h1 class="title"><a id="prevention_of_fingerprinting"/>Prevention of Fingerprinting</h1></div></div></div><p>Given the complexity of a typical IP stack, it is extremely difficult to prevent fingerprinting in general, but it is possible to address specific issues and disable specific types of known fingerprinting software by determining what parameter it relies on most and then changing it. For example, certain packet-filtering solutions, such as <code class="literal">pf</code> in OpenBSD, provide a packet normalization service that ensures that all outgoing traffic “looks the same.” Although this might prevent some aspects of fingerprinting to some degree or might simply make finger-printing more difficult by rendering some popular programs less accurate, it does not solve the problem completely.<a id="IDX-CHP-9-0486" class="indexterm"/><a id="IDX-CHP-9-0487" class="indexterm"/><a id="IDX-CHP-9-0488" class="indexterm"/><a id="IDX-CHP-9-0489" class="indexterm"/><a id="IDX-CHP-9-0490" class="indexterm"/><a id="IDX-CHP-9-0491" class="indexterm"/></p><p>Although the thorough and seemingly exhaustive manual or automated modification of certain operating system settings or TCP parameters can make system identification more difficult, certain behaviors are buried deep in the kernel and are not customizable. For example, it is fairly difficult to change the option ordering in a packet. Moreover, when users make manual modifications, they risk introducing unique characteristics into packets originating from their system, which only further affects their privacy and anonymity.</p><p>Fortunately, certain solutions do address specific types of testing. For example, IP Personality by Gael Roualland and Jean-Marc Saffroy alters the TCP stack so that it appears to specific tools as if it comes from a different operating system. If you fancy, you can use IP Personality to make NMAP think that your system is a Hewlett-Packard laser printer. However, some problems arise. For one, it is easy to actually weaken a system’s TCP stack by attempting to impersonate a device that uses a weak stack to begin with. For example, if, in order to comply with a printer’s particular characteristics, you use trivial sequence numbers on all connections, someone will sooner or later take advantage of this to easily disrupt or tamper with your traffic. Too, software such as IP Personality will only work against the most popular, well-known, and well-documented tools, but it offers no guarantee of success against the rest, because the characteristics examined by each tool and the way these characteristics are interpreted are different from place to place. You can only hope to fool the least determined, most naive, “mainstream” attackers who use tools you know about.<a id="IDX-CHP-9-0492" class="indexterm"/><a id="IDX-CHP-9-0493" class="indexterm"/></p><div class="note" title="Note"><h3 class="title">Note</h3><p>Unlike masquerading agents, proxy-type firewalls and other proxy devices do not forward packets, but intercept connections instead and initiate new ones using their own IP stack. These are the only complete solution to third and fourth OSI layer finger-printing, but they have a serious impact on performance and are more prone to problems due to introducing vastly increased complexity. Besides, a higher-level fin-gerprinting of the application itself is still possible.<a id="IDX-CHP-9-0494" class="indexterm"/></p></div></div>
<div class="sect1" title="Food for Thought: The Fatal Flaw of IP Fragmentation"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought_colon_the_fatal_flaw_of"/>Food for Thought: The Fatal Flaw of IP Fragmentation</h1></div></div></div><p>While discussing the defining features of the Internet Protocol, I casually mentioned that the process of packet fragmentation and reassembly is fatally flawed. This notion comes primarily from a fairly interesting observation I had while writing this book. Although the concept is related to an active and noticeable attack performed by an openly rogue entity (although it is not easily traceable back to that entity), it is a unique and interesting flaw inherent in the design of the Internet Protocol. It is not the result of a clearly defined mistake, but more a collision of paradigms on different design layers, both, curiously, specified by Jon Postel, one of the fathers of IP suite. I have decided to include it here to close this chapter, as food for thought for those interested in the pathology of computer flaws.<a id="IDX-CHP-9-0496" class="indexterm"/><a id="IDX-CHP-9-0497" class="indexterm"/><a id="IDX-CHP-9-0498" class="indexterm"/><a id="IDX-CHP-9-0499" class="indexterm"/><a id="IDX-CHP-9-0500" class="indexterm"/><a id="IDX-CHP-9-0501" class="indexterm"/><a id="IDX-CHP-9-0502" class="indexterm"/><a id="IDX-CHP-9-0495" class="indexterm"/></p><p>First, let’s look at the state of affairs today, or perhaps yesterday, as we are dusting off a fairly old attack technique, mentioned previously in the TCP discussion. The technique in question, <span class="emphasis"><em>blind spoofing</em></span>, was first described by Robert T. Morris in the mid ’80s.<sup>[<a href="apb.html#ftn.CHP-9-BIB-12" class="footnoteref">85</a>]</sup> It had its golden age a decade later, but its significance has decreased ever since. We’ll focus on a specific example of blind spoofing, that of injecting certain data into an existing session, to disrupt it, to convince the server that its user has issued a specific command, or to convince the user that they are getting a specific response from the server. This technique is often referred to as <span class="emphasis"><em>connection hijacking</em></span>.<a id="IDX-CHP-9-0503" class="indexterm"/><a id="IDX-CHP-9-0504" class="indexterm"/></p><p>Under normal circumstances, a malicious bystander, wanting to insert data into an existing TCP stream, first needs to determine the sequence numbers used by at least one of the parties. Even though such an attack is highly time sensitive and must be targeted against a specific, existing connection, it can be (and has been, many times) performed successfully when the sequence numbers are predictable. In fact, in the late 1990s, many tools were used to disrupt Windows TCP sessions to Internet Relay Chat (IRC) networks (for amusement or other), exploiting the Windows weak initial sequence number (ISN) selection algorithm; it was trivial to inject a single RST packet here and there, kicking a person off the chat server. This is what we called fun back then.</p><p>Today, the situation is a bit different. Thanks to the efforts of many researchers (including the most humble author of these words), developers have worked hard to make initial sequence numbers in TCP connections more difficult to predict. Many attempts to improve the quality and strength of sequence number generators in popular operating systems have, in the end, rendered ISN prediction attacks harder, with few rather unnoteworthy exceptions. Systems that use sequential ISN numbers are largely extinct; an attacker, unable to determine the numbers used in a conversation with another party, is forced to search the entire 32-bit space of possible values in order to perform a precise data insertion attack (fewer if they only want to abort or irrecoverably mangle the session). That’s some 4,294,967,296 combinations, and an attack like this requires the attacker to send an average of about 80 GB of data in order for it to succeed. Needless to say, this is not considered particularly feasible.</p><p>However, as to the actual benefits you can gain from a successful data injection attack, little has changed. Even though an increasing amount of communication is exchanged over channels that support encryption, the relevance of this type of attack has not decreased significantly; plenty of fruitful attack scenarios persist. Here are some examples.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Data can be inserted into unencrypted server-to-server or router-to-router traffic, such as an email exchange, DNS zone transfers, BGP communications, and so on. Much of the server-to-server traffic can be generated by the attacker and yet contain sensitive or trusted information, which makes a targeted and timed attack more feasible.</p></li><li class="listitem"><p>Data can be inserted into unencrypted client-to-server traffic, such as File Transfer Protocol (FTP) file downloads or HyperText Transfer Protocol (HTTP) responses. This attack can be used allow malicious, incriminating, or derogatory content to be provided to a visitor to a high-profile server or to make it appear as if a compromise attempt originates from an innocent visitor.</p></li><li class="listitem"><p>Data can be inserted into an existing session to exploit a vulnerability in the service at a stage that is not available to a nonauthenticated user. This applies both to encrypted and unencrypted traffic. For example, a service such as POP3 (point of presence, a remote mailbox access protocol) can accept various commands only if the user previously successfully logged in. Prior to logging in, the only commands available are those that directly pertain to the authentication process (<code class="literal">USER</code> and <code class="literal">PASS</code> directives). Without a valid password, the attacker cannot exploit a flaw in one of the commands available later (such as <code class="literal">RETR</code>, a command used to fetch a specific message from a mailbox). However, if the attacker manages to inject a malicious RETR request into an existing session of an already authenticated user, they win.</p></li><li class="listitem"><p>Even a secure and encrypted, integrity-protected stream is susceptible to a denial of service attack when a session is disrupted or terminated by a single, carefully crafted packet.</p></li></ul></div><p>As such, it is tempting to be able to inject data with little effort, without having to go through the entire spectrum of possible sequence numbers. And this is where fragmentation comes in quite handy.</p><div class="sect2" title="Breaking TCP into Fragments"><div class="titlepage"><div><div><h2 class="title"><a id="breaking_tcp_into_fragments"/>Breaking TCP into Fragments</h2></div></div></div><p>When an IP packet carrying a TCP payload is fragmented (arguably, a common occurrence during file transfers, and one that is not always prevented simply by setting the DF flag as some systems do), the data is traveling the network in multiple chunks and is reassembled only when it arrives at the recipient. A clever attacker, in anticipation of this fragmentation, can send a specially crafted, illegitimate IP fragment, masquerading as one from the expected sender. Upon receiving this fragment, the recipient might, with some luck (a matter of precise timing), end up using it instead of the real fragment in the reassembly of the original packet.<a id="IDX-CHP-9-0505" class="indexterm"/><a id="IDX-CHP-9-0506" class="indexterm"/><a id="IDX-CHP-9-0507" class="indexterm"/></p><p>In this attack scenario, the first fragment (containing the full TCP headers, including exact ports, sequence numbers, and so on) is merged with a malicious payload spoofed by the attacker. As a result, the attacker need not know sequence numbers or other session parameters to insert their data into the frame, thus effectively undermining the entire ISN-generation effort. Once the attack is complete, the final packet processed by the recipient consists of valid header data copied from a legitimate fragment and a malicious payload injected by the attacker.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>The attacker can replace any part of the payload in the first fragment by specifying a slight overlap between the fragments; many systems honor overlaps between fragments and overwrite previously received data with a newer copy. In an extreme case, the attacker can successfully replace all the data within a TCP packet except for the sequence number.</p></div><p>Naturally, some pieces of the puzzle are still missing. But, other than the need for precise timing and a knowledge of when the transmission is occurring,<sup>[<a id="CHP-9-FN-7" href="#ftn.CHP-9-FN-7" class="footnote">21</a>]</sup> the attacker in this scenario must overcome only two obstacles:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The fragment must have a correct IP ID number in order for it to be merged in. Thankfully, on many systems, this is not a problem, because IP identifiers are chosen sequentially. As such, the number likely to be used at the moment can be deduced simply by attempting a test connection. Some systems, most notably OpenBSD, FreeBSD, and Solaris, offer randomized ID numbers, which might make the attack more difficult but will still not prevent it. The attacker simply has to check thousands (not billions) of combinations, because the IP ID field is fairly small (only two bytes).</p></li><li class="listitem"><p>The TCP header contains a checksum that is verified after reassembly, and the checksum of the data modified by the attacker must be the same as that of the original payload. However, because the design of a TCP checksum is trivial (simply a variation of a straight 16-bit sum), you can craft a payload that does not alter the packet’s checksum, as long as the original section to be replaced is known to the attacker. (This is most often the case, particularly during file transfers when the attacker wants to insert malicious code or contents in a publicly available portion of data.)</p></li></ul></div><p>The following simplified checksum of a packet that consists of header words H1 and H2 and of payload words P1, P2, and P3 illustrates:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>C = H1 + H2 ... + P1 + P2 + P3 ...</td></tr></table><p>H1, H2, and C are not known to the attacker. (Headers contain sequence numbers, and the checksum is affected by this data.) The attacker has no way to actually examine this packet, but knows that the victim performs a specific (predictable) transaction on the application level (for example, checks their mail, downloads a web page, chats with friends, and so on). The attacker can deduce the payload data P1, P2, and P3 and wants to replace it with their own malicious words N1 and N2, using a third word for checksum compensation (CC) so that the packet still validates.</p><table border="0" summary="Simple list" class="simplelist"><tr><td>C = H1 + H2 ... + N1 + N2 + CC ...</td></tr></table><p>Solving these equations for CC, we conclude that the checksum must be compensated with CC = (P1 + P2 + P3 - N1 - N2). The attacker can then modify the packet so that the checksum remains the same without knowing the entire packet; they simply need the replaced bit. This is enough to calculate the compensation bit correctly and to preserve the checksum.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-9-FN-7" href="#CHP-9-FN-7" class="para">21</a>] </sup>Timing itself is not as much of a problem as it might appear at first. The attacker can choose to send their malicious second fragment slightly in advance; the recipient then creates a reassembly buffer and waits for the remaining parts to arrive within a certain period of time. Once the first legitimate fragment arrives, the buffer contents are considered fully reconstructed, without waiting for the real second chunk to arrive.</p></div></div></div>
<div class="chapter" title="Chapter&#xA0;10.&#xA0;Advanced Sheep-Counting Strategies"><div class="titlepage"><div><div><h1 class="title"><a id="advanced_sheep-counting_strategies"/>Chapter 10. Advanced Sheep-Counting Strategies</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where we dissect the ancient art of determining network architecture and computer’s whereabouts</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>Network reconnaissance and mapping is the art of exploiting a set of information disclosure vectors inherent in the Internet’s core communications protocols in order to recognize systems and networks or to identify and track potential offenders, users, customers, or competitors. It is perhaps the most developed, most widely deployed, and most significant and immediately useful application of passive data analysis to date, but it has its share of problems that affect both its accuracy and usability in certain scenarios. This is particularly true for known and tested TCP/IP passive fingerprinting techniques.</p><div class="sect1" title="Benefits and Liabilities of Traditional Passive Fingerprinting"><div class="titlepage"><div><div><h1 class="title"><a id="benefits_and_liabilities_of_traditional"/>Benefits and Liabilities of Traditional Passive Fingerprinting</h1></div></div></div><p>Use of the passive fingerprinting metrics discussed in the previous chapter will let you easily identify some characteristics of an originating system and network. Too, in some cases, these techniques will make it possible to trace individuals as they change their address or share it with other users of a single network. You can employ these techniques without interacting with the remote party as long as you can persuade the observed earthling to interact with a specific network or for as long as their network communications passes through a specific set of systems controlled by a sufficiently curious person. Thus, passive fingerprinting, among other uses, enables a server owner or a specific ISP to acquire massive and completely stealthy information rather easily.<a id="IDX-CHP-10-0508" class="indexterm"/><a id="IDX-CHP-10-0509" class="indexterm"/><a id="IDX-CHP-10-0510" class="indexterm"/></p><p>Passive fingerprinting provides such a remote party with a two-edged sword. You can deploy it to obtain useful data about the internal structure of a network, in order to make an attack easier or to learn more about the networking technologies used (even in a fairly complex environment, as shown in <a class="xref" href="ch10.html#you_can_use_passive_fingerprinting_to_ma" title="Figure 10-1. You can use passive fingerprinting to map a complex and even inaccessible network simply by observing traffic from some of the nodes (the most important being measuring operating system characteristics, TTL, and MSS values on packets) and then deducing the presence of other components to match the observed characteristics variances. It is left to the reader to determine how this network could be conclusively mapped out by merely observing traffic on the outside.">Figure 10-1</a>). You can also use it (quite rightfully) to monitor your own network for policy violations (such as illegal connections or access points that connect an internal network with the outside world) or to track attackers.</p><p>The resulting privacy loss for a single user is generally negligible, unless the ability to link casual activities performed by a user with the additional data acquired by fingerprinting, or the ability to track a single user across domains, is a particular problem (this is most likely true only when the user’s behavior is questionable to begin with). But the cumulative loss of privacy for all users could be quite worrisome, and the information gathered through fingerprinting or fingerprinting-assisted tracking can pose a noticeable market value. (Your personal data can be sold for much more to advertisers if it is combined with information about your preferences and interests, for example.) Too, the exposure of the technical inner workings of a network can indeed be undesirable for corporations and other portions of sensitive infrastructure.</p><p>Nevertheless, not all is lost just yet. As indicated previously, there are some problems with using passive fingerprinting to obtain accurate results. The reliability problem with traditional passive operating system finger-printing technique stems from how easy it is to fool the observer by carefully tweaking some or all the network settings used by a system that is subject to observation. Even if completely altering all settings is not particularly easy, a partial modification might be enough to thwart certain automated analysis attempts (hooray!) or mislead a researcher investigating a malicious incident (oops). Although not a large-scale problem, and thus not a concern for statistical analysis, the reliability issue can cause concern in individual cases.</p><p>Moreover, the user tracking and counting capabilities of the finger-printing approach we painfully dissected in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a> rely almost entirely on the availability of parameters such as the time-stamp information in TCP/IP packets. All other characteristics are either standardized or have too few possible options to provide a unique positive identification of a single computer, except in the most unusual cases. If such data is unavailable because this particular performance extension is disabled (as with most Windows systems, for example), the precise identification of a system is not possible. This lowers the potential value of the data both to members of an overzealous, evil conspiracy cabal (that, as we all know, is after our most precious secrets), as well as to security testers or incident analysts (computer forensics experts). Without this time stamp–based identification capability, it can be impossible to differentiate several identical systems running behind a masquerade or to identify an individual whose IP was changed once they reconnected their modem.</p><div class="figure"><a id="you_can_use_passive_fingerprinting_to_ma"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6679"/><img src="httpatomoreillycomsourcenostarchimages1138068.png.jpg" alt="You can use passive fingerprinting to map a complex and even inaccessible network simply by observing traffic from some of the nodes (the most important being measuring operating system characteristics, TTL, and MSS values on packets) and then deducing the presence of other components to match the observed characteristics variances. It is left to the reader to determine how this network could be conclusively mapped out by merely observing traffic on the outside."/></div></div><p class="title">Figure 10-1. You can use passive fingerprinting to map a complex and even inaccessible network simply by observing traffic from some of the nodes (the most important being measuring operating system characteristics, TTL, and MSS values on packets) and then deducing the presence of other components to match the observed characteristics variances. It is left to the reader to determine how this network could be conclusively mapped out by merely observing traffic on the outside.</p></div><p>Another, perhaps more interesting, promising, and challenging passive fingerprinting method, however, easily addresses the shortcomings of passive fingerprinting. This new approach makes it extremely difficult to mislead a remote observer and is almost universally suitable for tracking systems. Perhaps more interestingly, the technique makes it possible to differentiate between instances of exactly the same system in exactly the same configuration, taking masquerade detection to a whole new level. This technique uses the properties of sequence number generation mechanism within TCP/IP, and it can produce some pretty pictures, too.</p></div></div>
<div class="sect1" title="A Brief History of Sequence Numbers"><div class="titlepage"><div><div><h1 class="title"><a id="a_brief_history_of_sequence_numbers"/>A Brief History of Sequence Numbers</h1></div></div></div><p>Recall from the previous chapter that initial sequence numbers are a mechanism used within TCP to ensure session integrity, and—de facto—to guarantee its most basic security resilience.<a id="IDX-CHP-10-0511" class="indexterm"/></p><p>The only truly universal way to protect a plain-text TCP/IP session against data injection, hijacking, or fakery by a complete stranger is to ensure that the initial sequence numbers are selected in a manner that is unpredictable to the attacker. This reduces their chances of making a correct blind guess (and spoofing a packet that will be accepted as a legitimate part of someone else’s session) to a point where this risk is of little concern in the real world, even if the attacker takes the system by storm, sending thousands of packets in hopes that at least one will have a roughly matching sequence number.<a id="IDX-CHP-10-0512" class="indexterm"/></p><p>In the early ’80s, the security aspects of TCP-based communications did not seem to be a problem worth worrying about: the Internet was a fairly small, self-contained, and perhaps a bit elitist environment used by scientists and the like. As such, the RFC specification of the TCP protocol did not specify a requirement for initial sequence number selection, and almost all early (and some not quite so early) TCP/IP stack implementations used trivial, time-, or counter-based algorithms that returned subsequent numbers for subsequent connections. At the time, the idea of randomizing these numbers seemed a needless waste of precious computing power. Too, in doing so, the likelihood of a sequence number collision would be needlessly increased. (Collision is a situation in which two ISNs chosen for subsequent connections to a host are too similar, thus creating the possibility that old packets arriving in an untimely manner could be interpreted in the context of a wrong connection. Naturally, picking numbers randomly is more likely in the short run to produce collisions than picking sequentially increasing numbers.)</p><p>The Internet has advanced a lot since the 1980s, of course, with its increased availability and rapidly changing and growing user base; as more and more important data was sent over the wires, the security issues became more relevant. Unfortunately, popular and reliable integrity and privacy protection mechanisms have yet to catch up with the Internet’s expansion: not all services support encryption, not all users know when to use it, and, more important, most users do not know how to properly validate crypto-graphic certificates provided by remote parties.</p><p>Over time, and particularly with the widespread practical abuse of the weak ISN-generation mechanism in the mid ’90s (although mostly limited to online chat services and so forth), it became obvious that it was necessary to provide rudimentary integrity protection for TCP/IP streams. This was even important for the marginal fraction of all traffic that is actually crypto-graphically protected, because a disruption of the carrier layer by injecting junk data or RST packets is just as undesirable, even if the impact is only limited to disconnection (denial of service), as opposed to data injection.</p><p>Because the only way to fix things (without a major overhaul of just about every TCP-based communication scheme known to man) was to keep the protocol difficult to attack by itself, many developers undertook efforts to move away from the obsolete and dangerous trivial one-increment ISN-generation mechanisms. Although these efforts did indeed help to improve connection resilience to blind spoofing, they also opened several interesting information-gathering vectors that allow for more advanced fingerprinting of systems and networks, be it for security assessment or a planned attack.</p></div>
<div class="sect1" title="Getting More Out of Sequence Numbers"><div class="titlepage"><div><div><h1 class="title"><a id="getting_more_out_of_sequence_numbers"/>Getting More Out of Sequence Numbers</h1></div></div></div><p>Naturally, it is important to be able to tell the good ISN-generator implementations from the bad, both for quality assurance and for security testing. Until recently, the usual approach to assessing the quality of generated initial sequence numbers relied either on source-code analysis or on certain one-dimensional tests of the bit stream of subsequent ISNs to estimate the entropy carried by each bit of the output. The former is often complex and costly, is prone to errors, and is not always possible (in the absence of publicly available source code for a specific system). The latter lacked the ability to capture more subtle sequence dependencies and other characteristics of a generator in a reliable and readable way, focusing instead on more statistical imperfections than on the correlation between values returned for subsequent connections. Obviously, proving that an implementation is secure by observing only its output is just about impossible, but it is easy to check for certain common problems and to ensure that the underlying algorithm is reasonably robust. And yet, even there, the methods we used to check for this were rather weak at best.<a id="IDX-CHP-10-0513" class="indexterm"/></p><p>Both the original, insecure ISN-generator designs and some of today’s solutions are based on additive, iterative arithmetic systems that calculate new values based on their previous output; only the complexity of the recalculation algorithm and the amount of practical unpredictability introduced in the process seem to vary. The only secure designs that are not based on traditional arithmetic are some newer ones that use relatively slower but cryptographically secure shortcut functions to implement iterative systems. In all cases, though, it would be interesting to look for a nontrivial correlation between subsequent results produced by the generator for new connections to detect possible flaws in the algorithm design.</p><p>Clearly, if an apparent dependency between ISN-generator output at time <span class="emphasis"><em>t</em></span> and one at <span class="emphasis"><em>t+x</em></span> can be observed, the attacker can choose to connect in advance of the connection they hope to interfere with or fake altogether, just to obtain the ISN output at <span class="emphasis"><em>t</em></span>. Based on their observation of the returned sequence number, they can then determine the response that will be generated by the other party in the future (<span class="emphasis"><em>t+x</em></span>). Hence, the attacker can spoof a valid packet for that new connection despite not being able to directly observe the ISN being used.</p><p>With this in mind, in 2001 I performed some research that would provide a unified method of examining less obvious time dependencies in sequences of ISNs acquired from remote systems. My work resulted in a paper that examined some of the ISN-generation algorithms in more detail, providing a way to detect subtleties that go beyond the detection of the most obvious patterns and flaws we had been aware of. The paper, titled “Strange Attractors and TCP/IP Sequence Number Analysis,”<sup>[<a href="apb.html#ftn.CHP-10-BIB-1" class="footnoteref">86</a>]</sup> used an approach well known in the world of applied mathematics, but quite novel for networking.</p></div>
<div class="sect1" title="Delayed Coordinates: Taking Pictures of Time Sequences"><div class="titlepage"><div><div><h1 class="title"><a id="delayed_coordinates_colon_taking_picture"/>Delayed Coordinates: Taking Pictures of Time Sequences</h1></div></div></div><p>When dealing with a black-box ISN generator in one of today’s closed-source systems, you see only its output, a sequence of 32-bit values carried by TCP/IP packets, not the underlying algorithm. For many operating systems, the code is proprietary and well guarded, quite beyond the reach of mere mortals. Even in an open-source system, the sources can be tricky and misleading, and you can end up following the same mistakes as the original developer.<a id="IDX-CHP-10-0514" class="indexterm"/><a id="IDX-CHP-10-0515" class="indexterm"/><a id="IDX-CHP-10-0516" class="indexterm"/><a id="IDX-CHP-10-0517" class="indexterm"/></p><p>The typical input we would have to evaluate would likely look similar to this:</p><a id="I_programlisting2_d1e6762"/><pre class="programlisting">S<sub>0</sub> = 244782
S<sub>1</sub> = 245581
S<sub>2</sub> = 246380
S<sub>3</sub> = 247176
S<sub>4</sub> = 247975
S<sub>5</sub> = 248771
...</pre><p>Is the dependency in these numbers immediately obvious? And if so, is there is a relatively universal method for the computer to follow this and more complex schemes?</p><p>An elegant solution seemed far off. I hoped to develop a method to identify some universal properties of the ISN’s underlying algorithm based on the observation of output alone. But before doing that, and in order to make the analysis easier, it was desirable and quite convenient to assume that, because many implementations are based on reiterating certain arithmetic operations, it is better to observe the changes between subsequent results than to observe absolute values. Watching changes is advantageous for such algorithms, and would not do much harm to the rest of the possible generators. To achieve this, we must calculate a discrete derivative of the input sequence: the increments between elements of <span class="emphasis"><em>S</em></span>. The resulting sequence of deltas, <span class="emphasis"><em>D</em></span>, obviously starting at <span class="emphasis"><em>t = 1</em></span>, is given by the following equation:</p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>D<sub>t</sub></em></span> = <span class="emphasis"><em>S<sub>t</sub></em></span> − <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span> − 1</sub></td></tr></table><p>In this example, the resulting sequence of deltas is:</p><a id="I_programlisting2_d1e6816"/><pre class="programlisting">D<sub>1</sub> = 799
D<sub>2</sub> = 796
D<sub>3</sub> = 799
D<sub>4</sub> = 796
D<sub>5</sub> = 799
...</pre><p>By disregarding the actual values and looking only at the dynamics of ISNs, the underlying dependency becomes more apparent and will generally remain so for all implementations that rely on this type of arithmetics. (For systems not based on trivial iterative arithmetics, this has virtually no relevance whatsoever and will not significantly affect the quality of the data for the purpose of this analysis.)</p><div class="note" title="Note"><h3 class="title">Note</h3><p>A particularly pedantic researcher would also compensate for timing irregularities during sample acquisition; here, we assume that a fixed amount of time, a base unit of 1, always occurs between acquisitions. In high-speed acquisition, however, network performance and other events may significantly impact timings. To ensure that these timing differences will not influence the algorithms that use clock input as a part of the ISN- generation process, it might be safer to use the following equation instead (in which T<sub>t</sub> expresses the delay between acquiring S<sub>t-1</sub> and S<sub>t</sub>): D<sub>t</sub> = (S<sub>t</sub> − S<sub>t−1</sub>)/T<sub>t</sub>.</p></div><p>The advantage of this approach as applied to iterative arithmetics systems is fairly obvious. Trivial cases aside, however, this method alone is hardly sufficient: we simply move from one flat sequence of data that is fairly difficult to analyze to another.</p><p>The next thing I chose to do was to convert the sequence of deltas into a form that could be easily examined by a human or a machine for types of correlation perhaps less obvious than the previous example. Nothing works better than a three-dimensional model of the system dynamics for the first group of the intended audience of the data. Unfortunately, with ISNs we only have enough information to draw pictures in one dimension, on a single axis. So how do we turn our information into a neat three-dimensional shape?</p><p>The solution is to extend the data set by applying a coordinate reconstruction strategy called <span class="emphasis"><em>time-delayed coordinates</em></span>. We use a method that extends every sample by constructing virtual coordinates based on the previous samples in sequence. If the existing sample is considered the <span class="emphasis"><em>x</em></span> coordinate value, we can use this technique to assign <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> values to every existing sample, thus constructing a triplet of coordinates—<span class="emphasis"><em>x</em></span>, <span class="emphasis"><em>y</em></span>, and <span class="emphasis"><em>z</em></span>—sufficient to map every sample to a single point (here, pixel) in a three-dimensional space. (The technique is not limited to three dimensions. However, for the dual purposes of visualization and data analysis, it seemed impractical to choose a higher number. At any rate, most human beings do not cope with more dimensions too well, at least when sober.)</p><p>Time-delayed coordinates are calculated so that the second coordinate is constructed using the value sampled at <span class="emphasis"><em>t−1</em></span>, the third coordinate corresponds to the value observed <span class="emphasis"><em>t−2</em></span>, and so on. In this particular application, coordinates for data at time <span class="emphasis"><em>t</em></span> are given by the following set of equations:</p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>x<sub>t</sub></em></span> = <span class="emphasis"><em>D<sub>t</sub></em></span> = <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span></sub> − S<sub>t − 1</sub></td></tr><tr><td><span class="emphasis"><em>y<sub>t</sub></em></span> = <span class="emphasis"><em>D</em></span><sub><span class="emphasis"><em>t</em></span> − 1</sub> = <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span> − 1</sub> − <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span> − 2</sub></td></tr><tr><td><span class="emphasis"><em>z<sub>t</sub></em></span> = <span class="emphasis"><em>D</em></span><sub><span class="emphasis"><em>t</em></span> − 2</sub> = <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span> − 2</sub> − <span class="emphasis"><em>S</em></span><sub><span class="emphasis"><em>t</em></span> − 3</sub></td></tr></table><p>Given a sequence of newly constructed (<span class="emphasis"><em>x,y,z</em></span>) triplets for a system that is being tested for time dependencies, it is possible to plot the behavior of an ISN-generation system in three-dimensional space. Because the location of a pixel representing a given sample depends both on the “current” value and on a number of previous results, many even fairly complex dependencies result in abstract but noticeable, irregular density patterns in the phase space, thus creating a unique portrait of the underlying algorithm. (When used in reference to such portraits, the term <span class="emphasis"><em>attractor</em></span> denotes a shape that maps out the dynamics of a system. The shape (set, space) represents a “trail” of states through which the system cycles or evolves when left on its own.)</p><p><a class="xref" href="ch10s04.html#a_three-dimensional_rendition_of_the_dat" title="Figure 10-2. A three-dimensional rendition of the data set described in the text">Figure 10-2</a> is a rendition of a set of data that originally looked as follows:</p><a id="I_programlisting2_d1e6983"/><pre class="programlisting">4293832719
3994503850
4294386178
134819
4294768138
191541
4294445483
4294608504
4288751770
88040492
...</pre><div class="figure"><a id="a_three-dimensional_rendition_of_the_dat"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6988"/><img src="httpatomoreillycomsourcenostarchimages1138070.png.jpg" alt="A three-dimensional rendition of the data set described in the text"/></div></div><p class="title">Figure 10-2. A three-dimensional rendition of the data set described in the text</p></div><p><a class="xref" href="ch10s04.html#a_three-dimensional_rendition_of_a_data" title="Figure 10-3. A three-dimensional rendition of a data set acquired from a complex but insecure random number generator function">Figure 10-3</a> through <a class="xref" href="ch10s05.html#a_common_time_dependency_pattern_comma_a" title="Figure 10-5. A common time dependency pattern, as observed in imperfect testing conditions">Figure 10-5</a> illustrate several other common yet not necessarily obvious dependency patterns.</p><div class="figure"><a id="a_three-dimensional_rendition_of_a_data"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7001"/><img src="httpatomoreillycomsourcenostarchimages1138072.png.jpg" alt="A three-dimensional rendition of a data set acquired from a complex but insecure random number generator function"/></div></div><p class="title">Figure 10-3. A three-dimensional rendition of a data set acquired from a complex but insecure random number generator function</p></div><div class="figure"><a id="rendition_for_prng_with_no_strong_correl"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7010"/><img src="httpatomoreillycomsourcenostarchimages1138074.png.jpg" alt="Rendition for PRNG with no strong correlation but noticeable statistical biases"/></div></div><p class="title">Figure 10-4. Rendition for PRNG with no strong correlation but noticeable statistical biases</p></div></div>
<div class="sect1" title="Pretty Pictures: TCP/IP Stack Gallery"><div class="titlepage"><div><div><h1 class="title"><a id="pretty_pictures_colon_tcp_solidus_ip_sta"/>Pretty Pictures: TCP/IP Stack Gallery</h1></div></div></div><p>The visualization method seemed to work like a charm, producing unique and often instinctively worrying, charming patterns for many implementations that had been believed to be reasonably secure; many of these pictures can be found scattered on the next pages. But can these pictures do more than give us a visual representation of hard-to-quantify parameters and characteristics of a generator? Could an attacker use these mysterious three-dimensional shapes in meaningful ways, or could a computer examine them somehow to give us a clear answer about what is wrong and what is right? Is a sunflower-shaped generator easier to crack than a brick-shaped one?<a id="IDX-CHP-10-0518" class="indexterm"/><a id="IDX-CHP-10-0519" class="indexterm"/><a id="IDX-CHP-10-0520" class="indexterm"/><a id="IDX-CHP-10-0521" class="indexterm"/><a id="IDX-CHP-10-0522" class="indexterm"/><a id="IDX-CHP-10-0523" class="indexterm"/><a id="IDX-CHP-10-0524" class="indexterm"/><a id="IDX-CHP-10-0525" class="indexterm"/><a id="IDX-CHP-10-0526" class="indexterm"/></p><p>Before answering this question, allow me to interrupt myself and include a short gallery of some of the more interesting results acquired in the process of writing the original paper. This should help to demonstrate the wide variety and beauty of some of the observed patterns, following the ancient rule that a three-dimensional plot is worth a thousand words. <a class="xref" href="ch10s05.html#windows_98._the_set_shown_here_has_a_dia" title="Figure 10-6. Windows 98. The set shown here has a diameter of approximately 128, which indicates that subsequent ISNs are increased by a number carrying about 7 bits of “randomness.” Within the set, there is a strong frequency pattern similar to one of the examples discussed in the previous section, perhaps suggesting a trivial time dependency in all results. The size of the attractor is worryingly small.">Figure 10-6</a> through <a class="xref" href="ch10s05.html#openvms_7.2_open_parenthesis_default_tcp" title="Figure 10-14. OpenVMS 7.2 (default TCP/IP stack). A 32-bit-wide structure with little randomness, showing strong but fairly unusual correlation patterns indicative of a broken PRNG design">Figure 10-14</a> show PRNG portraits for several operating systems.</p><p>Not all plots are drawn to the same scale; some shapes are considerably smaller than others. The scale and other parameters can be read from the top line of every plot, as shown in <a class="xref" href="ch10s05.html#windows_98._the_set_shown_here_has_a_dia" title="Figure 10-6. Windows 98. The set shown here has a diameter of approximately 128, which indicates that subsequent ISNs are increased by a number carrying about 7 bits of “randomness.” Within the set, there is a strong frequency pattern similar to one of the examples discussed in the previous section, perhaps suggesting a trivial time dependency in all results. The size of the attractor is worryingly small.">Figure 10-6</a>.</p><div class="figure"><a id="a_common_time_dependency_pattern_comma_a"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7064"/><img src="httpatomoreillycomsourcenostarchimages1138076.png.jpg" alt="A common time dependency pattern, as observed in imperfect testing conditions"/></div></div><p class="title">Figure 10-5. A common time dependency pattern, as observed in imperfect testing conditions</p></div><div class="figure"><a id="windows_98._the_set_shown_here_has_a_dia"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7072"/><img src="httpatomoreillycomsourcenostarchimages1138078.png.jpg" alt="Windows 98. The set shown here has a diameter of approximately 128, which indicates that subsequent ISNs are increased by a number carrying about 7 bits of “randomness.” Within the set, there is a strong frequency pattern similar to one of the examples discussed in the previous section, perhaps suggesting a trivial time dependency in all results. The size of the attractor is worryingly small."/></div></div><p class="title">Figure 10-6. Windows 98. The set shown here has a diameter of approximately 128, which indicates that subsequent ISNs are increased by a number carrying about 7 bits of “randomness.” Within the set, there is a strong frequency pattern similar to one of the examples discussed in the previous section, perhaps suggesting a trivial time dependency in all results. The size of the attractor is worryingly small.</p></div><div class="figure"><a id="freebsd_4.2._a_16-bit-wide_uniform_cube"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7080"/><img src="httpatomoreillycomsourcenostarchimages1138080.png.jpg" alt="FreeBSD 4.2. A 16-bit-wide uniform cube, likely a sign of small but truly random increments in every step"/></div></div><p class="title">Figure 10-7. FreeBSD 4.2. A 16-bit-wide uniform cube, likely a sign of small but truly random increments in every step</p></div><div class="figure"><a id="hp_solidus_ux_11._a_strange_x-wing_struc"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7088"/><img src="httpatomoreillycomsourcenostarchimages1138082.png.jpg" alt="HP/UX 11. A strange x-wing structure, 18 bits wide but obviously irregular, likely a sign of high-correlation levels of a flawed PRNG"/></div></div><p class="title">Figure 10-8. HP/UX 11. A strange x-wing structure, 18 bits wide but obviously irregular, likely a sign of high-correlation levels of a flawed PRNG</p></div><div class="figure"><a id="mac_os_9._a_similar_but_slightly_differe"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7096"/><img src="httpatomoreillycomsourcenostarchimages1138084.png.jpg" alt="Mac OS 9. A similar but slightly different 17-bit structure"/></div></div><p class="title">Figure 10-9. Mac OS 9. A similar but slightly different 17-bit structure</p></div><div class="figure"><a id="windows_nt_4.0_sp3._again_comma_a_strong"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7104"/><img src="httpatomoreillycomsourcenostarchimages1138086.png.jpg" alt="Windows NT 4.0 SP3. Again, a strong attraction pattern and a tiny 8-bit-wide attractor"/></div></div><p class="title">Figure 10-10. Windows NT 4.0 SP3. Again, a strong attraction pattern and a tiny 8-bit-wide attractor</p></div><div class="figure"><a id="irix_6.5_a_16-to-18-bit-wide_highly"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7114"/><img src="httpatomoreillycomsourcenostarchimages1138088.png.jpg" alt="IRIX 6.5. A 16-to-18-bit-wide highly irregular random cloud; likely a flawed algorithm"/></div></div><p class="title">Figure 10-11. <span class="emphasis"><em>IRIX</em></span> 6.5. A 16-to-18-bit-wide highly irregular random cloud; likely a flawed algorithm</p></div><div class="figure"><a id="netware_6._a_seemingly_random_system_com"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7123"/><img src="httpatomoreillycomsourcenostarchimages1138090.png.jpg" alt="NetWare 6. A seemingly random system, with a 32-bit-wide attractor cloud, but consisting of a large number of high-density spots and not uniform"/></div></div><p class="title">Figure 10-12. NetWare 6. A seemingly random system, with a 32-bit-wide attractor cloud, but consisting of a large number of high-density spots and not uniform</p></div><div class="figure"><a id="unicos_10.0.0.8._a_strange_comma_17-bit"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7131"/><img src="httpatomoreillycomsourcenostarchimages1138092.png.jpg" alt="UNICOS 10.0.0.8. A strange, 17-bit-wide cloud with irregular stretches of higher hit probabilities"/></div></div><p class="title">Figure 10-13. UNICOS 10.0.0.8. A strange, 17-bit-wide cloud with irregular stretches of higher hit probabilities</p></div><div class="figure"><a id="openvms_7.2_open_parenthesis_default_tcp"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7139"/><img src="httpatomoreillycomsourcenostarchimages1138094.png" alt="OpenVMS 7.2 (default TCP/IP stack). A 32-bit-wide structure with little randomness, showing strong but fairly unusual correlation patterns indicative of a broken PRNG design"/></div></div><p class="title">Figure 10-14. OpenVMS 7.2 (default TCP/IP stack). A 32-bit-wide structure with little randomness, showing strong but fairly unusual correlation patterns indicative of a broken PRNG design</p></div></div>
<div class="sect1" title="Attacking with Attractors"><div class="titlepage"><div><div><h1 class="title"><a id="attacking_with_attractors"/>Attacking with Attractors</h1></div></div></div><p>Now, back to the question of sunflowers versus bricks. Yes, the relevance of the pretty pictures goes beyond visual delight for hard-core computer geeks. As it turns out, the attractor structure captured for each system creates a matrix of possible ISN behavior patterns, with densities that correspond to probabilities of a specific type of time dependency or statistical pattern appearing over time. Higher-density regions within the attractor correspond to historical correlations, which are also more likely to occur in the future; less populated areas are less likely to be visited. As such, once the approximate attractor for a specific system is mapped out, the attacker can guess at future results. But how, precisely, do those shapes map back to exact ISN values?</p><p>The key to a successful attack is recognizing that the <span class="emphasis"><em>x</em></span> coordinate of every point in the attractor depends on the value of <span class="emphasis"><em>D<sub>t</sub></em></span>—that is, on the sequence numbers observed at time <span class="emphasis"><em>t</em></span> and <span class="emphasis"><em>t-1</em></span> (because <span class="emphasis"><em>D<sub>t</sub></em></span> = <span class="emphasis"><em>S<sub>t</sub></em></span>- <span class="emphasis"><em>S<sub>t-1</sub></em></span>). The <span class="emphasis"><em>y</em></span> coordinate, on the other hand, depends on <span class="emphasis"><em>D<sub>t-1</sub></em></span> (ISNs at <span class="emphasis"><em>t-1</em></span> and <span class="emphasis"><em>t-2</em></span>), and <span class="emphasis"><em>z</em></span> depends on <span class="emphasis"><em>D<sub>t-2</sub></em></span> (ISNs at <span class="emphasis"><em>t-2</em></span> and <span class="emphasis"><em>t-3</em></span>).</p><p>Let’s assume an attacker has sent three probes to a remote system, for whose operating system the attractor structure has been mapped. The probes correspond to times <span class="emphasis"><em>t−3</em></span>, <span class="emphasis"><em>t−2</em></span>, and <span class="emphasis"><em>t−1</em></span> and—naturally—are sufficient to reconstruct the <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> coordinates of the point that would mark the behavior of the system at this particular time on the attractor structure.</p><p>The attacker can use this information to deduce values of <span class="emphasis"><em>x</em></span> for known <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> that are more likely to occur than others, based on the observation of the irregularities in the attractor structure noticed thus far. The <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> coordinates correspond to a single line in the attractor space, perpendicular to the <span class="emphasis"><em>x</em></span> plane (as shown in <a class="xref" href="ch10s06.html#an_lattack_liner_intersecting_the_attrac" title="Figure 10-15. An “attack line” intersecting the attractor">Figure 10-15</a>)—the collection of points with all possible <span class="emphasis"><em>x</em></span> values, but known remaining coordinates. The collection of points at which the line intersects with or nears the high-density areas of the attractor forms a set of most likely values for the <span class="emphasis"><em>x</em></span> coordinate. The areas of lowest density are, obviously, least likely to correspond to the correct value of <span class="emphasis"><em>x</em></span>; after all, the attractor points did not show up there during previous measurements.</p><p>The ability to construct a set of candidates for the <span class="emphasis"><em>x</em></span> value for known <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> is a major step toward a successful attack: knowing <span class="emphasis"><em>S<sub>t-1</sub></em></span> (which, you will recall, was previously acquired by the attacker), the attacker can easily calculate <span class="emphasis"><em>S<sub>t</sub></em></span> for every candidate <span class="emphasis"><em>x</em></span> (<span class="emphasis"><em>D<sub>t</sub></em></span>) value, as follows:</p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>S<sub>t</sub></em></span> = <span class="emphasis"><em>x + S</em></span><sub><span class="emphasis"><em>t</em></span> − 1</sub></td></tr></table><p>Having sampled three previous sequence numbers, <span class="emphasis"><em>S<sub>t-3</sub></em></span>, <span class="emphasis"><em>S<sub>t-2</sub></em></span>, and <span class="emphasis"><em>S<sub>t-1</sub></em></span>, the attacker can thus determine a set of likely candidates for the next sequence number, <span class="emphasis"><em>S<sub>t</sub></em></span>, which will likely be chosen for the next connection by the attacked system—the one the attacker did not initiate, but which he hopes to interfere with. The attacker can then execute an attack by sending TCP/IP packets with the candidate sequence numbers; he does not have to get it right from the beginning because all wrong guesses will simply be disregarded by the remote implementation. However, as soon as the value of any of the spoofed packets agrees with the expected number, within the expected window size, the traffic will be accepted, thereby defeating the session integrity protection offered by TCP/IP.</p><div class="figure"><a id="an_lattack_liner_intersecting_the_attrac"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7327"/><img src="httpatomoreillycomsourcenostarchimages1138096.png.jpg" alt="An “attack line” intersecting the attractor"/></div></div><p class="title">Figure 10-15. An “attack line” intersecting the attractor</p></div><p>The attack has some caveats, of course:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Their observed dynamics might be local to the observation conditions or source itself—though judging from the achieved success ratio when this technique is deployed against common implementations, this is unlikely.</p></li><li class="listitem"><p>If the candidate set is particularly large—as with algorithms that produce uniform attractor clouds with no clear irregularities—the technique becomes fairly impractical because it requires too many attempts to make a correct guess.</p></li><li class="listitem"><p>Because it is often impractical to sample the entire sequence of values generated by an ISN implementation in a system (some systems have long or even unlimited cycles), it is impossible to construct a complete attractor. To counter this, you must use an approximate approach: the value is chosen as a candidate if a point is present within a given radius from a specific point on the (<span class="emphasis"><em>y,z</em></span>) line, thus compensating for the fact that even fairly dense areas of the attractor can still contain gaps.</p></li></ul></div><p>To keep the results meaningful and to establish a method for comparative assessment of the quality of a ISN generator, I decided to empirically estimate the success ratio with a limited number of tries. Specifically, I wanted to determine the likelihood of hitting the correct number given 5,000 attempts, based on the assumption that an attacker using a low- to mid-end network connection could send at most 5,000 packets in a short period of time.<sup>[<a id="CHP-10-FN-1" href="#ftn.CHP-10-FN-1" class="footnote">22</a>]</sup></p><p>To test the validity of the approach, I chose to estimate the probability of success by dividing the input data acquired from remote systems into two parts: one part to construct the attractor and the other to perform actual tests. The test read four subsequent sequence numbers at once and then fed three of them to an implementation that, based on the attractor data, had to then generate a set of as many as 5,000 values. Finally, the output was compared with the fourth number acquired from the test data set. The test was repeated hundreds of times for subsequent ISN quadruplets for every attractor to determine an approximate successful guess percentage, which, in practice, denotes how likely the attacker is to succeed using this approach.</p><p>Following are some of the results for the systems in the attractor gallery:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Operating System</p></th><th style="text-align: left" valign="bottom"><p>Attack Feasibility</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>IRIX 6.5.15</p></td><td style="text-align: left" valign="top"><p>25% (25 out of 100 attempts)</p></td></tr><tr><td style="text-align: left" valign="top"><p>OpenVMS 7.2</p></td><td style="text-align: left" valign="top"><p>15.00%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Windows NT 4.0 SP3</p></td><td style="text-align: left" valign="top"><p>97.00%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Windows 98</p></td><td style="text-align: left" valign="top"><p>100.00%</p></td></tr><tr><td style="text-align: left" valign="top"><p>FreeBSD 4.2</p></td><td style="text-align: left" valign="top"><p>1%</p></td></tr><tr><td style="text-align: left" valign="top"><p>HP/UX 11</p></td><td style="text-align: left" valign="top"><p>100.00%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Mac OS 9</p></td><td style="text-align: left" valign="top"><p>89.00%</p></td></tr></tbody></table></div><p>This approach was obviously fairly effective<sup>[<a id="CHP-10-FN-2" href="#ftn.CHP-10-FN-2" class="footnote">23</a>]</sup> and prompted many vendors to redesign their algorithms or revisit their claims about algorithm security. (Follow-up research that I published one year later (2002) reviewed some of these changes, of which not all were satisfactory.)</p><p>But the real question is, What does this have to do with passive operating system fingerprinting?</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-10-FN-1" href="#CHP-10-FN-1" class="para">22</a>] </sup>The smallest SYN packet has 40 bytes; hence, sending 5,000 SYN packets consumes at least 200 kilobytes of bandwidth. This amount of data can be successfully sent out over a modem line with V42.bis modem compression in a matter of 10–20 seconds. The choice of this threshold is quite arbitrary, but seems reasonable.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-10-FN-2" href="#CHP-10-FN-2" class="para">23</a>] </sup>These results apply to scenarios in which a precise data injection or spoofing is necessary. If less precision is required or if the only goal of an attacker is to cause a disruption, the remote party is not only going to accept packets with the exact sequence number, but also those that fit within the window size, as specified in TCP/IP parameters (see <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>). In other words, DoS attacks will be even more successful.</p></div></div></div>
<div class="sect1" title="Back to System Fingerprinting"><div class="titlepage"><div><div><h1 class="title"><a id="back_to_system_fingerprinting"/>Back to System Fingerprinting</h1></div></div></div><p>Indeed, a couple of truly fascinating consequences result from our ability to map out the dynamics of a sequence number generator in a particular system and from the fact that most implementations exhibit certain more or less unique phase-space patterns. The most obvious trick is the application of ISN probing to old-school system fingerprinting.<a id="IDX-CHP-10-0527" class="indexterm"/></p><p>By observing a couple of sequence numbers acquired from a remote system (for example, when a party attempts to establish several connections to a server) you can attempt to find an attractor to which this data fits best, by comparing the observed sample against a library of known attractors. (The numbers don’t need to be predictable using the attack technique described; the attractor for a system need only be distinct.)</p><p>When compared with traditional, passive fingerprinting, this method usually provides us with less detailed insight into the system’s configuration, but it is also nearly foolproof. To thwart the technique, you would have to modify the way sequence numbers are generated, but it is usually impossible to significantly tweak ISN-generation settings from the user space, and a modification of the kernel without degrading security usually requires a good dose of knowledge and skill (not to mention, access to the sources).</p><p>But, is that all? Of course not!</p><div class="sect2" title="ISNProber—Theory in Action"><div class="titlepage"><div><div><h2 class="title"><a id="isnprobermtheory_in_action"/>ISNProber—Theory in Action</h2></div></div></div><p>Pictures and theory aside, it would be good to see how an ISN sampling works in the real world and how can it help to assess the configuration of a remote system or identify its instances. Fortunately for me, there is a program worth mentioning.<a id="IDX-CHP-10-0530" class="indexterm"/><a id="IDX-CHP-10-0531" class="indexterm"/><a id="IDX-CHP-10-0528" class="indexterm"/><a id="IDX-CHP-10-0529" class="indexterm"/></p><p>After reading my TCP/IP ISN analysis paper, Toni Vandepoel wrote a great tool called ISNProber. ISNProber uses sequence number analysis to differentiate among several instances of the same system, based on the observation that two distinct systems are likely to be at different locations in the attractor.</p><p>At its most trivial, ISNProber can tell that two systems are hiding behind a shared address, based on the appearance of observed ISNs. For the sake of simplicity, let’s assume that system Y uses an increase-by-one ISN-generator design. We approach an IP address of a website <a class="ulink" href="http://www.example.com">www.example.com</a> and want to determine how many systems there are. We first identify <a class="ulink" href="http://www.example.com">www.example.com</a> as system Y, establish several subsequent connections, and then observe ISNs as follows: 10, 11, 534, 13, 540, 19.</p><p>It should be obvious that the lower numbers form a sequence originating from a computer that either handled less traffic or has a lower uptime (10, 11, 13, 19), whereas the higher numbers correspond to the other system. Hence, two computers are “co-serving” the same public IP, perhaps behind a load balancer. Furthermore, by varying sampling intervals, we can carefully examine the type of load balancer, its request distribution policy, and the traffic it receives.</p><p>This approach can not only differentiate systems hiding behind a common address, but also track users of system Y as they hop from one IP to another, for as long as they do not reboot their machine (and hence reset the ISN counter). For systems that offer ISN-generation schemes more sophisticated than the one in our example, the distinction can be more difficult, but it is certainly possible, as long as the ISNs are not purely random on all 32 bits. (If they are, collision-related concerns arise.)</p><p>The approach used here simply requires that a dose of predictability be present in the ISN-generation algorithm. As such, TCP/IP initial sequence analysis seems to be a promising alternative or addition to traditional passive fingerprinting—and can, quite regrettably, serve as a useful tool for privacy invasion and user tracking, too.</p></div></div>
<div class="sect1" title="Preventing Passive Analysis"><div class="titlepage"><div><div><h1 class="title"><a id="preventing_passive_analysis"/>Preventing Passive Analysis</h1></div></div></div><p>Defending against sequence-number prediction is fairly trivial, and good solutions, such as Steven M. Bellovin’s RFC1948<sup>[<a href="apb.html#ftn.CHP-10-BIB-2" class="footnoteref">87</a>]</sup> specification, have been available for a long time. However, preventing passive analysis of the numbers is quite difficult, because the problem results not only from the weakness of the algorithms, but also from the diversity of the algorithms used, which causes few systems to share the same ISN footprint. Even among systems that implement RFC1948 or that use other cryptograph-ically secure, external entropy-based generators, behavioral patterns may vary significantly, depending on the subtleties of the algorithm and the implementor’s assumptions as to the values that would be sufficient to thwart an attack.<a id="IDX-CHP-10-0532" class="indexterm"/><a id="IDX-CHP-10-0533" class="indexterm"/><a id="IDX-CHP-10-0534" class="indexterm"/></p><p>A degree of prevention can be achieved by deploying a stateful packet firewall that rewrites all sequence numbers in outgoing packets<sup>[<a id="CHP-10-FN-3" href="#ftn.CHP-10-FN-3" class="footnote">24</a>]</sup>; this makes all systems within a protected network appear roughly the same. Unfortunately, only some offer this functionality, and only some can benefit from it.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-10-FN-3" href="#CHP-10-FN-3" class="para">24</a>] </sup>Solar Designer points out that, technically, this can also be implemented as a clever hack in a stateless firewall. The firewall may combine (through XOR, for example) the original sequence number with a secure hash of a secret key, combined with a quadruplet of addresses and ports that uniquely identify a connection. Returning packets could then have the hash removed (by subsequent XORing), making the packet match the internal host’s idea of the connection upon delivery, but existing only in an unpredictable, random 32-bit form while outside the firewall. This would work for all but the most broken (frequently repeating and collision-prone) ISN implementations.</p></div></div></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id5"/>Food for Thought</h1></div></div></div><p>The technique of phase-space analysis is useful in fields that go far beyond sequence-number generation. Other parameters that are chosen pseudo-randomly or according to some internal scheme—such as IP packet ID fields, DNS request identifiers (as shown in <a class="xref" href="ch10s09.html#an_interesting_attractor_pattern_for_lin" title="Figure 10-16. An interesting attractor pattern for Linux name-resolver implementation">Figure 10-16</a>), application-generated “secret” cookies that identify user sessions, and so on—can be analyzed successfully, either to find flaws in a design or to identify an implementation and simplify further analysis or facilitate an attack.<a id="IDX-CHP-10-0535" class="indexterm"/><a id="IDX-CHP-10-0536" class="indexterm"/><a id="IDX-CHP-10-0537" class="indexterm"/><a id="IDX-CHP-10-0538" class="indexterm"/><a id="IDX-CHP-10-0539" class="indexterm"/></p><div class="figure"><a id="an_interesting_attractor_pattern_for_lin"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7536"/><img src="httpatomoreillycomsourcenostarchimages1138098.png.jpg" alt="An interesting attractor pattern for Linux name-resolver implementation"/></div></div><p class="title">Figure 10-16. An interesting attractor pattern for Linux name-resolver implementation</p></div><p>Some work in this direction had been done or is under way; in a paper partly related to my original research, Joe Steward provides insight into some of the DNS system problems<sup>[<a href="apb.html#ftn.CHP-10-BIB-3" class="footnoteref">88</a>]</sup> that arise with the advancement of sequence number-prediction mechanisms. He notes that not only a UDP-based DNS protocol offers request verification methods that are simply not enough to withstand even “low-budget” spoofing attacks, but also the low quality of unique request identifiers generated by various implementations further weaken the scheme to make it trivially vulnerable to malicious data injection. Given that DNS is one of core services of the Internet, and that the perspective of spoofing a DNS response for a popular site to redirect all users of a specific network to a different web page is not exactly not tempting, DNS poisoning tops my list of downplayed threats on the Internet.<a id="IDX-CHP-10-0540" class="indexterm"/></p><p>Dan Kaminsky provides some interesting, more advanced visualizations of supposedly random data at <a class="ulink" href="http://www.doxpara.com/pics/index.php?album=phentropy">http://www.doxpara.com/pics/index.php?album=phentropy</a> (<a class="xref" href="ch10s09.html#danas_rendition_of_bsd_kernel_randomness" title="Figure 10-17. Dan’s rendition of BSD kernel randomness (courtesy of www.doxpara.com)">Figure 10-17</a>), definitely a worthy read.</p><div class="figure"><a id="danas_rendition_of_bsd_kernel_randomness"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e7560"/><img src="httpatomoreillycomsourcenostarchimages1138100.png.jpg" alt="Dan’s rendition of BSD kernel randomness (courtesy of www.doxpara.com)"/></div></div><p class="title">Figure 10-17. Dan’s rendition of BSD kernel randomness (courtesy of <a class="ulink" href="http://www.doxpara.com">www.doxpara.com</a>)</p></div></div>
<div class="chapter" title="Chapter&#xA0;11.&#xA0;In Recognition of Anomalies"><div class="titlepage"><div><div><h1 class="title"><a id="in_recognition_of_anomalies"/>Chapter 11. In Recognition of Anomalies</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Or what can be learned from subtle imperfections of network traffic</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>In the previous chapters, I dissected and analyzed a number of ways to extract chunks of potentially and likely valuable information from seemingly irrelevant, “technical” parameters supplied along with every message transmitted by a suspect over the network. As I hope you have seen, we can obtain a considerable amount of data on the sender that the sender is surely unaware of providing (or, at the very least, not very happy about often being unable to opt out of providing that data). Using a wide array of packet and stream analysis tricks, in a perfect and happy world we can measure many characteristics of the remote party and can map their behavior to a specific system’s signature and network configuration.</p><p>However, the reality is a bit different: some of the observed parameters deviate at least slightly from the expected set of values normally associated with a specific device or network configuration that the suspect is using. Although you may simply ignore these seemingly senseless and accidental discrepancies and still successfully identify the originating system or track its users, it is not necessarily wise to do so. We learn to pay no attention to seemingly meaningless annoyances like this, but nothing in the world of computing happens without a good reason (given a fairly lax definition of “good,” at least), and exploring the mechanism behind these apparently random anomalies and minority patterns, rather than ignoring them, can provide valuable information about the previously unseen specifics of network configuration.</p><p>In this chapter I take a closer look at some of the processes that can affect the observed characteristics of a system. I explain the underlying reason for, the purpose of (or lack thereof), and the consequences of the technologies that prompt such behavior.</p><p>Needless to say, most of the reproducible modifications to IP packets discussed here originate from more advanced types of IP-aware intermediate systems. Therefore, I’ll begin with a consideration of two long-neglected subjects: firewalls in general, and network address translation (NAT) in particular.</p><p>Firewalls are intended to remain stealthy bastions, and the less that is known about what the other guy uses, the better for him. Yet, despite rigorous firewall policies and settings, as these devices increase in complexity and become better suited to handle today’s security challenges, they also become easier to examine using indirect or passive probe techniques.</p><div class="sect1" title="Packet Firewall Basics"><div class="titlepage"><div><div><h1 class="title"><a id="packet_firewall_basics"/>Packet Firewall Basics</h1></div></div></div><p>Popular firewalls<sup>[<a href="apb.html#ftn.CHP-11-BIB-1" class="footnoteref">89</a>]</sup> are, in essence, a class of intermediate router devices engineered to violate the fundamental design of an intermediate router device. As opposed to routers proper, systems that are expected to make nondiscriminatory routing decisions based on the information encoded on the third OSI layer, firewalls usually interpret, act upon, or even modify information on higher layers (such as TCP or even HTTP). Firewall technology, although fairly recent, provides a well-established and well-understood set of solutions and can be found in home networks and in large corporations. Firewalls are configured to reject, allow, or redirect specific types of traffic addressed to specific services and are (not surprisingly) used to limit access to certain functions and resources for all traffic traveling across such a device. Hence, they provide a powerful, albeit sometimes overhyped and overly relied upon, security and network management solution.<a id="IDX-CHP-11-0541" class="indexterm"/></p><p>The key to the success of firewalls in all network environments is that they protect an array of complex systems using a single and comparatively more robust component and provide a fail-safe security measure if a configuration problem exposes a vulnerable service or function on a protected server. (In extreme cases, firewalls are used simply to cover for poor configuration and lack of maintenance of a protected system, usually with disastrous results.)</p><div class="sect2" title="Stateless Filtering and Fragmentation"><div class="titlepage"><div><div><h2 class="title"><a id="stateless_filtering_and_fragmentation"/>Stateless Filtering and Fragmentation</h2></div></div></div><p>Basic firewalls are stateless packet filters. They simply inspect certain features of every packet, such as the destination port on Transmission Control Protocol SYN connection attempts. They then decide, based on these characteristics alone, whether to allow the packet to go through. The stateless design is extremely simple, reliable, and memory and resource efficient. For example, a stateless firewall can limit incoming connections to a mail server to only those addressed to port 25 (SMTP) by dropping all SYN packets but those addressed to this port. Because no connection can be established without this initial SYN packet, the attacker cannot interact with applications on other ports in a meaningful manner. To achieve this, the firewall does not have to be nearly as fast and complex as the mail server itself, because it does not need to keep a record of currently established connections and their exact state.<a id="IDX-CHP-11-0542" class="indexterm"/><a id="IDX-CHP-11-0543" class="indexterm"/><a id="IDX-CHP-11-0544" class="indexterm"/><a id="IDX-CHP-11-0545" class="indexterm"/></p><p>The problem with this type of completely transparent protection is that the firewall and the final recipient might understand some of the parameters differently. For example, say an attacker convinces the firewall that it is connecting to an allowed port, but crafts its traffic so that the final recipient reads it differently and establishes a connection to a port that the firewall is supposed to be protecting. An attacker can thus access a vulnerable service or an administrative interface, and we are in trouble.</p><p>Although causing such a misunderstanding might sound unlikely, it turned out to be fairly easy to achieve with the help of our old friend, packet fragmentation, using an approach commonly referred to as the “overlapping fragment attack”<sup>[<a href="apb.html#ftn.CHP-11-BIB-2" class="footnoteref">90</a>]</sup> (described in 1995 by RFC1858). In this situation, the attacker sends an initial packet, containing the beginning of the Transmission Control Protocol SYN request, to a port that is allowed by the victim’s firewall (such as the aforementioned port 25). The packet is missing only a tiny bit at the end and has a “more fragments” flag set in its IP header, but why should the firewall bother about the trailing data in a packet?</p><p>The firewall examines the packet, and because it is a SYN packet, its destination port is also examined and found acceptable. The packet is passed through, but the recipient does not interpret it immediately (remember the reassembly process discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>?). Instead, the packet is kept, pending the successful completion of defragmentation, which will not occur until the last trailing chunk of the packet arrives.</p><p>Next, the attacker sends a second packet fragment. This second packet is created to overlap with the original packet just enough so that it overwrites the destination port (one of the fields of the TCP header) at its location in the reassembly buffer. The fragment is crafted so that it starts at a nonzero offset and lacks most of the TCP header, except for the overwritten bit.</p><p>Because of this (and because it lacks the information needed to examine the flags of a TCP packet or other vital parameters the firewall could use to determine whether to allow or block this traffic), the second fragment is usually relayed as is by a stateless firewall. When combined with the first packet by the recipient, this second packet overwrites the original destination port to a more naughty value chosen by the attacker and actually opens a connection to a port that should be protected by the firewall.</p><p>Whoops.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>To protect against this attack, a well-designed stateless firewall performs initial defragmentation before analyzing packets. This, however, makes it somewhat less “stateless,” and less transparent.</p></div></div><div class="sect2" title="Stateless Filtering and Out-of-Sync Traffic"><div class="titlepage"><div><div><h2 class="title"><a id="stateless_filtering_and_out-of-sync_traf"/>Stateless Filtering and Out-of-Sync Traffic</h2></div></div></div><p>Another problem with stateless packet filters is that they are not nearly as tight as we might hope. The filtering can only be carried out when a single packet contains all the information necessary for the filter to make an informed decision on how to handle it. Because, following the initial handshake, a TCP connection is largely symmetrical, with both parties having equal rights and using the same type of traffic (ACK packets) to exchange data, it is not easy to apply meaningful filters to anything other than the initial phase of a connection. There is no way to determine who (if anyone) initiated the connection through which ACK packets are being swapped without actually tracking and recording connections. Thus, it is a bit hard to define in a meaningful way the filtering policy that the firewall should attempt to apply to traffic such as ACK and other midway packets such as FIN or RST.<a id="IDX-CHP-11-0546" class="indexterm"/><a id="IDX-CHP-11-0547" class="indexterm"/><a id="IDX-CHP-11-0548" class="indexterm"/><a id="IDX-CHP-11-0549" class="indexterm"/><a id="IDX-CHP-11-0550" class="indexterm"/></p><p>The inability to filter past SYN is not normally a problem. After all, if an attacker cannot deliver the initial SYN packets, they cannot establish a connection. But there’s a catch: how systems handle non-SYN traffic to a specific port depends on whether a port is closed or the system is listening on that port. For example, some operating systems reply with RST to stray FIN packets and generate no reply on ports that are in open (listening) state.<sup>[<a id="CHP-11-FN-1" href="#ftn.CHP-11-FN-1" class="footnote">25</a>]</sup></p><p>Techniques such as a FIN or ACK scan (the latter initially described by Uriel Maimon<sup>[<a href="apb.html#ftn.CHP-11-BIB-3" class="footnoteref">91</a>]</sup> in <span class="emphasis"><em>Phrack Magazine</em></span>), as well as NUL and Xmas scans (scans with illegal packets with no flags set and all flags set, respectively) can thus be used against stateless packet filters to gather preattack evidence about which ports are open on a remote system or to map out what traffic is being dropped by the firewall. The ability to learn that a specific port is open without the ability to establish a proper connection to it is not an immediate threat by itself. However, a scan of this nature often discloses extremely valuable information about network internals (such as the operating system and services being run), which can be used to facilitate a better, more efficient, and more-difficult-to-detect attack once the first line of defense is compromised or bypassed. Thus, this is perceived as a potential weakness of a stateless firewall.<a id="IDX-CHP-11-0551" class="indexterm"/></p><p>Perhaps a more grave threat is associated with the mechanism of SYN cookies when combined with stateless filtering. SYN cookies are used to protect operating systems against resource starvation attacks, in which the attacker sends a very large number of spoofed connection requests to the host (not itself a difficult operation to perform). This forces the recipient to send bogus SYN+ACK replies, and additionally to allocate memory and consume other resources when adding this connection-to-be to its TCP state tables. Most systems under such an attack would either consume excess resources and slow to a crawl or deny service to all clients at some point until those bogus connections time out.<a id="IDX-CHP-11-0552" class="indexterm"/></p><p>To deal with this potential problem, SYN cookies use a cryptographical signature (a shortcut, actually, identifying the connection uniquely) in all SYN+ACK responses inside the ISN field, and then forget about the connection altogether. Only once the ACK response arrives from the host, and only if the acknowledgement number validates against the cryptographic procedure, will the connection be added to the state table.</p><p>The problem with SYN cookies, however, is that, in such a design, there is the possibility that SYN (and SYN+ACK response) was never sent in the first place. If the attacker can create an ISN cookie that validates against the host’s SYN cookie algorithm (perhaps because the attacker has enough bandwidth, or because the algorithm is weak), he can send an ACK packet that would trigger the remote host to add a new connection to its state table despite, as mentioned, not ever sending SYN and receiving SYN+ACK. A stateless firewall would have no way of knowing that a connection has just been established, because it never received the opening request in the first place! Because there is no initial SYN packet, the destination IP and port could not be checked by the firewall and either approved or rejected, and yet, a connection is all of a sudden established.</p><p>That’s really bad.</p></div><div class="sect2" title="Stateful Packet Filters"><div class="titlepage"><div><div><h2 class="title"><a id="stateful_packet_filters"/>Stateful Packet Filters</h2></div></div></div><p>To solve the problems of stateless filters, we need to store some of the information about previous traffic and the state of established streams on the firewall. This is the only way to transparently predict the outcome of defragmentation or to obtain the context for midconnection packets and decide whether they are illegitimate and should be discarded or are expected by the recipient and should be delivered.<a id="IDX-CHP-11-0553" class="indexterm"/></p><p>With the increase of affordable high-performance computing, it has become possible to devise firewall systems that are much more complex and advanced than we could ever imagine. Thus, we have progressed to stateful connection tracking, a situation in which the firewall not only examines single packets, but remembers the context of a connection and validates every packet against this data. This allows the firewall to seal the network tightly and to disregard undesirable or unexpected traffic without relying on the recipient’s ability to always tell good traffic from bad. Stateful packet filters try to track connections and allow only the traffic that belongs to one of the active sessions; as a result, they provide better protection and logging capabilities.</p><p>The task of stateful filtering is, of course, more challenging than stateless filtering and consumes considerably more resources, especially when a sizable network is protected by such a device. When protecting a large network, the firewall suddenly requires plenty of memory and a fast processor to store and look up the information about what is happening on the wire.</p><p>Stateful analysis is also more likely to cause problems or confusion. Issues ensue as soon as the understanding of the current state of a given TCP/IP session differs between the firewall and the endpoints; a situation that is not unlikely given the ambiguity of specifications and the variety of stacks used. For example, upon receiving an RST packet that is not within sequence number limits accepted by the recipient, a firewall that applies sequence number inspection less stringently than the final recipient does might conclude that a connection is closed, whereas the recipient might conclude the session is still open and be willing to accept further communications pertaining to this connection, and vice versa. In the end, stateful inspection comes at a price.</p></div><div class="sect2" title="Packet Rewriting and NAT"><div class="titlepage"><div><div><h2 class="title"><a id="packet_rewriting_and_nat"/>Packet Rewriting and NAT</h2></div></div></div><p>The solution to improving packet interpretation, and to providing better protection against attacks such as those that use packet fragmentation to bypass firewall rules, was to give firewalls the ability to not only forward, but also rewrite portions of the traffic transmitted. For example, one approach attempts to resolve ambiguity by performing a mandatory packet defrag-mentation (reassembly) before comparing the packet against any access rules configured by the network administrator.<a id="IDX-CHP-11-0554" class="indexterm"/><a id="IDX-CHP-11-0555" class="indexterm"/><a id="IDX-CHP-11-0556" class="indexterm"/><a id="IDX-CHP-11-0557" class="indexterm"/></p><p>With the development of more sophisticated solutions, it became obvious that packet rewriting would not only benefit the network, but also provide a quantum leap for network security and functionality by deploying extremely useful technologies such as NAT. NAT is the practice of mapping certain IP addresses to a different set of IPs prior to forwarding them and demangling the responses sent back by a protected system. A stateful NAT mechanism can be used, among other applications, to implement fault-tolerant setups in which a single, publicly accessible IP address is served by more than one internal server. Or to save address space and improve security, NAT can be implemented to allow the internal network to use a pool of private, not publicly accessible, addresses, while enabling hosts on the network to communicate with the Internet by “masquerading” as a single public IP machine.<a id="IDX-CHP-11-0558" class="indexterm"/></p><p>In the first scenario, NAT rewrites destination addresses on incoming packets to a number of private systems behind the firewall. This provides a fault-tolerant load-balancing setup, in which subsequent requests to a popular website (<a class="ulink" href="http://www.microsoft.com">http://www.microsoft.com</a>, perhaps) or other critical service can be distributed among an array of systems, and if any one fails, other systems can take over. The task is sometimes achieved with dedicated devices (not surprisingly called <span class="emphasis"><em>load balancers</em></span>), but often also supported by NAT-enabled firewalls.</p><p>The latter scenario, commonly referred to as <span class="emphasis"><em>masquerading</em></span>, relies on rewriting source addresses on outgoing packets so that a number of private, protected systems (that might be using private addresses not routed to this network from the Internet, such as 10.0.0.0) can connect to the external world by having their outgoing connections intercepted and rewritten by the firewall. The systems are hidden behind a firewall, and their actions appear to recipients outside the NAT-protected network as originating from the firewall. The connection is mapped to a specific public IP address and a specific port, and then the traffic is pushed out. All traffic returning from the destination to this IP and port is rewritten to point back to the private system that initiated the connection and forwarded to the internal network. This allows the entire private network of workstations that are not intended to offer any services to the Internet to remain not directly reachable from the external world, thus greatly increasing the network’s security, concealing some of its structure, and preserving expensive public IP address space that would otherwise have to be purchased to accommodate every system. Using this system, a party that has only one public IP routed to them can still construct a network of hundreds or thousands of computers and provide them with Internet access.<a id="IDX-CHP-11-0559" class="indexterm"/></p></div><div class="sect2" title="Lost in Translation"><div class="titlepage"><div><div><h2 class="title"><a id="lost_in_translation"/>Lost in Translation</h2></div></div></div><p>Once again, address translation is more complex than it might sound: some higher-level protocols are not as straightforward as just connecting to a remote system and sending a bunch of commands. For example, the ancient but wildly popular File Transfer Protocol<sup>[<a href="apb.html#ftn.CHP-11-BIB-4" class="footnoteref">92</a>]</sup> (FTP), in its most basic and most widely supported mode, relies on establishing a return (reverse direction) connection from the server back to the client for the purpose of transferring the requested data; the initial connection initiated by the client is used only to issue commands. Many other protocols—most notably some chat pro-tocols, peer-to-peer collaboration or data-sharing tools, media broadcast services, and so forth—also use weird or unusual designs that call for reverse connections and port hopping or allowing specific session-less traffic (such as User Datagram Protocol [UDP] packets) back to the workstation.<a id="IDX-CHP-11-0562" class="indexterm"/><a id="IDX-CHP-11-0563" class="indexterm"/><a id="IDX-CHP-11-0564" class="indexterm"/><a id="IDX-CHP-11-0565" class="indexterm"/><a id="IDX-CHP-11-0560" class="indexterm"/><a id="IDX-CHP-11-0561" class="indexterm"/></p><p>To address these challenges, every implementation of masquerading that does not aim to render these protocols useless must be equipped with a number of protocol helpers. These protocols inspect the application data exchanged within a connection, even sometimes rewriting some of it and opening temporary holes in the firewall to allow for a return connection.</p><p>And herein lies another problem, first spotted in FTP helper by Mikael Olsson several years ago<sup>[<a href="apb.html#ftn.CHP-11-BIB-5" class="footnoteref">93</a>]</sup> and later researched in other protocol helpers by, among others, the author of this book.<sup>[<a href="apb.html#ftn.CHP-11-BIB-6" class="footnoteref">94</a>]</sup> The problem is that these helpers decide to open holes in the firewall based on the information sent by a workstation over a specific protocol to a remote system. They assume that the traffic generated by the system is being transmitted on the user’s behalf and with the user’s knowledge. Needless to say, some programs, such as web browsers, can be tricked into sending certain types of network traffic, including traffic that “looks like” a protocol the program does not natively support, and can even be forced to do so automatically by crafting specific malicious content and sending it to the application. This spoofed traffic can fool a helper program into poking a hole in the firewall.</p><p>A classic example of such an attack is an abuse of a generic web browser: by adding a reference to a web page or a web element supposedly located on an attacker’s system on a nonstandard HTTP port (which is, however, quite standard for FTP traffic), the client can be forced to connect to this resource and attempt to issue an HTTP request. Because the port to which the connection is established is normally used by FTP, the firewall’s FTP helper starts listening to the conversation, hoping to give a hand when necessary.</p><p>The following example URL would cause the HTTP client to connect to the FTP port and issue what appears to be an FTP <code class="literal">PORT</code>command, which would be picked up by the firewall helper:</p><a id="I_programlisting3_d1e7790"/><pre class="programlisting">HTTP://SERVER:21/FOO&lt;RETURN&gt;PORT MY_IP,122,105&lt;RETURN&gt;</pre><p>The request issued by the client would be just meaningless gibberish to a legitimate FTP service on the other end, and the service’s response would be incomprehensible to the web client issuing this request—but that’s not the point. What matters is that the attacker can control a part of the request— the file name the client will request from the server. This fictitious file name, chosen by the rogue, can contain any data the rogue wishes. By making the file name contain substrings normally identified with FTP requests, the attacker can trick an FTP protocol helper that is listening to this connection for a specific text command (<code class="literal">PORT</code>) into believing that the user is attempting to download a specific file. Hence, the remote server is temporarily allowed to connect to the victim (here, to a naughty sounding port 31337—122*256+105=31337). And so we let the attacker in without the victim knowing. Oops—again, more than we bargained for.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-11-FN-1" href="#CHP-11-FN-1" class="para">25</a>] </sup>Some aspects of this behavior (the tendency to reply with RST to stray and unexpected packets to closed ports and simply disregarding the same traffic addressed to ports on which a service listens for connections) is mandated by RFC793, and some is just a practice chosen by a specific group of implementors.</p></div></div></div>
<div class="sect1" title="The Consequences of Masquerading"><div class="titlepage"><div><div><h1 class="title"><a id="the_consequences_of_masquerading"/>The Consequences of Masquerading</h1></div></div></div><p>All of the aforementioned scenarios are related to masquerading abuse, but the mere presence of masquerading itself can provide us with interesting information about another party.<a id="IDX-CHP-11-0566" class="indexterm"/><a id="IDX-CHP-11-0567" class="indexterm"/></p><p>As noted earlier, masquerading is not nonintrusive. Its basic operating principle is to alter the outgoing traffic by rewriting portions of it. In so doing, it goes beyond merely tweaking the address and not only makes it possible to conclude that masquerading is taking place, but also enables a careful observer to identify the particular firewall system in use. Specifically, when using masquerading, we may encounter some of the following changes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>There will be an observed discrepancy between the TTL on arriving packets and the expected or measured distance to the destination network. Traffic that originated behind a masquerade is at least one hop “older” than a packet originating from a system that gets its IP address for outgoing connections directly from a protected network.</p></li><li class="listitem"><p>In most cases, various operating systems or slightly different system configurations (or uptimes) can be found in the originating network. These systems have slightly different TCP/IP characteristics, as discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a> and <a class="xref" href="ch10.html" title="Chapter 10. Advanced Sheep-Counting Strategies">Chapter 10</a>. If we observe various TCP/IP fingerprints in connections seemingly originating from the same IP, we can get a strong hint as to whether NAT is present at a particular machine with an internal network behind it.</p></li><li class="listitem"><p>Finally, a remote observer is likely to notice <span class="emphasis"><em>source port shift</em></span>. This is an other-wise unusual occurrence that arises because connections coming from the network are using ephemeral source ports that are not in the particular operating system’s normal range.</p></li></ul></div><p>Every operating system reserves a specific range of source ports for establishing a local endpoint identifier for all outgoing connections. However, a firewall often uses a different range of ports for mapping masqueraded connections that is specific to the NAT device’s operating system. In this case, if the observed ranges differ from what is expected for the detected operating system (for example, if Linux, which normally operates in the range of 1024 to 4999, appears to be using very high port numbers instead), it is possible to deduce the presence of address translation and sometimes even determine the type of firewall in use.</p><p>These techniques are commonly used and form the basis for masquerade detection and masqueraded network reconnaissance. But several other means of detecting packet rewriting are also available.</p></div>
<div class="sect1" title="Segment Size Roulette"><div class="titlepage"><div><div><h1 class="title"><a id="segment_size_roulette"/>Segment Size Roulette</h1></div></div></div><p>One of the less obvious and hence less popular ways to detect packet rewriting devices and learn more about network configuration is analyzing the maximum segment size field in incoming traffic.<a id="IDX-CHP-11-0568" class="indexterm"/><a id="IDX-CHP-11-0569" class="indexterm"/><a id="IDX-CHP-11-0570" class="indexterm"/><a id="IDX-CHP-11-0571" class="indexterm"/><a id="IDX-CHP-11-0572" class="indexterm"/><a id="IDX-CHP-11-0573" class="indexterm"/><a id="IDX-CHP-11-0574" class="indexterm"/><a id="IDX-CHP-11-0575" class="indexterm"/><a id="IDX-CHP-11-0576" class="indexterm"/></p><p>Because IP packet fragmentation adds noticeable overhead to the fragmented traffic, it is often perceived as a performance nightmare, and many implementers try to prevent it. On the other hand, as discussed earlier, fragmentation is difficult to eliminate, as it seems to be nearly impossible to accurately, quickly, and reliably determine the maximum transmission unit (MTU) over a path in advance of actual communications. Even the best method available, path MTU discovery, is far from perfect and still impacts performance when triggered. In order for it to detect the correct MTU setting by trial and error, some packets that do not fit might have to be discarded and be resent.</p><p>To prevent the performance and reliability impact of path MTU discovery and reduce the overhead of fragmentation, many NAT firewalls that rewrite certain parameters of outgoing traffic also change the declared Maximum Segment Size (MSS) parameter in TCP headers on connections originating from the private network to one more suitable for the external link from the network. This new setting is likely to be slightly narrower (have a lower MTU) than that of the LAN. This modification ensures that the receiving party does not attempt to send data that would not fit over the link if that link is across the particular part of the infrastructure with the lowest MTU, thus making fragmentation less likely to occur. (This assumes that any MTU incompatibility is most likely to occur near the sender or recipient system on the so-called last mile, where various types of low MTU links, such as DSL connections or wireless lines, are often found, and packets might need to be “downsized” to fit through those pipes.)</p><p>This reduction in the MSS alone is not particularly easy to detect. In fact, it is impossible to tell whether the MSS was set to a given value by the sender or modified somewhere down the road. That is, except for one minor thing. Recall from <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a> that there is something special about the window size selection algorithm on many of today’s systems:</p><div class="blockquote"><blockquote class="blockquote"><p>The window size setting determines the amount of data that can be sent without acknowledgment. The specific setting is often chosen according to the developer’s personal voodoo rules and other religious beliefs. The two most popular approaches say the value should be either a multiple of the MTU minus protocol headers (a value referred to as Maximum Segment Size, or MSS) or simply something sufficiently high and “round.” Older versions of Linux (2.0) used values that were powers of 2 (for example, 16,384). Linux 2.2 switched to a multiple of MSS (11 or 22 times MSS, for some reason), and newer versions of Linux commonly use 2 to 4 times MSS. The Sega Dreamcast, a network-enabled console, uses a value of 4,096, and Windows often uses 6,4512.</p></blockquote></div><p>An ever-increasing number of today’s systems (including newer versions of Linux and Solaris, certain versions of Windows, and SCO UnixWare) uses a window size setting that is a multiple of the MSS. Thus, it’s easy to tell when the MSS setting in a packet has been tampered with because the window size on the resulting packet will no longer be a specific multiple of MSS. In fact, it’s likely that it will no longer divide by MSS at all.</p><p>By comparing the MSS to window size, you can reliably detect the presence of a group of firewalls that support MSS <span class="emphasis"><em>clamping</em></span> (readjusting to match the link) on a variety of systems. Although clamping is optional on Linux and FreeBSD, it is often performed automatically on home firewalls and on smart DSL routers or other home networks. Hence, the presence of an anomalous MSS setting indicates not only a packet-rewriting device, but an association also with NAT capability, which can be taken as an indicator of the sender’s network connection.</p></div>
<div class="sect1" title="Stateful Tracking and Unexpected Responses"><div class="titlepage"><div><div><h1 class="title"><a id="stateful_tracking_and_unexpected_respons"/>Stateful Tracking and Unexpected Responses</h1></div></div></div><p>Another important consequence of stateful connection tracking and packet rewriting is that some RFC-mandated responses are generated by the firewall, not the sender. This enables an attacker to discover and probe such a device quite efficiently. When a connection is dropped from the NAT state table (whether due to a time-out or to a termination by one of the endpoints with an RST packet that did not reach the other end), further traffic in this session will not be forwarded to the recipient, as it would with stateless packet filters. It is handled directly by the firewall, instead.<a id="IDX-CHP-11-0577" class="indexterm"/><a id="IDX-CHP-11-0578" class="indexterm"/><a id="IDX-CHP-11-0579" class="indexterm"/><a id="IDX-CHP-11-0580" class="indexterm"/><a id="IDX-CHP-11-0581" class="indexterm"/></p><p>The TCP/IP specification mandates that a recipient reply to all unexpected ACK packets with RST, to inform the sender that the session they are attempting to continue is no longer honored by the recipient or never was. Some firewalls might violate the RFC and refuse to reply to this traffic at all, simply dropping packets that do not seem to belong to an existing session. (This is not always wise, because it can cause unnecessary delays when a legitimate connection is dropped due to intermittent network problems.)</p><p>Numerous devices, however, reply with a legitimate and expected RST packet. This opens yet another avenue for the detection and careful finger-printing of the firewall device. Because the packet is created from scratch by the firewall, its parameters relate to the firewall, not to what the firewall is protecting. This allows the traditional fingerprinting techniques discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a> (such as examining DF flags, TTL, window size, option types, values and ordering, and so on) to be used to identify the firewall.</p><p>There is also another possibility, per RFC1122:<sup>[<a href="apb.html#ftn.CHP-11-BIB-7" class="footnoteref">95</a>]</sup></p><div class="blockquote"><blockquote class="blockquote"><p>4.2.2.12 RST Segment: RFC-793 Section 3.4</p></blockquote></div><div class="blockquote"><blockquote class="blockquote"><p>A TCP SHOULD allow a received RST segment to include data.</p></blockquote></div><div class="blockquote"><blockquote class="blockquote"><p>DISCUSSION: It has been suggested that an RST segment could contain ASCII text that encoded and explained the cause of the RST. No standard has yet been established for such data.</p></blockquote></div><p>And indeed, even though no standard had been established, some systems choose to reply with verbose (albeit often cryptic) RST messages upon encountering a stray ACK, hoping that the other party will find comfort in knowing what went wrong. These replies often include internal keywords or, it would seem, attempts at some strange genre of geek humor that may be operating system specific, such as <code class="literal">no tcp, reset</code>; <code class="literal">tcp_close, during connect</code> (Mac OS); <code class="literal">tcp_fin_wait_2_timeout; No TCP</code> (HP/UX); <code class="literal">new data when detached; tcp_lift_anchor, can't wait</code> (SunOS).</p><p>Whenever we see such a verbose RST packet in response to network problems or unexpected traffic sent to the host, and we otherwise know that the remote system from which it originated does not use such verbose messages, we get a hint. We can deduce that there is a device between us and the recipient, likely a stateful firewall, and we can tell its operating system by matching the response against known messages produced by common and not-so-common operating systems.</p><p>These two fingerprinting techniques prove to be extremely effective in detecting the presence of stateful packet filters whenever network traffic can be observed during short-term network problems. These techniques can also be used for active fingerprinting without targeting the firewall device itself by sending a stray ACK packet to a target to differentiate stateless and stateful filters. Based on the target’s response to the packet, the attacker can then devise the best method to approach the firewall (or use the knowledge gained in other ways).</p></div>
<div class="sect1" title="Reliability or Performance: The DF Bit Controversy"><div class="titlepage"><div><div><h1 class="title"><a id="reliability_or_performance_colon_the_df"/>Reliability or Performance: The DF Bit Controversy</h1></div></div></div><p>Path MTU discovery (PMTUD) is a fingerprinting venue that is closely related to the IP fragmentation avoidance scheme described in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>.<a id="IDX-CHP-11-0582" class="indexterm"/><a id="IDX-CHP-11-0583" class="indexterm"/><a id="IDX-CHP-11-0584" class="indexterm"/><a id="IDX-CHP-11-0585" class="indexterm"/><a id="IDX-CHP-11-0586" class="indexterm"/><a id="IDX-CHP-11-0587" class="indexterm"/></p><p>Recent versions of the Linux kernel (2.2, 2.4, 2.6) and of Windows (2000 and XP) implement and enable PMTUD by default. Thus, unless this setting is changed, all traffic originating from them has a don’t fragment (DF) bit set. Again, the path discovery algorithm tends to cause issues in some rare but not entirely unheard of situations.</p><div class="sect2" title="Path MTU Discovery Failure Scenarios"><div class="titlepage"><div><div><h2 class="title"><a id="path_mtu_discovery_failure_scenarios"/>Path MTU Discovery Failure Scenarios</h2></div></div></div><p>The problem with PMTUD is that it depends on the ability for the sender of a packet to receive the ICMP error message <span class="emphasis"><em>“</em></span>fragmentation required but DF set<span class="emphasis"><em>”</em></span> and to determine the optimal settings for a connection. The packet that triggered the message is discarded before reaching the destination and has to be resized and sent again.<a id="IDX-CHP-11-0588" class="indexterm"/><a id="IDX-CHP-11-0589" class="indexterm"/></p><p>If the sender does not receive this message, they remain unaware that their packet did not get through. This prompts a delay at best or an indefinite lockup of the connection at worst, since retransmissions are also not likely to get through a link for which the maximum allowed size of a packet is smaller than what the sender is trying to push through.</p><p>The ICMP message generated when a packet is too large for a link is not guaranteed to reach the sender, however. In some networks, as a result of an ill-conceived attempt to improve security, all ICMP messages are simply dropped. Finally, even if a device sends one, it might not be delivered.</p><p>Why would ICMP messages be dropped? Because historically, many such messages were known to cause security problems: certain oversized or fragmented ICMP packets corrupted the kernel memory in many systems (also called the “ping of death”). ICMP messages sent to broadcast addresses were also used to trigger a storm of responses to a spoofed source address in an attack named “Smurf,” as well as to carry out DoS attacks. Too, incorrectly configured systems often interpreted a specific type of ICMP broadcasts, a router advertisement message,<sup>[<a id="CHP-11-FN-2" href="#ftn.CHP-11-FN-2" class="footnote">26</a>]</sup> as a command to modify their network settings. Because they would accept it, regardless of whether those messages could be trusted, this opened yet another interesting attack route. And so, ICMP is feared and blocked by many.<a id="IDX-CHP-11-0590" class="indexterm"/></p><div class="note" title="Note"><h3 class="title">Note</h3><p>A suggestion to reject all ICMP traffic can often be found in naive security guides, and some system administrators follow it. I have even seen it in a professional pen-test recommendation from an acclaimed auditor, whose name I regrettably cannot reveal here.</p></div><p>Another issue that can make PMTUD unreliable is that some received error messages come from devices that use private address space. Sometimes, in order to preserve limited public IP address space (which is usually expensive), interfaces on the cable that connect the router and the firewall of a remote network are chosen from a pool of addresses reserved for private, local use, instead of from ones actually routed to the particular network from the outside world.</p><p>Unfortunately, the use of private address space can break PMTUD. Why? Because if a packet coming from the external world is too big to be forwarded by the recipient’s firewall to the destination, the firewall sends an ICMP error message with a source address of the firewall itself, which belongs to the private pool. The firewall of the sender of the original packet can then reject such a response packet, because it appears to come from the external world, but with an IP address from a private pool (perhaps even from the same pool as the sender’s private LAN). The firewall rejects this traffic because it is usually a sign of a spoofing attempt intended to impersonate a trusted, internal host. However, in this case, this decision breaks a relatively recent PMTU discovery mechanism and leaves the original sender unaware that their packet did not get through.</p><p>To make things worse, even if all conditions are right, and the packet reaches its destination, many of today’s devices limit ICMP response rates and will not send more than a given number of messages during a particular time period. This, too, has been implemented as a security measure. Because ICMP messages were designed for informational purposes only and were not critical to communication before the introduction of PMTUD algorithms, rate limiting seemed like a sensible way to fend off certain types of DoS or bandwidth starvation attacks.</p></div><div class="sect2" title="The Fight against PMTUD, and Its Fallout"><div class="titlepage"><div><div><h2 class="title"><a id="the_fight_against_pmtud_comma_and_its_fa"/>The Fight against PMTUD, and Its Fallout</h2></div></div></div><p>In light of the foregoing, some regard PMTUD as a fairly bad design. It offers a slight performance improvement but at the price of infrequent but persistent and usually hard-to-diagnose problems that can prevent users from accessing specific servers or cause their connections to stall unexpectedly. Although many “black-hole detection” algorithms were devised to detect hosts or networks for which PMTUD should be disabled (and these work with varying success), this does not fully solve the problem and can introduce additional delays—usually when least desirable.</p><p>To solve these problems and avoid complaints, some commercial firewall vendors configure their solutions to perform a dirty trick: They clear the DF flag on all outgoing traffic. This is a subtle and often appreciated modification, but it is also a great way to identify the presence of a packet-filtering and rewriting device. If the characteristics of PMTUD-enabled systems are observed at a given address or a given network, but the incoming packets lack a DF flag as expected, the careful observer can deduce the presence and type of a firewall, thus obtaining another tiny bit of data without any interaction with the victim.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-11-FN-2" href="#CHP-11-FN-2" class="para">26</a>] </sup>Router advertisements were intended to allow the autoconfiguration of network hosts without the need to enter any settings by hand. The router periodically—or on request—broadcast a message saying, “Here I am. Use me.” By default, some systems accepted unsolicited advertisements without much hesitation—a bad idea.</p></div></div></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id6"/>Food for Thought</h1></div></div></div><p>This concludes my little story about how making firewalls better and more powerful to prevent infiltration and direct reconnaissance also made them easier to examine with indirect assessment. But allow me this brief digression.<a id="IDX-CHP-11-0591" class="indexterm"/><a id="IDX-CHP-11-0592" class="indexterm"/><a id="IDX-CHP-11-0593" class="indexterm"/><a id="IDX-CHP-11-0594" class="indexterm"/></p><p>Perhaps the most bizarre and interesting discovery is one I encountered somewhere back in 1999. Although not directly related to the design of firewalls, it still provides interesting food for thought for anyone interested in the problem of passively fingerprinting interim systems.</p><p>Jacek P. Szymanski, with whom I worked briefly and with whom I later had the pleasure of discussing certain unusual and suspicious network traffic patterns,<sup>[<a id="CHP-11-FN-3" href="#ftn.CHP-11-FN-3" class="footnote">27</a>]</sup> noted a sudden increase in badly broken TCP/IP packets coming to port 21536 (and, to a lesser extent, to ports such as 18477 or 19535). The broken packets always originated from ports such as 18245, 21331, or 17736 and came from a large number of systems in the dial-up address space operated by <code class="literal">Poland</code>’s national telco, Telekomunikacja Polska.</p><p>Once a couple of those packets were captured, the traffic was badly and strangely mangled. The packets arrived with IP headers in place (with protocol type set to TCP), but the headers were immediately followed with TCP payload—the TCP headers were simply gone. The observed port combinations resulted from interpreting the first four bytes of the payload as a pair of numbers (which, had there been a TCP header there instead, would correspond to the source and destination port combination). The pair 18245 and 21536 was merely a representation of the text string “GET ”—four characters that open most HTTP requests transferred over the network. Similarly, 18477 and 21331 stood for SSH-, an opening phrase of every Secure Shell session. And 19535 and 17736 represented EHLO, a command that opens all ESMTP (Extended SMTP) sessions.</p><p>But the reason this type of traffic suddenly began to appear remained a mystery. Too, why did it come only from this particular network? And why did this type of packet mangling not result in connectivity problems or other inconvenience for the users, if some network equipment did indeed produce it?</p><p>The answer soon followed. As it turned out, all the observed traffic originated from Nortel CVX devices, a modem access system that this telco had begun to use. The problem occurred only sporadically, under heavy load. Consequently, only a small percentage of incomplete packets were sent, and only this small number reached the recipients (to their utmost surprise). The most likely reason was improper queue locking or buffer management, a problem that could be noticed only when numerous sessions were processed nearly simultaneously. In such cases, certain packets seemed to be sent out too early, while still “under construction,” or were otherwise mangled by the implementation.</p><p>The company fixed their TCP/IP implementation shortly after the deployment in Poland, and all lived happily ever after. But, as you can imagine, they were not the first and not the last to accidentally leave a unique footprint of their systems in packets they trafficked.</p><p>The moral of this story is that it is once again naive to disregard what we typically ignore. In today’s networking world subtle hints and unusual or unexpected and unexplained observations are extremely valuable. They are easy to find, but difficult to analyze.</p><p>Perhaps food for thought and a field worth further exploration are the various methods deployed to thwart system fingerprinting. Various firewall vendors have attempted to incorporate antifingerprinting measures that alter some packet characteristics by tweaking various TCP/IP parameters (such as Internet Protocol IDs, TCP sequence numbers, and so on). Needless to say, such a solution actually helps the attacker and produces an outcome precisely opposite to what they hoped for: unless all characteristics susceptible to fingerprinting are changed and homogenized (including sequence numbers, retransmission timings, time-stamp values, and so on), it is not only possible to detect the underlying operating system, but also the firewall being used to protect the network.</p><p>C’est la vie.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-11-FN-3" href="#CHP-11-FN-3" class="para">27</a>] </sup>A cooperation that, at some point, resulted in the creation of a loosely knit group of Polish researchers who worked through 1999 and 2000 to correlate, track, and seek to explain many bizarre types of unexpected traffic patterns across the network.</p></div></div></div>
<div class="chapter" title="Chapter&#xA0;12.&#xA0;Stack Data Leaks"><div class="titlepage"><div><div><h1 class="title"><a id="stack_data_leaks"/>Chapter 12. Stack Data Leaks</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Yet another short story on where to find what we did not intend to send out at all</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>Sometimes, all it takes to find subtle but fascinating and helpful hints about your co-Netizens and their whereabouts is some luck. At least that was the case with a fairly interesting and extremely elusive information disclosure vector that I discovered in 2003, after several weeks of a daunting hunt.</p><div class="sect1" title="Kristjan’s Server"><div class="titlepage"><div><div><h1 class="title"><a id="kristjanas_server"/>Kristjan’s Server</h1></div></div></div><p>First things first. Several years ago, I asked a friend of mine, Kristjan, to let me use some disk space on one of his machines so that I could host a bunch of my projects on a reliable and fast system. He agreed, and soon after, I began to gradually move most of my programs and papers to their new home. Among the projects I transferred was a new version of p0f, my passive operating system fingerprinting tool (which you may remember from <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>). This humble tool implemented some interesting passive analysis techniques, but to be truly powerful, it needed to ship with a strong and current database of operating system signatures. Maintaining it manually was difficult, and I soon ran out of obscure systems to fingerprint and add to it.</p><p>Fortunately, whereas gathering signatures for active fingerprinting software required often objectionable interaction with the target (stirring controversy and straining the network link and sometimes crashing particularly poorly implemented TCP/IP stacks), passive fingerprinting required no such action and could be performed effortlessly on all systems that connected to Kristjan’s system to fetch my page. To encourage submissions, I set up a subpage where any user could immediately see their fingerprint and correct the way their system was being reported or add a new signature. This page proved to be a great way to collect signatures and improve the software, but this is not where the story ends.</p><p>In a bizarre turn of events, Kristjan decided to host a different, for-profit site on his system so that his system could pay its own bills. The site, as you might imagine, was not at all devoted to network security, gardening, or some other noble cause. Rather, it focused on some less prestigious, yet perhaps more appealing aspects of our lives: sex, nudity, and everything related. I rejoiced, as any self-respecting geek would, not because of the contents he served, but because millions of connection signatures started pouring down in a matter of hours, to be analyzed by the software I was developing. Hallelujah!</p></div></div>
<div class="sect1" title="Surprising Findings"><div class="titlepage"><div><div><h1 class="title"><a id="surprising_findings"/>Surprising Findings</h1></div></div></div><p>Better safe than sorry: While designing the new code for p0f, I decided to implement a number of sanity checks to detect even the most bizarre, unlikely, or unheard of patterns in incoming traffic, covering all possible illegal or meaningless combinations of TCP/IP settings. Although common sense suggested I should never encounter packets that have their parameters mangled in bizarre ways (at least not when communicating with popular and thus well-tested systems), there seemed to be no harm in implementing this functionality. Too, if a system indeed turned out to be sending packets that exhibited a particular type of anomaly, the ability to detect it would provide an excellent way to tell this particular OS from similar-looking implementations that do not share this flaw.<a id="IDX-CHP-12-0595" class="indexterm"/><a id="IDX-CHP-12-0596" class="indexterm"/><a id="IDX-CHP-12-0597" class="indexterm"/><a id="IDX-CHP-12-0598" class="indexterm"/><a id="IDX-CHP-12-0599" class="indexterm"/><a id="IDX-CHP-12-0600" class="indexterm"/></p><p>During the merry months of this blessed signature storm, I saw the strangest things. I eventually managed to explain some of these and document them for p0f, and some remained a mystery. Most of the anomaly checks I implemented previously hit the spot, and I immediately located systems that indeed were sharing more unusual TCP/IP implementation quirks. But one thing was particularly disturbing and hard to believe, so I decided to pay more attention to it.</p><p>Two of the tests—one a check for the ACK value set in TCP/IP headers when the ACK flag is not set (indeed a futile action), and the other a test for the URG value set when the URG flag is not set—seemed relatively meaningless atfirst, never yielding interesting results, until I noticed something quite unusual. I found that some Windows 2000 and XP systems that connected to Kristjan’s server had, from time to time, nonzero URG or ACK values in packets that had neither flag set (most notably, SYN packets that open a new connection).</p><p>Having URG or ACK values set when a respective flag is not set is not strictly a problem. According to RFC793, when this is the case, the values simply lose all significance; for example:</p><div class="blockquote"><blockquote class="blockquote"><p>Urgent Pointer: 16 bits</p></blockquote></div><div class="blockquote"><blockquote class="blockquote"><p>This field communicates the current value of the urgent pointer as a positive offset from the sequence number in this segment. The urgent pointer points to the sequence number of the octet following the urgent data. This field is only be interpreted in segments with the URG control bit set.</p></blockquote></div><p>RFC793, in its very special way, tells us that this anomaly is not likely to cause any networking problems, and as such it might have gone unnoticed forever. But I took notice, simply because it was kind of odd.</p><p>I initially thought that a specific piece of network equipment was to blame, as was the case with most of the problems described in <a class="xref" href="ch11.html" title="Chapter 11. In Recognition of Anomalies">Chapter 11</a>, but this was not so. The hits were coming from single systems, not entire networks, and they were not persistent; they just showed up in a couple of packets (with values either still or changing randomly) and then disappeared, never to show up again on subsequent connections. Also, the problem seemed to be exclusive to Windows; there were no minority operating systems represented at all in the group of systems exhibiting this issue.</p><p>I found myself spending week after week trying to trace the problem. As part of my hunt, I deployed some other installations in more controlled environments; and, to my amazement, the problem showed up, even in local networks and even from the most up-to-date systems, though only for short periods of time. Users could not recall doing anything unusual when this type of traffic occurred from their systems, and I could not track down any particular type of communications or set of actions that would trigger it; there seemed to be no pattern.</p><p>Puzzling.</p></div>
<div class="sect1" title="Revelation: Phenomenon Reproduced"><div class="titlepage"><div><div><h1 class="title"><a id="revelation_colon_phenomenon_reproduced"/>Revelation: Phenomenon Reproduced</h1></div></div></div><p>I was close to giving up. I posted my observations to several public mailing lists (most notably VULN-DEV, a popular vulnerability discussion list hosted by Security Focus), seeking further analysis and feedback from other researchers, but this failed to yield any results. And then, only by sheer luck, I caught one of my own test stations generating this exact behavioral pattern while working on a wholly different problem. I happened to have a sniffer running in the background (don’t we all).</p><p>Soon, I had a diagnosis: the problem occurred when the workstation was performing a background file transfer or other network-extensive operations when attempting to establish a connection. In almost every OS, the packet to be sent out on a wire was first constructed in the system’s main memory, using either a <span class="emphasis"><em>static buffer</em></span> (a fixed location in memory used exclusively for this purpose) or a <span class="emphasis"><em>dynamic buffer</em></span> (one allocated as needed using memory that could have been used previously for some other purpose). In this particular scenario, when two connections occur at roughly the same time, the buffer used to construct outgoing packets before sending them to the network card appeared to not be initialized properly prior to use; that is, it was not cleared of any leftover contents because the buffer was last used for a different purpose. The implementation code assumes that all contents of the buffer are zero and does not bother to touch those it does not need to initialize to any particular value (as is the case with ACK and URG values when respective flags are not set). As a result, some of the leftover contents are sent out on the wire.</p><p>Naturally, all other IP and TCP fields were properly initialized, as they ought to be; only URG and ACK were left out, as they had no relevance in this particular context. But this omission meant that a small portion of data that belonged to a different connection (or a different aspect of computer operations) was being sent out to another party. The problem manifested itself only during multiple sessions (common during web browsing, background downloads, and similar scenarios), but not when the system was idle.</p><p>The relevance of the information disclosed in this situation is twofold:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>It can be viewed as a traditional information disclosure scenario. Although the amount of information disclosed in every packet that does not have URG and ACK values initialized properly is fairly small and is not guaranteed to be meaningful (unless the buffer held something interesting to begin with), it may be of value in certain scenarios, particularly when a simultaneous session that can contain sensitive information, and effectively the bug itself, can be induced by an external entity.</p></li><li class="listitem"><p>The vulnerability can be considered a convenient fingerprinting metric that reveals additional information about the operating system and the state it is in—a simple way to differentiate systems that extensively use the network from idle ones.</p></li></ul></div><p>That’s it. And although the significance of this discovery is perhaps easy to overestimate, I decided to include it here for its amusement value and to illustrate how easy it is to obtain even sophisticated data from a remote party without even asking.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id7"/>Food for Thought</h1></div></div></div><p>It is easy to lay blame for this on the developers. Although the developers are naturally at fault for not initializing memory properly, the entire notion of having a separate “enabler” for a field in the header is perhaps a design flaw in TCP itself and might contribute to this kind of problem. Similar subtleties plague protocol specifications, as demonstrated in <a class="xref" href="ch07.html" title="Chapter 7. Secure in Switched Networks">Chapter 7</a>, in which a similar type of a vulnerability was caused by following a specification too closely, without giving much thought to its potential side effects.</p></div>
<div class="chapter" title="Chapter&#xA0;13.&#xA0;Smoke and Mirrors"><div class="titlepage"><div><div><h1 class="title"><a id="smoke_and_mirrors"/>Chapter 13. Smoke and Mirrors</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Or how to disappear with grace</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>Many of the information disclosure scenarios discussed so far require careful analysis of the information sent by a remote system in order to deduce certain facts about the sender or to intercept additional data they are not aware of sending in the first place. In several cases, however, only circumstantial evidence of the presence of some form of activity can be gathered. As discussed in <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a> and <a class="xref" href="ch02.html" title="Chapter 2. Extra Efforts Never Go Unnoticed">Chapter 2</a>, by precisely interpreting this evidence, you can determine the probable whereabouts of the user or an application that processes sensitive data, thus indirectly uncovering secrets of the victim’s machine without having to access the data itself.</p><p>Some features of the IP make many of its implementations susceptible to circumstantial evidence information disclosure vulnerabilities, quite similar to what we witnessed earlier with certain types of system pseudo-random number generators or variable complexity data-processing algorithms. Carefully observing and then deciphering this information can be advantageous, providing us at the very least with much-needed intelligence regarding our adversary’s general habits or a particular activity in which they are engaged.</p><p>Until now, this part of the book has focused on IP-layer attacks that require direct observation of the traffic coming from a sender, though typically without interacting with the victim. In this chapter, however, we take a peek at a spectacularly active but indirect IP-based attack in which an attacker profiles their victim by making an educated guess about what they cannot see. They do so by interacting with an innocent bystander who is not the real subject of the test and without this party’s consent or knowledge, learning what they can about the actual victim.</p><p>Such an approach does not sound like the easy way to gather data. So, in the spirit of a geekdom, why not take the scenic, albeit a bit longer, route and look at it in more detail?</p><div class="sect1" title="Abusing IP: Advanced Port Scanning"><div class="titlepage"><div><div><h1 class="title"><a id="abusing_ip_colon_advanced_port_scanning"/>Abusing IP: Advanced Port Scanning</h1></div></div></div><p>Rogue Internet users frequently use port scanning for pre-attack reconnais-sance and system fingerprinting. When port scanning, a would-be attacker attempts a short connection to every port on a system and maps out all programs that listen for network traffic. In this way, they can determine where to attack by finding any vulnerable or otherwise potentially interesting network service on the system. Too, in many cases, they can determine which operating system their victim is using, because default services are often operating-system specific.<a id="IDX-CHP-13-0601" class="indexterm"/><a id="IDX-CHP-13-0602" class="indexterm"/></p><p>The first problem with traditional scanning is that it is quite noisy—the victim is likely to notice a storm or even a steady flow of connection attempts to unusual ports. Hiding is not easy, either; the attacker must be able to see the responses to their SYN packets to determine whether a port is open or closed. Open ports respond with SYN+ACK, closed ones with RST, and ports filtered by a firewall are likely to generate no response or an Internet Control Message Protocol (ICMP) message. Consequently, the attacker cannot simply spoof a source address on all outgoing packets; they must reveal their identity by providing source addresses that route back to the network they are listening on for incoming traffic.</p><div class="sect2" title="Tree in the Forest: Hiding Yourself"><div class="titlepage"><div><div><h2 class="title"><a id="tree_in_the_forest_colon_hiding_yourself"/>Tree in the Forest: Hiding Yourself</h2></div></div></div><p>Whether the party scans out of curiosity (for example, to see what operating system a competitor is running) or follows with an attack attempt, they usually want to leave as few traces as possible and avoid alerting the victim. Network administrators and certain authorities generally perceive host and network scans quite negatively. Although debate is ongoing about whether these scans should be considered malicious, the person doing the probing almost always loses when an annoyed systems administrator decides to file an abuse report or if your competitor identifies one of your employees as trying to probe their networks, regardless of the true intent and further plans of the curious tester.</p><p>One common way to camouflage port scans is to deploy a “decoy” scan, whereby the attacker sends SYN packets from a number of fake addresses, as well as from their actual IP, to each port. The victim handles these bogus packets just like real ones, except that the responses to bogus ones, of course, are sent out into the void. As a result, the victim has a much more difficult time determining who really is behind the scan, because to do so they have to eliminate all the decoy systems from the list of packet sources through either careful analysis or simple trial and error. Still, with some determination it is possible to locate the sender without help from the authorities, though the attacker hopes to discourage the victim by making it too time-consuming to fully resolve such a minor incident.</p></div><div class="sect2" title="Idle Scanning"><div class="titlepage"><div><div><h2 class="title"><a id="idle_scanning"/>Idle Scanning</h2></div></div></div><p>The ultimate defense against being discovered came—as it often does—from a guy who had too much time on his hands and wasted it reading through protocol specifications instead of doing something productive. And so a technique called “idle” scanning was born. Initially devised by Salvatore “antirez” Sanfilippo in 1998, it was soon widely implemented and became quite popular among hackers (both the simply curious and the malicious).<sup>[<a href="apb.html#ftn.CHP-13-BIB-1" class="footnoteref">96</a>]</sup><a id="IDX-CHP-13-0603" class="indexterm"/><a id="IDX-CHP-13-0604" class="indexterm"/><a id="IDX-CHP-13-0605" class="indexterm"/><a id="IDX-CHP-13-0606" class="indexterm"/><a id="IDX-CHP-13-0607" class="indexterm"/><a id="IDX-CHP-13-0608" class="indexterm"/><a id="IDX-CHP-13-0609" class="indexterm"/><a id="IDX-CHP-13-0610" class="indexterm"/><a id="IDX-CHP-13-0611" class="indexterm"/></p><p>Idle scanning is based on an important observation. To quote RFC793:</p><div class="blockquote"><blockquote class="blockquote"><p>As a general rule, reset (RST) must be sent whenever a segment arrives which apparently is not intended for the current connection. A reset must not be sent if it is not clear that this is the case.</p></blockquote></div><p>Transmission Control Protocol RST packets are used to unconditionally terminate a connection and to tell the sender to cease any further attempts to communicate. The system, without much hesitation, sends an RST when encountering unexpected traffic, according to the rule in RFC793. (Naturally, RST packets themselves, even when unexpected, are not replied to; if they were, an endless stream of RSTs would bounce back and forth upon the slightest network hiccup.)</p><p>Idle scanning uses and cleverly abuses the fact that a bystander, a <span class="emphasis"><em>witness host</em></span>, will handle all unexpected packets in this way. The attack enables rogue Netizens to scan a victim with whom they do not intend to directly communicate. When idle scanning, the attacker uses an unsuspecting and randomly chosen system on the Internet to scan a third system (the real victim), without ever revealing their own identity.<a id="IDX-CHP-13-0612" class="indexterm"/><a id="IDX-CHP-13-0613" class="indexterm"/></p><p>Idle scanning works like this: The attacker spoofs a SYN packet to a given port they want to check on the victim’s system. This packet is addressed to the victim host, but with a spoofed return address of the witness system instead of the attacker’s system. This alone does not sound like a good way to get anything done, but wait just a moment.</p><p>What happens next depends on whether the port is open:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>If the probed port on the victim system replies with RST to the witness host, the witness host receives it and simply ponders the RST in silence, without generating any traffic back to the victim.</p></li><li class="listitem"><p>If the probed port is open, the victim replies with SYN+ACK. The witness, with utmost disbelief, concludes that it had never sent a SYN packet to begin with, so it sends RST to instruct the victim that they are grossly mistaken and that they had better stop now. The victim sheepishly accepts the response and drops all records for the connection it hoped to accept.</p></li></ul></div><p>The relevance of this distinction is difficult to appreciate at first. But return to <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>, and recall the following information about one of the fields in an IP header:</p><div class="blockquote"><blockquote class="blockquote"><p>The identification number (ID) is a 16-bit value that differentiates IP packets when fragmentation occurs. Without IP IDs, if two packets are fragmented at once, reassembly would severely mangle, interchange, or otherwise damage fragments of two packets that were fragmented simultaneously. IP IDs uniquely identify several reassembly buffers for different packets. The value used for this purpose is often chosen simply by incrementing a counter with every packet sent; the first packet sent by a system has an IP ID of 0, the second an Internet Protocol of ID 1, and so on.</p></blockquote></div><p>Because the attacker has chosen a witness host that indeed uses this IP ID selection scheme (and there are many candidates to choose from), they can now easily determine whether the witness host has sent an IP packet within a given time frame. They do so simply by sending some meaningless traffic to the witness system before and after the actual probe and comparing IP ID values in the responses it sends. If two observed IP IDs differ only by 1, no packets were sent out by the witness system in between. However, if the difference is more than 1, some packets were indeed exchanged, though we cannot be sure with whom.</p><p>The attacker can also issue a probe just before sending a spoofed packet to the victim and shortly thereafter. Thus, they can determine whether a port is open or closed based on the witness host’s replies. If the witness had an increased IP ID, it most likely replied with an RST to the victim, which means that the victim must have sent SYN+ACK in the first place in response to the spoofed packet. The attacker can then conclude that the port is open. If, on the other hand, the witness produces the next IP ID as expected, it did not receive any traffic from the victim, or it decided to ignore the received RST packet.</p><p>There are, of course, some practical considerations. Most important, the witness host should be relatively idle during the idle scan, and the test should be repeated several times to eliminate false positives; otherwise, we can incorrectly interpret some third-party communications on the witness’s side as telling us that a specific port on the victim’s machine is open.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Neither issue has proven to be much of a deal, however, and many advanced tools (beginning with idlescan in 1999, and now the ingenious NMAP) implement idle scanning and do it well.</p></div><p>The importance of idle scanning is that it can obfuscate the origin of a scan not by merely trying to discourage the victim, but by actually inhibiting any identifiable communications from the attacker. This makes it more difficult to track the attacker without the help of the owner of a witness host (which itself can be queried by the attacker for IP IDs as a part of legitimate traffic such as an HTTP session and hence can have a hard time figuring out whether it was used as a tool for an attack at all) or from external entities (law enforcement and ISPs). Because law enforcement response is usually initiated only once the system is compromised, not merely probed (curious competitors can sleep soundly) and requires the victim to admit to being compromised (which is not always convenient for certain large corporations), the attacker feels rather safe.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Despite at first appearing no different from a regular SYN scan in the results it can offer, idle scanning offers a fairly unique scanning perspective. The use of witness scans makes it possible to see the destination system from the viewpoint of a witness. If the witness has higher access privileges to the victim’s system (if, for example, it is a system within a protected network behind a firewall, or a system for which certain lax IP filtering rules are set for easier access to a corporate network, and so on), you can use idle scanning to discover the inner workings of a protected network.</p></div></div></div></div>
<div class="sect1" title="Defense against Idle Scanning"><div class="titlepage"><div><div><h1 class="title"><a id="defense_against_idle_scanning"/>Defense against Idle Scanning</h1></div></div></div><p>There is at present no immediate defense against an idle scan, and no easy way to tell it from a regular SYN scan. However, it is quite easy to defend against being a witness host by using random or constant IP IDs, as discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>. Although doing so won’t make attacks against you—or attacks in general—any more difficult (plenty of systems will always use sequential identifiers), it will prevent your network from being abused for this purpose.</p><p>To avoid the firewall bypassing (“perspective”) attack, use common sense when designing access channels for external systems, and use proper ingress filtering on gateway systems, dropping all packets that arrive from the Internet with source addresses that seem to belong to a protected network. Although, as discussed previously, this type of filtering might break path maximum transmission unit (PMTU) discovery mechanisms, it usually fixes more problems than it breaks.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id8"/>Food for Thought</h1></div></div></div><p>Although less feasible, it is still possible to use IP IDs for the general profiling of IP activity. In fact, when the victim establishes an interactive session to a remote system, IP IDs can even be used to time keystrokes or similar actions, thus turning this technique into one of the previously discussed timing attack scenarios. Similarly, you can enhance user-racking capabilities by measuring the number of packets sent by a specific host between two subsequent visits to a monitored network.<a id="IDX-CHP-13-0614" class="indexterm"/><a id="IDX-CHP-13-0615" class="indexterm"/><a id="IDX-CHP-13-0616" class="indexterm"/><a id="IDX-CHP-13-0617" class="indexterm"/></p><p>You can also use TCP sequence numbers on certain systems to achieve the same functionality as IP ID analysis, depending on the ISN-generator design. I encourage you to explore this idea in more detail.</p><p>As for tracking down the source of an idle scan (or any other spoofed attack), see <a class="xref" href="ch17.html" title="Chapter 17. Topology of the Network">Chapter 17</a>.</p></div>
<div class="chapter" title="Chapter&#xA0;14.&#xA0;Client Identification: Papers, Please!"><div class="titlepage"><div><div><h1 class="title"><a id="client_identification_colon_papers_comma"/>Chapter 14. Client Identification: Papers, Please!</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Seeing through a thin disguise may come in handy on many occasions</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>The challenge of determining the true identity of software and its legitimacy can be rather easily resolved locally on the computer running the software. But it’s not so easy to do so over a network.<a id="IDX-CHP-14-0618" class="indexterm"/></p><p>Both system administrators and application developers often attempt to identify software being used at the other end of a network-based session, with varying degrees of success. We attempt to identify software for several reasons. For the WWW (World Wide Web), the most common goal is to optimize the content served to a client based on the rendering engine being used—whether that content is legitimate or malicious. The goal for client identification within numerous other communication schemes—instant messengers, mail clients, and so on—is to ensure policy compliance and to detect communications originating from possibly dangerous or otherwise unacceptable applications. And last but not least, programmers themselves attempt to identify software to prevent unapproved (or unlicensed) software from using a particular network service (possibly stripping them of some of their income) or to detect cases such occurrences and take corrective actions.</p><p>The most trivial and common way to identify the other party relies on examining the information voluntarily advertised by the remote system. This information can include simply noticing a “welcome” banner provided by a server, taking a look at protocol headers sent by a client (such as <span class="emphasis"><em>X-Mailer</em></span> in emails, <span class="emphasis"><em>User-Agent</em></span> within WWW sessions, and so forth), and analyzing textual status and error or warning messages used by the service in response to certain types of traffic.<sup>[<a id="CHP-14-FN-1" href="#ftn.CHP-14-FN-1" class="footnote">28</a>]</sup> Unfortunately, the first method is extremely unreliable and easily sabotaged by users who have something to hide; the last method is intrusive and quite difficult to use against clients without causing problems. (Most client software is designed to bail out and complain upon encountering the first error condition; users who, as a result of an attempt to identify their software, encounter an error message and cannot legitimately access a service, will not be impressed.)</p><div class="sect1" title="Camouflage"><div class="titlepage"><div><div><h1 class="title"><a id="camouflage"/>Camouflage</h1></div></div></div><p>Examining textual announcements produced by the client is unreliable not simply because users <span class="emphasis"><em>can</em></span> camouflage their Internet software (web browsers, mail clients, and so forth) in order to mimic the responses of the most popular clients, but because they often also have a good incentive to try: either to blend in with the crowd or simply to fool servers that tend to know better what version of a program the visitor needs to be running. It’s simple to do so, either by using a client’s built-in functionality or by modifying a program’s sources or binaries with one of a multitude of freely available tools.<a id="IDX-CHP-14-0619" class="indexterm"/><a id="IDX-CHP-14-0620" class="indexterm"/><a id="IDX-CHP-14-0621" class="indexterm"/><a id="IDX-CHP-14-0622" class="indexterm"/><a id="IDX-CHP-14-0623" class="indexterm"/><a id="IDX-CHP-14-0624" class="indexterm"/></p><p>Too, because many corporate environments have begun to implement more rigorous content filtering in order to block unwanted traffic, some coders who work on more questionable applications have, in response, begun to impersonate harmless software. Not long ago, peer-to-peer music-sharing applications, malicious Trojan horses, and spyware began to pretend to be the most prevalent web browser, Microsoft Internet Explorer, in their outgoing communications. The same was true for many address-gathering web crawlers used by shoddy marketing businesses around the globe.</p><p>Other protocols are also plagued by impersonators. Not surprisingly, a majority of much despised bulk-mailing software used by spammers and con artists pretends to be programs such as Microsoft Outlook, PINE, Mutt, Eudora, The Bat!, or Netscape Mail. The basic premise is to hide behind camouflage to sneak past network administrators who, were they to become aware of the software’s presence, would find it easy to block them. No sane spammer will announce that their emails are coming from “Uncle Bernie’s Notorious Mass-Mailer, Extreme Edition,” simply because it would be too easy for a user or spam filter to filter them out.</p><div class="sect2" title="Approaching the Problem"><div class="titlepage"><div><div><h2 class="title"><a id="approaching_the_problem"/>Approaching the Problem</h2></div></div></div><p>Because it is trivial to modify the basic text responses and banners returned by a program, we need to find a better way to detect trickery than trivial textual response matching in order to identify client software with reasonable accuracy. Solutions that simply check less obvious parameters or responses are bound to fail at one point or another: although in almost all cases, it is possible to devise a single check to identify a specific type of undesirable software, three heads will grow back in place of the one just cut off.</p><p>It soon becomes impractical to try to address every single incarnation of malicious software. In some cases, a general malicious client detection can be achieved by simply checking for patterns that are clearly indicative of the type of abuse we hope to prevent: The difference between a legitimate mail client and a spammer’s software is that the former is unlikely to attempt to send out 10,000,000 mails in one shot. Yet, this approach is very limited: while for some protocols and some clearly defined attacks, this may work like a charm; for WWW traffic, it is another story, and it is difficult to hit the right spot without ending up with an excessive number of false positives or missed programs.</p><p>Because it is perceived as the core of all Internet services available to end users, the WWW is one of few protocols that simply must be open for almost all, and, thus web traffic is most commonly chosen by naughty applications to masquerade their behavior in a system and the data they are transferring to a remote host. It is not uncommon for web browsers to trigger bursts of connections to various sites or to perform thousands of requests per hour. At the same time, it is not impossible to send out sensitive information to a remote host in a single, brief connection. Here, traffic profiling falls just short of providing an answer.</p></div><div class="sect2" title="Towards a Solution"><div class="titlepage"><div><div><h2 class="title"><a id="towards_a_solution"/>Towards a Solution</h2></div></div></div><p>Given all this, it would appear that differentiating spyware or a Trojan horse from a legitimate application can be extremely tricky. However, as it turns out, some good tools are available for precisely identifying this kind of software, thus enabling interested parties to more accurately and precisely identify client applications. The most promising and universal approach, generally referred to as <span class="emphasis"><em>behavioral analysis</em></span> (a fancy term for old and busted “timing patterns”) aims to analyze the subtle internal dependencies between subsequent portions of traffic, as opposed to looking at the actual data exchange in a single request or in the sheer volume of connections over time. Because these dependencies are closely associated with internal algorithms and a program’s performance, they are much more difficult to spoof than most of the other metrics we could examine. I’ll discuss this approach in this chapter and propose a basic analysis toolset to achieve this level of accuracy and detail, using World Wide Web traffic as a convenient example.<a id="IDX-CHP-14-0625" class="indexterm"/></p><p>But before we dive into the details, we need a bit of background. Let’s take a quick look at the history of the WWW, the design of web clients, and the protocols they use to talk to servers. It all began earlier than you might think. . . .</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-14-FN-1" href="#CHP-14-FN-1" class="para">28</a>] </sup>A popular tool that uses fingerprinting to analyze responses is AMAP by THC; you can find out more at <a class="ulink" href="http://www.thc.org/releases.php">http://www.thc.org/releases.php</a>. Fyodor’s NMAP can identify services by analyzing banners.</p></div></div></div>
<div class="sect1" title="A (Very) Brief History of the Web"><div class="titlepage"><div><div><h1 class="title"><a id="a_open_parenthesis_very_close_parenthesi"/>A (Very) Brief History of the Web</h1></div></div></div><p>The concept of the World Wide Web is not particularly difficult to grasp: the idea behind the Web is to give users instant access to a number of cross-referenced, linked documents that combine different types of information. Simple enough.<a id="IDX-CHP-14-0626" class="indexterm"/><a id="IDX-CHP-14-0627" class="indexterm"/><a id="IDX-CHP-14-0628" class="indexterm"/><a id="IDX-CHP-14-0629" class="indexterm"/><a id="IDX-CHP-14-0630" class="indexterm"/><a id="IDX-CHP-14-0631" class="indexterm"/><a id="IDX-CHP-14-0632" class="indexterm"/><a id="IDX-CHP-14-0633" class="indexterm"/></p><p>The Web as we know it today consists primarily of text with metadata (such as references to other files, formatting elements, annotations, dynamic or interactive elements), often enhanced with all kinds of multimedia (video, music, and various applications). It represents the spirit of our times and signifies a brand new method of communicating and finding information. But the idea of the Web is not new. It was born many years before technology made it possible to achieve this set of features for electronic documents—perhaps long before electronic documents were even considered a serious possibility.</p><p>According to a timeline<sup>[<a href="apb.html#ftn.CHP-14-BIB-1" class="footnoteref">97</a>]</sup> published by the World Wide Web Consortium (W3C), the concept of hyperlinking was first discussed in the <span class="emphasis"><em>Atlantic Monthly</em></span><sup>[<a href="apb.html#ftn.CHP-14-BIB-2" class="footnoteref">98</a>]</sup>back in 1945 by Vannevar Bush, a director of the Office of Scientific Research and Development during and after World War II.</p><p>Bush proposed a device called Memex, a personal, electromechanical unit that could, in fact, be seen as an early predecessor of today’s PDAs. Memex provided storage for a user’s documents and personal files and aimed to provide intuitive mechanisms for accessing the data. One of Memex’s features was its ability to create and follow links between documents stored on microfilm. For some reason, the idea of an insanely complex mechanical device running on microfilm did not really catch on back then.</p><p>The concept of hyperlinking popped up several times in later years, resulting in the first computer-based implementations in the 1960s. These attempts were not particularly successful though, largely because the computing power needed to make the technology appeal to users was still years in the future.</p><p>The right time came in the late 1980s. After the microcomputer boom, and shortly before the frontal assault of the PC platform, a number of humble proposals made the rounds at Conseil Europeén pour la Recherche Nucléaire<sup>[<a id="CHP-14-FN-2" href="#ftn.CHP-14-FN-2" class="footnote">29</a>]</sup> (CERN) concerning the possibilities of hyperlinking. Tim Berners-Lee, one of the CERN researchers, is by all accounts the one to officially blame for spawning HyperText Markup Language (HTML), a set of controls for embedding metadata, links, and media resources in text documents. (Truth be told, HTML, the core of the Web as we know it, is hardly an entirely new design and borrows some ideas from SGML, an ISO 8879 Standard Generalized Markup Language of 1986.) The first web browser was born shortly thereafter on what is now a barely known, but was then an innovative and advanced computer platform, NeXT. The browser was given the ubiquitous name World Wide Web.</p><p>Now that we came up with a catchy name, the revolution was unstoppable. In 1992, Berners-Lee filed an initial specification draft<sup>[<a href="apb.html#ftn.CHP-14-BIB-3" class="footnoteref">99</a>]</sup> for HyperText Trans-fer Protocol (HTTP), a tool for encapsulating HTML data and other resources in server-to-client communications. In 1993, several web browser engines became available, and a handful of web servers were already serving their contents to curious visitors. Of course, HTTP accounted for only a smashing 0.01% of all backbone traffic, but it was rising!</p><p>The first popular web browser, Mosaic, was developed at the National Center for Supercomputer Applications, at the University of Illinois. It borrowed from Berners-Lee’s code, but added support for contents other than text, and introduced fillable forms and many other features that we now take for granted. Mosaic’s code eventually evolved into Mozilla, which, in turn, served as the core code for Netscape Navigator (later to fork into the open-source project Mozilla, whose codebase would be then used as a foundation for subsequent generations of Netscape Navigator—simple, isn’t it?). At the same time, just to further confuse users, a company called Spyglass transformed Mosaic into the core of what was to become Netscape’s main competitor, Microsoft Internet Explorer.</p><p>In 1994 the W3C, a body devised to oversee the development of the Web, was formed. The first official, much-improved, and extended version of the protocol was filed by Berners-Lee, Roy T. Fielding, and Henrik Frystyk in 1996, soon followed by the HTML 3.2 specifications. In subsequent years we saw newer, enhanced versions of HTTP and HTML, now governed by the W3C. And you all know the story’s ending; or is it only the beginning?<a id="IDX-CHP-14-0634" class="indexterm"/><a id="IDX-CHP-14-0635" class="indexterm"/><a id="IDX-CHP-14-0636" class="indexterm"/><a id="IDX-CHP-14-0637" class="indexterm"/><a id="IDX-CHP-14-0638" class="indexterm"/></p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-14-FN-2" href="#CHP-14-FN-2" class="para">29</a>] </sup>European Laboratory for Particle Physics, Geneva, Switzerland.</p></div></div></div>
<div class="sect1" title="A HyperText Transfer Protocol Primer"><div class="titlepage"><div><div><h1 class="title"><a id="a_hypertext_transfer_protocol_primer"/>A HyperText Transfer Protocol Primer</h1></div></div></div><p>HTTP<sup>[<a href="apb.html#ftn.CHP-14-BIB-4" class="footnoteref">100</a>]</sup> is a surprisingly straightforward, text-based protocol built on top of TCP/IP. A client for this protocol connects to an HTTP-capable service on a remote server and makes a request, asking for a specific resource on the server. An HTTP request includes the following parameters in the first line of a query:<a id="IDX-CHP-14-0641" class="indexterm"/><a id="IDX-CHP-14-0642" class="indexterm"/><a id="IDX-CHP-14-0643" class="indexterm"/><a id="IDX-CHP-14-0644" class="indexterm"/><a id="IDX-CHP-14-0645" class="indexterm"/><a id="IDX-CHP-14-0646" class="indexterm"/><a id="IDX-CHP-14-0647" class="indexterm"/><a id="IDX-CHP-14-0648" class="indexterm"/><a id="IDX-CHP-14-0649" class="indexterm"/><a id="IDX-CHP-14-0639" class="indexterm"/><a id="IDX-CHP-14-0640" class="indexterm"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A method for accessing the resource. Most often, the client simply asks to retrieve a file, by issuing a GET request (though other methods exist for tasks such as submitting form data, performing diagnostics, storing data on a server, or executing certain extensions).</p></li><li class="listitem"><p>A universal resource identifier (URI). This is a path to a static file or to a dynamic executable that is the subject of the request. If the file is a dynamic executable, it is also possible to pass additional, appropriately encoded parameters to this program as a part of the URI.</p></li><li class="listitem"><p>The version of the protocol the client supports and wants to use. The server can choose to reply with a lower protocol version if the one used by the client is unsupported. (If this information is missing, the client is assumed to be using HTTP/0.9, an early and obsolete version of the protocol, which we won’t address here.)<a id="IDX-CHP-14-0650" class="indexterm"/></p></li></ul></div><p>For example, an HTTP request might look like this:</p><a id="I_programlisting6_d1e8613"/><pre class="programlisting">GET /show_plush_toys.cgi?param1=value&amp;param2=this+is+a+test HTTP/1.1
Host: www.plush-penguins.com
User-Agent: Joe's Own Web Client (UnixWare)
Accept: text/html, text/plain, audio/wav
Accept-Language: pl, en
Connection: close</pre><p>This request asks for a resource called <code class="literal">/show_plush_toys.cgi</code> at <a class="ulink" href="http://www.plush-penguins.com">www.plush-penguins.com</a>. Judging by the file’s <code class="literal">cgi</code> extension, this is a dynamically executed program that is invoked with two parameters (<code class="literal">param1</code> and <code class="literal">param2</code>), as listed following the question mark.</p><p>The client request can be (and in this example indeed is) followed by a number of text headers, one on each line, that specify additional parameters. These can be anything from client identification (User-Agent field, as mentioned earlier), to the preferred language for the contents (here Polish and English), to the specification of a virtual server the client is referring to. (If several domain names point to a single IP address, this specification makes it possible for the server to determine whether the user is looking for <a class="ulink" href="http://www.squeaky-ducks.com">www.squeaky-ducks.com</a> and <a class="ulink" href="http://www.plush-penguins.com">www.plush-penguins.com</a>, both of which might be hosted on the same system.)</p><p>The protocol mandates some of these headers. The set of required headers depends on its version, but most servers are fairly lax and make no fuss if some are omitted. This aside, some headers specify features that go beyond the protocol’s specification itself.</p><p>Each request must end with an empty line, denoting the end of the client headers, at which point, for most types of requests, the server is expected to process the query and produce a reply. The server usually responds with a message in a structure similar to the query, starting with an HTTP return code and some descriptive text, like this one:</p><a id="I_programlisting6_d1e8644"/><pre class="programlisting">HTTP/1.0 404 Not Found
Content-Type: text/plain
Server: Uncle Mary's Cookie Recipe Server (Linux and proud of it!)
Date: Mon, 09 Feb 2004 19:45:56  GMT

The document you are looking for is nowhere to be found.</pre><p>The return code or message might report various conditions, such as the successful completion of the request, an instruction for the browser to look somewhere else, or an error message such as “File Not Found” or “Permission Denied.” This information is followed by a set of headers, similar to the format accepted for the request. These describe various parameters such as the server software version, the location the browser should proceed to next, a content type specification for the returned file, a setting used to differentiate images from plain-text or HTML documents from binary files, and so on. The actual contents follow, if available.</p><p>As you can see, basic HTTP is fairly simple. Although it does offer some advanced features, most are either slightly bizarre, or just rarely used. (I’m guessing that you do not see the “402 Payment Required” error message every day.) Still, it would be naive to trust that the basic protocol is sufficient to meet the needs and expectations of today’s users.</p></div>
<div class="sect1" title="Making HTTP Better"><div class="titlepage"><div><div><h1 class="title"><a id="making_http_better"/>Making HTTP Better</h1></div></div></div><p>The days when a typical website consisted of several kilobytes of static text and perhaps some minor graphic elements are long gone. As computers have become more powerful, and 300 bps modems have become easier to find in a museum than in every household, form has begun to dominate substance on the Web. Hundreds of kilobytes of images and subpages, subframes, and client-side scripts are commonly used to make sites more attractive and professional, with varying degrees of success. For many sites, multimedia contents have actually become the primary type of information served, with HTML providing only a placeholder for images, video, embedded Java programs, or games. The Web in general is no longer merely a way to tell others about your private projects or interests; the driving force behind it is the ability to market and sell products and services cheaper and faster than ever. And marketing demands the eye-catching presentation of products and services.<a id="IDX-CHP-14-0652" class="indexterm"/><a id="IDX-CHP-14-0651" class="indexterm"/></p><p>Web browsers, web servers, and HTTP itself have had to adapt to this changing reality to make it easy to deploy new technologies and follow new trends. Conveniently enough, many of the technologies introduced in this process have interesting security implications for mere mortals and can also help us identify the client on the other end of the wire in a transparent way. As such, we must consider the optional features and extensions introduced since the day the Web was born.</p><div class="sect2" title="Latency Reduction: A Nasty Kludge"><div class="titlepage"><div><div><h2 class="title"><a id="latency_reduction_colon_a_nasty_kludge"/>Latency Reduction: A Nasty Kludge</h2></div></div></div><p>The problem with the Web and some other current protocols is that the content presented to a user by a single multimedia site must be obtained from various sources (including wholly different domains) and then combined. Web pages have their text and formatting information separate from actual images and other sizable goodies (a practice truly to be praised by those who have a limited bandwidth and just want to get to the point).<a id="IDX-CHP-14-0653" class="indexterm"/><a id="IDX-CHP-14-0654" class="indexterm"/><a id="IDX-CHP-14-0655" class="indexterm"/><a id="IDX-CHP-14-0656" class="indexterm"/></p><p>This situation makes it necessary for clients to make several requests in order to render a web page. The most naive way to achieve this is by requesting each piece, one by one, in sequence, but this is not the best practice in the real world because it leads to bottlenecks: Why wait for a page to load simply because the banner server is running slowly? Hence, to improve the speed of content retrieval, the browser issues numerous requests at once.</p><p>And herein lies the first shortcoming of HTTP: it offers no native ability to serve simultaneous requests. Instead, requests must be issued sequentially.</p><p>The <span class="emphasis"><em>sequential</em></span> (also called <span class="emphasis"><em>serial</em></span>) <span class="emphasis"><em>fetch</em></span> model results in a considerable performance penalty if one of the web page elements needs to be downloaded from a slow server or over a spotty link or if it takes a while for the server to prepare and deliver a particular element. If sequential fetching were the only option, any such slow request would prevent subsequent requests from being issued and served until it (the slow request) is filled.</p><p>Because newer versions of HTTP have not improved this situation, most client software implements a kludge: the web browser simply opens a number of simultaneous, separate TCP/IP sessions to a server or a set of servers and attempts to issue many requests at once. This solution is actually quite sane when the page is requesting resources from several separate machines. However, it’s not a good fix when the requested resources are on a single system, where all requests could be made in a single session and reasonably managed by the server. Here’s why:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The server has no chance to determine the best order in which to serve requests. (If it could, it would serve time-consuming, sizable, or simply the least relevant objects last.) It is simply forced to do all nearly at once, which can still cause the most important stuff to be needlessly delayed by increased CPU load.</p></li><li class="listitem"><p>If several larger resources are served at once, and the operating system scheduler switches between the sessions, the result can be considerable negative performance impact due to the need for the disk drive to seek between two possibly distant files repeatedly and in rapid succession.</p></li><li class="listitem"><p>Considerable overhead is usually associated with completing a new TCP/IP handshake (though this is somewhat lessened by keep-alive capabilities in newer versions of HTTP). It’s more efficient to issue all requests within a single connection.</p></li><li class="listitem"><p>Opening a new session and spawning a new process to serve the request involves overhead on the operating system level and strains devices such as stateful firewalls. Although modern web servers attempt to minimize this problem by keeping spare, persistent processes to accept requests as they arrive, the problem is seldom eliminated fully. A single session avoids unnecessary overhead and lets the server allocate only the resources absolutely needed to asynchronously serve chosen requests.</p></li><li class="listitem"><p>Last but not least, if the network, not the server, is the bottleneck, performance can actually deteriorate as packets are dropped as the link saturates with data from several sources arriving at once.</p></li></ul></div><p>Alas, good or bad, this architecture is with us for now, and it is still better than serial fetch. We should acknowledge its presence and learn to take advantage of it.</p><p>How can this very property help us to identify the software that the client is using? Quite simply. The significance of parallel file fetching for the purpose of browser fingerprinting should be fairly obvious: no two concurrent fetch algorithms are exactly the same, and there are good ways to measure this.</p><p>But before we turn our attention to parallel fetching, we need to take a look at two other important pieces of the security and privacy equation for the Web: caches and identity management. Although seemingly unrelated, they make a logical whole in the end. Thus, a brief intermission.</p></div><div class="sect2" title="Content Caching"><div class="titlepage"><div><div><h2 class="title"><a id="content_caching"/>Content Caching</h2></div></div></div><p>Keeping local caches of documents received from the server is one of the more important features of the Web during its rapid expansion in recent years.<sup>[<a id="CHP-14-FN-3" href="#ftn.CHP-14-FN-3" class="footnote">30</a>]</sup> Without it, the cost of running this business would have been considerably higher.<a id="IDX-CHP-14-0658" class="indexterm"/><a id="IDX-CHP-14-0659" class="indexterm"/><a id="IDX-CHP-14-0660" class="indexterm"/><a id="IDX-CHP-14-0661" class="indexterm"/><a id="IDX-CHP-14-0662" class="indexterm"/><a id="IDX-CHP-14-0663" class="indexterm"/><a id="IDX-CHP-14-0664" class="indexterm"/><a id="IDX-CHP-14-0657" class="indexterm"/></p><p>The problem with the increasing weight and complexity of a typical website is that it requires more and more bandwidth (which for businesses remains generally quite expensive), as well as better servers to serve the data at a reasonable speed.</p><p>If performance is not impacted by bandwidth bottlenecks, solutions such as concurrent sessions (as described earlier) put additional strain on service providers instead. The reason might be fairly surprising: if a person on a fairly slow link (such as a modem) opens four subsequent sessions to fetch even a fairly simple page, four connections and four processes or threads need to be kept alive on the server, taking away those resources from those with faster connections.</p><p>Finally, to make things worse, heavier and more complex websites don’t always mesh with user expectations. Relatively long web page load times that were once considered fairly decent now seem annoying and drive users away. In fact, research suggests that the average web user won’t wait more than 10 seconds for a page to download before they move on.<sup>[<a href="apb.html#ftn.CHP-14-BIB-5" class="footnoteref">101</a>]</sup> The result is that corporations and service providers need more resources and better links to handle the incoming traffic. In fact, had things been left the way they were initially designed, the demand for serverside resources would have likely exceeded our capacity to fulfill the demand some time ago.</p><p>Of some help is that the contents served to web surfers is static or changes seldom, at least when compared with the rate at which a resource is retrieved by users. (This is especially true for large files, such as graphics, video, documents, executables, and so on.) By caching data closer to the end user—be it on the ISP level or even on the endpoint browser itself—we can dramatically decrease the bandwidth used for subsequent visits from users who share a common caching engine and make it easier on the servers handling the traffic. The ISP benefits from a lowered bandwidth consumption, as well, being able to serve more customers without having to invest in new equipment and connections. What HTTP needs, however, is a mechanism to keep the cache accurate and up-to-date. The author of a page (either human or machine) needs to be able to tell the cache engine when to fetch a newer version of a document.<a id="IDX-CHP-14-0665" class="indexterm"/></p><p>To implement document caching, HTTP provides two built-in features:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A method for telling, with minimum effort, whether a portion of data has been modified since the most recent version held by the cache engine (the document recorded at the time of the last visit).</p></li><li class="listitem"><p>A method for determining which portions of data should <span class="emphasis"><em>not</em></span> be cached, whether for security reasons or because the data is generated dynamically every time the resource is requested.</p></li></ul></div><p>This functionality is in practice achieved fairly simply: The server returns all cacheable documents with the regular HTTP session, but with an additional protocol-level header, Last-Modified. To no surprise, this header represents the server’s idea of the time this document was last modified. Documents that cannot be cached are, on the other hand, marked by the server with the header Pragma: no-cache (Cache-Control: no-cache in HTTP/1.1).</p><p>The client browser (or an intermediate cache engine run by the ISP) is supposed to cache a copy of every cacheable page based on the presence of an appropriate header, along with the last modification information. It should keep the cached page for as long as possible, either until the user-configured cache limit is exceeded or the user manually purges the cache, unless specifically instructed to discard it after a specific date with an Expires header.</p><p>Later, when the site is visited again, the client concludes that they have a previous instance of the page cached on the disk and follows a slightly different procedure when accessing it. As long as a document lives in the cache, the client attempts to fetch the file every time the user revisits a site, but specifies the If-Modified-Since header with every request, using the value previously seen in the Last-Modified header for &lt;Since&gt;. The server is expected to compare the Modified-Since value with its knowledge of the last modification time for a given resource. If the resource has not been changed since that time, the HTTP error message “304 Not Modified” is returned instead of the requested data. As a result, the actual file transfer is suppressed, thus preserving bandwidth (with only a couple of hundred bytes exchanged during this communication). The client (or intermediate cache engine) is expected to use a previously cached copy of the resource instead of downloading it again.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>A more up-to-date approach, ETag and If-None-Match headers, a part of entity tagging functionality of HTTP/1.1, works in a similar manner but aims to resolve the ambiguity surrounding the interpretation of file modification times: the problems that stem from a file being modified several times in a short period of time (below the resolution of the clock used for Last-Modified data). of files being restored from a backup (with a modification time older than the last cached copy), and so on.</p></div></div><div class="sect2" title="Managing Sessions: Cookies"><div class="titlepage"><div><div><h2 class="title"><a id="managing_sessions_colon_cookies"/>Managing Sessions: Cookies</h2></div></div></div><p>Another important and seemingly unrelated requirement for HTTP was that it be able to differentiate between sessions and track them across connections, store session settings and identity information. For example, some websites greatly benefit from the ability to adapt to one’s personal preferences and to restore the look and feel chosen by the user each time they visit the site. Naturally, a user’s identity can be established by prompting for a login and password every time a page is viewed, at which point the user’s personal settings can be loaded, but this bit of extra effort dramatically reduces the number of people who would be willing to do this to access the page.<a id="IDX-CHP-14-0666" class="indexterm"/><a id="IDX-CHP-14-0667" class="indexterm"/></p><p>A transparent and persistent way to store and retrieve certain information from the client’s machine was needed to ensure seamless and personalized access to web forums, bulletin boards, chats, and many other features that define the browsing experience for so many people. On the other hand, the ability for web server administrators to recognize and identify returning visitors by assigning them a unique tag and retrieving it later meant the surrender of anonymity in exchange for a little convenience. Such a mechanism would give companies with second-grade ethics a great tool to track and profile users, record their shopping and browsing preferences, determine their interests, and so forth. Search engines could easily correlate requests from the same user, and content providers that serve resources such as ad banners could use this information to track people even without their permission or the knowledge of site operators.<sup>[<a id="CHP-14-FN-4" href="#ftn.CHP-14-FN-4" class="footnote">31</a>]</sup> Regardless of the concerns, however, there seemed to be no better, sufficiently universal alternative for this mechanism. And so web cookies were born.</p><p>Cookies, as specified in RFC2109,<sup>[<a href="apb.html#ftn.CHP-14-BIB-6" class="footnoteref">102</a>]</sup> are small portions of text that are issued by a server when the client connects to it. The server specifies a Set-Cookie header in the response to the visitor. This portion of text is, by its additional parameters, limited in scope to a specific domain, server, or resource and has a limited lifespan. Cookies are stored by cookie-enabled client software in a special container file or folder (often referred to as a <span class="emphasis"><em>cookie jar</em></span>) and are automatically sent back to the server using a Cookie header whenever a connection to a specific resource is established again.</p><p>Servers can choose to store (or push out) user settings in Set-Cookie headers and just read them back on subsequent visits; and here is where cookie functionality would end in a perfect world. Unfortunately, computers have no way of telling what is stored in a cookie. A server can choose to assign a unique identifier to a client using the Set-Cookie header and then read it back to link current user activity to previous actions in the system.<a id="IDX-CHP-14-0668" class="indexterm"/></p><p>The mechanism is wildly regarded as having serious privacy implications. Some activists downright hate cookies, but the opposition to this technology is getting less and less vocal nowadays. Browsing the Web with cookies disabled gets increasingly more difficult—with some sites even refusing traffic from clients that do not pass a cookie check. Thankfully, many browsers offer extensive cookie acceptance, restriction, or rejection settings and can even prompt for every single cookie before accepting it (although the latter is not particularly practical). This makes it possible to mount a reasonable defense of your privacy, if only by defining who the “good guys” are and who to trust.</p><p>But is our privacy in our hands then?</p></div><div class="sect2" title="When Cookies and Caches Mix"><div class="titlepage"><div><div><h2 class="title"><a id="when_cookies_and_caches_mix"/>When Cookies and Caches Mix</h2></div></div></div><p>The privacy of web browsing has long been considered a hot issue, and not without reason. Many people do not want others to snoop on their preferences and interests, even if their whereabouts are not particularly questionable. Why? Sometimes, you simply do not want a shoddy advertising company to know that you are reading about a specific medical condition and then be able to link this information to an account you have on a professional bulletin board, particularly because there is no way of knowing where this information will end up.<a id="IDX-CHP-14-0670" class="indexterm"/><a id="IDX-CHP-14-0669" class="indexterm"/></p><p>Cookie control makes our browsing experience reasonably comfortable, while keeping bad guys at bay. But even turning cookies off does not prevent information from being stored on one’s system to be later sent back to a server. The functionality needed to store and retrieve data on a victim’s machine has long been present in all browsers, regardless of cookie policy settings. The two necessary technologies work in a similar manner and differ only in terms of their intended use: cookies and file caching.</p><p>Somewhere back in 2000, Martin Pool posted a fairly short but insightful message<sup>[<a href="apb.html#ftn.CHP-14-BIB-7" class="footnoteref">103</a>]</sup> to the Bugtraq mailing list, sharing an interesting observation and supporting it with some actual code. He concluded that there is no significant difference between the Set-Cookie and Cookie functionality versus Last-Modified and If-Modified-Since, at least for systems that do not use centralized proxy caches and that store copies of already fetched documents locally on disk (as is the case with most of us mere mortals). A malicious website administrator can store just about any message in the Last-Modified header returned for a page their victim visits (or, if this header is sanity-checked, it might simply use a unique, arbitrary date to uniquely identify this visitor). The client would then send If-Modified-Since with an exact copy of the unique identifier stored by a rogue operator on their computer whenever a page is revisited. A “304 Not Modified” response ensures that this “cookie” is not discarded.</p></div><div class="sect2" title="Preventing the Cache Cookie Attack"><div class="titlepage"><div><div><h2 class="title"><a id="preventing_the_cache_cookie_attack"/>Preventing the Cache Cookie Attack</h2></div></div></div><p>Using your browser to slightly tweak Last-Modified data in response might seem like a neat way to prevent this type of exposure (while introducing some cache inaccuracy), but this is not the case. Another variant of this attack is to rely on storing data in cached documents, as opposed to using tags directly: a malicious operator can prepare a special page for the victim when a website is visited for the first time. The page contains a reference to a unique file name listed as an embedded resource (for example, an image). When a client revisits this page, the server notices the If-Modified-Since header and replies with the 304 error message, prompting the old copy of the page to be used. The old page contains a unique file reference that is then requested from the server, making it possible to map the client’s IP to a previous session in which that file name had been returned. Oops.</p><p>Naturally, the lifetime of cache-based “cookies” is limited by cache size and expiration settings for cached documents configured by the user. However, these values are generally quite generous, and information stored within metadata for a resource that is revisited once every couple of weeks can last for years, until the cache is manually purged. For companies that serve common components included on hundreds or thousands of sites (again, banners are a good example), this is a nonissue.</p><p>The main difference with these cache cookies, compared with cookies proper, is not a matter of the functionality they offer, but rather the ease of controlling the aforementioned exposure. (Cache data must also serve other purposes and cannot be easily restricted without a major performance impact associated with disabling caching partly or completely.)</p><p>In this bizarre twist, you can see how two aspects of the Web collide, effectively nullifying security safeguards built around one of them. Practice shows that intentions are not always enough, because rogues are not always willing to play by the rules and use the technology the way we want them to. Perhaps turning your cookies off does not make that much of a difference after all?</p><p>But then it is about time to go back to the main subject of our discussion.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-14-FN-3" href="#CHP-14-FN-3" class="para">30</a>] </sup>Its importance is slowly decreasing, however: as more and more web pages are generated dynamically, and our Internet backbone becomes more mature and capable, caching is bound to lose its significance.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-14-FN-4" href="#CHP-14-FN-4" class="para">31</a>] </sup>If an advertisement banner or any other element of a website is placed on a shared server, such as <a class="ulink" href="http://banners.evilcompany.com">http://banners.evilcompany.com</a>, the operator of <a class="ulink" href="http://evilcompany.com">evilcompany.com</a> can issue and retrieve cookies whenever a person visits any legitimate website that uses banners supplied by them. Needless to say, most banner providers do issue cookies and track users, albeit primarily for market research purposes.</p></div></div></div>
<div class="sect1" title="Uncovering Treasons"><div class="titlepage"><div><div><h1 class="title"><a id="uncovering_treasons"/>Uncovering Treasons</h1></div></div></div><p>The subject of detecting trickery and accurately fingerprinting client software, that is. I have thus far mentioned that the task of detecting deceptive clients is complex, but not impossible and that behavioral analysis, a careful monitoring of the sequence of events produced by the browsers in question is a route worth exploring.</p><p>HTTP is a particularly generous subject of study, because, as we have seen, much of the activity occurs in parallel or nearly in parallel, and the exact queuing and data-processing algorithms are fairly subtle and unique for each client. By measuring the number of files downloaded at once, the relative time delays between requests, the ordering of requests, and other fine details of a session, it is possible to measure the unique characteristics of a system on a level that is much more difficult for the user to tamper with. Hence, you can distinguish impersonators from law-abiding citizens with no effort.</p><p>To provide a real-world example of this approach in the simplest possible way, and to stay as close to real applications as possible, I decided to see how much could be told from existing, fairly limited samples of data that many of you probably have on hand, so I reached for the standard logs of slightly more than 1 million requests to a relatively popular website. The data used for this analysis was a typical Apache web server access log, containing request completion times, requested URIs, advertised browser data from the User-Agent header, and other basic information of this nature. The page for which the log was kept consists of a set of relatively small pictures of comparable size and a single HTML document that calls for them all.</p><div class="sect2" title="A Trivial Case of Behavioral Analysis"><div class="titlepage"><div><div><h2 class="title"><a id="a_trivial_case_of_behavioral_analysis"/>A Trivial Case of Behavioral Analysis</h2></div></div></div><p>Apache’s practice of logging requests when they are completed, as opposed to logging them when issued, could be perceived as a problem, but is actually quite helpful, assuming the requested set of files is relatively homogeneous. Request initiation order is usually more influenced by the sequence in which resources are referenced within the main page, whereas completion timing is a more complex beast.<a id="IDX-CHP-14-0671" class="indexterm"/><a id="IDX-CHP-14-0672" class="indexterm"/><a id="IDX-CHP-14-0673" class="indexterm"/><a id="IDX-CHP-14-0674" class="indexterm"/><a id="IDX-CHP-14-0675" class="indexterm"/><a id="IDX-CHP-14-0676" class="indexterm"/><a id="IDX-CHP-14-0677" class="indexterm"/><a id="IDX-CHP-14-0678" class="indexterm"/><a id="IDX-CHP-14-0679" class="indexterm"/><a id="IDX-CHP-14-0680" class="indexterm"/><a id="IDX-CHP-14-0681" class="indexterm"/><a id="IDX-CHP-14-0682" class="indexterm"/><a id="IDX-CHP-14-0683" class="indexterm"/><a id="IDX-CHP-14-0684" class="indexterm"/><a id="IDX-CHP-14-0685" class="indexterm"/></p><p>Completion order probabilities depend on the number of requests, inter-request delays, and other parameters that subtly but noticeably vary from browser to browser. In particular, browsers that always keep only one connection open always issue requests in a known order, A-B-C-D; browsers that open three connections at once and issue requests rapidly are just as likely to produce B-A-C-D, C-B-A-D, C-A-B-D . . . and in those later cases, requesting queuing and session management matters most.</p><p>Naturally, we cannot forget that the observed sequence is also heavily affected by network latency and reliability and other random issues. Still, it is reasonable to expect that, for such a large set of samples, these non–browser-specific effects would either average out or affect data for all clients in a similar way. And when this happens, we will hopefully see subtle differences between browsers that lie underneath a friendly user interface.</p><p><a class="xref" href="ch14s05.html#behavioral_pattern_differences_for_popul" title="Figure 14-1. Behavioral pattern differences for popular web clients">Figure 14-1</a> shows a statistical distribution of attempts to load the ten-element web page mentioned earlier for the four most popular web clients in the dataset. Each graph is divided into ten major segments. The first corresponds to the main HTML file, which is directly requested and naturally makes the first element of the site. The remaining nine major segments correspond to nine images referenced from this HTML, in the order in which they are called for in HTML.</p><p>Each of the segments is further divided into ten discrete locations on the X axis (not explicitly shown here to avoid cluttering the chart). The height of the graph at the <span class="emphasis"><em>n</em></span>th discrete location within a given segment represents the likelihood of this particular file being loaded as the <span class="emphasis"><em>n</em></span>th item in sequence.</p><div class="figure"><a id="behavioral_pattern_differences_for_popul"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject6_d1e8978"/><img src="httpatomoreillycomsourcenostarchimages1138102.png.jpg" alt="Behavioral pattern differences for popular web clients"/></div></div><p class="title">Figure 14-1. Behavioral pattern differences for popular web clients</p></div><p>To make the graph more readable, distribution probabilities are given as percentages between 1 and 100 (corresponding to percentages, with all values less than 1 percent rounded up), and discrete points are connected with lines. The graphs are then plotted on a logarithmic scale (log10, with major guides at 1, 10, and 100) to make subtle features more pronounced and easier to visually compare.</p><p>In a perfect world, with fully sequential and predictable browsers, the first segment would contain only a peak at the first (leftmost) discrete location; the second segment would contain a peak only at the second location, and so forth. In practice, however, some browsers issue many requests at once, and thus the order is more easily shuffled: the third referenced file can end up being loaded before the second or after the fourth. The less pronounced a single spike is in each segment, the more aggressive the browser fetch algorithm appears to be—for the more even the probability of this file being loaded out of order is.</p><p>The differences should be clearly visible, even between browsers historically based on the same engine: Mozilla and Internet Explorer. All clients appear to observe the order in which files were referenced in the main document, and so subsequent spikes move slowly from left to right across the segments. Yet, as you can see, Mozilla is generally considerably less impatient than Internet Explorer and more often finishes downloading files in the order in which they were requested. Opera, on the other hand, touted as the fastest browser on earth, is considerably less sequential (with many files having two or three nearly identically pronounced spikes, suggesting that a set of requests is issued so rapidly that the completion sequence is almost arbitrary, and most heavily influenced by network jitter). Wget, a popular open-source web spider, is for comparison perfectly sequential (a pattern common for automated crawlers), uses a single connection, and loads all files in the same order.</p></div><div class="sect2" title="Giving Pretty Pictures Meaning"><div class="titlepage"><div><div><h2 class="title"><a id="giving_pretty_pictures_meaning"/>Giving Pretty Pictures Meaning</h2></div></div></div><p>Pictures and graphs are nice, but have little or no value for automated policy enforcement or abuse detection. To quantify observed patterns somehow, and to make fingerprinting a bit more realistic, I decided to introduce a simple metric that gives a segment a better score (in the range of 0 to 10) when only a single peak is present and gives a lower score when the distribution is more arbitrary. This could allow for creating a simple, ten-value fingerprint for a specific piece of software and then match observed activity against a set of signatures to determine the best fit.</p><p>To construct a metric that expresses a relative quality (linearity) <span class="emphasis"><em>Q</em></span> of observed behavior at major segment <span class="emphasis"><em>s</em></span>, I used the following formula (<span class="emphasis"><em>f<sub>n</sub></em></span> denotes the probability of file appearing at position <span class="emphasis"><em>n</em></span> in fetch sequence, expressed in percentage values for convenience and to upset purists):</p><div class="informalfigure"><a id="image_no_caption-id4"/><div class="mediaobject"><a id="I_mediaobject6_d1e9011"/><img src="httpatomoreillycomsourcenostarchimages1138104.png" alt="image with no caption"/></div></div><p>This equation, although scary at first sight, is actually straightforward. I wanted the formula to give preference to the situation when this particular file is most often loaded at a fixed position in a sequence (that is, one <span class="emphasis"><em>f</em></span> value is near 100 percent, and remaining probabilities are close to 0 percent) over those when all positions are equally likely to occur (all <span class="emphasis"><em>f</em></span> values at 10 percent).</p><p>Because the sum of all elements of <span class="emphasis"><em>f</em></span> is fixed (100 percent), the easiest way to achieve this is to use a sum of squares: for any sequence of nonzero numbers; a sum of squares of those numbers is always less than a square of the sum. The highest and lowest results are as follows:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> + 10<sup>2</sup> = 1,000</td></tr><tr><td>100<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> = 10,000</td></tr></table><p>The remaining math, besides the main sum, is used merely to map results to a reasonable scale of 0 to 10 (when rounded).</p><p>The results of calculating this metric for each segment of observed traffic for each browser are superimposed on <a class="xref" href="ch14s05.html#behavioral_pattern_differences_for_popul" title="Figure 14-1. Behavioral pattern differences for popular web clients">Figure 14-1</a>, as a numeric value describing every segment of the graph. As expected, Wget scores perfectly for each segment. Scores for the other browsers confirm previous visual observations and make them more tangible. Although Internet Explorer and the Mozilla/Netscape engines appear to have roughly similar graphs, strong differences can be observed around load charts for items 4 through 6 and to a lesser degree across the entire fetch sequence. Opera clearly distances itself from the bunch, with consistently lower scores for each segment.</p><p>As a result, by applying a fairly trivial analytic tool, we ended up with a framework for devising a practical method to identify browsers and detect trickery in a statistically significant sample of user’s HTTP traffic. You can enhance the model by analyzing other auto-load elements such as scripts, HTML style sheets, image maps, frames, and other files that exhibit even greater browser-to-browser variance. The Santa might find it easier this year to prepare the naughty user list.</p></div><div class="sect2" title="Beyond the Engine . . ."><div class="titlepage"><div><div><h2 class="title"><a id="beyond_the_engine"/>Beyond the Engine . . .</h2></div></div></div><p>I merely hope to show how easy it is to detect hidden characteristics of an unknown application by observing its behavior, without making any specific assumptions or dissecting the internals of such a program. The above exact numbers are likely not directly applicable to any website other than the one I used, and so you are encouraged to do your homework should you find a potential use for this technique. Once you profile a site or a set of sites, you can use the data to efficiently recognize systems based on their activity patterns over time.</p><p>Needless to say, the method I’ve used here is a (perhaps overly) simplistic approach to behavioral analysis and is based on perhaps the most trivial of all possible scenarios; I provide it as encouragement and to tempt you to search for more. In advanced cases, you can readily use the process of rendering contents in frames, tables, and other visual containers or fetching and rendering special types of files to determine which browser is being used even without performing statistical matching—in various highly specific aspects of browser activity, differences become far more striking. A clever application of differential timing is also promising.</p><p>And consider this: You can take more thought out forms of behavioral analysis a step further and deploy them not to tell one rendering engine from another, but to tell machines from humans or even identify single users. As discussed in <a class="xref" href="ch08.html" title="Chapter 8. Us versus Them">Chapter 8</a>, keyboard use patterns are often so unique for an individual that it is possible to use them for biometrics. Similarly, research suggests we can use the ways users click links, make choices, read information, and so on to indicate who or what is behind a set of requests.<sup>[<a href="apb.html#ftn.CHP-14-BIB-8" class="footnoteref">104</a>]</sup> Although now closer to scientific speculation than fact, this is a wonderful field to explore and play with.</p></div><div class="sect2" title=". . . And Beyond Identification"><div class="titlepage"><div><div><h2 class="title"><a id="and_beyond_identification"/>. . . And Beyond Identification</h2></div></div></div><p>Browser activity and behavioral analysis applications go beyond the detection of browser software—in fact, some enter the domain of user privacy and anonymity.<a id="IDX-CHP-14-0686" class="indexterm"/><a id="IDX-CHP-14-0687" class="indexterm"/><a id="IDX-CHP-14-0688" class="indexterm"/><a id="IDX-CHP-14-0689" class="indexterm"/><a id="IDX-CHP-14-0690" class="indexterm"/><a id="IDX-CHP-14-0691" class="indexterm"/><a id="IDX-CHP-14-0692" class="indexterm"/></p><p>An interesting piece of research published in 2000 by Edward Felten and Michael Schneider<sup>[<a href="apb.html#ftn.CHP-14-BIB-9" class="footnoteref">105</a>]</sup> makes a fascinating contribution to the possible applications for the technique, an ability that is closely allied with caching mechanisms deployed in today’s engines, bringing us to the point where all the elements discussed so far finally meet.</p><p>The basic premise of their research is that, by inserting a reference to a file on a particular site and then measuring the delay the browser encounters while downloading it, it is possible to tell whether the user had visited a particular site in recent days. Simple enough.</p><p>I’ll spare you a lengthy excursion into the world of theory, predictions, and speculations (just this once) and instead propose a nearly real-world example. Assume that I am running <a class="ulink" href="http://www.rogue-severs.com">www.rogue-severs.com</a>. I’ve decided that my main page will, for some reason, refer to a picture (such as a front-page logo) taken from <a class="ulink" href="http://www.kinky-kittens.com">www.kinky-kittens.com</a>; I make the visual element difficult to find or scale it down so that it is not visible, but it will be still loaded by a browser.</p><p>An unsuspecting user visits my site. If they have never been to <a class="ulink" href="http://www.kinky-kittens.com">www.kinky-kittens.com</a>, it takes them a while to download the image I have referenced. If they are a frequent visitor, however, the image is already present in their cache and is fetched almost instantly.</p><p>Because the reference to the <a class="ulink" href="http://www.kinky-kittens.com">www.kinky-kittens.com</a> resource is preceded and followed by requests for other visual elements I happen to host on my site, by deploying clever timing heuristics, it is possible to reliably measure whether the entire logo had been fetched or whether it was already in the cache. All this suffices to determine whether a newcomer to my page is indeed a frequent visitor to a specific website (or a particular section of a website) and effectively brutally invades their privacy. Although the scenario is not likely to be used for widely deployed routine espionage (primarily because clear evidence is left behind and might be noticed by the operator of the server on whose users we desire to snoop), targeted attacks might be quite effective.</p><p>In the end, all pieces of the puzzle fit together, perhaps loosely, but still fit together. Users, programs, and habits can all be easily exposed through a careful abuse of modern features of a popular Internet protocol. Something not necessarily always comforting to the valued visitors of <a class="ulink" href="http://www.kinky-kittens.com">www.kinky-kittens.com</a>.</p></div></div>
<div class="sect1" title="Prevention"><div class="titlepage"><div><div><h1 class="title"><a id="prevention-id1"/>Prevention</h1></div></div></div><p>Fully anonymizing one’s web-browsing experience appears to be a battle already lost. Although some practices for improving the privacy and anonymity of online web users are commonly accepted, these features can be easily circumvented by a malicious website.</p><p>The problem is, unfortunately, too serious to dismiss. It is one thing to have an entity we have decided to trust (such as an ISP) be aware of our activity, but an entirely different issue when parties we’d rather not deal with routinely gather sensitive profiling information and probably just as routinely resell it to others as a part of their business model. This is enough to concern even those who do not wear a tinfoil hat and aluminum underwear on a daily basis.</p><p>On the other hand, the relative difficulty of remaining fully anonymous or appearing completely harmless is important in environments where HTTP traffic must be allowed and yet where users should be protected and supervised without violating their privacy beyond bare necessity. In corporate networks, the ability to track offending systems without the need to manually inspect data is truly invaluable and appreciated both by users and system administrators alike.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id9"/>Food for Thought</h1></div></div></div><p>No single component of HTTP is ill conceived, broken, or unwarranted. Yet, when we put it all together, many security and privacy features seem to cancel out, and the user is left quite exposed to eavesdroppers running rampant. Sadly, we can do little without starting over from scratch, and there is no guarantee that the results would work as well or provide even as much privacy as HTTP, HTML, and WWW clients do now.</p></div>
<div class="chapter" title="Chapter&#xA0;15.&#xA0;The Benefits of Being a Victim"><div class="titlepage"><div><div><h1 class="title"><a id="the_benefits_of_being_a_victim"/>Chapter 15. The Benefits of Being a Victim</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>In which we conclude that approaching life with due optimism may help us track down the attacker</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>I have discussed a variety of problems that can have a significant cumulative impact on all daily communications, risks that we are not always comfortable with. You have seen how others can exploit the network to steal information or to get more than you expect or would allow them to, as well as how to use these techniques to gather more information about your enterprise or home network, and attackers that target it.</p><p>I hope I have offered both useful insight into how problems like these are born and how to avoid them whenever possible. I’ve tried to show that security and privacy implications are simply a part of every activity and that they cannot be fully eliminated simply by making the correct design decisions, installing the right software, or establishing and enforcing the proper policies. Information disclosure simply cannot be fully suppressed, and our only hope is to have enough information and knowledge about potential leak or attack scenarios to mitigate the most significant ones as much as possible in a particular application.</p><p>This, the third part of the book, has focused on wide area networking and the threats that lurk there. Although this is the longest part and is only now about to conclude, it is the furthest from offering a complete view of all the issues that can arise in an open network. In fact, it would be quite difficult and largely pointless to discuss all variants of problems; thus I’ve chosen to cover only the most complex, challenging, or fascinating aspects of host-to-host communications. I’ve focused on discovering attack scenarios on different protocol layers and different abstraction levels, instead of enumerating concepts and attack vectors that rehash old ideas and add nothing new to the subject. I hope that the information provided thus far will help and encourage you to find other incarnations of these issues in other areas of networking and computing—and perhaps even beyond.</p><p>We make a significant paradigm shift in the next part of the book as we explore how careful observation of the network as a whole, rather than as single systems, can be used to defend ourselves or to attack others. But before we do, let’s look at some other possibilities in one of the more unusual areas of network surveillance: passive counterintelligence—that is, learning more about the attacker or their aims by analyzing their actions. The data gathered this way can provide a powerful set of investigative leads that make it easy to identify an attacker’s intentions, toolset, or even the attacker themself. The task of building an attacker profile, attempting to read their mind, and perhaps even playing a game of deception with them is often a thrilling experience in and of itself.</p><div class="sect1" title="Defining Attacker Metrics"><div class="titlepage"><div><div><h1 class="title"><a id="defining_attacker_metrics"/>Defining Attacker Metrics</h1></div></div></div><p>As expected, you can acquire a good deal of information about a remote rogue party by merely applying some of the common TCP/IP traffic metrics discussed previously—such as passive operating system fingerprinting—to the observed traffic. You can, for example, identify the specific tool used to perform a port scan.<a id="IDX-CHP-15-0693" class="indexterm"/><a id="IDX-CHP-15-0694" class="indexterm"/><a id="IDX-CHP-15-0695" class="indexterm"/><a id="IDX-CHP-15-0696" class="indexterm"/><a id="IDX-CHP-15-0697" class="indexterm"/><a id="IDX-CHP-15-0698" class="indexterm"/><a id="IDX-CHP-15-0699" class="indexterm"/><a id="IDX-CHP-15-0700" class="indexterm"/><a id="IDX-CHP-15-0701" class="indexterm"/><a id="IDX-CHP-15-0702" class="indexterm"/><a id="IDX-CHP-15-0703" class="indexterm"/><a id="IDX-CHP-15-0704" class="indexterm"/></p><p>Similarly, we can also apply behavioral analysis to characteristics of the attacker’s behavior such as inter-request delays and request ordering (for example, the order in which ports are scanned and how fast). We can use behavioral analysis with some success to track programs or, during a manually performed break-in or unauthorized assessment attempts, even to determine the individual characteristics of an attacker (such as their computer proficiency).</p><p>One particularly interesting method we can deploy to identify the tool the attacker used to scan our network relies on applying one of the methods discussed in <a class="xref" href="ch09.html" title="Chapter 9. Foreign Accent">Chapter 9</a>—port sequence fingerprinting—to a wholly new task; this is based on the observation that a majority of scanners in use today either scan networks and systems from lowest to highest ports or addresses (sequentially) or randomize the order in which resources are accessed. The latter approach is more often used and is regarded as the better because it can balance loads and make scanning detection slightly more difficult. But, in a surprising twist, the use of randomness can fire back at the attacker in a couple of bizarre ways.</p><p>The problem arises because their authors do not consider network scanning tools mission-critical applications with high-security requirements. The most common (and easiest) way to implement a pseudorandom number generator in programs that do not require cryptographically secure output is to invoke standard system or built-in language facilities. The ISO standard<sup>[<a href="apb.html#ftn.CHP-15-BIB-1" class="footnoteref">106</a>]</sup> for the most prevalent programming language in the world, C, suggests that a simple linear congruent algorithm be used to implement a standard C library pseudorandom number generator (discussed in <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a>). The recipe for building and using the generator devised by the standard is as follows:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>The generator should be seeded with an initial 32-bit value (S<sub>0</sub>) by invoking a standard library function <code class="literal">srand()</code>. If the generator is not seeded, it will begin with a fixed default seed and will produce identical result sequences in all cases.</p></li><li class="listitem"><p>In each call to <code class="literal">rand()</code>, the main function that is repeatedly invoked to obtain subsequent pseudorandom numbers for use in user applications, the seed S is recomputed as follows: S<sub>t+1</sub> = S<sub>t</sub> * 1103515245 + 12345. The result is truncated to 32 bits (modulo 4294967296).</p></li><li class="listitem"><p>The return value for each <code class="literal">rand()</code> call is the more significant word of S<sub>t+1</sub>, modulo 32768. In a 32-bit variant, one of the algorithms more commonly used on today’s computers, the procedure in this and the previous step is repeated several times to calculate subsequent bit portions of the result value.</p></li></ol></div><p>All linear congruent generators, including the one described here, are susceptible to the general cryptanalysis methodology proposed by H. Krawczyk in the ’90s, as mentioned in <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a>. Based on the observation of a couple of subsequent (or otherwise ordered) outputs, it is possible to reconstruct the internal state of the generator and thus predict all its previous and future outputs.</p><p>Naturally, the immediate implication of this possibility—the victim’s ability to determine, based on a knowledge of prior attempts, in what order the attacker will try to target other resources on the machine or network—is not particularly exciting or valuable itself. Still, this possibility has two important consequences in the context of network probe attempts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>We might be able to determine <span class="emphasis"><em>S</em></span><sub>0</sub>. If we know or can estimate when the generator began its work (or, alternatively, which general properties the initial seed should exhibit), it is possible to reconstruct the value used to initialize the generator. Because S<sub>0</sub> is the only input to the algorithm, it must produce identical behavior for identical seed values—and so, we can trace the seed by observing PRNG output.</p></li><li class="listitem"><p>We might be able to determine <span class="emphasis"><em>t</em></span> increments. Once we reconstruct the generator state, it is possible to determine how many random values were requested by the scanner by calling <code class="literal">rand()</code> in between two calls that the scanner used to obtain values (port numbers or host addresses) for packets the observer captured.</p></li></ul></div><p>The importance of the first consequence of this design, our ability to reconstruct the value used to initialize the generator, might be not immediately apparent. But we have another bit of the puzzle to consider. One common way to initialize a random number generator is to use a handy 32-bit value that changes often enough not to risk identical PRNG behavior too frequently. The system time counter is often used for this purpose, and it is sometimes combined with another small number, such as the current process ID (PID), to decrease the likelihood that two programs run in a short time interval will produce similar results.</p><p>By applying this knowledge to the calculated <span class="emphasis"><em>S</em></span><sub>0</sub>, the probe victim can discover the attacker’s system time (GMT or local, depending on the operating system settings and scanner type). Knowledge of the system’s local time can give the observer a hint about the attacker’s origin and identity in a most trivial way. If they are trying to confuse us by spoofing packets from various sources, we can get lucky ruling out those perceived sources for which S<sub>0</sub> would indicate a time zone not matching the geographical region to which the source address belongs. For example, if by comparing the attacker’s estimated system time with GMT we determine that attacker’s time is five hours behind Greenwich Mean, we might conclude that they are likely on the east coast of the United States and not in China. Thus, by comparing our best guess of the time zone with records for various IP address blocks, we can tell that, of all observed “decoy” scan sources, the attacker’s true identity is more likely to be behind packets originating from a Boston ISP than ones from an ISP located in Beijing.</p><p>Additionally, once we know the attacker’s local time, we can track them by measuring the distance of their system clock from the real time (and, in the long run, how fast it drifts). Because computer clocks are usually not particularly accurate and tend to drift quite a bit when they are not regularly synchronized with an external source (as much as several minutes a day in some cases), this might be a good way to correlate attacks carried out by the same person. Different machines are likely to be systematically off by a different amount of time that would be changing at a distinctive ratio.</p><p>Finally, when the PID is used as a part of the initialization seed along with system time, and the attacker’s system time is known to be within a certain range, the PID can be used to determine the approximate system uptime or the number of tasks executed between two scans. Because every new process on a machine is assigned a higher PID number, this dependency is rather straightforward.<sup>[<a id="CHP-15-FN-1" href="#ftn.CHP-15-FN-1" class="footnote">32</a>]</sup></p><p>By reconstructing the PRNG state, we can also see how many random numbers were generated between the generation of two packets received by the recipient. When only one system is being scanned, there should be no gaps whatsoever or only marginal discrepancies due to network problems. However, when more than one system is being scanned, these gaps (caused by packets that are being sent to different targets) can be easily detected. By detecting them we can determine how many systems are being targeted simultaneously.</p><p>Furthermore, when the scanner software generates fake decoy packets that appear to come from random hosts, it is possible to eliminate spoofed addresses—ones that were made up using PRNG (and thus match its possible output) and determine which one does not match and hence must be real—pointing conclusively to the real perpetrator of an attack. For example, if our reconstructed PRNG data shows traffic coming from addresses such as:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>198.187.190.55 (decimal representation: 3334192695)</td></tr><tr><td>195.117.3.59 (decimal representation: 3279225659)</td></tr><tr><td>207.46.245.214 (decimal representation: 3475961302)</td></tr></table><p>we can determine that both 3334192695 and 3475961302 were one of the first outputs we would see of a generator seeded with S<sub>0</sub>; whereas 3279225659 does not seem to be any of the first outputs of a reconstructed PRNG and hence is likely a real address.</p><p>We can use all this information to determine an attacker’s intentions and the software they are using. We can even use it to track the system they are working on, correlate it with other data to determine their true identity and geographical location, and sometimes even determine how they are using their computer as the scan progresses.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>NMAP, in response to the uptime and scan history disclosure problems discussed above, attempts to use secure system RNG facilities (such as /dev/random, as discussed in <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a>) to generate random numbers instead of relying on standard C library tools. However, this method is not available on many operating systems (such as Windows), and other scanners have not taken similar steps to defend an attacker.<a id="IDX-CHP-15-0705" class="indexterm"/></p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-15-FN-1" href="#CHP-15-FN-1" class="para">32</a>] </sup>Although some systems offer optional PID randomization for the purpose of making certain unrelated types of local attacks more difficult.</p></div></div></div>
<div class="sect1" title="Protecting Yourself: Observing Observations"><div class="titlepage"><div><div><h1 class="title"><a id="protecting_yourself_colon_observing_obse"/>Protecting Yourself: Observing Observations</h1></div></div></div><p>The Internet has become a giant battlefield in the last ten years. Newly connected machines are being instantly flooded with automated attack probes, worms, and other types of information that stress their security. The traditional, and now fairly trendy, intrusion detection and prevention movement aims to find out about and stop attacks, by warning the administrator when pre-attack probes are being carried out using specially crafted traffic analysis tools. In heterogeneous or simply sufficiently complex environments, these often produce more noise and false positives than one can handle.<a id="IDX-CHP-15-0706" class="indexterm"/><a id="IDX-CHP-15-0707" class="indexterm"/></p><p>In some cases, however, the ability to observe attacks and the responses they trigger is a great way for the administrator to learn about network problems and attacks as they occur (even though those incidents themselves are hardly noteworthy, usually). For one thing, in some networks, active discovery and asset scanning to ensure policy compliance and system configuration is difficult to initiate or too troublesome to perform, whether due to policy regulations, slow turnaround times, rarely open network maintenance windows, and so forth. In such an environment, the ability to peek and determine what rogues are seeing may be an invaluable substitute for locally initiated active reconnaissance.</p><p>Too, periodic active discovery might not be fast enough to respond to certain threats; thus, the ability to learn that something has suddenly gone wrong by merely observing the results others get could be quite valuable. And, of course, this is a two-edged sword—a hacker who has compromised or plans to compromise a network, but wants to keep a low profile and plan their steps in advance, can watch traffic generated by other discovery attempts in order to build their knowledge about a particular system.</p><p>The task of stealing knowledge acquired by an attacker appears to be simple only in theory; the challenge of correlating and processing results, particularly when analyzing large environments or when based only on partial information from separate attack attempts from different locations, is not trivial. Some tools to facilitate network and system mapping using “passive scanning” are nevertheless slowly showing up on the horizon—with Preston Wood’s DISCO<sup>[<a href="apb.html#ftn.CHP-15-BIB-2" class="footnoteref">107</a>]</sup> being a prime example.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id10"/>Food for Thought</h1></div></div></div><p>I find it strange that the techniques described in this chapter are often not supported by comprehensive research, published white papers, or readily available tools. With the attack tracking craze initiated by Lance Spitzner’s honeypot research, and only fueled by products such as intrusion detection systems, one would expect to see fewer efforts to identify attacks (which are usually not particularly exciting themselves and which typically use well-documented vectors and flaws) and more attempts to determine the intent and origin of an attack and to correlate events that are meaningless alone, but that can signal a problem when combined.<a id="IDX-CHP-15-0708" class="indexterm"/><a id="IDX-CHP-15-0709" class="indexterm"/></p><p>I can only shed some light on the tip of an iceberg, but needless to say, this may be one of the more exciting areas to research and contribute to.</p><p><span class="emphasis"><em>And now, for something completely different. . . .</em></span></p></div></body></html>