<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Security in the World of Web Applications"><div class="titlepage"><div><div><h1 class="title"><a id="security_in_the_world_of_web_application"/>Chapter 1. Security in the World of Web Applications</h1></div></div></div><p>To provide proper context for the technical discussions later in the book, it seems prudent to first of all explain what the field of security engineering tries to achieve and then to outline why, in this otherwise well-studied context, web applications deserve special treatment. So, shall we?<a class="indexterm" id="IDX-CHP-1-0001"/></p><div class="sect1" title="Information Security in a Nutshell"><div class="titlepage"><div><div><h1 class="title"><a id="information_security_in_a_nutshell"/>Information Security in a Nutshell</h1></div></div></div><p>On the face of it, the field of information security appears to be a mature, well-defined, and accomplished branch of computer science. Resident experts eagerly assert the importance of their area of expertise by pointing to large sets of neatly cataloged security flaws, invariably attributed to security-illiterate developers, while their fellow theoreticians note how all these problems would have been prevented by adhering to this year’s hottest security methodology. A commercial industry thrives in the vicinity, offering various nonbinding security assurances to everyone, from casual computer users to giant international corporations.<a class="indexterm" id="IDX-CHP-1-0002"/></p><p>Yet, for several decades, we have in essence completely failed to come up with even the most rudimentary usable frameworks for understanding and assessing the security of modern software. Save for several brilliant treatises and limited-scale experiments, we do not even have any real-world success stories to share. The focus is almost exclusively on reactive, secondary security measures (such as vulnerability management, malware and attack detection, sandboxing, and so forth) and perhaps on selectively pointing out flaws in somebody else’s code. The frustrating, jealously guarded secret is that when it comes to enabling others to develop secure systems, we deliver far less value than should be expected; the modern Web is no exception.</p><p>Let’s look at some of the most alluring approaches to ensuring information security and try to figure out why they have not made a difference so far.</p><div class="sect2" title="Flirting with Formal Solutions"><div class="titlepage"><div><div><h2 class="title"><a id="flirting_with_formal_solutions"/>Flirting with Formal Solutions</h2></div></div></div><p>Perhaps the most obvious tool for building secure programs is to algorithmically prove they behave just the right way. This is a simple premise that intuitively should be within the realm of possibility—so why hasn’t this approach netted us much?</p><p>Well, let’s start with the adjective <span class="emphasis"><em>secure</em></span> itself: What is it supposed to convey, precisely? Security seems like an intuitive concept, but in the world of computing, it escapes all attempts to usefully define it. Sure, we can restate the problem in catchy yet largely unhelpful ways, but you know there’s a problem when one of the definitions most frequently cited by practitioners<sup>[<a class="footnote" href="#ftn.CHP-1-FN-1" id="CHP-1-FN-1">2</a>]</sup> is this:<a class="indexterm" id="IDX-CHP-1-0003"/></p><div class="blockquote"><blockquote class="blockquote"><p>A system is secure if it behaves precisely in the manner intended—and does nothing more.</p></blockquote></div><p>This definition is neat and vaguely outlines an abstract goal, but it tells very little about how to achieve it. It’s computer science, but in terms of specificity, it bears a striking resemblance to a poem by Victor Hugo:</p><div class="blockquote"><blockquote class="blockquote"><p>Love is a portion of the soul itself, and it is of the same nature as the celestial breathing of the atmosphere of paradise.</p></blockquote></div><p>One could argue that practitioners are not the ones to be asked for nuanced definitions, but go ahead and pose the same question to a group of academics and they’ll offer you roughly the same answer. For example, the following common academic definition traces back to the Bell-La Padula security model, published in the 1960s. (This was one of about a dozen attempts to formalize the requirements for secure systems, in this case in terms of a finite state machine;<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-1">86</a>]</sup> it is also one of the most notable ones.)<a class="indexterm" id="IDX-CHP-1-0004"/></p><div class="blockquote"><blockquote class="blockquote"><p>A system is secure if and only if it starts in a secure state and cannot enter an insecure state.</p></blockquote></div><p>Definitions along these lines are fundamentally true, of course, and may serve as the basis for dissertations or even a couple of government grants. But in practice, models built on these foundations are bound to be nearly useless for generalized, real-world software engineering for at least three reasons:<a class="indexterm" id="IDX-CHP-1-0005"/><a class="indexterm" id="IDX-CHP-1-0006"/><a class="indexterm" id="IDX-CHP-1-0007"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>There is no way to define desirable behavior for a sufficiently complex computer system</strong></span>. No single authority can define what the “intended manner” or “secure states” should be for an operating system or a web browser. The interests of users, system owners, data providers, business process owners, and software and hardware vendors tend to differ significantly and shift rapidly—when the stakeholders are capable and willing to clearly and honestly disclose their interests to begin with. To add insult to injury, sociology and game theory suggest that computing a simple sum of these particular interests may not actually result in a beneficial outcome. This dilemma, known as “the tragedy of the commons,” is central to many disputes over the future of the Internet.</p></li><li class="listitem"><p><span class="strong"><strong>Wishful thinking does not automatically map to formal constraints</strong></span>. Even if we can reach a perfect, high-level agreement about how the system should behave in a subset of cases, it is nearly impossible to formalize such expectations as a set of permissible inputs, program states, and state transitions, which is a prerequisite for almost every type of formal analysis. Quite simply, intuitive concepts such as “I do not want my mail to be read by others,” do not translate to mathematical models particularly well. Several exotic approaches will allow such vague requirements to be at least partly formalized, but they put heavy constraints on software-engineering processes and often result in rulesets and models that are far more complicated than the validated algorithms themselves. And, in turn, they are likely to need their own correctness to be proven . . . <span class="emphasis"><em>ad infinitum</em></span>.</p></li><li class="listitem"><p><span class="strong"><strong>Software behavior is very hard to conclusively analyze</strong></span>. Static analysis of computer programs with the intent to prove that they will always behave according to a detailed specification is a task that no one has managed to believably demonstrate in complex, real-world scenarios (though, as you might expect, limited success in highly constrained settings or with very narrow goals is possible). Many cases are likely to be impossible to solve in practice (due to computational complexity) and may even turn out to be completely undecidable due to the halting problem.<sup>[<a class="footnote" href="#ftn.CHP-1-FN-2" id="CHP-1-FN-2">3</a>]</sup></p></li></ul></div><p>Perhaps more frustrating than the vagueness and uselessness of the early definitions is that as the decades have passed, little or no progress has been made toward something better. In fact, an academic paper released in 2001 by the Naval Research Laboratory backtracks on some of the earlier work and arrives at a much more casual, enumerative definition of software security—one that explicitly disclaims its imperfection and incompleteness.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-2">87</a>]</sup><a class="indexterm" id="IDX-CHP-1-0008"/></p><div class="blockquote"><blockquote class="blockquote"><p>A system is secure if it adequately protects information that it processes against unauthorized disclosure, unauthorized modification, and unauthorized withholding (also called denial of service). We say “adequately” because no practical system can achieve these goals without qualification; security is inherently relative.<a class="indexterm" id="IDX-CHP-1-0009"/></p></blockquote></div><p>The paper also provides a retrospective assessment of earlier efforts and the unacceptable sacrifices made to preserve the theoretical purity of said models:</p><div class="blockquote"><blockquote class="blockquote"><p>Experience has shown that, on one hand, the axioms of the Bell-La Padula model are overly restrictive: they disallow operations that users require in practical applications. On the other hand, trusted subjects, which are the mechanism provided to overcome some of these restrictions, are not restricted enough. . . . Consequently, developers have had to develop ad hoc specifications for the desired behavior of trusted processes in each individual system.</p></blockquote></div><p>In the end, regardless of the number of elegant, competing models introduced, all attempts to understand and evaluate the security of real-world software using algorithmic foundations seem bound to fail. This leaves developers and security experts with no method to make authoritative, future-looking statements about the quality of produced code. So, what other options are on the table?</p></div><div class="sect2" title="Enter Risk Management"><div class="titlepage"><div><div><h2 class="title"><a id="enter_risk_management"/>Enter Risk Management</h2></div></div></div><p>In the absence of formal assurances and provable metrics, and given the frightening prevalence of security flaws in key software relied upon by modern societies, businesses flock to another catchy concept: <span class="emphasis"><em>risk management</em></span>.<a class="indexterm" id="IDX-CHP-1-0010"/></p><p>The idea of risk management, applied successfully to the insurance business (with perhaps a bit less success in the financial world), simply states that system owners should learn to live with vulnerabilities that cannot be addressed in a cost-effective way and, in general, should scale efforts according to the following formula:</p><table border="0" class="simplelist" summary="Simple list"><tr><td><span class="emphasis"><em>risk</em></span> = <span class="emphasis"><em>probability of an event</em></span> × <span class="emphasis"><em>maximum loss</em></span></td></tr></table><p>For example, according to this doctrine, if having some unimportant workstation compromised yearly won’t cost the company more than $1,000 in lost productivity, the organization should just budget for this loss and move on, rather than spend say $100,000 on additional security measures or contingency and monitoring plans to prevent the loss. According to the doctrine of risk management, the money would be better spent on isolating, securing, and monitoring the mission-critical mainframe that churns out billing records for all customers.</p><p>Naturally, it’s prudent to prioritize security efforts. The problem is that when risk management is done strictly by the numbers, it does little to help us to understand, contain, and manage real-world problems. Instead, it introduces a dangerous fallacy: that structured inadequacy is almost as good as adequacy and that underfunded security efforts <span class="emphasis"><em>plus</em></span> risk management are about as good as properly funded security work.<a class="indexterm" id="IDX-CHP-1-0011"/><a class="indexterm" id="IDX-CHP-1-0012"/><a class="indexterm" id="IDX-CHP-1-0013"/><a class="indexterm" id="IDX-CHP-1-0014"/></p><p>Guess what? No dice.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>In interconnected systems, losses are not capped and are not tied to an asset</strong></span>. Strict risk management depends on the ability to estimate typical and maximum cost associated with the compromise of a resource. Unfortunately, the only way to do this is to overlook the fact that many of the most spectacular security breaches—such as the attacks on TJX<sup>[<a class="footnote" href="#ftn.CHP-1-FN-3" id="CHP-1-FN-3">4</a>]</sup> or Microsoft<sup>[<a class="footnote" href="#ftn.CHP-1-FN-4" id="CHP-1-FN-4">5</a>]</sup>—began at relatively unimportant and neglected entry points. These initial intrusions soon escalated and eventually resulted in the nearly complete compromise of critical infrastructure, bypassing any superficial network compartmentalization on their way. In typical by-the-numbers risk management, the initial entry point is assigned a lower weight because it has a low value when compared to other nodes. Likewise, the internal escalation path to more sensitive resources is downplayed as having a low probability of ever being abused. Still, neglecting them both proves to be an explosive mix.<a class="indexterm" id="IDX-CHP-1-0015"/><a class="indexterm" id="IDX-CHP-1-0016"/></p></li><li class="listitem"><p><span class="strong"><strong>The nonmonetary costs of intrusions are hard to offset with the value contributed by healthy systems</strong></span>. Loss of user confidence and business continuity, as well as the prospect of lawsuits and the risk of regulatory scrutiny, are difficult to meaningfully insure against. These effects can, at least in principle, make or break companies or even entire industries, and any superficial valuations of such outcomes are almost purely speculative.<a class="indexterm" id="IDX-CHP-1-0017"/></p></li><li class="listitem"><p><span class="strong"><strong>Existing data is probably not representative of future risks</strong></span>. Unlike the participants in a fender bender, attackers will not step forward to helpfully report break-ins and will not exhaustively document the damage caused. Unless the intrusion is painfully evident (due to the attacker’s sloppiness or disruptive intent), it will often go unnoticed. Even though industry-wide, self-reported data may be available, there is simply no reliable way of telling how complete it is or how much extra risk one’s current business practice may be contributing.</p></li><li class="listitem"><p><span class="strong"><strong>Statistical forecasting is not a robust predictor of individual outcomes</strong></span>. Simply because on average people in cities are more likely to be hit by lightning than mauled by a bear does not mean you should bolt a lightning rod to your hat and then bathe in honey. The likelihood that a compromise will be associated with a particular component is, on an individual scale, largely irrelevant: Security incidents are nearly certain, but out of thousands of exposed nontrivial resources, any service can be used as an attack vector—and no one service is likely to see a volume of events that would make statistical forecasting meaningful within the scope of a single enterprise.<a class="indexterm" id="IDX-CHP-1-0018"/><a class="indexterm" id="IDX-CHP-1-0019"/><a class="indexterm" id="IDX-CHP-1-0020"/><a class="indexterm" id="IDX-CHP-1-0021"/></p></li></ul></div></div><div class="sect2" title="Enlightenment Through Taxonomy"><div class="titlepage"><div><div><h2 class="title"><a id="enlightenment_through_taxonomy"/>Enlightenment Through Taxonomy</h2></div></div></div><p>The two schools of thought discussed above share something in common: Both assume that it is possible to define security as a set of computable goals and that the resulting unified theory of a secure system or a model of acceptable risk would then elegantly trickle down, resulting in an optimal set of low-level actions needed to achieve perfection in application design.</p><p>Some practitioners preach the opposite approach, which owes less to philosophy and more to the natural sciences. These practitioners argue that, much like Charles Darwin of the information age, by gathering sufficient amounts of low-level, experimental data, we will be able to observe, reconstruct, and document increasingly more sophisticated laws in order to arrive some sort of a unified model of secure computing.</p><p>This latter worldview brings us projects like the Department of Homeland Security-funded Common Weakness Enumeration (CWE), the goal of which, in the organization’s own words, is to develop a unified “Vulnerability Theory”; “improve the research, modeling, and classification of software flaws”; and “provide a common language of discourse for discussing, finding and dealing with the causes of software security vulnerabilities.” A typical, delightfully baroque example of the resulting taxonomy may be this:<a class="indexterm" id="IDX-CHP-1-0022"/><a class="indexterm" id="IDX-CHP-1-0023"/></p><div class="blockquote"><blockquote class="blockquote"><p>Improper Enforcement of Message or Data Structure</p><p>Failure to Sanitize Data into a Different Plane</p><p>Improper Control of Resource Identifiers</p><p>Insufficient Filtering of File and Other Resource Names for Executable Content</p></blockquote></div><p>Today, there are about 800 names in the CWE dictionary, most of which are as discourse-enabling as the one quoted here.</p><p>A slightly different school of naturalist thought is manifested in projects such as the Common Vulnerability Scoring System (CVSS), a business-backed collaboration that aims to strictly quantify known security problems in terms of a set of basic, machine-readable parameters. A real-world example of the resulting vulnerability descriptor may be this:<a class="indexterm" id="IDX-CHP-1-0024"/></p><div class="blockquote"><blockquote class="blockquote"><p>AV:LN / AC:L / Au:M / C:C / I:N / A:P / E:F / RL:T / RC:UR / CDP:MH / TD:H / CR:M / IR:L / AR:M</p></blockquote></div><p>Organizations and researchers are expected to transform this 14-dimensional vector in a carefully chosen, use-specific way in order to arrive at some sort of objective, verifiable, numerical conclusion about the significance of the underlying bug (say, “42”), precluding the need to judge the nature of security flaws in any more subjective fashion.<a class="indexterm" id="IDX-CHP-1-0025"/><a class="indexterm" id="IDX-CHP-1-0026"/></p><p>Yes, I am poking gentle fun at the expense of these projects, but I do not mean to belittle their effort. CWE, CVSS, and related projects serve noble goals, such as bringing a more manageable dimension to certain security processes implemented by large organizations. Still, none has yielded a grand theory of secure software, and I doubt such a framework is within sight.</p></div><div class="sect2" title="Toward Practical Approaches"><div class="titlepage"><div><div><h2 class="title"><a id="toward_practical_approaches"/>Toward Practical Approaches</h2></div></div></div><p>All signs point to security being largely a nonalgorithmic problem for now. The industry is understandably reluctant to openly embrace this notion, because it implies that there are no silver bullet solutions to preach (or better yet, commercialize); still, when pressed hard enough, eventually everybody in the security field falls back to a set of rudimentary, empirical recipes. These recipes are deeply incompatible with many business management models, but they are all that have really worked for us so far. They are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>Learning from (preferably other people’s) mistakes</strong></span>. Systems should be designed to prevent known classes of bugs. In the absence of automatic (or even just elegant) solutions, this goal is best achieved by providing ongoing design guidance, ensuring that developers know what could go wrong, and giving them the tools to carry out otherwise error-prone tasks in the simplest manner possible.</p></li><li class="listitem"><p><span class="strong"><strong>Developing tools to detect and correct problems</strong></span>. Security deficiencies typically have no obvious side effects until they’re discovered by a malicious party: a pretty costly feedback loop. To counter this problem, we create security quality assurance (QA) tools to validate implementations and perform audits periodically to detect casual mistakes (or systemic engineering deficiencies).<a class="indexterm" id="IDX-CHP-1-0027"/></p></li><li class="listitem"><p><span class="strong"><strong>Planning to have everything compromised</strong></span>. History teaches us that major incidents will occur despite our best efforts to prevent them. It is important to implement adequate component separation, access control, data redundancy, monitoring, and response procedures so that service owners can react to incidents before an initially minor hiccup becomes a disaster of biblical proportions.</p></li></ul></div><p>In all cases, a substantial dose of patience, creativity, and real technical expertise is required from all the information security staff.</p><p>Naturally, even such simple, commonsense rules—essentially basic engineering rigor—are often dressed up in catchphrases, sprinkled liberally with a selection of acronyms (such as <span class="emphasis"><em>CIA</em></span>: <span class="emphasis"><em>confidentiality</em></span>, <span class="emphasis"><em>integrity</em></span>, <span class="emphasis"><em>availability</em></span>), and then called “methodologies.” Frequently, these methodologies are thinly veiled attempts to pass off one of the most frustrating failures of the security industry as yet another success story and, in the end, sell another cure-all product or certification to gullible customers. But despite claims to the contrary, such products are no substitute for street smarts and technical prowess—at least not today.<a class="indexterm" id="IDX-CHP-1-0028"/><a class="indexterm" id="IDX-CHP-1-0029"/><a class="indexterm" id="IDX-CHP-1-0030"/></p><p>In any case, through the remainder of this book, I will shy away from attempts to establish or reuse any of the aforementioned grand philosophical frameworks and settle for a healthy dose of anti-intellectualism instead. I will review the exposed surface of modern browsers, discuss how to use the available tools safely, which bits of the Web are commonly misunderstood, and how to control collateral damage when things go boom.</p><p>And that is, pretty much, the best take on security engineering that I can think of.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-1" id="ftn.CHP-1-FN-1">2</a>] </sup>The quote is attributed originally to Ivan Arce, a renowned vulnerability hunter, circa 2000; since then, it has been used by Crispin Cowan, Michael Howard, Anton Chuvakin, and scores of other security experts.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-2" id="ftn.CHP-1-FN-2">3</a>] </sup>In 1936, Alan Turing showed that (paraphrasing slightly) it is not possible to devise an algorithm that can generally decide the outcome of other algorithms. Naturally, some algorithms are very much decidable by conducting case-specific proofs, just not all of them.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-3" id="ftn.CHP-1-FN-3">4</a>] </sup>Sometime in 2006, several intruders, allegedly led by Albert Gonzalez, attacked an unsecured wireless network at a retail location and subsequently made their way through the corporate networks of the retail giant. They copied the credit card data of about 46 million customers and the Social Security numbers, home addresses, and so forth of about 450,000 more. Eleven people were charged in connection with the attack, one of whom committed suicide.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-4" id="ftn.CHP-1-FN-4">5</a>] </sup>Microsoft’s formally unpublished and blandly titled presentation <span class="emphasis"><em>Threats Against and Protection of Microsoft’s Internal Network</em></span> outlines a 2003 attack that began with the compromise of an engineer’s home workstation that enjoyed a long-lived VPN session to the inside of the corporation. Methodical escalation attempts followed, culminating with the attacker gaining access to, and leaking data from, internal source code repositories. At least to the general public, the perpetrator remains unknown.</p></div></div></div>
<div class="sect1" title="A Brief History of the Web"><div class="titlepage"><div><div><h1 class="title"><a id="a_brief_history_of_the_web"/>A Brief History of the Web</h1></div></div></div><p>The Web has been plagued by a perplexing number, and a remarkable variety, of security issues. Certainly, some of these problems can be attributed to one-off glitches in specific client or server implementations, but many are due to capricious, often arbitrary design decisions that govern how the essential mechanisms operate and mesh together on the browser end.</p><p>Our empire is built on shaky foundations—but why? Perhaps due to simple shortsightedness: After all, back in the innocent days, who could predict the perils of contemporary networking and the economic incentives behind today’s large-scale security attacks?</p><p>Unfortunately, while this explanation makes sense for truly ancient mechanisms such as SMTP or DNS, it does not quite hold water here: The Web is relatively young and took its current shape in a setting not that different from what we see today. Instead, the key to this riddle probably lies in the tumultuous and unusual way in which the associated technologies have evolved.</p><p>So, pardon me another brief detour as we return to the roots. The prehistory of the Web is fairly mundane but still worth a closer look.<a class="indexterm" id="IDX-CHP-1-0031"/></p><div class="sect2" title="Tales of the Stone Age: 1945 to 1994"><div class="titlepage"><div><div><h2 class="title"><a id="tales_of_the_stone_age_colon_1945_to_199"/>Tales of the Stone Age: 1945 to 1994</h2></div></div></div><p>Computer historians frequently cite a hypothetical desk-sized device called the Memex as one of the earliest fossil records, postulated in 1945 by Vannevar Bush.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-3">88</a>]</sup> Memex was meant to make it possible to create, annotate, and follow cross-document links in microfilm, using a technique that vaguely resembled modern-day bookmarks and hyperlinks. Bush boldly speculated that this simple capability would revolutionize the field of knowledge management and data retrieval (amusingly, a claim still occasionally ridiculed as uneducated and naïve until the early 1990s). Alas, any useful implementation of the design was out of reach at that time, so, beyond futuristic visions, nothing much happened until transistor-based computers took center stage.<a class="indexterm" id="IDX-CHP-1-0032"/><a class="indexterm" id="IDX-CHP-1-0033"/></p><p>The next tangible milestone, in the 1960s, was the arrival of IBM’s Generalized Markup Language (GML), which allowed for the annotation of documents with machine-readable directives indicating the function of each block of text, effectively saying “this is a header,” “this is a numbered list of items,” and so on. Over the next 20 years or so, GML (originally used by only a handful of IBM text editors on bulky mainframe computers) became the foundation for Standard Generalized Markup Language (SGML), a more universal and flexible language that traded an awkward colon- and period-based syntax for a familiar angle-bracketed one.<a class="indexterm" id="IDX-CHP-1-0034"/><a class="indexterm" id="IDX-CHP-1-0035"/><a class="indexterm" id="IDX-CHP-1-0036"/><a class="indexterm" id="IDX-CHP-1-0037"/><a class="indexterm" id="IDX-CHP-1-0038"/><a class="indexterm" id="IDX-CHP-1-0039"/><a class="indexterm" id="IDX-CHP-1-0040"/><a class="indexterm" id="IDX-CHP-1-0041"/></p><p>While GML was developing into SGML, computers were growing more powerful and user friendly. Several researchers began experimenting with Bush’s cross-link concept, applying it to computer-based document storage and retrieval, in an effort to determine whether it would be possible to cross-reference large sets of documents based on some sort of key. Adventurous companies and universities pursued pioneering projects such as ENQUIRE, NLS, and Xanadu, but most failed to make a lasting impact. Some common complaints about the various projects revolved around their limited practical usability, excess complexity, and poor scalability.<a class="indexterm" id="IDX-CHP-1-0042"/><a class="indexterm" id="IDX-CHP-1-0043"/><a class="indexterm" id="IDX-CHP-1-0044"/></p><p>By the end of the decade, two researchers, Tim Berners-Lee and Dan Connolly, had begun working on a new approach to the cross-domain reference challenge—one that focused on simplicity. They kicked off the project by drafting HyperText Markup Language (HTML), a bare-bones descendant of SGML, designed specifically for annotating documents with hyperlinks and basic formatting. They followed their work on HTML with the development of HyperText Transfer Protocol (HTTP), an extremely basic, dedicated scheme for accessing HTML resources using the existing concepts of Internet Protocol (IP) addresses, domain names, and file paths. The culmination of their work, sometime between 1991 and 1993, was Tim Berners-Lee’s World Wide Web (<a class="xref" href="ch01s02.html#tim_berners-leeas_world_wide_web" title="Figure 1-1. Tim Berners-Lee’s World Wide Web">Figure 1-1</a>), a rudimentary browser that parsed HTML and allowed users to render the resulting data on the screen, and then navigate from one page to another with a mouse click.</p><div class="figure"><a id="tim_berners-leeas_world_wide_web"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e646"/><img alt="Tim Berners-Lee’s World Wide Web" src="httpatomoreillycomsourcenostarchimages949987.png.jpg"/></div></div><p class="title">Figure 1-1. Tim Berners-Lee’s World Wide Web</p></div><p>To many people, the design of HTTP and HTML must have seemed a significant regression from the loftier goals of competing projects. After all, many of the earlier efforts boasted database integration, security and digital rights management, or cooperative editing and publishing; in fact, even Berners-Lee’s own project, ENQUIRE, appeared more ambitious than his current work. Yet, because of its low entry requirements, immediate usability, and unconstrained scalability (which happened to coincide with the arrival of powerful and affordable computers and the expansion of the Internet), the unassuming WWW project turned out to be a sudden hit.<a class="indexterm" id="IDX-CHP-1-0045"/><a class="indexterm" id="IDX-CHP-1-0046"/><a class="indexterm" id="IDX-CHP-1-0047"/><a class="indexterm" id="IDX-CHP-1-0048"/><a class="indexterm" id="IDX-CHP-1-0049"/><a class="indexterm" id="IDX-CHP-1-0050"/></p><p>All right, all right, it turned out to be a “hit” by the standards of the mid-1990s. Soon, there were no fewer than dozens of web servers running on the Internet. By 1993, HTTP traffic accounted for 0.1 percent of all bandwidth in the National Science Foundation backbone network. The same year also witnessed the arrival of Mosaic, the first reasonably popular and sophisticated web browser, developed at the University of Illinois. Mosaic extended the original World Wide Web code by adding features such as the ability to embed images in HTML documents and submit user data through forms, thus paving the way for the interactive, multimedia applications of today.<a class="indexterm" id="IDX-CHP-1-0051"/><a class="indexterm" id="IDX-CHP-1-0052"/><a class="indexterm" id="IDX-CHP-1-0053"/></p><p>Mosaic made browsing prettier, helping drive consumer adoption of the Web. And through the mid-1990s, it served as the foundation for two other browsers: Mosaic Netscape (later renamed Netscape Navigator) and Spyglass Mosaic (ultimately acquired by Microsoft and renamed Internet Explorer). A handful of competing non-Mosaic engines emerged as well, including Opera and several text-based browsers (such as Lynx and w3m). The first search engines, online newspapers, and dating sites followed soon after.<a class="indexterm" id="IDX-CHP-1-0054"/><a class="indexterm" id="IDX-CHP-1-0055"/><a class="indexterm" id="IDX-CHP-1-0056"/><a class="indexterm" id="IDX-CHP-1-0057"/></p></div><div class="sect2" title="The First Browser Wars: 1995 to 1999"><div class="titlepage"><div><div><h2 class="title"><a id="the_first_browser_wars_colon_1995_to_199"/>The First Browser Wars: 1995 to 1999</h2></div></div></div><p>By the mid-1990s, it was clear that the Web was here to stay and that users were willing to ditch many older technologies in favor of the new contender. Around that time, Microsoft, the desktop software behemoth that had been slow to embrace the Internet before, became uncomfortable and began to allocate substantial engineering resources to its own browser, eventually bundling it with the Windows operating system in 1996.<sup>[<a class="footnote" href="#ftn.CHP-1-FN-5" id="CHP-1-FN-5">6</a>]</sup> Microsoft’s actions sparked a period colloquially known as the “browser wars.”<a class="indexterm" id="IDX-CHP-1-0058"/><a class="indexterm" id="IDX-CHP-1-0059"/><a class="indexterm" id="IDX-CHP-1-0060"/><a class="indexterm" id="IDX-CHP-1-0061"/></p><p>The resulting arms race among browser vendors was characterized by the remarkably rapid development and deployment of new features in the competing products, a trend that often defied all attempts to standardize or even properly document all the newly added code. Core HTML tweaks ranged from the silly (the ability to make text blink, a Netscape invention that became the butt of jokes and a telltale sign of misguided web design) to notable ones, such as the ability to change typefaces or embed external documents in so-called frames. Vendors released their products with embedded programming languages such as JavaScript and Visual Basic, plug-ins to execute platform-independent Java or Flash applets on the user’s machine, and useful but tricky HTTP extensions such as cookies. Only a limited degree of superficial compatibility, sometimes hindered by patents and trademarks,<sup>[<a class="footnote" href="#ftn.CHP-1-FN-6" id="CHP-1-FN-6">7</a>]</sup> would be maintained.<a class="indexterm" id="IDX-CHP-1-0062"/><a class="indexterm" id="IDX-CHP-1-0063"/><a class="indexterm" id="IDX-CHP-1-0064"/><a class="indexterm" id="IDX-CHP-1-0065"/><a class="indexterm" id="IDX-CHP-1-0066"/><a class="indexterm" id="IDX-CHP-1-0067"/><a class="indexterm" id="IDX-CHP-1-0068"/><a class="indexterm" id="IDX-CHP-1-0069"/><a class="indexterm" id="IDX-CHP-1-0070"/><a class="indexterm" id="IDX-CHP-1-0071"/></p><p>As the Web grew larger and more diverse, a sneaky disease spread across browser engines under the guise of fault tolerance. At first, the reasoning seemed to make perfect sense: If browser A could display a poorly designed, broken page but browser B refused to (for any reason), users would inevitably see browser B’s failure as a bug in that product and flock in droves to the seemingly more capable client, browser A. To make sure that their browsers could display almost any web page correctly, engineers developed increasingly complicated and undocumented heuristics designed to second-guess the intent of sloppy webmasters, often sacrificing security and occasionally even compatibility in the process. Unfortunately, each such change further reinforced bad web design practices<sup>[<a class="footnote" href="#ftn.CHP-1-FN-7" id="CHP-1-FN-7">8</a>]</sup> and forced the remaining vendors to catch up with the mess to stay afloat. Certainly, the absence of sufficiently detailed, up-to-date standards did not help to curb the spread of this disease.<a class="indexterm" id="IDX-CHP-1-0072"/></p><p>In 1994, in order to mitigate the spread of engineering anarchy and govern the expansion of HTML, Tim Berners-Lee and a handful of corporate sponsors created the World Wide Web Consortium (W3C). Unfortunately for this organization, for a long while it could only watch helplessly as the format was randomly extended and tweaked. Initial W3C work on HTML 2.0 and HTML 3.2 merely tried to catch up with the status quo, resulting in half-baked specs that were largely out-of-date by the time they were released to the public. The consortium also tried to work on some novel and fairly well-thought-out projects, such as Cascading Style Sheets, but had a hard time getting buy-in from the vendors.<a class="indexterm" id="IDX-CHP-1-0073"/></p><p>Other efforts to standardize or improve already implemented mechanisms, most notably HTTP and JavaScript, were driven by other auspices such as the European Computer Manufacturers Association (ECMA), the International Organization for Standardization (ISO), and the Internet Engineering Task Force (IETF). Sadly, the whole of these efforts was seldom in sync, and some discussions and design decisions were dominated by vendors or other stakeholders who did not care much about the long-term prospects of the technology. The results were a number of dead standards, contradictory advice, and several frightening examples of harmful cross-interactions between otherwise neatly designed protocols—a problem that will be particularly evident when we discuss a variety of content isolation mechanisms in <a class="xref" href="ch09.html" title="Chapter 9. Content Isolation Logic">Chapter 9</a>.<a class="indexterm" id="IDX-CHP-1-0074"/><a class="indexterm" id="IDX-CHP-1-0075"/><a class="indexterm" id="IDX-CHP-1-0076"/><a class="indexterm" id="IDX-CHP-1-0077"/></p></div><div class="sect2" title="The Boring Period: 2000 to 2003"><div class="titlepage"><div><div><h2 class="title"><a id="the_boring_period_colon_2000_to_2003"/>The Boring Period: 2000 to 2003</h2></div></div></div><p>As the efforts to wrangle the Web floundered, Microsoft’s dominance grew as a result of its operating system-bundling strategy. By the beginning of the new decade, Netscape Navigator was on the way out, and Internet Explorer held an impressive 80 percent market share—a number roughly comparable to what Netscape had held just five years before. On both sides of the fence, security and interoperability were the two most notable casualties of the feature war, but one could hope now that the fighting was over, developers could put differences aside and work together to fix the mess.<a class="indexterm" id="IDX-CHP-1-0078"/><a class="indexterm" id="IDX-CHP-1-0079"/><a class="indexterm" id="IDX-CHP-1-0080"/><a class="indexterm" id="IDX-CHP-1-0081"/><a class="indexterm" id="IDX-CHP-1-0082"/><a class="indexterm" id="IDX-CHP-1-0083"/><a class="indexterm" id="IDX-CHP-1-0084"/></p><p>Instead, dominance bred complacency: Having achieved its goals brilliantly, Microsoft had little incentive to invest heavily in its browser. Although through version 5, major releases of Internet Explorer (IE) arrived yearly, it took two years for version 6 to surface, then five full years for Internet Explorer 6 to be updated to Internet Explorer 7. Without Microsoft’s interest, other vendors had very little leverage to make disruptive changes; most sites were unwilling to make improvements that would work for only a small fraction of their visitors.</p><p>On the upside, the slowdown in browser development allowed the W3C to catch up and to carefully explore some new concepts for the future of the Web. New initiatives finalized around the year 2000 included HTML 4 (a cleaned-up language that deprecated or banned many of the redundant or politically incorrect features embraced by earlier versions) and XHTML 1.1 (a strict and well-structured XML-based format that was easier to unambiguously parse, with no proprietary heuristics allowed). The consortium also made significant improvements to JavaScript’s Document Object Model and to Cascading Style Sheets. Regrettably, by the end of the century, the Web was too mature to casually undo some of the sins of the old, yet too young for the security issues to be pressing and evident enough for all to see. Syntax was improved, tags were deprecated, validators were written, and deck chairs were rearranged, but the browsers remained pretty much the same: bloated, quirky, and unpredictable.<a class="indexterm" id="IDX-CHP-1-0085"/><a class="indexterm" id="IDX-CHP-1-0086"/><a class="indexterm" id="IDX-CHP-1-0087"/></p><p>But soon, something interesting happened: Microsoft gave the world a seemingly unimportant, proprietary API, confusingly named <span class="emphasis"><em>XMLHttpRequest</em></span>. This trivial mechanism was meant to be of little significance, merely an attempt to scratch an itch in the web-based version of Microsoft Outlook. But <span class="emphasis"><em>XMLHttpRequest</em></span> turned out to be far more, as it allowed for largely unconstrained asynchronous HTTP communications between client-side JavaScript and the server without the need for time-consuming and disruptive page transitions. In doing so, the API contributed to the emergence of what would later be dubbed <span class="emphasis"><em>web 2.0—</em></span>a range of complex, unusually responsive, browser-based applications that enabled users to operate on complex data sets, collaborate and publish content, and so on, invading the sacred domain of “real,” installable client software in the process. Understandably, this caused quite a stir.<a class="indexterm" id="IDX-CHP-1-0088"/></p></div><div class="sect2" title="Web 2.0 and the Second Browser Wars: 2004 and Beyond"><div class="titlepage"><div><div><h2 class="title"><a id="web_2.0_and_the_second_browser_wars_colo"/>Web 2.0 and the Second Browser Wars: 2004 and Beyond</h2></div></div></div><p><span class="emphasis"><em>XMLHttpRequest</em></span>, in conjunction with the popularity of the Internet and the broad availability of web browsers, pushed the Web to some new, exciting frontiers—and brought us a flurry of security bugs that impacted both individual users and businesses. By about 2002, worms and browser vulnerabilities had emerged as a frequently revisited theme in the media. Microsoft, by virtue of its market dominance and a relatively dismissive security posture, took much of the resulting PR heat. The company casually downplayed the problem, but the trend eventually created an atmosphere conducive to a small rebellion.<a class="indexterm" id="IDX-CHP-1-0089"/><a class="indexterm" id="IDX-CHP-1-0090"/><a class="indexterm" id="IDX-CHP-1-0091"/></p><p>In 2004, a new contender in the browser wars emerged: Mozilla Firefox (a community-supported descendant of Netscape Navigator) took the offensive, specifically targeting Internet Explorer’s poor security track record and standards compliance. Praised by both IT journalists and security experts, Firefox quickly secured a 20 percent market share. While the newcomer soon proved to be nearly as plagued by security bugs as its counterpart from Redmond, its open source nature and the freedom from having to cater to stubborn corporate users allowed developers to fix issues much faster.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Why would vendors compete so feverishly? Strictly speaking, there is no money to be made by having a particular market share in the browser world. That said, pundits have long speculated that it is a matter of power: By bundling, promoting, or demoting certain online services (even as simple as the default search engine), whoever controls the browser controls much of the Internet.</p></div><p>Firefox aside, Microsoft had other reasons to feel uneasy. Its flagship product, the Windows operating system, was increasingly being used as an (expendable?) launch pad for the browser, with more and more applications (from document editors to games) moving to the Web. This could not be good.<a class="indexterm" id="IDX-CHP-1-0092"/></p><p>These facts, combined with the sudden emergence of Apple’s Safari browser and perhaps Opera’s advances in the world of smartphones, must have had Microsoft executives scratching their heads. They had missed the early signs of the importance of the Internet in the 1990s; surely they couldn’t afford to repeat the mistake. Microsoft put some steam behind Internet Explorer development again, releasing drastically improved and somewhat more secure versions 7, 8, and 9 in rapid succession.</p><p>Competitors countered with new features and claims of even better (if still superficial) standards compliance, safer browsing, and performance improvements. Caught off guard by the unexpected success of <span class="emphasis"><em>XMLHttpRequest</em></span> and quick to forget other lessons from the past, vendors also decided to experiment boldly with new ideas, sometimes unilaterally rolling out half-baked or somewhat insecure designs like <span class="emphasis"><em>globalStorage</em></span> in Firefox or <span class="emphasis"><em>httponly</em></span> cookies in Internet Explorer, just to try their luck.</p><p>To further complicate the picture, frustrated by creative differences with W3C, a group of contributors created a wholly new standards body called the Web Hypertext Application Technology Working Group (WHATWG). The WHATWG has been instrumental in the development of HTML5, the first holistic and security-conscious revision of existing standards, but it is reportedly shunned by Microsoft due to patent policy disputes.<a class="indexterm" id="IDX-CHP-1-0093"/></p><p>Throughout much of its history, the Web has enjoyed a unique, highly competitive, rapid, often overly political, and erratic development model with no unifying vision and no one set of security principles. This state of affairs has left a profound mark on how browsers operate today and how secure the user data handled by browsers can be.</p><p>Chances are, this situation is not going to change anytime soon.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-5" id="ftn.CHP-1-FN-5">6</a>] </sup>Interestingly, this decision turned out to be a very controversial one. On one hand, it could be argued that in doing so, Microsoft contributed greatly to the popularization of the Internet. On the other, it undermined the position of competing browsers and could be seen as anticompetitive. In the end, the strategy led to a series of protracted legal battles over the possible abuse of monopoly by the company, such as <span class="emphasis"><em>United States v. Microsoft</em></span>.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-6" id="ftn.CHP-1-FN-6">7</a>] </sup>For example, Microsoft did not want to deal with Sun to license a trademark for JavaScript (a language so named for promotional reasons and not because it had anything to do with Java), so it opted to name its almost-but-not-exactly-identical version “JScript.” Microsoft’s official documentation still refers to the software by this name.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-7" id="ftn.CHP-1-FN-7">8</a>] </sup>Prime examples of misguided and ultimately lethal browser features are content and character set-sniffing mechanisms, both of which will be discussed in <a class="xref" href="ch13.html" title="Chapter 13. Content Recognition Mechanisms">Chapter 13</a>.</p></div></div></div>
<div class="sect1" title="The Evolution of a Threat"><div class="titlepage"><div><div><h1 class="title"><a id="the_evolution_of_a_threat"/>The Evolution of a Threat</h1></div></div></div><p>Clearly, web browsers, and their associated document formats and communication protocols, evolved in an unusual manner. This evolution may explain the high number of security problems we see, but by itself it hardly proves that these problems are unique or noteworthy. To wrap up this chapter, let’s take a quick look at the very special characteristics behind the most prevalent types of online security threats and explore why these threats had no particularly good equivalents in the years before the Web.<a class="indexterm" id="IDX-CHP-1-0094"/><a class="indexterm" id="IDX-CHP-1-0095"/><a class="indexterm" id="IDX-CHP-1-0096"/><a class="indexterm" id="IDX-CHP-1-0097"/></p><div class="sect2" title="The User as a Security Flaw"><div class="titlepage"><div><div><h2 class="title"><a id="the_user_as_a_security_flaw"/>The User as a Security Flaw</h2></div></div></div><p>Perhaps the most striking (and entirely nontechnical) property of web browsers is that most people who use them are overwhelmingly unskilled. Sure, nonproficient users have been an amusing, fringe problem since the dawn of computing. But the popularity of the Web, combined with its remarkably low barrier to entry, means we are facing a new foe: Most users simply don’t know enough to stay safe.</p><p>For a long time, engineers working on general-purpose software have made seemingly arbitrary assumptions about the minimal level of computer proficiency required of their users. Most of these assumptions have been without serious consequences; the incorrect use of a text editor, for instance, would typically have little or no impact on system security. Incompetent users simply would not be able to get their work done, a wonderfully self-correcting issue.</p><p>Web browsers do not work this way, however. Unlike certain complicated software, they can be <span class="emphasis"><em>successfully</em></span> used by people with virtually no computer training, people who may not even know how to use a text editor. But at the same time, browsers can be operated <span class="emphasis"><em>safely</em></span> only by people with a pretty good understanding of computer technology and its associated jargon, including topics such as Public-Key Infrastructure. Needless to say, this prerequisite is not met by most users of some of today’s most successful web applications.</p><p>Browsers still look and feel as if they were designed by geeks and for geeks, complete with occasional cryptic and inconsistent error messages, complex configuration settings, and a puzzling variety of security warnings and prompts. A notable study by Berkeley and Harvard researchers in 2006 demonstrated that casual users are almost universally oblivious to signals that surely make perfect sense to a developer, such as the presence or absence of lock icons in the status bar.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-4">89</a>]</sup> In another study, Stanford and Microsoft researchers reached similar conclusions when they examined the impact of the modern “green URL bar” security indicator. The mechanism, designed to offer a more intuitive alternative to lock icons, actually made it easier to trick users by teaching the audience to trust a particular shade of green, no matter where this color appeared.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-5">90</a>]</sup></p><p>Some experts argue that the ineptitude of the casual user is not the fault of software vendors and hence not an engineering problem at all. Others note that when creating software so easily accessible and so widely distributed, it is irresponsible to force users to make security-critical decisions that depend on technical prowess not required to operate the program in the first place. To blame browser vendors alone is just as unfair, however: The computing industry as a whole has no robust answers in this area, and very little research is available on how to design comparably complex user interfaces (UIs) in a bulletproof way. After all, we barely get it right for ATMs.<a class="indexterm" id="IDX-CHP-1-0098"/><a class="indexterm" id="IDX-CHP-1-0099"/><a class="indexterm" id="IDX-CHP-1-0100"/></p></div><div class="sect2" title="The Cloud, or the Joys of Communal Living"><div class="titlepage"><div><div><h2 class="title"><a id="the_cloud_comma_or_the_joys_of_communal"/>The Cloud, or the Joys of Communal Living</h2></div></div></div><p>Another peculiar characteristic of the Web is the dramatically understated separation between unrelated applications and the data they process.</p><p>In the traditional model followed by virtually all personal computers over the last 15 years or so, there are very clear boundaries between high-level data objects (documents), user-level code (applications), and the operating system kernel that arbitrates all cross-application communications and hardware input/output (I/O) and enforces configurable security rules should an application go rogue. These boundaries are well studied and useful for building practical security schemes. A file opened in your text editor is unlikely to be able to steal your email, unless a really unfortunate conjunction of implementation flaws subverts all these layers of separation at once.</p><p>In the browser world, this separation is virtually nonexistent: Documents and code live as parts of the same intermingled blobs of HTML, isolation between completely unrelated applications is partial at best (with all sites nominally sharing a global JavaScript environment), and many types of interaction between sites are implicitly permitted with few, if any, flexible, browser-level security arbitration frameworks.</p><p>In a sense, the model is reminiscent of CP/M, DOS, and other principally nonmultitasking operating systems with no robust memory protection, CPU preemption, or multiuser features. The obvious difference is that few users depended on these early operating systems to simultaneously run multiple untrusted, attacker-supplied applications, so there was no particular reason for alarm.</p><p>In the end, the seemingly unlikely scenario of a text file stealing your email is, in fact, a frustratingly common pattern on the Web. Virtually all web applications must heavily compensate for unsolicited, malicious cross-domain access and take cumbersome steps to maintain at least some separation of code and the displayed data. And sooner or later, virtually all web applications fail. Content-related security issues, such as cross-site scripting or cross-site request forgery, are extremely common and have very few counterparts in dedicated, compartmentalized client architectures.</p></div><div class="sect2" title="Nonconvergence of Visions"><div class="titlepage"><div><div><h2 class="title"><a id="nonconvergence_of_visions"/>Nonconvergence of Visions</h2></div></div></div><p>Fortunately, the browser security landscape is not entirely hopeless, and despite limited separation between web applications, several selective security mechanisms offer rudimentary protection against the most obvious attacks. But this brings us to another characteristic that makes the Web such an interesting subject: There is no shared, holistic security model to grasp and live by. We are not looking for a grand vision for world peace, mind you, but simply a common set of flexible paradigms that would apply to most, if not all, of the relevant security logic. In the Unix world, for example, the <span class="emphasis"><em>rwx</em></span> user/group permission model is one such strong unifying theme. But in the browser realm?<a class="indexterm" id="IDX-CHP-1-0101"/><a class="indexterm" id="IDX-CHP-1-0102"/><a class="indexterm" id="IDX-CHP-1-0103"/><a class="indexterm" id="IDX-CHP-1-0104"/></p><p>In the browser realm, a mechanism called <span class="emphasis"><em>same-origin policy</em></span> could be considered a candidate for a core security paradigm, but only until one realizes that it governs a woefully small subset of cross-domain interactions. That detail aside, even within its scope, it has no fewer than seven distinct varieties, each of which places security boundaries between applications in a slightly different place.<sup>[<a class="footnote" href="#ftn.CHP-1-FN-8" id="CHP-1-FN-8">9</a>]</sup> Several dozen additional mechanisms, with no relation to the same-origin model, control other key aspects of browser behavior (essentially implementing what each author considered to be the best approach to security controls that day).</p><p>As it turns out, hundreds of small, clever hacks do not necessarily add up to a competent security opus. The unusual lack of integrity makes it very difficult even to decide where a single application ends and a different one begins. Given this reality, how does one assess attack surfaces, grant or take away permissions, or accomplish just about any other security-minded task? Too often, “by keeping your fingers crossed” is the best response we can give.</p><p>Curiously, many well-intentioned attempts to improve security by defining new security controls only make the problem worse. Many of these schemes create new security boundaries that, for the sake of elegance, do not perfectly align with the hairy juxtaposition of the existing ones. When the new controls are finer grained, they are likely to be rendered ineffective by the legacy mechanisms, offering a false sense of security; when they are more coarse grained, they may eliminate some of the subtle assurances that the Web depends on right now. (Adam Barth and Collin Jackson explore the topic of destructive interference between browser security policies in their academic work.)<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-6">91</a>]</sup></p></div><div class="sect2" title="Cross-Browser Interactions: Synergy in Failure"><div class="titlepage"><div><div><h2 class="title"><a id="cross-browser_interactions_colon_synergy"/>Cross-Browser Interactions: Synergy in Failure</h2></div></div></div><p>The overall susceptibility of an ecosystem composed of several different software products could be expected to be equal to a simple sum of the flaws contributed by each of the applications. In some cases, the resulting exposure may be less (diversity improves resilience), but one would not expect it to be more.</p><p>The Web is once again an exception to the rule. The security community has discovered a substantial number of issues that cannot be attributed to any particular piece of code but that emerge as a real threat when various browsers try to interact with each other. No particular product can be easily singled out for blame: They are all doing their thing, and the only problem is that no one has bothered to define a common etiquette for all of them to obey.</p><p>For example, one browser may assume that, in line with its own security model, it is safe to pass certain URLs to external applications or to store or read back certain types of data from disk. For each such assumption, there likely exists at least one browser that strongly disagrees, expecting other parties to follow its rules instead. The exploitability of these issues is greatly aggravated by vendors’ desire to get their foot in the door and try to allow web pages to switch to their browser on the fly without the user’s informed consent. For example, Firefox allows pages to be opened in its browser by registering a <span class="emphasis"><em>firefoxurl:</em></span> protocol; Microsoft installs its own .NET gateway plug-in in Firefox; Chrome does the same to Internet Explorer via a protocol named <span class="emphasis"><em>cf:</em></span>.<a class="indexterm" id="IDX-CHP-1-0105"/><a class="indexterm" id="IDX-CHP-1-0106"/></p><div class="note" title="Note"><h3 class="title">Note</h3><p>Especially in the case of such interactions, pinning the blame on any particular party is a fool’s errand. In a recent case of a bug related to <span class="emphasis"><em>firefoxurl:</em></span>, Microsoft and half of the information security community blamed Mozilla, while Mozilla and the other half of experts blamed Microsoft.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-7">92</a>]</sup> It did not matter who was right: The result was still a very real mess.</p></div><p>Another set of closely related problems (practically unheard of in the days before the Web) are the incompatibilities in superficially similar security mechanisms implemented in each browser. When the security models differ, a sound web application–engineering practice in one product may be inadequate and misguided in another. In fact, several classes of rudimentary tasks, such as serving a user-supplied plaintext file, cannot be safely implemented in certain browsers at all. This fact, however, will not be obvious to developers unless they are working in one of the affected browsers—and even then, they need to hit just the right spot.</p><p>In the end, all the characteristics outlined in this section contribute to a whole new class of security vulnerabilities that a taxonomy buff might call a <span class="emphasis"><em>failure to account for undocumented diversity</em></span>. This class is very well populated today.</p></div><div class="sect2" title="The Breakdown of the Client-Server Divide"><div class="titlepage"><div><div><h2 class="title"><a id="the_breakdown_of_the_client-server_divid"/>The Breakdown of the Client-Server Divide</h2></div></div></div><p>Information security researchers enjoy the world of static, clearly assigned roles, which are a familiar point of reference when mapping security interactions in the otherwise complicated world. For example, we talk about Alice and Bob, two wholesome, hardworking users who want to communicate, and Mallory, a sneaky attacker who is out to get them. We then have client software (essentially dumb, sometimes rogue I/O terminals that frivolously request services) and humble servers, carefully fulfilling the clients’ whim. Developers learn these roles and play along, building fairly comprehensible and testable network-computing environments in the process.</p><p>The Web began as a classical example of a proper client-server architecture, but the functional boundaries between client and server responsibilities were quickly eroded. The culprit is JavaScript, a language that offers the HTTP servers a way to delegate application logic to the browser (“client”) side and gives them two very compelling reasons to do so. First, such a shift often results in more responsive user interfaces, as servers do not need to synchronously participate in each tiny UI state change imaginable. Second, server-side CPU and memory requirements (and hence service-provisioning costs) can decrease drastically when individual workstations across the globe chip in to help with the bulk of the work.<a class="indexterm" id="IDX-CHP-1-0107"/></p><p>The client-server diffusion process began innocently enough, but it was only a matter of time before the first security mechanisms followed to the client side too, along with all the other mundane functionality. For example, what was the point of carefully scrubbing HTML on the server side when the data was only dynamically rendered by JavaScript on the client machine?</p><p>In some applications, this trend was taken to extremes, eventually leaving the server as little more than a dumb storage device and moving almost all the parsing, editing, display, and configuration tasks into the browser itself. In such designs, the dependency on a server could even be fully severed by using offline web extensions such as HTML5 persistent storage.</p><p>A simple shift in where the entire application magic happens is not necessarily a big deal, but not all security responsibilities can be delegated to the client as easily. For example, even in the case of a server acting as dumb storage, clients cannot be given indiscriminate access to all the data stored on the server for other users, and they cannot be trusted to enforce access controls. In the end, because it was not desirable to keep all the application security logic on the server side, and it was impossible to migrate it fully to the client, most applications ended up occupying some arbitrary middle ground instead, with no easily discernible and logical separation of duties between the client and server components. The resulting unfamiliar designs and application behaviors simply had no useful equivalents in the elegant and wholesome world of security role-play.</p><p>The situation has resulted in more than just a design-level mess; it has led to irreducible complexity. In a traditional client-server model with well-specified APIs, one can easily evaluate a server’s behavior without looking at the client, and vice versa. Moreover, within each of these components, it is possible to easily isolate smaller functional blocks and make assumptions about their intended operation. With the new model, coupled with the opaque, one-off application APIs common on the Web, these analytical tools, and the resulting ease of reasoning about the security of a system, have been brutally taken away.</p><p>The unexpected failure of standardized security modeling and testing protocols is yet another problem that earns the Web a very special—and scary—place in the universe of information security.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-1-FN-8" id="ftn.CHP-1-FN-8">9</a>] </sup>The primary seven varieties, as discussed throughout <a class="xref" href="pt02.html" title="Part II. Browser Security Features">Part II</a> of this book, include the security policy for JavaScript DOM access; <span class="emphasis"><em>XMLHttpRequest</em></span> API; HTTP cookies; local storage APIs; and plug-ins such as Flash, Silverlight, or Java.</p></div></div></div>
<div class="sect1" title="Global browser market share, May 2011"><div class="titlepage"><div><div><h1 class="title"><a id="global_browser_market_share_comma_may_20"/>Global browser market share, May 2011</h1></div></div></div><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Vendor<a class="indexterm" id="IDX-CHP-1-0108"/></p></th><th style="text-align: left" valign="bottom"><p>Browser Name</p></th><th colspan="2" style="text-align: left" valign="bottom"><p>Market Share</p></th></tr></thead><tbody><tr><td rowspan="4" style="text-align: left" valign="top"><p>Microsoft</p></td><td style="text-align: left" valign="top"><p>Internet Explorer 6</p></td><td style="text-align: left" valign="top"><p>10%</p></td><td rowspan="4" style="text-align: center" valign="middle"><p>52%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Internet Explorer 7</p></td><td style="text-align: left" valign="top"><p>7%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Internet Explorer 8</p></td><td style="text-align: left" valign="top"><p>31%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Internet Explorer 9</p></td><td style="text-align: left" valign="top"><p>4%</p></td></tr><tr><td rowspan="2" style="text-align: left" valign="top"><p>Mozilla</p></td><td style="text-align: left" valign="top"><p>Firefox 3</p></td><td style="text-align: left" valign="top"><p>12%</p></td><td rowspan="2" style="text-align: center" valign="middle"><p>22%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Firefox 4+</p></td><td style="text-align: left" valign="top"><p>10%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Google</p></td><td style="text-align: left" valign="top"><p>Chrome</p></td><td colspan="2" style="text-align: center" valign="top"><p>13%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Apple</p></td><td style="text-align: left" valign="top"><p>Safari</p></td><td colspan="2" style="text-align: center" valign="top"><p>7%</p></td></tr><tr><td style="text-align: left" valign="top"><p>Opera Software</p></td><td style="text-align: left" valign="top"><p>Opera</p></td><td colspan="2" style="text-align: center" valign="top"><p>3%</p></td></tr></tbody></table></div><p><span class="emphasis"><em>Source</em></span>: Data drawn from public Net Applications reports.<sup>[<a class="footnoteref" href="pr03.html#ftn.CHP-1-FT-8">93</a>]</sup></p></div></body></html>