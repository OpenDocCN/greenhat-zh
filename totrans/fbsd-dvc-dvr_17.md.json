["```\nstatic void\nem_msix_rx(void *arg)\n{\n        struct rx_ring *rxr = arg;\n        struct adapter *adapter = rxr->adapter;\n        bool more;\n\n        ++rxr->rx_irq;\n\n        more = em_rxeof(rxr, adapter->rx_process_limit, NULL);\n        if (more)\n                taskqueue_enqueue(rxr->tq, &rxr->rx_task);\n        else\n                E1000_WRITE_REG(&adapter->hw, E1000_IMS, rxr->ims);\n}\n```", "```\nstatic bool\nem_rxeof(struct rx_ring *rxr, int count, int *done)\n{\n        struct adapter *adapter = rxr->adapter;\n        struct ifnet *ifp = adapter->ifp;\n        struct e1000_rx_desc *cur;\n        struct mbuf *mp, *sendmp;\n        u8 status = 0;\n        u16 len;\n        int i, processed, rxdone = 0;\n        bool eop;\n\n        EM_RX_LOCK(rxr);\n\n      for (i = rxr->next_to_check, processed = 0; count != 0; ) {\n              if ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0)\n                        break;\n\n              bus_dmamap_sync(rxr->rxdma.dma_tag, rxr->rxdma.dma_map,\n                    BUS_DMASYNC_POSTREAD);\n\n                mp = sendmp = NULL;\n                cur = &rxr->rx_base[i];\n                status = cur->status;\n                if ((status & E1000_RXD_STAT_DD) == 0)\n                        break;\n                len = le16toh(cur->length);\n                eop = (status & E1000_RXD_STAT_EOP) != 0;\n\n                if ((cur->errors & E1000_RXD_ERR_FRAME_ERR_MASK) ||\n                    (rxr->discard == TRUE)) {\n                        ++ifp->if_ierrors;\n                        ++rxr->rx_discarded;\n                        if (!eop)\n                                rxr->discard = TRUE;\n                        else\n                                rxr->discard = FALSE;\n                      em_rx_discard(rxr, i);\n                        goto next_desc;\n                }\n...\n```", "```\n...\n              mp = rxr->rx_buffers[i].m_head;\n                mp->m_len = len;\n                rxr->rx_buffers[i].m_head = NULL;\n\n              if (rxr->fmp == NULL) {\n                        mp->m_pkthdr.len = len;\n                      rxr->fmp = rxr->lmp = mp;\n                } else {\n                        mp->m_flags &= ˜M_PKTHDR;\n                      rxr->lmp->m_next = mp;\n                      rxr->lmp = mp;\n                        rxr->fmp->m_pkthdr.len += len;\n                }\n...\n```", "```\n...\n                 if (eop) {\n                          --count;\n                        sendmp = rxr->fmp;\n                            sendmp->m_pkthdr.rcvif = ifp;\n                          ++ifp->if_ipackets;\n                        em_receive_checksum(cur, sendmp);\n #ifndef __NO_STRICT_ALIGNMENT\n                        if (adapter->max_frame_size >\n                              (MCLBYTES - ETHER_ALIGN) &&\n                            em_fixup_rx(rxr) != 0)\n                                  goto skip;\n  #endif\n                          if (status & E1000_RXD_STAT_VP) {\n                                  sendmp->m_pkthdr.ether_vtag =\n                                      le16toh(cur->special) &\n                                      E1000_RXD_SPC_VLAN_MASK;\n                                  sendmp->m_flags |= M_VLANTAG;\n                          }\n  #ifndef __NO_STRICT_ALIGNMENT\n  skip:\n  #endif\n                        rxr->fmp = rxr->lmp = NULL;\n                  }\n  ...\n```", "```\n...\nnext_desc:\n                cur->status = 0;\n                ++rxdone;\n                ++processed;\n\n                if (++i == adapter->num_rx_desc)\n                        i = 0;\n\n              if (sendmp != NULL) {\n                        rxr->next_to_check = i;\n                        EM_RX_UNLOCK(rxr);\n                      (*ifp->if_input)(ifp, sendmp);\n                        EM_RX_LOCK(rxr);\n                        i = rxr->next_to_check;\n                }\n\n                if (processed == 8) {\n                      em_refresh_mbufs(rxr, i);\n                        processed = 0;\n                }\n        }                                      /* The end of the for loop. */\n...\n```", "```\n...\n        if (e1000_rx_unrefreshed(rxr))\n                em_refresh_mbufs(rxr, i);\n\n        rxr->next_to_check = i;\n        if (done != NULL)\n                *done = rxdone;\n        EM_RX_UNLOCK(rxr);\n\n      return ((status & E1000_RXD_STAT_DD) ? TRUE : FALSE);\n}\n```", "```\nstatic void\nem_handle_rx(void *context, int pending)\n{\n        struct rx_ring *rxr = context;\n        struct adapter *adapter = rxr->adapter;\n        bool more;\n\n        more = em_rxeof(rxr, adapter->rx_process_limit, NULL);\n        if (more)\n                taskqueue_enqueue(rxr->tq, &rxr->rx_task);\n        else\n                E1000_WRITE_REG(&adapter->hw, E1000_IMS, rxr->ims);\n}\n```", "```\nstatic void\nem_start(struct ifnet *ifp)\n{\n        struct adapter *adapter = ifp->if_softc;\n        struct tx_ring *txr = adapter->tx_rings;\n\n        if (ifp->if_drv_flags & IFF_DRV_RUNNING) {\n              EM_TX_LOCK(txr);\n              em_start_locked(ifp, txr);\n                EM_TX_UNLOCK(txr);\n        }\n}\n```", "```\nstatic void\nem_start_locked(struct ifnet *ifp, struct tx_ring *txr)\n{\n        struct adapter *adapter = ifp->if_softc;\n        struct mbuf *m_head;\n\n        EM_TX_LOCK_ASSERT(txr);\n\n        if ((ifp->if_drv_flags & (IFF_DRV_RUNNING | IFF_DRV_OACTIVE)) !=\n            IFF_DRV_RUNNING)\n                return;\n\n        if (!adapter->link_active)\n                return;\n\n      while (!IFQ_DRV_IS_EMPTY(&ifp->if_snd)) {\n              if (txr->tx_avail <= EM_TX_CLEANUP_THRESHOLD)\n                      em_txeof(txr);\n\n              if (txr->tx_avail < EM_MAX_SCATTER) {\n                      ifp->if_drv_flags |= IFF_DRV_OACTIVE;\n                        break;\n                }\n\n              IFQ_DRV_DEQUEUE(&ifp->if_snd, m_head);\n                if (m_head == NULL)\n                        break;\n\n                if (em_xmit(txr, &m_head)) {\n                        if (m_head == NULL)\n                                break;\n                        ifp->if_drv_flags |= IFF_DRV_OACTIVE;\n                        IFQ_DRV_PREPEND(&ifp->if_snd, m_head);\n                        break;\n                }\n\n                ETHER_BPF_MTAP(ifp, m_head);\n\n                txr->watchdog_time = ticks;\n                txr->queue_status = EM_QUEUE_WORKING;\n        }\n}\n```", "```\nstatic bool\nem_txeof(struct tx_ring *txr)\n{\n        struct adapter *adapter = txr->adapter;\n        struct ifnet *ifp = adapter->ifp;\n        struct e1000_tx_desc *tx_desc, *eop_desc;\n        struct em_buffer *tx_buffer;\n        int processed, first, last, done;\n\n        EM_TX_LOCK_ASSERT(txr);\n\n        if (txr->tx_avail == adapter->num_tx_desc) {\n                txr->queue_status = EM_QUEUE_IDLE;\n                return (FALSE);\n        }\n\n        processed = 0;\n      first = txr->next_to_clean;\n      tx_desc = &txr->tx_base[first];\n      tx_buffer = &txr->tx_buffers[first];\n      last = tx_buffer->next_eop;\n        eop_desc = &txr->tx_base[last];\n\n        if (++last == adapter->num_tx_desc)\n                last = 0;\n      done = last;\n...\n```", "```\n...\n        bus_dmamap_sync(txr->txdma.dma_tag, txr->txdma.dma_map,\n            BUS_DMASYNC_POSTREAD);\n\n      while (eop_desc->upper.fields.status & E1000_TXD_STAT_DD) {\n              while (first != done) {\n                      tx_desc->upper.data = 0;\n                        tx_desc->lower.data = 0;\n                        tx_desc->buffer_addr = 0;\n                        ++txr->tx_avail;\n                        ++processed;\n\n                        if (tx_buffer->m_head) {\n                                bus_dmamap_unload(txr->txtag,\n                                    tx_buffer->map);\n                              m_freem(tx_buffer->m_head);\n                                tx_buffer->m_head = NULL;\n                        }\n\n                        tx_buffer->next_eop = −1;\n                        txr->watchdog_time = ticks;\n\n                        if (++first == adapter->num_tx_desc)\n                                first = 0;\n                        tx_buffer = &txr->tx_buffers[first];\n                        tx_desc = &txr->tx_base[first];\n                }\n\n                ++ifp->if_opackets;\n\n                last = tx_buffer->next_eop;\n              if (last != −1) {\n                        eop_desc = &txr->tx_base[last];\n                        if (++last == adapter->num_tx_desc)\n                                last = 0;\n                        done = last;\n                } else\n                        break;\n        }\n\n        bus_dmamap_sync(txr->txdma.dma_tag, txr->txdma.dma_map,\n            BUS_DMASYNC_PREWRITE);\n...\n```", "```\n...\n        txr->next_to_clean = first;\n\n        if (!processed && ((ticks - txr->watchdog_time) > EM_WATCHDOG))\n                txr->queue_status = EM_QUEUE_HUNG;\n\n      if (txr->tx_avail > EM_MAX_SCATTER)\n              ifp->if_drv_flags &= ˜IFF_DRV_OACTIVE;\n\n        if (txr->tx_avail == adapter->num_tx_desc) {\n                txr->queue_status = EM_QUEUE_IDLE;\n              return (FALSE);\n        }\n\n      return (TRUE);\n}\n```", "```\nstatic void\nem_msix_tx(void *arg)\n{\n        struct tx_ring *txr = arg;\n        struct adapter *adapter = txr->adapter;\n        bool more;\n\n        ++txr->tx_irq;\n\n        EM_TX_LOCK(txr);\n        more = em_txeof(txr);\n        EM_TX_UNLOCK(txr);\n        if (more)\n              taskqueue_enqueue(txr->tq, &txr->tx_task);\n        else\n                E1000_WRITE_REG(&adapter->hw, E1000_IMS, txr->ims);\n}\n```", "```\nstatic void\nem_handle_tx(void *context, int pending)\n{\n        struct tx_ring *txr = context;\n        struct adapter *adapter = txr->adapter;\n        struct ifnet *ifp = adapter->ifp;\n\n        EM_TX_LOCK(txr);\n\n      em_txeof(txr);\n      em_start_locked(ifp, txr);\n        E1000_WRITE_REG(&adapter->hw, E1000_IMS, txr->ims);\n\n        EM_TX_UNLOCK(txr);\n}\n```"]