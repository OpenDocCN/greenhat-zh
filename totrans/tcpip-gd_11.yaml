- en: Part II-8. TCP/IP TRANSPORT LAYER PROTOCOLS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 42](ch42.html "Chapter 42. OVERVIEW AND COMPARISON OF TCP AND UDP")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 43](ch43.html "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 44](ch44.html "Chapter 44. TCP/IP USER DATAGRAM PROTOCOL (UDP)")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 45](ch45.html "Chapter 45. TCP OVERVIEW, FUNCTIONS, AND CHARACTERISTICS")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 46](ch46.html "Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS
    AND GENERAL OPERATION")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 47](ch47.html "Chapter 47. TCP BASIC OPERATION: CONNECTION ESTABLISHMENT,
    MANAGEMENT, AND TERMINATION")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 48](ch48.html "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER")'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 49](ch49.html "Chapter 49. TCP RELIABILITY AND FLOW CONTROL FEATURES")'
  prefs: []
  type: TYPE_NORMAL
- en: The first three layers of the OSI Reference Model—the physical layer, data link
    layer, and network layer—are very important layers for understanding how networks
    function. The physical layer moves bits over wires; the data link layer moves
    frames on a network; and the network layer moves datagrams on an internetwork.
    Taken as a whole, they are the parts of a protocol stack that are responsible
    for the actual nuts and bolts of getting data from one place to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Immediately above these three layers is the fourth layer of the OSI Reference
    Model: the transport layer, called the host-to-host transport layer in the TCP/IP
    model. This layer is interesting in that it resides in the very architectural
    center of the model. Accordingly, it represents an important transition point
    between the hardware-associated layers below it that do the grunt work and the
    layers above that are more software-oriented and abstract.'
  prefs: []
  type: TYPE_NORMAL
- en: Protocols running at the transport layer are charged with providing several
    important services to enable software applications in higher layers to work over
    an internetwork. They are typically responsible for allowing connections to be
    established and maintained between software services on possibly distant machines.
    Many higher-layer applications need to send data in a reliable way, without needing
    to worry about error correction, lost data, or flow management. However, network
    layer protocols are typically unreliable and unacknowledged. Transport layer protocols
    are often very tightly tied to the network layer protocols directly below them
    and designed specifically to take care of functions that are not dealt with by
    those protocols.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part describes transport layer protocols and related technologies used
    in the TCP/IP protocol suite. There are two main protocols at this layer: the
    Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP). UDP
    is the simpler of the two and doesn''t take a great deal of time to explain. In
    contrast, TCP is a rather complex protocol that is also a very important part
    of the TCP/IP protocol suite, and thus it requires considerably more explanation.'
  prefs: []
  type: TYPE_NORMAL
- en: The first chapter in this part provides a quick overview of the roles of these
    two protocols in the TCP/IP protocol suite, a discussion of why they are both
    important, and a summary that compares their key attributes. The second chapter
    describes the method that both protocols employ for addressing, using transport
    layer ports and sockets. The third chapter contains a discussion of UDP.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining five chapters encompass a comprehensive description of the concepts,
    characteristics, and functions of TCP. The fourth chapter in this part provides
    an overview of TCP, describing its history, what it does, and how it works. The
    fifth chapter covers some important background information that is necessary to
    understanding how TCP operates, explaining key concepts such as streams and segments,
    sliding windows, and TCP ports and connections. The sixth chapter describes the
    process used by TCP to establish, maintain, and terminate sessions. The seventh
    chapter describes TCP messages and how they are formatted and transferred. Finally,
    the last chapter in this part shows how TCP provides reliability and other important
    transport layer functions, such as flow control, retransmission of lost data,
    and congestion avoidance.
  prefs: []
  type: TYPE_NORMAL
- en: Since TCP is built on top of the Internet Protocol (IP), in describing TCP,
    I assume that you have at least a basic familiarity with IP (covered in [Part II-3](pt06.html
    "Part II-3. INTERNET PROTOCOL VERSION 4 (IP/IPV4)"); specifically, see Chapters
    [Chapter 15](ch15.html "Chapter 15. INTERNET PROTOCOL VERSIONS, CONCEPTS, AND
    OVERVIEW") and [Chapter 16](ch16.html "Chapter 16. IPV4 ADDRESSING CONCEPTS AND
    ISSUES") for descriptions of basic IP concepts).
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 42. OVERVIEW AND COMPARISON OF TCP AND UDP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: TCP/IP is the most important internetworking protocol suite in the world. It
    is the basis for the Internet and the "language" spoken by the vast majority of
    the world's networked computers. TCP/IP includes a large set of protocols that
    operate at the network layer and the layers above it. The suite as a whole is
    anchored at layer 3 by the Internet Protocol (IP), which many people consider
    the single most important protocol in the world of networking.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there's a bit of *architectural distance* between the network layer
    and the applications that run at the layers well above that layer. IP is the protocol
    that performs the bulk of the functions needed to make an internetwork work, but
    it does not include some capabilities that many applications need. In TCP/IP,
    a pair of protocols that operate at the transport layer performs these tasks.
    The protocols are the *Transmission Control Protocol (TCP)* and the *User Datagram
    Protocol (UDP)*.
  prefs: []
  type: TYPE_NORMAL
- en: Of these two, TCP gets the most attention. It is the transport layer protocol
    that is most often associated with TCP/IP. It is also the transport protocol that
    many of the Internet's most popular applications use.
  prefs: []
  type: TYPE_NORMAL
- en: UDP, on the other hand, gets second billing. However, UDP and TCP are really
    peers that play the same role in TCP/IP. They function very differently and provide
    different benefits for and drawbacks to the applications that use them. Yet they
    are both important to the protocol suite as a whole. This chapter introduces what
    TCP and UDP do and highlights the similarities and differences between them.
  prefs: []
  type: TYPE_NORMAL
- en: Two Protocols for TCP/IP Transport Layer Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The transport layer in a protocol suite is responsible for a specific set of
    functions. For this reason, you might expect that the TCP/IP suite would have
    a single main transport protocol that performs those functions, just as it has
    IP as its core protocol at the network layer. But there are *two* different widely
    used TCP/IP transport layer protocols, an arrangement that is probably one of
    the best examples of the power of protocol layering (showing that it was worth
    all the time you spent learning to understand that pesky OSI Reference Model back
    in Chapters [Chapter 5](ch05.html "Chapter 5. GENERAL OSI REFERENCE MODEL ISSUES
    AND CONCEPTS") through [Chapter 7](ch07.html "Chapter 7. OSI REFERENCE MODEL SUMMARY")).
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with a look back at layer 3\. In my overview of the key operating
    characteristics of IP in [Chapter 15](ch15.html "Chapter 15. INTERNET PROTOCOL
    VERSIONS, CONCEPTS, AND OVERVIEW"), I described several limitations of IP. The
    most important limitations are that IP is *connectionless*, *unreliable*, and
    *unacknowledged*. Using a best-effort paradigm, data is sent over an IP internetwork
    without first establishing a connection. Messages *usually* get where they need
    to go, but there are no guarantees, and the sender usually doesn't even know if
    the data arrived at its destination.
  prefs: []
  type: TYPE_NORMAL
- en: These characteristics present serious problems for software. Many, if not most,
    applications need to be able to count on the fact that the data they send will
    get to its destination without loss or error. Applications also want the connection
    between two devices to be automatically managed, with problems such as congestion
    and flow control taken care of as needed. Unless some mechanism is provided for
    this at lower layers, every application would need to perform these jobs, and
    that would be a massive duplication of effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, you might argue that establishing connections, providing reliability,
    and handling retransmissions, buffering, and data flow are sufficiently important
    that it might have been best to simply build these abilities directly into IP.
    Interestingly, that was exactly the case in the early days of TCP/IP. In the beginning
    there was just a single protocol called TCP. It combined the tasks of IP with
    the reliability and session management features that I just mentioned. There''s
    a big problem with this, however: Establishing connections, providing a mechanism
    for reliability, managing flow control, managing acknowledgments, and managing
    retransmissions all come at a cost of time and bandwidth. Building all of these
    capabilities into a single protocol that spanned layers 3 and 4 would mean that
    all applications would receive the benefits of reliability, but would also take
    on the costs. While this approach would be fine for many applications, there are
    others that either don''t need the reliability or can''t afford the overhead required
    to provide it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution was simple: Let the network layer (IP) take care of basic data
    movement on the internetwork, and define two protocols at the transport layer.
    One protocol would provide a rich set of services for applications that need that
    functionality, and the understanding would be that some overhead would be required
    when using this protocol. The other protocol would be simpler, providing little
    in the way of classic layer 4 functions, but it would be fast and easy to use.
    Thus, the result was two TCP/IP transport layer protocols:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transmission Control Protocol (TCP)** TCP is a full-featured, connection-oriented,
    reliable transport protocol for TCP/IP applications. It provides transport layer
    addressing that allows multiple software applications to simultaneously use a
    single IP address, and it allows a pair of devices to establish a virtual connection
    and then pass data bidirectionally. Transmissions are managed using a special
    *sliding window* system, with unacknowledged transmissions detected and automatically
    retransmitted. Additional functionality allows the flow of data between devices
    to be managed, and special circumstances to be addressed.'
  prefs: []
  type: TYPE_NORMAL
- en: '**User Datagram Protocol (UDP)** In contrast, UDP is a very simple transport
    protocol that provides transport layer addressing like TCP, but little else. UDP
    is barely more than a wrapper protocol that provides a way for applications to
    access IP. No connection is established, transmissions are unreliable, and data
    can be lost.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Many TCP/IP applications require different transport requirements,
    thus two TCP/IP transport layer protocols are necessary. The *Transmission Control
    Protocol (TCP)* is a full-featured, connection-oriented protocol that provides
    the acknowledged delivery of data while managing traffic flow and handling issues
    such as congestion and transmission loss. The *User Datagram Protocol (UDP)*,
    in contrast, is a much simpler protocol that concentrates only on delivering data
    in order to maximize the speed of communication when the features of TCP are not
    required.'
  prefs: []
  type: TYPE_NORMAL
- en: Applications of TCP and UDP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use an analogy, TCP is a fully loaded luxury performance sedan with a chauffeur
    and a satellite tracking/navigation system. It provides a lot of frills, comfort,
    and performance. It virtually guarantees that you will get where you need to go
    without any problems, and any concerns that do arise can be corrected. In contrast,
    UDP is a stripped-down race car. Its goal is simplicity and speed; everything
    else is secondary. You will probably get where you need to go, but you can have
    trouble keeping race cars up and running.
  prefs: []
  type: TYPE_NORMAL
- en: Having two transport layer protocols with such complementary strengths and weaknesses
    provides considerable flexibility to the creators of networking software.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most typical applications need the reliability and other services provided by
    TCP, and most applications don't care about the loss of a small amount of performance
    due to TCP's overhead requirements. For example, most applications that transfer
    files or important data between machines use TCP, because the loss of any portion
    of the file renders the data useless. Examples include such well-known applications
    as the Hypertext Transfer Protocol (HTTP), which is used by the World Wide Web
    (WWW), the File Transfer Protocol (FTP), and the Simple Mail Transfer Protocol
    (SMTP). I describe TCP applications in more detail in Section III.
  prefs: []
  type: TYPE_NORMAL
- en: UDP Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What sort of application doesn't care if its data gets there, and why would
    anyone want to use such an unreliable application? You might be surprised. A lot
    of TCP/IP protocols use UDP. It is a good match when the application doesn't really
    care if some of the data gets lost, such as if you are streaming video or multimedia.
    The application won't notice one lost byte of data. UDP is also a good match when
    the application itself chooses to provide some other mechanism to make up for
    the lack of functionality in UDP.
  prefs: []
  type: TYPE_NORMAL
- en: Applications that send very small amounts of data often use UDP and assume that
    the client will just send a new request later on if a request is sent and a reply
    is not received. This provides enough reliability without the overhead of a TCP
    connection. I discuss some common UDP applications in [Chapter 44](ch44.html "Chapter 44. TCP/IP
    USER DATAGRAM PROTOCOL (UDP)").
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Most typical applications, especially ones that send files
    or messages, require that data be delivered reliably, and therefore use TCP for
    transport. The loss of a small amount of data usually is not a concern to applications
    that use UDP or that use their own application-specific procedures for dealing
    with potential delivery problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that even though TCP is often described as being *slower* than UDP, this
    is a *relative* measurement. TCP is a very well-written protocol that is capable
    of highly efficient data transfers. It is slow only compared to UDP because of
    the overhead of establishing and managing connections. The difference can be significant,
    but it is not enormous.
  prefs: []
  type: TYPE_NORMAL
- en: Incidentally, if you want a good real-world illustration of why it's valuable
    to have both UDP and TCP, consider message transport under the Domain Name System
    (DNS). As described in [Chapter 57](ch57.html "Chapter 57. DNS MESSAGING AND MESSAGE,
    RESOURCE RECORD, AND MASTER FILE FORMATS"), DNS actually uses UDP for certain
    types of communication and TCP for others.
  prefs: []
  type: TYPE_NORMAL
- en: Summary Comparison of UDP and TCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the next few chapters, we will explore both UDP and TCP in further detail.
    I will help you to understand much better the strengths and drawbacks of both
    protocols. While informative, these chapters are time-consuming to read. Thus,
    for your convenience, I have included [Table 42-1](ch42s03.html#summary_comparison_of_udp_and_tcp-id001
    "Table 42-1. Summary Comparison of UDP and TCP"), which describes the most important
    attributes of both protocols and how they contrast with each other.
  prefs: []
  type: TYPE_NORMAL
- en: Table 42-1. Summary Comparison of UDP and TCP
  prefs: []
  type: TYPE_NORMAL
- en: '| Characteristic/Description | UDP | TCP |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| General Description | Simple, high-speed, low-functionality wrapper that
    interfaces applications to the network layer and does little else | Full-featured
    protocol that allows applications to send data reliably without worrying about
    network layer issues |'
  prefs: []
  type: TYPE_TB
- en: '| Protocol Connection Setup | Connectionless; data is sent without setup |
    Connection-oriented; connection must be established prior to transmission |'
  prefs: []
  type: TYPE_TB
- en: '| Data Interface to Application | Message-based; the application sends data
    in discrete packages | Stream-based; the application sends data with no particular
    structure |'
  prefs: []
  type: TYPE_TB
- en: '| Reliability and Acknowledgments | Unreliable, best-effort delivery without
    acknowledgments | Reliable delivery of messages; all data is acknowledged |'
  prefs: []
  type: TYPE_TB
- en: '| Retransmissions | Not performed; application must detect lost data and retransmit
    if needed | Delivery of all data is managed, and lost data is retransmitted automatically
    |'
  prefs: []
  type: TYPE_TB
- en: '| Features Provided to Manage Flow of Data | None | Flow control using sliding
    windows; window size adjustment heuristics; congestion-avoidance algorithms |'
  prefs: []
  type: TYPE_TB
- en: '| Overhead | Very low | Low, but higher than UDP |'
  prefs: []
  type: TYPE_TB
- en: '| Transmission Speed | Very high | High, but not as high as UDP |'
  prefs: []
  type: TYPE_TB
- en: '| Data Quantity Suitability | Small to moderate amounts of data (up to a few
    hundred bytes) | Small to very large amounts of data (up to a few gigabytes) |'
  prefs: []
  type: TYPE_TB
- en: '| Types of Applications That Use the Protocol | Applications where data delivery
    speed matters more than completeness, where small amounts of data are sent, or
    where multicast/broadcast are used | Most protocols and applications sending data
    that must be received reliably, including most file and message transfer protocols
    |'
  prefs: []
  type: TYPE_TB
- en: '| Well-Known Applications and Protocols | Multimedia applications, DNS, BOOTP,
    DHCP, TFTP, SNMP, RIP, NFS (early versions) | FTP, Telnet, SMTP, DNS, HTTP, POP,
    NNTP, IMAP, BGP, IRC, NFS (later versions) |'
  prefs: []
  type: TYPE_TB
- en: 'Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Internet Protocol (IP) addresses are the main form of addressing used on a TCP/IP
    network. These network layer addresses uniquely identify each network interface,
    and as such, they serve as the mechanism by which data is routed to the correct
    network on the internetwork and then to the correct device on that network.
  prefs: []
  type: TYPE_NORMAL
- en: But there is an additional level of addressing that occurs at the transport
    layer in TCP/IP, above that of the IP address. Both of the TCP/IP transport protocols—the
    Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP)—use the
    concepts of *ports* and *sockets* for virtual software addressing. Ports and sockets
    enable many applications to function simultaneously on an IP device.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I describe the special mechanism used for addressing in both
    TCP and UDP. I begin with a discussion of TCP/IP application processes, including
    the client/server nature of communication, which provides a background for explaining
    how ports and sockets are used. I then give an overview of the concept of ports
    and how they enable the multiplexing of data over an IP address. I describe the
    way that port numbers are categorized in ranges and assigned to server processes
    for common applications. I explain the concept of ephemeral port numbers used
    for clients. I then discuss sockets and their use for connection identification,
    including the means by which multiple devices can talk to a single port on another
    device. I then provide a summary table of the most common registered port numbers.
  prefs: []
  type: TYPE_NORMAL
- en: TCP/IP Processes, Multiplexing, and Client/Server Application Roles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most sensible place to start learning about how the TCP/IP protocol suite
    works is by examining IP itself, as well as the support protocols that function
    in tandem with it at the network layer. IP is the foundation upon which most of
    the rest of TCP/IP is built. It is the mechanism by which data is packaged and
    routed throughout a TCP/IP internetwork.
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense, then, that when we examine the operation of TCP/IP from the
    perspective of IP, we talk very generically about sending and receiving datagrams.
    To the IP layer software that sends and receives IP datagrams, the higher-level
    application that datagrams come from and go to is really unimportant. To IP, a
    datagram is a datagram. All datagrams are packaged and routed in the same way,
    and IP is mainly concerned with lower-level aspects of moving them between devices
    in an efficient manner. It's important to remember, however, that this is really
    an abstraction for the convenience of describing a layer 3 operation. It doesn't
    consider how datagrams are really generated and used above layer 3.
  prefs: []
  type: TYPE_NORMAL
- en: Layer 4 represents a transition point between the OSI model hardware-related
    layers (1, 2, and 3) and the software-related layers (5 to 7). This means that
    the TCP/IP transport layer protocols, TCP and UDP, need to pay attention to the
    way that software uses TCP/IP, even if IP really does not.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the entire point of having networks, internetworks, and protocol
    suites like TCP/IP is to enable networking *applications*. Most Internet users
    employ these applications on a daily basis. In fact, most of us run many different
    applications simultaneously. For example, you might use a web browser to check
    the news, a File Transfer Program (FTP) client to upload some pictures to share
    with family, and an Internet Relay Chat (IRC) program to discuss something with
    a friend or colleague. In fact, it is common to have multiple instances of a single
    application. The most common example is having multiple web browser windows open
    (I sometimes find myself with as many as 30 going at one time!).
  prefs: []
  type: TYPE_NORMAL
- en: Multiplexing and Demultiplexing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most communication in TCP/IP takes the form of exchanges of information between
    a program running on one device and a matching program running on another device.
    Each instance of an application represents a copy of that application's software
    that needs to send and receive information. These application instances are commonly
    called *processes*. A TCP/IP application process is any piece of networking software
    that sends and receives information using the TCP/IP protocol suite. This includes
    classic end-user applications such as the ones described earlier, and support
    protocols that behave like applications when they send messages. Examples of the
    latter would include a network management protocol like the Simple Network Management
    Protocol (SNMP; see Chapters [Chapter 65](ch65.html "Chapter 65. TCP/IP INTERNET
    STANDARD MANAGEMENT FRAMEWORK OVERVIEW") through [Chapter 69](ch69.html "Chapter 69. TCP/IP
    REMOTE NETWORK MONITORING (RMON)")), or even the routing protocol Border Gateway
    Protocol (BGP; see [Chapter 40](ch40.html "Chapter 40. BORDER GATEWAY PROTOCOL
    (BGP/BGP-4)")), which sends messages using TCP the way an application does.
  prefs: []
  type: TYPE_NORMAL
- en: So, a typical TCP/IP host has multiple processes, and each one needs to send
    and receive datagrams. All of these datagrams, however, must be sent using the
    same interface to the internetwork, using the IP layer. This means that the data
    from all applications (with some possible exceptions) is initially funneled down
    to the transport layer, where TCP or UDP handles it. From there, messages pass
    to the device's IP layer, where they are packaged in IP datagrams and sent out
    over the internetwork to different destinations. The technical term for this is
    *multiplexing*. This term simply means combining, and its use here is a software
    analog to the way multiplexing is done with signals (such as how individual telephone
    calls are packaged).
  prefs: []
  type: TYPE_NORMAL
- en: A complementary mechanism is responsible for the receipt of datagrams. At the
    same time that the IP layer multiplexes datagrams to send from many application
    processes, it receives many datagrams that are intended for different processes.
    The IP layer must take this stream of unrelated datagrams and pass them to the
    correct process (through the transport layer protocol above it). This is *demultiplexing*,
    the opposite of multiplexing.
  prefs: []
  type: TYPE_NORMAL
- en: You can see an illustration of the concept behind TCP/IP process multiplexing
    and demultiplexing in [Figure 43-1](ch43.html#process_multiplexing_and_demultiplexing_
    "Figure 43-1. Process multiplexing and demultiplexing in TCP/IP In a typical machine
    that is running TCP/IP, there are many different protocols and applications running
    simultaneously. This example shows four different applications communicating between
    a client and server machine. All four are multiplexed for transmission using the
    same IP software and physical connection; received data is demultiplexed and passed
    to the appropriate application. IP, TCP, and UDP provide a way of keeping the
    data from each application distinct.").
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP/IP is designed to allow many different applications to
    send and receive data simultaneously using the same IP software on a given device.
    To accomplish this, it is necessary to *multiplex* transmitted data from many
    sources as it is passed down to the IP layer. As a stream of IP datagrams is received,
    it is *demultiplexed* and the appropriate data passed to each application software
    instance on the receiving host.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP/IP Client Processes and Server Processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP/IP software is generally *asymmetric*. This means that when a TCP/IP application
    process on one computer tries to talk to an application process on another computer,
    the two processes are usually not exactly the same. They are instead *complements*
    of each other, designed to function together as a team.
  prefs: []
  type: TYPE_NORMAL
- en: As I explained in the overview description of TCP/IP in [Chapter 8](ch08.html
    "Chapter 8. TCP/IP PROTOCOL SUITE AND ARCHITECTURE"), most networking applications
    use a *client/server* model of operation. This term can be used to refer to the
    roles of computers, where a *server* is a relatively powerful machine that provides
    services to a large number of user-operated *clients*. It also applies to software.
    In a software context, a *client process* usually runs on a client machine and
    initiates contact to perform some sort of function. A *server process* usually
    runs on a hardware server, listens for requests from clients, and responds to
    them.
  prefs: []
  type: TYPE_NORMAL
- en: The classic example of this client/server operation is the World Wide Web (WWW).
    The Web uses the Hypertext Transfer Protocol (HTTP; see [Chapter 80](ch80.html
    "Chapter 80. HTTP GENERAL OPERATION AND CONNECTIONS")), which is a good example
    of an application protocol. A web browser is an HTTP client that normally runs
    on an end-user client machine. It initiates an exchange of HTTP (web) data by
    sending a request to a web (HTTP) server. A server process on that web server
    hears the request and replies either with the requested item(s)—a web page or
    other data—or an error message. The server is usually specifically designed to
    handle many incoming client requests, and in many cases, has no other use.
  prefs: []
  type: TYPE_NORMAL
- en: Why am I telling you all of this in a section that is supposed to explain TCP
    and UDP ports? I started here because many application processes run simultaneously
    and have their data multiplexed for transmission. The simultaneity of application
    processes and the multiplexing of data are the impetus for why higher-level addressing
    is a necessity in TCP/IP. The client/server arrangement used by TCP/IP has an
    important impact on the way that ports are used and the mechanisms for how they
    are assigned. The next two sections explore these concepts more completely.
  prefs: []
  type: TYPE_NORMAL
- en: '![Process multiplexing and demultiplexing in TCP/IP In a typical machine that
    is running TCP/IP, there are many different protocols and applications running
    simultaneously. This example shows four different applications communicating between
    a client and server machine. All four are multiplexed for transmission using the
    same IP software and physical connection; received data is demultiplexed and passed
    to the appropriate application. IP, TCP, and UDP provide a way of keeping the
    data from each application distinct.](httpatomoreillycomsourcenostarchimages288079.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 43-1. Process multiplexing and demultiplexing in TCP/IP In a typical
    machine that is running TCP/IP, there are many different protocols and applications
    running simultaneously. This example shows four different applications communicating
    between a client and server machine. All four are multiplexed for transmission
    using the same IP software and physical connection; received data is demultiplexed
    and passed to the appropriate application. IP, TCP, and UDP provide a way of keeping
    the data from each application distinct.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP/IP Ports: TCP/UDP Addressing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A typical host on a TCP/IP internetwork has many different software application
    processes running concurrently. Each process generates data that it sends to either
    TCP or UDP, which then passes it to IP for transmission. The IP layer sends out
    this multiplexed stream of datagrams to various destinations. Simultaneously,
    each device's IP layer is receiving datagrams that originated in numerous application
    processes on other hosts. These datagrams need to be demultiplexed so that they
    end up at the correct process on the device that receives them.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplexing and Demultiplexing Using Ports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The question is how do we demultiplex a sequence of IP datagrams that need to
    go to many different application processes? Let's consider a particular host with
    a single network interface bearing the IP address 24.156.79.20\. Normally, every
    datagram received by the IP layer will have this value in the IP Destination Address
    field. The consecutive datagrams that IP receives may contain a piece of a file
    you are downloading with your web browser, an email your brother sent to you,
    and a line of text a buddy wrote in an IRC chat channel. How does the IP layer
    know which datagrams go where if they all have the same IP address?
  prefs: []
  type: TYPE_NORMAL
- en: The first part of the answer lies in the Protocol field included in the header
    of each IP datagram. This field carries a code that identifies the protocol that
    sent the data in the datagram to IP. Since most end-user applications use TCP
    or UDP at the transport layer, the Protocol field in a received datagram tells
    IP to pass data to either TCP or UDP as appropriate. Of course, this just defers
    the problem to the transport layer.
  prefs: []
  type: TYPE_NORMAL
- en: Many applications use both TCP and UDP at once. This means that TCP or UDP must
    figure out which process to send the data to. To make this possible, an additional
    addressing element is necessary. This address allows a more specific location—a
    software process—to be identified within a particular IP address. In TCP/IP, this
    transport layer address is called a *port*.
  prefs: []
  type: TYPE_NORMAL
- en: Source Port and Destination Port Numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In UDP and TCP messages two addressing fields appear: a *source port* and a
    *destination port*. These are analogous to the source address and destination
    address fields at the IP level, but at a higher level of detail. They identify
    the originating process on the source machine and the destination process on the
    destination machine. The TCP or UDP software fills them in before transmission,
    and they direct the data to the correct process on the destination device.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*The term* port *has many meanings aside from this one in TCP/IP. For example,
    a physical outlet in a network device is often called a* port. *Usually, you can
    discern whether the port in question refers to a hardware port or a software port
    from the context*.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP and UDP port numbers are 16 bits in length. Valid port numbers can theoretically
    take on values from 0 to 65,535\. As you will see in the next section, these values
    are divided into ranges for different purposes, with certain ports reserved for
    particular uses.
  prefs: []
  type: TYPE_NORMAL
- en: One fact that is sometimes a bit confusing is that both UDP and TCP use the
    same range of port numbers, but they are independent. In theory, it is possible
    for UDP port number 77 to refer to one application process and TCP port number
    77 to refer to an entirely different one. There is no ambiguity, at least to the
    computers, because as mentioned earlier, each IP datagram contains a Protocol
    field that specifies whether it is carrying a TCP message or a UDP message. IP
    passes the datagram to either TCP or UDP, which sends the message on to the right
    process using the port number in the TCP or UDP header. This mechanism is illustrated
    in [Figure 43-2](ch43s02.html#tcpip_process_multiplexingdemultiplexing "Figure 43-2. TCP/IP
    process multiplexing/demultiplexing using TCP/UDP ports A more concrete version
    of Figure 43-1, this figure shows how TCP and UDP ports accomplish software multiplexing
    and demultiplexing. Again there are four different TCP/IP applications communicating,
    but this time I am showing only the traffic going from the client to the server.
    Two of the applications use TCP, and two use UDP. Each application on the client
    sends messages using a specific TCP or UDP port number. The server's UDP or TCP
    software uses these port numbers to pass the datagrams to the appropriate application
    process.").
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP/IP process multiplexing/demultiplexing using TCP/UDP ports A more concrete
    version of , this figure shows how TCP and UDP ports accomplish software multiplexing
    and demultiplexing. Again there are four different TCP/IP applications communicating,
    but this time I am showing only the traffic going from the client to the server.
    Two of the applications use TCP, and two use UDP. Each application on the client
    sends messages using a specific TCP or UDP port number. The server''s UDP or TCP
    software uses these port numbers to pass the datagrams to the appropriate application
    process.](httpatomoreillycomsourcenostarchimages288081.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 43-2. TCP/IP process multiplexing/demultiplexing using TCP/UDP ports
    A more concrete version of [Figure 43-1](ch43.html#process_multiplexing_and_demultiplexing_
    "Figure 43-1. Process multiplexing and demultiplexing in TCP/IP In a typical machine
    that is running TCP/IP, there are many different protocols and applications running
    simultaneously. This example shows four different applications communicating between
    a client and server machine. All four are multiplexed for transmission using the
    same IP software and physical connection; received data is demultiplexed and passed
    to the appropriate application. IP, TCP, and UDP provide a way of keeping the
    data from each application distinct."), this figure shows how TCP and UDP ports
    accomplish software multiplexing and demultiplexing. Again there are four different
    TCP/IP applications communicating, but this time I am showing only the traffic
    going from the client to the server. Two of the applications use TCP, and two
    use UDP. Each application on the client sends messages using a specific TCP or
    UDP port number. The server's UDP or TCP software uses these port numbers to pass
    the datagrams to the appropriate application process.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, having TCP and UDP use different port numbers is confusing, especially
    for the reserved port numbers that common applications use. To avoid confusion,
    by convention, most reserved port numbers are reserved for both TCP and UDP. For
    example, port 80 is reserved for HTTP for both TCP and UDP, even though HTTP only
    uses TCP. We'll examine this in greater detail in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP/IP transport layer addressing is accomplished by using
    TCP and UDP *ports*. Each port number within a particular IP device identifies
    a particular software process.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary of Port Use for Datagram Transmission and Reception
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s how transport layer addressing (port addressing) works in TCP and UDP:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sending Datagrams** An application specifies the source and destination port
    it wishes to use for the communication. The port numbers are encoded into the
    TCP or UDP header, depending on which transport layer protocol the application
    is using. When TCP or UDP passes data to IP, IP indicates the protocol type that''s
    appropriate for TCP or UDP in the Protocol field of the IP datagram. The source
    and destination port numbers are encapsulated as part of the TCP or UDP message,
    within the IP datagram''s data area.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receiving Datagrams** The IP software receives the datagram, inspects the
    Protocol field, and decides which protocol the datagram belongs to (in this case,
    TCP or UDP). TCP or UDP receives the datagram and passes its contents to the appropriate
    process based on the destination port number.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Application process multiplexing and demultiplexing in TCP/IP
    is implemented using the IP Protocol field and the UDP/TCP Source Port and Destination
    Port fields. Upon transmission, the Protocol field is given a number to indicate
    whether TCP or UDP was used, and the port numbers are filled in to indicate the
    sending and receiving software process. The device receiving the datagram uses
    the Protocol field to determine whether TCP or UDP was used and then passes the
    data to the software process that the destination port number indicates.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP/IP Application Assignments and Server Port Number Ranges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The port numbers I just discussed provide a method of transport layer addressing
    that allows many applications to use TCP and UDP simultaneously. By specifying
    the appropriate destination port number, an application sending data can be sure
    that the right process on the destination device will receive the message. Unfortunately,
    there's still a problem to be solved.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go back to using the World Wide Web. You fire up a web browser, which
    is client software that sends requests using HTTP. You need to know the IP address
    of the website you want to access, or you may have the Domain Name System (DNS)
    supply the IP address to you automatically. Once you have the address, the web
    browser can generate an HTTP message and send it to the website's IP address.
  prefs: []
  type: TYPE_NORMAL
- en: This HTTP message is intended for the web server process on the site you are
    trying to reach. The problem is how does the web browser (client process) know
    which port number has been assigned to the server process on the website? Port
    numbers can range from 0 to 65535, which means a lot of choices. And, in theory,
    every website could assign a different port number to its web server process.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of different ways to resolve this problem. TCP/IP takes
    what is probably the simplest possible approach: It *reserves* certain port numbers
    for particular applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Reserved Port Numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Server processes, which listen for requests for that application and then respond
    to them, assign each common application a specific port number. To avoid chaos,
    the software that implements a particular server process normally uses the same
    reserved port number on every IP device so that clients can find it easily.
  prefs: []
  type: TYPE_NORMAL
- en: In the example of accessing a website with a web browser, the reserved port
    number for HTTP is 80\. Every web browser knows that web designers design websites
    to listen for requests sent to port 80\. The web browser will thus use this value
    in requests to ensure that the IP and TCP software on the web browser directs
    these HTTP messages to the web server software. It is possible for a particular
    web server to use a different port number, but in this case, the web server must
    inform the user of this number somehow, and must explicitly tell the web browser
    to use it instead of the default port number (80).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** To allow client devices to establish connections to TCP/IP
    servers more easily, server processes for common applications use universal server
    port numbers. Clients are preprogrammed to know to use the port numbers by default.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order for this system to work well, universal agreement on port assignments
    is essential. Thus, this becomes another situation where a central authority is
    needed to manage a list of port assignments that everyone uses. For TCP/IP, it
    is the same authority responsible for the assignment and coordination of other
    centrally managed numbers, including IP addresses, IP protocol numbers, and so
    forth: the Internet Assigned Numbers Authority (IANA; see [Chapter 3](ch03.html
    "Chapter 3. NETWORK STANDARDS AND STANDARDS ORGANIZATIONS")).'
  prefs: []
  type: TYPE_NORMAL
- en: TCP/UDP Port Number Ranges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you have seen, there are 65,536 port numbers that can be used for processes.
    But there are also a fairly large number of TCP/IP applications, and the list
    grows every year. IANA needs to carefully manage the port number address space
    in order to ensure that port numbers are not wasted on protocols that won''t be
    widely used. IANA also needs to provide flexibility for organizations that must
    make use of obscure applications. To this end, the full spectrum of TCP and UDP
    port numbers is divided into three ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Well-Known (Privileged) Port Numbers (0 to 1023)** IANA manages these port
    numbers and reserves them for only the most universal TCP/IP applications. The
    IANA assigns these port numbers only to protocols that have been standardized
    using the TCP/IP RFC process, protocols that are in the process of being standardized,
    or protocols that are likely to be standardized in the future. On most computers,
    only server processes run by system administrators or privileged users use these
    port numbers. These processes generally correspond to processes that implement
    key IP applications, such as web servers, FTP servers, and the like. For this
    reason, these processes are sometimes called *system port numbers*.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Registered (User) Port Numbers (1024 to 49151)** There are many applications
    that need to use TCP/IP, but are not specified in RFCs or are not as universally
    used as other applications, so they do not warrant a worldwide well-known port
    number. To ensure that these various applications do not conflict with each other,
    IANA uses the bulk of the overall port number range for registered port numbers.
    Anyone who creates a viable TCP/IP server application can request to reserve one
    of these port numbers, and if the request is approved, the IANA will register
    that port number and assign it to the application. Any user on a system can generally
    access registered port numbers; thus they are sometimes called *user port numbers*.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Private/Dynamic Port Numbers (49152 to 65535)** IANA neither reserves nor
    maintains these ports. Anyone can use them for any purpose without registration,
    so they are appropriate for a private protocol that only a particular organization
    uses.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** IANA manages port-number assignments to ensure universal compatibility
    around the global Internet. The numbers are divided into three ranges: well-known
    port numbers used for the most common applications, registered port numbers for
    other applications, and private/dynamic port numbers that can be used without
    IANA registration.'
  prefs: []
  type: TYPE_NORMAL
- en: Use of these ranges ensures that there will be universal agreement on how to
    access a server process for the most common TCP/IP protocols. They also allow
    flexibility for special applications. Most of the TCP/IP applications and application
    protocols use numbers in the well-known port number range for their servers. These
    port numbers are not generally used for client processes, but there are some exceptions.
    For example, port 68 is reserved for a client using the Bootstrap Protocol (BOOTP)
    or Dynamic Host Configuration Protocol (DHCP).
  prefs: []
  type: TYPE_NORMAL
- en: TCP/IP Client (Ephemeral) Ports and Client/Server Application Port Use
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The significance of the asymmetry between clients and servers in TCP/IP becomes
    evident when you examine in detail how port numbers are used. Since clients initiate
    application data transfers using TCP and UDP, they need to know the port number
    of the server process. Consequently, servers are required to use universally known
    port numbers. Thus, well-known and registered port numbers identify server processes.
    Clients that send requests use the well-known or registered port number as the
    destination port number.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, servers respond to clients; they do not initiate contact with them.
    Thus, the client doesn't need to use a reserved port number. In fact, this is
    really an understatement. A server shouldn't use a well-known or registered port
    number to send responses back to clients because it is possible for a particular
    device to have client and server software from the same protocol running on the
    same machine. If a server received an HTTP request on port 80 of its machine and
    sent the reply back to port 80 on the client machine, the server would be sending
    the reply to the client machine's HTTP server process (if present), rather than
    the client process that sent the initial request.
  prefs: []
  type: TYPE_NORMAL
- en: To know where to send the reply, the server must know the port number the client
    is using. The client supplies the port number as the *source port* in the request,
    and then the server uses the source port as the destination port to send the reply.
    Client processes don't use well-known or registered ports. Instead, each client
    process is assigned a temporary port number for its use. This is commonly called
    an *ephemeral port number*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Your $10 word for the day:* ephemeral: *"short-lived; existing or continuing
    for a short time only." — Webster''s Revised Unabridged Dictionary*.'
  prefs: []
  type: TYPE_NORMAL
- en: Ephemeral Port Number Assignment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The TCP/IP software assigns ephemeral port numbers as needed to processes. Obviously,
    each client process that's running concurrently needs to use a unique ephemeral
    port number, so the TCP and UDP layers must keep track of which ones are in use.
    The TCP/IP software generally assigns these port numbers in a *pseudo-random*
    manner from a reserved pool of numbers. I say pseudo-random because there is no
    specific meaning to an ephemeral port number that is assigned to a process, so
    the TCP/IP software could select a random one for each client process. However,
    since it is necessary to reuse the port numbers in this pool over time, many implementations
    use a set of rules to minimize the chance of confusion due to reuse.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a client process that used only ephemeral port number 4121 to send
    a request. The client process received a reply and then terminated. Suppose you
    immediately reallocate 4121 to some other process. However, the prior user of
    port 4121 accesses the server, which for some reason sends an extra reply. The
    reply would go to the new process, thereby creating confusion. To avoid this,
    it is wise to wait as long as possible before reusing port number 4121 for another
    client process. Some implementations will therefore cycle through the port numbers
    in order to ensure that the maximum amount of time elapses between consecutive
    uses of the same ephemeral port number.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Well-known and registered port numbers are needed for server
    processes since a client must know the server''s port number to initiate contact.
    On the other hand, client processes can use any port number. Each time a client
    process initiates a UDP or TCP communication, the TCP/IP software assigns it a
    temporary, or *ephemeral*, port number to use for that conversation. The TCP/IP
    software assigns these port numbers in a pseudo-random way because the exact number
    that the software uses is not important as long as each process has a different
    number.'
  prefs: []
  type: TYPE_NORMAL
- en: Ephemeral Port Number Ranges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The range of port numbers that TCP/IP software uses for ephemeral ports on a
    device also depends on the implementation. The TCP/IP implementation in Berkeley
    Standard Distribution (BSD) UNIX established the classic ephemeral port range.
    BSD UNIX defined it as 1024 to 4999, thereby providing 3,976 ephemeral ports.
    This seems like a very large number, and it is indeed usually more than enough
    for a typical client. However, the size of this number can be deceiving. Many
    applications use more than one process, and it is theoretically possible to run
    out of ephemeral port numbers on a very busy IP device. For this reason, most
    of the time, the ephemeral port number range can be changed. The default range
    may be different for other operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: Just as well-known and registered port numbers are used for server processes,
    ephemeral port numbers are for client processes only. This means that the use
    of a range of addresses from 1024 to 4999 does not conflict with the use of that
    same range for registered port numbers. I discussed this in the previous section,
    "Ephemeral Port Number Assignment."
  prefs: []
  type: TYPE_NORMAL
- en: Port Number Use During a Client/Server Exchange
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now let's return to the matter of client/server application message exchange.
    Once a client is assigned an ephemeral port number, that port number is used as
    the source port in the client's request TCP/UDP message. The server receives the
    request and then generates a reply. In forming this response message, the server
    *swaps* the source and destination port numbers, just as it does the source and
    destination IP addresses. So the server's reply is sent from the well-known or
    registered port number on the server process back to the ephemeral port number
    on the client machine.
  prefs: []
  type: TYPE_NORMAL
- en: Now back to the web browser example. The web browser, with IP address 177.41.72.6,
    wants to send an HTTP request to a particular website at IP address 41.199.222.3\.
    The TCP/IP software sends the HTTP request with a *destination port* number of
    80 (the one reserved for HTTP servers). The TCP/IP software allocates the *source
    port* number from a pool of ephemeral ports; let's say it's port 3022\. When the
    HTTP request arrives at the web server, it is conveyed to port 80 where the HTTP
    server receives it. That process generates a reply and sends it back to 177.41.72.6,
    using *destination port* 3022 and *source port* 80\. The two processes can exchange
    information back and forth each time the TCP/IP software swaps the source port
    number and destination port number along with the source and destination IP addresses.
    This example is illustrated in [Figure 43-3](ch43s04.html#tcpip_clientserver_application_port_mech
    "Figure 43-3. TCP/IP client/server application port mechanics This highly simplified
    example shows how clients and servers use port numbers for a request.reply exchange.
    The client is making an HTTP request and sends it to the server at HTTP's well-known
    port number, 80\. Its port number for this exchange is the pseudo-randomly selected
    port 3022\. The server sends its reply back to that port number, which it reads
    from the request.").
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP/IP client/server application port mechanics This highly simplified example
    shows how clients and servers use port numbers for a request.reply exchange. The
    client is making an HTTP request and sends it to the server at HTTP''s well-known
    port number, 80\. Its port number for this exchange is the pseudo-randomly selected
    port 3022\. The server sends its reply back to that port number, which it reads
    from the request.](httpatomoreillycomsourcenostarchimages288083.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 43-3. TCP/IP client/server application port mechanics This highly simplified
    example shows how clients and servers use port numbers for a request.reply exchange.
    The client is making an HTTP request and sends it to the server at HTTP's well-known
    port number, 80\. Its port number for this exchange is the pseudo-randomly selected
    port 3022\. The server sends its reply back to that port number, which it reads
    from the request.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** In most TCP/IP client/server communications, the client uses
    a random ephemeral port number and sends a request to the appropriate reserved
    port number at the server''s IP address. The server sends its reply back to whatever
    port number it finds in the Source Port field of the request.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP/IP Sockets and Socket Pairs: Process and Connection Identification'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, I have discussed the key difference between addressing at the
    level of IP and addressing with regard to application processes. To summarize,
    at layer 3 an IP address is all that is really important for properly transmitting
    data between IP devices. In contrast, application protocols must be concerned
    with the port assigned to each instance of the application so that the protocols
    can properly use TCP or UDP.
  prefs: []
  type: TYPE_NORMAL
- en: So, the overall identification of an application process actually uses the combination
    of the IP address of the host it runs on—or the network interface over which it
    is talking, to be more precise—and the port number that has been assigned to it.
    This combined address is called a *socket*. Sockets are specified using the notation
    <*IP Address*>:<*Port Number*>. For example, if you have a website running on
    IP address 41.199.222.3, the socket corresponding to the HTTP server for that
    site would be *41.199.222.3:80*.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The overall identifier of a TCP/IP application process on a
    device is the combination of its IP address and port number, which is called a
    *socket*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also sometimes see a socket specified using a host name instead of
    an IP address, like this: <*Host Name*>:<*Port Number*>. To use this descriptor,
    the web browser must first resolve the name to an IP address using DNS. For example,
    you might find a website URL such as [http://www.thisisagreatsite.com:8080](http://www.thisisagreatsite.com:8080).
    This tells the web browser to *resolve* the name [www.thisisagreatsite.com](http://www.thisisagreatsite.com)
    first to an IP address using DNS. Then it tells the browser to send a request
    to that address using the nonstandard server port 8080, which the browser occasionally
    uses instead of port 80\. (See [Chapter 70](ch70.html "Chapter 70. TCP/IP APPLICATION
    LAYER ADDRESSING: UNIFORM RESOURCE IDENTIFIERS, LOCATORS, AND NAMES (URIS, URLS,
    AND URNS)")''s discussion of application layer addressing using URLs for more
    information.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *socket* is a fundamental concept to the operation of TCP/IP application
    software. In fact, it is the basis for an important TCP/IP application program
    interface (API) with the same name: *sockets*. A version of this API for Windows
    is called *Windows Sockets* or *Winsock*, which you may have heard of before.
    These APIs allow application programs to easily use TCP/IP to communicate.'
  prefs: []
  type: TYPE_NORMAL
- en: So the exchange of data between a pair of devices consists of a series of messages
    sent from a socket on one device to a socket on the other. Each device will normally
    have multiple simultaneous conversations going on. In the case of TCP, a connection
    is established for each pair of devices for the duration of the communication
    session. These connections must be managed, and this requires that they be uniquely
    identified. This is done using the socket identifiers for each of the two devices
    that are connected.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Each device may have multiple TCP connections active at any
    given time. Each connection is uniquely identified using the combination of the
    client socket and server socket, which in turn contains four elements: the client
    IP address and port, and the server IP address and port.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s return to the example in [Figure 43-3](ch43s04.html#tcpip_clientserver_application_port_mech
    "Figure 43-3. TCP/IP client/server application port mechanics This highly simplified
    example shows how clients and servers use port numbers for a request.reply exchange.
    The client is making an HTTP request and sends it to the server at HTTP''s well-known
    port number, 80\. Its port number for this exchange is the pseudo-randomly selected
    port 3022\. The server sends its reply back to that port number, which it reads
    from the request."). You are sending an HTTP request from your client at 177.41.72.6
    to the website at 41.199.222.3\. The server for that website will use well-known
    port number 80, so its socket is 41.199.222.3:80, as you saw before. You have
    been ephemeral port number 3022 for the web browser, so the client socket is 177.41.72.6:3022\.
    The overall connection between these devices can be described using this socket
    pair: (41.199.222.3:80, 177.41.72.6:3022).'
  prefs: []
  type: TYPE_NORMAL
- en: For much more on how TCP identifies connections, see the topic on TCP ports
    and connection identification in [Chapter 46](ch46.html "Chapter 46. TRANSMISSION
    CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION").
  prefs: []
  type: TYPE_NORMAL
- en: Unlike TCP, UDP is a connectionless protocol, so it obviously doesn't use connections.
    The pair of sockets on the sending and receiving devices can still be used to
    identify the two processes that are exchanging data, but because there are no
    connections, the socket pair doesn't have the significance that it does in TCP.
  prefs: []
  type: TYPE_NORMAL
- en: Common TCP/IP Applications and Well-Known and Registered Port Numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The great popularity of the TCP/IP protocol suite has led to the development
    of literally thousands of different applications and protocols. Most of these
    use the client/server model of operation that I discussed earlier in this chapter.
    Server processes for a particular application are designed to use a particular
    reserved port number, and clients use an ephemeral (temporary) port number to
    initiate a connection to the server. To ensure that everyone agrees on which port
    numbers each server application should use for each application, port numbers
    are centrally managed by the IANA.
  prefs: []
  type: TYPE_NORMAL
- en: Originally, IANA kept the list of well-known and registered port numbers in
    a lengthy text document along with all the many other parameters for which IANA
    was centrally responsible (such as IP Protocol field numbers, Type and Code field
    values for ICMP, and so on). These port numbers were published on a periodic basis
    in Internet (RFC) standards documents titled "Assigned Numbers." This system worked
    fine in the early days of the Internet, but by the mid-1990s, these values were
    changing so rapidly that using the RFC process was not feasible. It was too much
    work to keep publishing them, and the RFC was practically out of date the day
    after it was published.
  prefs: []
  type: TYPE_NORMAL
- en: The last "Assigned Numbers" standard was RFC 1700, which was published in October
    1994\. After that time, IANA moved to a set of World Wide Web documents that contained
    the parameters they manage. This allowed IANA to keep the lists constantly up-to-date,
    and enabled TCP/IP users to get more current information. RFC 1700 was officially
    obsoleted in 2002.
  prefs: []
  type: TYPE_NORMAL
- en: You can find complete information on all the parameters that IANA maintains
    at [http://www.iana.org/numbers.html](http://www.iana.org/numbers.html). The URL
    of the file that contains TCP/UDP port assignments is [http://www.iana.org/assignments/port-numbers](http://www.iana.org/assignments/port-numbers).
  prefs: []
  type: TYPE_NORMAL
- en: This document is the definitive list of all well-known and registered TCP and
    UDP port assignments. Each port number is assigned a short *keyword* with a brief
    description of the protocol that uses it. There are two problems with this document.
    First, it is incredibly long; it contains over 10,000 lines of text. Most of the
    protocols mentioned in those thousands of lines are for obscure applications that
    you have probably never heard of before (I certainly have never heard of most
    of them!). This makes it hard to easily see the port assignments for the protocols
    that are most commonly used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other problem with this document is that it shows the same port number
    as reserved for both TCP and UDP for an application. As I mentioned earlier, TCP
    and UDP port numbers are actually independent, so, in theory, one port number
    could assign TCP port 80 to one server application type and UDP port 80 to another.
    It was believed that this would lead to confusion, so with very few exceptions,
    the same port number is shown in the list for the same application for both TCP
    and UDP. Nevertheless, showing this in the list has a drawback: You can''t tell
    which protocol the application actually uses, and which has just been reserved
    for consistency.'
  prefs: []
  type: TYPE_NORMAL
- en: Given all that, I have decided to include a couple of summary tables that show
    the well-known and registered port numbers for the most common TCP/IP applications.
    I have indicated whether or not the protocol uses TCP, UDP, or both. [Table 43-1](ch43s06.html#common_tcpip_well-known_port_numbers_and
    "Table 43-1. Common TCP/IP Well-Known Port Numbers and Applications") lists the
    well-known port numbers for the most common TCP/IP application protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Table 43-1. Common TCP/IP Well-Known Port Numbers and Applications
  prefs: []
  type: TYPE_NORMAL
- en: '| Port # | TCP/UDP | Keyword | Protocol Abbreviation | Application or Protocol
    Name/Comments |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | TCP + UDP | echo | — | Echo Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | TCP + UDP | discard | — | Discard Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | TCP + UDP | systat | — | Active Users Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | TCP + UDP | daytime | — | Daytime Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | TCP + UDP | qotd | QOTD | Quote of the Day Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | TCP + UDP | chargen | — | Character Generator Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | TCP | ftp-data | FTP (data) | File Transfer Protocol (default data port)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | TCP | ftp | FTP (control) | File Transfer Protocol (control/commands)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | TCP | telnet | — | Telnet Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | TCP | smtp | SMTP | Simple Mail Transfer Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 37 | TCP + UDP | time | — | Time Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 43 | TCP | nicname | — | Whois Protocol (also called Nicname) |'
  prefs: []
  type: TYPE_TB
- en: '| 53 | TCP + UDP | domain | DNS | Domain Name Server (Domain Name System) |'
  prefs: []
  type: TYPE_TB
- en: '| 67 | UDP | bootps | BOOTP/DHCP | Bootstrap Protocol/Dynamic Host Configuration
    Protocol (server) |'
  prefs: []
  type: TYPE_TB
- en: '| 68 | UDP | bootpc | BOOTP/DHCP | Bootstrap Protocol/Dynamic Host Configuration
    Protocol (client) |'
  prefs: []
  type: TYPE_TB
- en: '| 69 | UDP | tftp | TFTP | Trivial File Transfer Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 70 | TCP | gopher | — | Gopher Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 79 | TCP | finger | — | Finger User Information Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 80 | TCP | http | HTTP | Hypertext Transfer Protocol (World Wide Web) |'
  prefs: []
  type: TYPE_TB
- en: '| 110 | TCP | pop3 | POP | Post Office Protocol (version 3) |'
  prefs: []
  type: TYPE_TB
- en: '| 119 | TCP | nntp | NNTP | Network News Transfer Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 123 | UDP | ntp | NTP | Network Time Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 137 | TCP + UDP | netbios-ns | — | NetBIOS (Name Service) |'
  prefs: []
  type: TYPE_TB
- en: '| 138 | UDP | netbios-dgm | — | NetBIOS (Datagram Service) |'
  prefs: []
  type: TYPE_TB
- en: '| 139 | TCP | netbios-ssn | — | NetBIOS (Session Service) |'
  prefs: []
  type: TYPE_TB
- en: '| 143 | TCP | imap | IMAP | Internet Message Access Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 161 | UDP | snmp | SNMP | Simple Network Management Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 162 | UDP | snmptrap | SNMP | Simple Network Management Protocol (Trap) |'
  prefs: []
  type: TYPE_TB
- en: '| 179 | TCP | bgp | BGP | Border Gateway Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 194 | TCP | irc | IRC | Internet Relay Chat |'
  prefs: []
  type: TYPE_TB
- en: '| 443 | TCP | https | HTTP over SSL | Hypertext Transfer Protocol over Secure
    Sockets Layer |'
  prefs: []
  type: TYPE_TB
- en: '| 500 | UDP | isakmp | IKE | IPsec Internet Key Exchange |'
  prefs: []
  type: TYPE_TB
- en: '| 520 | UDP | router | RIP | Routing Information Protocol (RIP-1 and RIP-2)
    |'
  prefs: []
  type: TYPE_TB
- en: '| 521 | UDP | ripng | RIPng | Routing Information Protocol - Next Generation
    |'
  prefs: []
  type: TYPE_TB
- en: The registered port numbers are by definition for protocols that are not standardized
    using the RFC process, so they are mostly esoteric applications, and I don't think
    it's necessary to list all of them. [Table 43-2](ch43s06.html#common_tcpip_registered_port_numbers_and
    "Table 43-2. Common TCP/IP Registered Port Numbers and Applications") shows a
    few that I feel are of particular interest.
  prefs: []
  type: TYPE_NORMAL
- en: Table 43-2. Common TCP/IP Registered Port Numbers and Applications
  prefs: []
  type: TYPE_NORMAL
- en: '| Port # | TCP/UDP | Keyword | Protocol Abbreviation | Application or Protocol
    Name/Comments |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1512 | TCP + UDP | wins | WINS | Microsoft Windows Internet Naming Service
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1701 | UDP | l2tp | L2TP | Layer 2 Tunneling Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 1723 | TCP | pptp | PPTP | Point-to-Point Tunneling Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| 2049 | TCP + UDP | nfs | NFS | Network File System |'
  prefs: []
  type: TYPE_TB
- en: '| 6000–6063 | TCP | x11 | X11 | X Window System |'
  prefs: []
  type: TYPE_TB
- en: Chapter 44. TCP/IP USER DATAGRAM PROTOCOL (UDP)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The very fact that the TCP/IP protocol suite bears the name of the Internet
    Protocol (IP) and the Transmission Control Protocol (TCP) suggests that these
    are the two key protocols in the suite. IP resides at the network layer, and TCP
    is at the transport layer. It's no wonder that many people don't even realize
    that there is a second transport layer protocol in TCP/IP.
  prefs: []
  type: TYPE_NORMAL
- en: Like a shy younger brother, the *User Datagram Protocol (UDP)* sits in the shadows
    while TCP gets the glory. The fancier sibling deserves much of this limelight,
    since TCP is arguably the more important of the two. However, UDP fills a critical
    niche in the TCP/IP protocol suite, because it allows many applications to work
    at their best when using TCP would be less than ideal.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I discuss UDP, the simpler and less-known TCP/IP transport
    protocol. I begin with an overview of the protocol and describe its history and
    standards. I outline how UDP operates, and explain the format used for UDP messages.
    I conclude with a discussion of what kinds of applications use UDP and the well-known
    or registered ports that are assigned to them.
  prefs: []
  type: TYPE_NORMAL
- en: UDP Overview, History, and Standards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I suppose the sibling rivalry analogy I mentioned in the introduction to this
    section may be a bit silly. I highly doubt that protocols lie awake at night worrying
    about how much we use them. However, it's interesting to discover just how important
    UDP really is, given how little attention it gets compared to TCP. In fact, in
    true older-sibling, spotlight-stealing fashion, you can't even really understand
    the history of UDP without first discussing TCP.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 8](ch08.html "Chapter 8. TCP/IP PROTOCOL SUITE AND ARCHITECTURE"),
    where I described the history of TCP/IP, I explained that very early on in the
    development of the protocol suite, there was only one protocol that handled the
    functions IP and TCP perform. This protocol, called TCP, provided network layer
    connectivity like IP, and also established connections, offered reliability, and
    took care of the typical transport layer quality requirements that you associate
    with modern TCP, such as flow control and retransmission handling.
  prefs: []
  type: TYPE_NORMAL
- en: It didn't take long before the developers of the fledgling combined TCP protocol
    quickly realized that mixing these functions together was a mistake. While most
    conventional applications needed the classic transport layer reliability functions,
    some did not. These features introduced overhead, which was added whether or not
    applications actually needed the reliability features. Worse, there were some
    applications for which the features not only were of no value, but also were a
    detriment, since even a small amount of lost performance due to the overhead would
    be a problem.
  prefs: []
  type: TYPE_NORMAL
- en: The solution was to separate the original protocol into IP and TCP. IP would
    do basic internetworking, and TCP would do the reliability features. This paved
    the way for the creation of an alternative transport layer protocol—UDP—for applications
    that didn't want or need the features that TCP provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main attributes that are always associated with UDP: simple and
    fast. UDP is a simple protocol that uses a very straightforward messaging structure
    that is similar to the message format that many other TCP/IP protocols use (in
    contrast to the more complex data structures—streams and segments—that TCP uses).
    In fact, when you boil it down, UDP''s only real goal is to serve as an interface
    between networking application processes that are running at the higher layers,
    and the internetworking capabilities of IP.'
  prefs: []
  type: TYPE_NORMAL
- en: Like TCP, UDP layers a method of transport layer addressing (and hence, process
    identification) on top of IP through the use of UDP port numbers. UDP includes
    an optional checksum capability for error detection, but adds virtually no other
    functionality.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to see the simplicity of UDP is to look at the standards that define
    it. Or rather, I should say *standard* in the singular, because there is only
    one. UDP was defined in RFC 768, "User Datagram Protocol," in 1980\. This document
    is three pages in length, and no one has ever needed to revise it.
  prefs: []
  type: TYPE_NORMAL
- en: UDP is a fast protocol specifically because it doesn't have all the bells and
    whistles of TCP. This makes it unsuitable for use by many, if not most, typical
    networking applications. But for some applications, this speed is exactly what
    the applications want from a transport layer protocol, namely something that takes
    the applications' data and quickly shuffles it down to the IP layer with minimal
    fuss. In choosing to use UDP, the application writer takes it upon himself to
    take care of issues such as reliability and retransmissions, if necessary. This
    can be a recipe for success or failure, depending on the application and how carefully
    the writer uses UDP.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** *The User Datagram Protocol (UDP)* was developed for use by
    application protocols that do not require reliability, acknowledgment, or flow
    control features at the transport layer. It is designed to be simple and fast.
    It provides only transport layer addressing (in the form of UDP ports), an optional
    checksum capability, and little else.'
  prefs: []
  type: TYPE_NORMAL
- en: UDP Operation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: UDP is so simple that I can't say a great deal about how it works. It is designed
    to do as little as possible.
  prefs: []
  type: TYPE_NORMAL
- en: What UDP Does
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'UDP''s only real task is to take data from higher-layer protocols and place
    it in UDP messages, which are then passed down to IP for transmission. The basic
    steps for transmission using UDP are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Higher-Layer Data Transfer** An application sends a message to the UDP software.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**UDP Message Encapsulation** The higher-layer message is encapsulated into
    the Data field of a UDP message. The headers of the UDP message are filled in,
    including the Source Port field of the application that sent the data to UDP and
    the Destination Port field of the intended recipient. The checksum value may also
    be calculated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Transfer Message to IP** The UDP message is passed to IP for transmission.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And that's about it. Of course, when the destination device receives the message,
    this short procedure is reversed.
  prefs: []
  type: TYPE_NORMAL
- en: What UDP Does Not Do
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'UDP is so simple that its operation is often described in terms of what it
    does not do, instead of what it does. As a transport protocol, UDP does not do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Establish connections before sending data. It just packages the data and sends
    it off.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide acknowledgments to show that data was received.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide any guarantees that its messages will arrive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect lost messages and retransmit them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that data is received in the same order that it was sent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide any mechanism to handle congestion or manage the flow of data between
    devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** UDP is probably the simplest protocol in all of TCP/IP. It
    takes application layer data that has been passed to it, packages it in a simplified
    message format, and sends it to IP for transmission.'
  prefs: []
  type: TYPE_NORMAL
- en: If these limitations sound similar the ones for IP, then you're paying attention.
    UDP is basically IP with transport layer port addressing. (For this reason, UDP
    is sometimes called a *wrapper protocol*, since all it does is wrap application
    data in its simple message format and send it to IP.)
  prefs: []
  type: TYPE_NORMAL
- en: However, despite the previous list, there are a couple of limited feedback and
    error-checking mechanisms that do exist within UDP. One is the optional checksum
    capability, which can allow for the detection of an error in transmission or the
    situation in which a UDP message is delivered to the wrong place (see the next
    section, "UDP Message Format" for details). The other is Internet Control Message
    Protocol (ICMP) error reporting (see [Chapter 31](ch31.html "Chapter 31. ICMP
    CONCEPTS AND GENERAL OPERATION")). For example, if a UDP message is sent that
    contains a destination port number that the destination device does not recognize,
    the destination host will send an ICMP Destination Unreachable message back to
    the original source. Of course, ICMP exists for all IP errors of this sort, so
    I'm stretching a bit here.
  prefs: []
  type: TYPE_NORMAL
- en: UDP Message Format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What's the magic word when it comes to UDP? It's *simple*. This is true of the
    operation of the protocol, and it is also true of the format used for UDP messages.
    Interestingly, however, there is one aspect of UDP that is not simple.
  prefs: []
  type: TYPE_NORMAL
- en: In keeping with the goal of efficiency, the UDP header is only 8 bytes in length.
    You can contrast this with the TCP header size of 20 bytes or more. [Table 44-1](ch44s03.html#udp_message_format-id002
    "Table 44-1. UDP Message Format") and [Figure 44-1](ch44s03.html#udp_message_format-id001
    "Figure 44-1. UDP message format") show the format of UDP messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The UDP Checksum field is the one area where the protocol is a bit confusing.
    The concept of a checksum itself is nothing new; checksums are used widely in
    networking protocols to provide protection against errors. What''s a bit odd is
    this notion of computing the checksum over the regular datagram as well as a pseudo
    header. So instead of calculating the checksum over only the fields in the UDP
    datagram, the UDP software first constructs a fake additional header that contains
    the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: IP Source Address field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IP Destination Address field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IP Protocol field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UDP Length field
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![UDP message format](httpatomoreillycomsourcenostarchimages288085.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 44-1. UDP message format
  prefs: []
  type: TYPE_NORMAL
- en: Table 44-1. UDP Message Format
  prefs: []
  type: TYPE_NORMAL
- en: '| Field Name | Size (Bytes) | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Source Port | 2 | The 16-bit port number of the process that originated the
    UDP message on the source device. This will normally be an ephemeral (client)
    port number for a request that a client sends to a server or a well-known/registered
    (server) port number for a reply that a server sends to a client. (See [Chapter 43](ch43.html
    "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS") for details.) |'
  prefs: []
  type: TYPE_TB
- en: '| Destination Port | 2 | The 16-bit port number of the process that is the
    ultimate intended recipient of the message on the destination device. This will
    usually be a well-known/registered (server) port number for a client request or
    an ephemeral (client) port number for a server reply. (See [Chapter 43](ch43.html
    "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS") for details.) |'
  prefs: []
  type: TYPE_TB
- en: '| Length | 2 | The length of the entire UDP datagram, including both header
    and Data fields. |'
  prefs: []
  type: TYPE_TB
- en: '| Checksum | 2 | An optional 16-bit checksum computed over the entire UDP datagram
    plus a special pseudo header of fields. See below for more information. |'
  prefs: []
  type: TYPE_TB
- en: '| Data | Variable | The encapsulated higher-layer message that will be sent.
    |'
  prefs: []
  type: TYPE_TB
- en: The UDP pseudo header format is illustrated in [Figure 44-2](ch44s03.html#udp_pseudo_header_format
    "Figure 44-2. UDP pseudo header format").
  prefs: []
  type: TYPE_NORMAL
- en: '![UDP pseudo header format](httpatomoreillycomsourcenostarchimages288087.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 44-2. UDP pseudo header format
  prefs: []
  type: TYPE_NORMAL
- en: The total length of this pseudo header is 11 bytes. It is padded to 12 bytes
    with a byte of zeros and then prepended to the real UDP message. The checksum
    is then computed over the combination of the pseudo header and the real UDP message,
    and the value is placed into the Checksum field. The pseudo header is used only
    for this calculation and is then discarded; it is not actually transmitted. The
    UDP software in the destination device creates the same pseudo header when calculating
    its checksum in order to compare it to the one transmitted in the UDP header.
  prefs: []
  type: TYPE_NORMAL
- en: Computing the checksum over the regular UDP fields protects the UDP message
    against bit errors. Adding the pseudo header allows the checksum to also protect
    the UDP message against other types of problems as well, most notably the accidental
    delivery of a message to the wrong destination. The checksum calculation in UDP,
    including the use of the pseudo header, is exactly the same as the method used
    in TCP (except that the Length field is different in TCP). See [Chapter 48](ch48.html
    "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER") for a full description
    of why the pseudo header is important, as well as some of the interesting implications
    of using IP fields in transport layer datagram calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** UDP packages application layer data into a very simple message
    format that includes only four header fields. One of these is an optional Checksum
    field. When the Checksum field is used, the checksum is computed over both the
    real header and a pseudo header of fields from the UDP and IP headers, in a manner
    that''s very similar to the way the TCP checksum is calculated.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the use of the Checksum field is optional in UDP. If UDP doesn't use
    the Checksum field, UDP sets it to a value of all zeros. This could potentially
    create confusion, however, since when UDP uses the checksum, the calculation can
    sometimes result in a value of zero. To avoid having the destination think that
    UDP didn't use the checksum in this case, UDP instead represents this zero value
    as a value of all ones (65,535 decimal).
  prefs: []
  type: TYPE_NORMAL
- en: UDP Common Applications and Server Port Assignments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you have seen, UDP contains very little functionality. With the exception
    of the important addressing capability that UDP ports represent, using UDP is
    very much like using IP. This means that UDP has most of the same disadvantages
    that IP has. It doesn't establish a lasting connection between devices; it doesn't
    acknowledge received data or retransmit lost messages; and it certainly isn't
    concerned with obscurities such as flow control and congestion management.
  prefs: []
  type: TYPE_NORMAL
- en: The absence of those features makes UDP simply unsuitable for the majority of
    classic networking applications. These applications usually need to establish
    a connection so that the two devices can exchange data. Many applications also
    must have the ability to occasionally, or even regularly, send very large amounts
    of data that must be received intact for it to be of value. For example, consider
    a message transfer protocol like the Hypertext Transfer Protocol (HTTP). If only
    part of a web page gets from a server back to a web browser, it's useless. HTTP
    and other file and message transfer protocols like it need the capabilities of
    TCP.
  prefs: []
  type: TYPE_NORMAL
- en: Why Some TCP/IP Applications Use UDP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So what applications use UDP then? UDP's classic limitation is that because
    it doesn't provide reliability features, an application that uses UDP is responsible
    for those functions. In reality, if an application needs the features that TCP
    provides but not the ones that UDP provides, it's inefficient to allow the application
    to implement those features, except in special cases. If the application needs
    what TCP provides, it should just use TCP! However, applications that only need
    some of what TCP implements are sometimes better off using UDP and implementing
    that limited set of functionality at the application level.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the applications that run over UDP are normally the ones that do not require
    all or even most of the features that TCP has. These applications can benefit
    from the increased efficiency that comes about from avoiding the setup and overhead
    associated with TCP. Applications usually (but not always) meet this description
    because the data they send falls into one of two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Where Performance Is More Important Than Completeness** The classic
    example of this category is a multimedia application. For streaming a video clip
    over the Internet, the most important feature is that the stream starts flowing
    quickly and keeps flowing. Human beings notice only significant disruptions in
    the flow of this type of information, so a few bytes of data missing due to a
    lost datagram is not a big problem. Furthermore, even if someone used TCP for
    something like this and noticed and retransmitted a lost datagram, it would be
    useless, because the lost datagram would belong to a part of the clip that is
    long past—and the time spent in that retransmission might make the current part
    of the clip arrive late. Clearly, UDP is best for this situation.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Exchanges That Are "Short and Sweet"** There are many TCP/IP applications
    in which the underlying protocol consists of only a very simple request/reply
    exchange. A client sends a short request message to a server, and a short reply
    message goes back from the server to the client. In this situation, there is no
    real need to set up a connection the way that TCP does. Also, if a client sends
    only one short message, a single IP datagram can carry the message. This means
    that there is no need to worry about data arriving out of order, flow control
    between the devices, and so forth. How about the loss of the request or the reply?
    These can be handled simply at the application level using timers. If a client
    sends a request and the server doesn''t get it, the server won''t reply, and the
    client will eventually send a replacement request. The same logic applies if the
    server sends a response that never arrives.'
  prefs: []
  type: TYPE_NORMAL
- en: These are the most common cases where UDP is used, but there are other reasons.
    For example, if an application needs to multicast or broadcast data, it must use
    UDP, because TCP is supported only for unicast communication between two devices.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A protocol uses UDP instead of TCP in two situations. The first
    is when an application values timely delivery over reliable delivery, and when
    TCP''s retransmission of lost data would be of limited or even no value. The second
    is when a simple protocol can handle the potential loss of an IP datagram itself
    at the application layer using a timer/retransmit strategy, and when the other
    features of TCP are not required. Applications that require multicast or broadcast
    transmissions also use UDP, because TCP does not support those transmissions.'
  prefs: []
  type: TYPE_NORMAL
- en: Incidentally, I have read about problems that have occurred in the past in applications
    using UDP. Sometimes, programmers don't realize how little UDP does, how it leaves
    the application responsible for handling all the potential vagaries of an internetworking
    environment. Someone writing a UDP-based application must always keep in mind
    that no one can make assumptions about how or even whether a destination will
    receive any message. Insufficient testing can lead to disaster in worst-case scenarios
    on a larger internetwork, especially the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: Common UDP Applications and Server Port Use
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Table 44-2](ch44s04.html#common_udp_applications_and_server-id001 "Table 44-2. Common
    UDP Applications and Server Port Assignments") shows some of the more interesting
    protocols that use UDP and the well-known and registered port numbers used for
    each one''s server processes. It also provides a very brief description of why
    these protocols use UDP instead of TCP.'
  prefs: []
  type: TYPE_NORMAL
- en: Applications That Use Both UDP and TCP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are some protocols that use both of the TCP/IP transport layer protocols.
    This is often the case either for utility protocols that are designed to accept
    connections using both transport layer protocols, or for applications that need
    the benefits of TCP in some cases but not others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The classic example of the latter is the TCP/IP Domain Name System (DNS), which
    normally uses UDP port 53 for simple requests and replies, which are usually short.
    Larger messages requiring reliable delivery, such as zone transfers, use TCP port
    53 instead. Note that in [Table 44-2](ch44s04.html#common_udp_applications_and_server-id001
    "Table 44-2. Common UDP Applications and Server Port Assignments"), I have omitted
    some of the less-significant protocols such as the ones used for diagnostic purposes
    (Echo, Discard, CharGen, and so on). For a full list of all common applications,
    see [Chapter 43](ch43.html "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS").'
  prefs: []
  type: TYPE_NORMAL
- en: Table 44-2. Common UDP Applications and Server Port Assignments
  prefs: []
  type: TYPE_NORMAL
- en: '| Port # | Keyword | Protocol | Comments |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 53 | domain | Domain Name Server (DNS) | Uses a simple request/reply messaging
    system for most exchanges (but also uses TCP for longer ones). |'
  prefs: []
  type: TYPE_TB
- en: '| 67 and 68 | bootps/bootpc | Bootstrap Protocol (BOOTP) and Dynamic Host Configuration
    Protocol (DHCP) | Host configuration protocols that consist of short request and
    reply exchanges. |'
  prefs: []
  type: TYPE_TB
- en: '| 69 | tftp | Trivial File Transfer Protocol (TFTP) | TFTP is a great example
    of a protocol that was specifically designed for UDP, especially when you compare
    it to regular FTP. The latter protocol uses TCP to establish a session between
    two devices and then makes use of its own large command set and TCP''s features
    in order to ensure the reliable transfer of possibly very large files. In contrast,
    TFTP is designed for the quick and easy transfer of small files. To avoid file
    corruption, TFTP includes simple versions of some of TCP''s features, such as
    acknowledgments. |'
  prefs: []
  type: TYPE_TB
- en: '| 161 and 162 | snmp | Simple Network Management Protocol | An administrative
    protocol that uses relatively short messages. |'
  prefs: []
  type: TYPE_TB
- en: '| 520 and 521 | router/ripng | Routing Information Protocol (RIP-1, RIP-2,
    RIPng) | Unlike more complex routing protocols like BGP, RIP uses a simple request/reply
    messaging system, doesn''t require connections, and does require multicasts/broadcasts.
    This makes it a natural choice for UDP. If a routing update is sent due to a request
    and is lost, it can be replaced by sending a new request. Routine (unsolicited)
    updates that are lost are replaced in the next cycle. |'
  prefs: []
  type: TYPE_TB
- en: '| 2049 | nfs | Network File System | NFS is an interesting case. Since it is
    a file-sharing protocol, you would think that it would use TCP instead of UDP,
    but it was originally designed to use UDP for performance reasons. There were
    many people who felt that this was not the best design decision, and later versions
    moved to the use of TCP. The latest version of NFS uses only TCP. |'
  prefs: []
  type: TYPE_TB
- en: Chapter 45. TCP OVERVIEW, FUNCTIONS, AND CHARACTERISTICS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As I mentioned in [Chapter 42](ch42.html "Chapter 42. OVERVIEW AND COMPARISON
    OF TCP AND UDP"), the Transmission Control Protocol (TCP) is a critically important
    part of the TCP/IP protocol suite. It's also a fairly complicated protocol, with
    a lot of important concepts and mechanisms that you need to understand. The old
    joke says the "best way to eat an elephant is one bite at a time." Similarly here,
    you can best comprehend the operation of this complicated protocol by going slowly,
    starting with a high-level look at it, where it came from, and what it does.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I begin by introducing you to TCP. I first provide an overview
    and history of TCP and then describe the standards that define it. Then I illustrate
    what TCP actually does by listing its functions and explaining how TCP works by
    describing its most important characteristics. This will give you a feel for what
    TCP is all about, and it will set the stage for the more complex technical discussions
    in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Overview, History, and Standards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Between them, layers 3 and 4 of the OSI Reference Model represent the interface
    between networking software (the applications that need to move data across networks)
    and networking hardware (the devices that carry the data over networks). Any protocol
    suite must have a protocol or set of protocols that handles these layer 3 and
    layer 4 functions.
  prefs: []
  type: TYPE_NORMAL
- en: The TCP/IP protocol suite is named for the two main protocols that provide these
    capabilities. Both TCP and the Internet Protocol (IP) allow software to run on
    an internetwork. IP deals with internetwork datagram delivery and routing, while
    TCP handles connections and provides reliability. What's interesting, however,
    is that in the early days of the protocol suite, there was, in fact, no TCP/IP
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: TCP History
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to its prominent role in the history of networking, TCP is impossible to
    describe without going back to the early days of the protocol suite. In the early
    1970s, what we know today as the global Internet was a small research internetwork
    called the *ARPAnet*, an acronym that came from the United States Defense Advanced
    Research Projects Agency (DARPA or ARPA). This network used a technology called
    the *Network Control Protocol (NCP)*, which allowed hosts to connect to each other.
    NCP did approximately the same job that TCP and IP do together today.
  prefs: []
  type: TYPE_NORMAL
- en: Due to limitations in NCP, development began on a new protocol that would be
    better suited to a growing internetwork. This new protocol, first formalized in
    RFC 675, was called the Internet *Transmission Control Program (TCP)*. Like its
    predecessor NCP, TCP was responsible for basically everything that was needed
    to allow applications to run on an internetwork. Thus, TCP was at first both TCP
    and IP.
  prefs: []
  type: TYPE_NORMAL
- en: As I explain in detail in the description of the history of TCP/IP as a whole
    in [Chapter 8](ch08.html "Chapter 8. TCP/IP PROTOCOL SUITE AND ARCHITECTURE"),
    several years were spent adjusting and revising TCP, with version 2 of the protocol
    documented in 1977\. While the functionality of TCP was steadily improved, there
    was a problem with the basic concept behind the protocol. Having TCP handle datagram
    transmissions, routing (layer 3 functions), and connections, reliability, and
    data-flow management (layer 4 functions) meant that TCP violated key concepts
    of protocol layering and modularity. TCP forced all applications to use the layer
    4 functions in order to use the layer 3 functions. This made TCP inflexible and
    poorly suited to the needs of applications that required only the lower-level
    functions and not the higher-level ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, the decision was made to split TCP into two: the layer 4 functions
    were retained, with TCP renamed the *Transmission Control Protocol* (as opposed
    to Transmission Control Program). The layer 3 functions became the Internet Protocol.
    This split was finalized in version 4 of TCP, and so the first IP was given "version
    4" as well, for consistency. RFC 793, "Transmission Control Protocol," published
    in September 1981, defined TCP version 4, and it is still the current version
    of the standard.'
  prefs: []
  type: TYPE_NORMAL
- en: Even though it is more than 20 years old and is the first version most people
    have ever used, version 4 was the result of several years' work and many earlier
    TCP versions tested on the early Internet. It is therefore a very mature protocol
    for its age. A precocious protocol, you might say. (To be fair, other standards
    have described many additional features and modifications to TCP, rather than
    upgrading the main document.)
  prefs: []
  type: TYPE_NORMAL
- en: Overview of TCP Operation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP is a full-featured transport layer protocol that provides all the functions
    that a typical application needs for the reliable transportation of data across
    an arbitrary internetwork. It provides transport layer addressing for application
    processes in the form of TCP ports and allows machines to use these ports in order
    to establishing connections between them. Once the devices have connected to each
    other, they can pass data bidirectionally between them. Applications can send
    data to TCP as a simple stream of bytes, and TCP takes care of packaging and sending
    the data as segments that TCP packages into IP datagrams. The receiving device's
    TCP implementation reverses the process, passing up to the application the stream
    of data that the device originally sent.
  prefs: []
  type: TYPE_NORMAL
- en: TCP includes an extensive set of mechanisms. These mechanisms ensure that data
    gets from source to destination reliably, consistently, and in a timely fashion.
    The key to its operation in this regard is the *sliding window acknowledgment
    system*, which allows each device to keep track of the bytes of data it has sent
    and to confirm the receipt of data received from the other device in the connection.
    Unacknowledged data is eventually retransmitted automatically, and the parameters
    of the system can be adjusted to the needs of the devices and the connection.
    This same system also provides buffering and flow control capabilities between
    devices. These capabilities handle uneven data delivery rates and other problems.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The primary transport layer protocol in the TCP/IP protocol
    suite is the *Transmission Control Protocol (TCP)*. TCP is a connection-oriented,
    acknowledged, reliable, full-featured protocol designed to provide applications
    with a reliable way to send data using the unreliable Internet Protocol (IP).
    It allows applications to send bytes of data as a stream of bytes and automatically
    packages them into appropriately sized segments for transmission. It uses a special
    sliding *window acknowledgment system* to ensure that its recipient receives all
    data, handles necessary retransmissions, and provides flow control so that each
    device in a connection can manage the rate at which other devices send data to
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: Because of TCP's many capabilities, it's likely that the protocol will satisfy
    just about any application that requires reliable, connection-oriented data delivery.
    A primary goal of TCP, reliable data delivery means that higher-layer applications
    don't need to provide TCP's common functions. Because the majority of conventional
    message-passing applications employ it, the TCP/IP transport protocol is the most
    widely used transport protocol.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RFC 793 is the defining standard for TCP, but it doesn't include all the details
    about how modern TCP operates. Several other standards include additional information
    about how the protocol works and describe enhancements to the basic TCP mechanisms
    that were developed over the years. Some of these are fairly esoteric, but they
    are useful for gaining a more complete understanding of TCP. I have listed some
    of them in [Table 45-1](ch45.html#supplementary_tcp_standards "Table 45-1. Supplementary
    TCP Standards").
  prefs: []
  type: TYPE_NORMAL
- en: Table 45-1. Supplementary TCP Standards
  prefs: []
  type: TYPE_NORMAL
- en: '| RFC # | Name | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 813 | Window and Acknowledgment Strategy in TCP | Discusses the TCP sliding
    window acknowledgment system, describes certain problems that can occur with it,
    and offers methods to correct them. |'
  prefs: []
  type: TYPE_TB
- en: '| 879 | The TCP Maximum Segment Size and Related Topics | Discusses the important
    maximum segment size (MSS) parameter that controls the size of TCP messages, and
    then relates this parameter to IP datagram size. |'
  prefs: []
  type: TYPE_TB
- en: '| 896 | Congestion Control in IP/TCP Internetworks | Talks about congestion
    problems and how you can use TCP to handle them. Note the interesting inversion
    of the normal protocol suite name: IP/TCP. |'
  prefs: []
  type: TYPE_TB
- en: '| 1122 | Requirements for Internet Hosts — Communication Layers | Describes
    important details of how TCP should be implemented on hosts. |'
  prefs: []
  type: TYPE_TB
- en: '| 1146 | TCP Alternate Checksum Options | Specifies a mechanism for having
    TCP devices use an alternative method of checksum generation. |'
  prefs: []
  type: TYPE_TB
- en: '| 1323 | TCP Extensions for High Performance | Defines extensions to TCP for
    high-speed links and new TCP options. |'
  prefs: []
  type: TYPE_TB
- en: '| 2018 | TCP Selective Acknowledgment Options | An enhancement to basic TCP
    functionality that allows TCP devices to selectively specify specific segments
    for retransmission. |'
  prefs: []
  type: TYPE_TB
- en: '| 2581 | TCP Congestion Control | Describes four algorithms used for congestion
    control in TCP networks: slow start, congestion avoidance, fast retransmit, and
    fast recovery. |'
  prefs: []
  type: TYPE_TB
- en: '| 2988 | Computing TCP''s Retransmission Timer | Discusses issues related to
    setting the TCP retransmission timer, which controls how long a device waits for
    acknowledgment of sent data before retransmitting it. |'
  prefs: []
  type: TYPE_TB
- en: There are hundreds of higher-layer application protocols that use TCP and whose
    defining standards therefore make at least glancing reference to it.
  prefs: []
  type: TYPE_NORMAL
- en: TCP is designed to use IP, since they were developed together and as you have
    seen, were even once part of the same specification. They were later split up
    in order to respect the principles of architectural layering. For this reason,
    TCP tries to make as few assumptions as possible regarding the underlying protocol
    over which it runs. It is not as strictly tied to the use of IP as you might imagine,
    and you can even adapt it for use over other network layer protocols. For our
    purposes, however, this should be considered mainly an interesting aside.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have now seen where TCP comes from and the standards that describe it. As
    I said in the introduction to this chapter, TCP is a complicated protocol, so
    it will take some time to explain how it works. Here, I'll describe what TCP does
    and what it doesn't do.
  prefs: []
  type: TYPE_NORMAL
- en: Functions That TCP Performs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite the TCP''s complexity, I can simplify its basic operation by describing
    its primary functions. The following are what I believe to be the five main tasks
    that TCP performs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Addressing/Multiplexing** Many different applications use TCP for a transport
    protocol. Therefore, like its simpler sibling, the User Datagram Protocol (UDP),
    multiplexing the data that TCP receives from these different processes so that
    the data can be sent out using the underlying network layer protocol is an important
    job for TCP. At the same time, these higher-layer application processes are identified
    using TCP ports. [Chapter 43](ch43.html "Chapter 43. TCP AND UDP ADDRESSING: PORTS
    AND SOCKETS") contains a great deal of detail about how this addressing works.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Establishing, Managing, and Terminating Connections** TCP provides a set
    of procedures that devices can follow in order to negotiate and establish a TCP
    connection over which data can travel. Once a connection is opened, TCP includes
    logic for managing the connection and handling problems that may result with the
    connection. When a device is finished with a TCP connection, a special process
    is followed to terminate it.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling and Packaging Data** TCP defines a mechanism by which applications
    are able to send data to TCP from higher layers. This data is then packaged into
    messages that will be sent to the destination TCP software. The destination software
    unpackages the data and gives it to the application on the destination machine.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transferring Data** Conceptually, the TCP implementation on a transmitting
    device is responsible for the transfer of packaged data to the TCP process on
    the other device. Following the principle of layering, this transfer is done by
    having the TCP software on the sending machine pass the data packets to the underlying
    network layer protocol, which again normally means IP.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Providing Reliability and Transmission Quality Services** TCP includes a
    set of services and features that allows an application to consider the protocol
    a reliable means of sending of data. This means that normally a TCP application
    doesn''t need to worry about data being sent and never showing up or arriving
    in the wrong order. It also means that other common problems that might arise
    if IP were used directly are avoided.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Providing Flow Control and Congestion Avoidance Features** TCP allows the
    flow of data between two devices to be controlled and managed. It also includes
    features that deal with congestion that devices may experience during communication
    between each other.'
  prefs: []
  type: TYPE_NORMAL
- en: Functions That TCP Doesn't Perform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Clearly, TCP is responsible for a fairly significant number of key functions.
    The items listed in the preceding section may not seem that impressive, but this
    is just a high-level look at the protocol. When you look at these functions in
    detail, you will see that each one actually involves a rather significant amount
    of work for TCP to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversely, sometimes TCP is described as doing everything an application needs
    in order to use an internetwork. However, the protocol doesn''t do everything.
    It has limitations and certain areas that its designers specifically did not address.
    The following are some of the notable functions that TCP does not perform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Specifying Application Use** TCP defines the transport protocol. It does
    not specifically describe how applications should use TCP. That is up to the application
    protocol.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Providing Security** TCP does not provide any mechanism for ensuring the
    authenticity or privacy of data that it transmits. If authenticity and privacy
    are important to applications, they must accomplish them using some other means,
    such as IPsec, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Maintaining Message Boundaries** TCP sends data as a continuous stream rather
    than discrete messages. It is up to the application to specify where one message
    ends and the next begins.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guaranteeing Communication** Wait a minute; isn''t TCP supposed to guarantee
    that data will get to its destination? Well, yes and no. TCP will detect unacknowledged
    transmissions and resend them if needed. However, if some sort of problem prevents
    reliable communication, all TCP can do is keep trying. It can''t make any guarantees,
    because there are too many things out of its control. Similarly, it can attempt
    to manage the flow of data, but it cannot resolve every problem.'
  prefs: []
  type: TYPE_NORMAL
- en: This last point might seem a bit pedantic, but it is important to keep in mind,
    especially since many people tend to think of TCP as bulletproof. The overall
    success of communication depends entirely on the underlying internetwork and the
    networks that constitute it. A chain is as strong as its weakest link, and if
    there is a problem at the lower layers, nothing TCP can do will guarantee successful
    data transfer.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP provides reliable communication only by detecting failed
    transmissions and resending them. It cannot guarantee any particular transmission,
    because it relies on IP, which is unreliable. All it can do is keep trying if
    an initial delivery attempt fails.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Characteristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In many ways, it is more interesting to look at how TCP does its job than the
    functions of the job. By examining the most important attributes of TCP and its
    operation, you can get a better handle on the way TCP works. You can also see
    the many ways that it contrasts with its simpler transport layer sibling, UDP.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP has the following characteristics, which allow it to perform its functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection-Oriented** TCP requires that devices first establish a connection
    with each other before they send data. The connection creates the equivalent of
    a circuit between the units; it is analogous to a telephone call. A process of
    negotiation occurs, and that process establishes the connection, thereby ensuring
    that both devices agree on how they will exchange data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bidirectional** Once a connection is established, TCP devices send data bidirectionally.
    Both devices on the connection can send and receive, regardless of which one initiated
    the connection.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiply Connected and Endpoint Identified** The pair of sockets used by
    the two devices in the connection identifies the endpoints of the TCP connection.
    This identification method allows each device to have multiple connections opened,
    either to the same IP device or different IP devices, and to handle each connection
    independently without conflicts.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reliable** Communication using TCP is said to be reliable because TCP keeps
    track of data that has been sent and received to ensure that all the data gets
    to its destination. As you saw in the previous section earlier, TCP can''t really
    guarantee that data will always be received. However, it can guarantee that all
    data sent will be checked for reception, checked for data integrity, and then
    retransmitted when needed.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledged** A key to providing reliability is that TCP acknowledges all
    transmissions at the TCP layer. Furthermore, TCP cannot guarantee that the remote
    application will receive all such transmissions. The recipient must tell the sender,
    "Yes, I got that" for each piece of data transferred. This is in stark contrast
    to typical messaging protocols in which the sender never knows what happened to
    its transmission. As you will see, this acknowledgment is fundamental to the operation
    of TCP as a whole.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stream-Oriented** Most lower-layer protocols are designed so that higher-layer
    protocols must send them data in blocks in order to use them. IP is the best example
    of this; you send it a message to be formatted and IP puts that message into a
    datagram. UDP works the same way. In contrast, TCP allows applications to send
    it a continuous stream of data for transmission. Applications don''t need to worry
    about dividing this stream into chunks for transmission; TCP does it.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unstructured Data** An important consequence of TCP''s stream orientation
    is that there are no natural divisions between data elements in the application''s
    data stream. When multiple messages are sent over TCP, applications must provide
    a way of differentiating one message (data element, record, and so on) from the
    next.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Managed Data Flow** TCP does more than just package data and send it as fast
    as possible. A TCP connection is managed to ensure that data flows evenly and
    smoothly and that connection includes the ability to deal with problems that arise
    along the way.'
  prefs: []
  type: TYPE_NORMAL
- en: You'll notice that I have not listed "slow" as one of TCP's characteristics.
    It is true that applications use UDP for performance reasons when they don't want
    to deal with the overhead that TCP incorporates for connections and reliability.
    That, however, should not lead you to conclude that TCP is glacially slow. It
    is in fact quite efficient—were it not, it's unlikely that it would have ever
    achieved such widespread use.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** To summarize TCP''s key characteristics, we can say that it
    is connection-oriented, bidirectional, multiply connected, reliable, acknowledged,
    stream-oriented, and flow-managed.'
  prefs: []
  type: TYPE_NORMAL
- en: The Robustness Principle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The TCP standard says that TCP follows the *robustness principle*, which is
    described in this way: "Be conservative in what you do; be liberal in what you
    accept from others." This rule means that every TCP implementation tries to avoid
    doing anything that would cause a problem for another device''s TCP layer. At
    the same time, every TCP implementation is also trying to anticipate problems
    that another TCP may cause and attempting to deal with those problems gracefully.'
  prefs: []
  type: TYPE_NORMAL
- en: This principle represents a "belt and suspenders" approach that helps provide
    extra protection against unusual conditions in TCP operation. In fact, this general
    principle is applied to many other protocols in the TCP/IP protocol suite, which
    is part of the reason why it has proven to be so capable over the years. The principle
    allows TCP and other protocols to deal with unanticipated problems that might
    show up in the difficult environment of a large internetwork such as the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Many people have a difficult time understanding how the Transmission Control
    Protocol (TCP) works. After spending dozens of hours writing almost 100 pages
    on the protocol, I am quite sympathetic! I think a main reason for the difficulty
    is that many descriptions of the protocol leap too quickly from a brief introduction
    straight into the mind-boggling details of TCP's operation. The problem is that
    TCP works in a very particular way. Its operation is built around a few very important
    fundamentals that you absolutely must understand before the details of TCP operation
    will make much sense.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I describe some of the key operating fundamentals of TCP. I
    begin with a discussion of how TCP handles data and introduce the concepts of
    streams, segments, and sequences. I then describe the very important TCP sliding
    window system, which is used for acknowledgment, reliability, and data flow control.
    I discuss how TCP uses ports and how it identifies connections. I also describe
    the most important applications that use TCP and what ports they use for server
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Data Handling and Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the givens in the operation of most of the protocols you'll find at upper
    layers in the OSI Reference Model is that the protocols are oriented around the
    use of messages. These messages are analogous to a written letter in an envelope
    that contains a specific piece of information. They are passed from higher layers
    down to lower ones, where they are encapsulated in the lower layers' headers (like
    putting them in another envelope), and then passed down further until they are
    actually sent out at the physical layer.
  prefs: []
  type: TYPE_NORMAL
- en: You can see a good example of this by looking at the User Datagram Protocol
    (UDP), TCP's transport layer peer. To use UDP, an application passes it a distinct
    block of data that is usually fairly short. The block is packaged into a UDP message,
    then sent to the Internet Protocol (IP). IP packs the message into an IP datagram
    and eventually passes it to a layer 2 protocol such as Ethernet. There, IP places
    it into a frame and sends it to layer 1 for transmission.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing the Flexibility of Application Data Handling: TCP''s Stream Orientation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The use of discrete messaging is pretty simple, and it obviously works well
    enough since most protocols make use of it. However, it is inherently limiting
    because it forces applications to create discrete blocks of data in order to communicate.
    There are many applications that need to send information continuously in a manner
    that doesn't lend itself well to creating "chunks" of data. Others need to send
    data in chunks that are so large that applications could never send them as a
    single message at the lower layers.
  prefs: []
  type: TYPE_NORMAL
- en: To use a protocol like UDP, many applications would be forced to artificially
    divide their data into messages of a size that has no inherent meaning to them.
    This would immediately introduce new problems that would require more work for
    the application. The application would have to keep track of what data is in what
    message, and replace any data that was lost. It would need to ensure that the
    messages could be reassembled in the correct order, since IP might deliver them
    out of order.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you could program applications to do this, but it would make little
    sense, because these functions are already ones that TCP is charged with handling.
    Instead, the TCP designers took the very smart approach of generalizing TCP so
    that it could accept application data of any size and structure without requiring
    the data to be in discrete pieces. More specifically, TCP treats data coming from
    an application as a *stream*—thus, the description of TCP as *stream-oriented*.
    Each application sends the data it wishes to transmit as a steady stream of octets
    (bytes). The application doesn't need to carve the data into blocks or worry about
    how lengthy streams will get across the internetwork. It just "pumps bytes" to
    TCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP Data Packaging: Segments'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP must take the bytes it gets from an application and send them using a network
    layer protocol, which is IP in this case. IP is a message-oriented protocol; it
    is not stream-oriented. Thus, we have simply "passed the buck" to TCP, which must
    take the stream from the application and divide it into discrete messages for
    IP. These messages are called *TCP segments*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Segment *is one of the most confusing data structure names in the world of networking.
    From a dictionary definition standpoint, referring to a piece of a stream as a*
    segment *is sensible, but most people working with networks don't think of a message
    as being a segment. In the industry, the term also refers to a length of cable
    or a part of a local area network (LAN), among other things, so watch out for
    that*.
  prefs: []
  type: TYPE_NORMAL
- en: 'IP treats TCP segments like all other discrete messages for transmission. IP
    places them into IP datagrams and transmits them to the destination device. The
    recipient unpackages the segments and passes them to TCP, which converts them
    back to a byte stream in order to send them to the application. This process is
    illustrated in [Figure 46-1](ch46.html#tcp_data_stream_processing_and_segment_p
    "Figure 46-1. TCP data stream processing and segment packaging TCP is different
    from most protocols because it does not require applications that use it to send
    data to it in messages. Once a TCP connection is set up, an application protocol
    can send TCP a steady stream of bytes that does not need to conform to any particular
    structure. TCP packages these bytes into segments that are sized based on a number
    of different parameters. These segments are passed to IP, where they are encapsulated
    into IP datagrams and transmitted. The receiving device reverses the process:
    Segments are removed from IP datagrams, and then the bytes are taken from the
    segments and passed up to the appropriate recipient application protocol as a
    byte stream.").'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP is designed to have applications send data to it as a stream
    of bytes, rather than requiring fixed-size messages to be used. This provides
    maximum flexibility for a wide variety of uses, because applications don''t need
    to worry about data packaging and can send files or messages of any size. TCP
    takes care of packaging these bytes into messages called *segments*.'
  prefs: []
  type: TYPE_NORMAL
- en: The TCP layer on a device accumulates data that it receives from the application
    process stream. On regular intervals, the TCP layer forms segments that it will
    transmit using IP. Two primary factors control the size of the segment. First,
    there is an overall limit to the size of a segment, chosen to prevent unnecessary
    fragmentation at the IP layer. A parameter called the *maximum segment size (MSS)*
    governs this size limit. The MSS is determined during connection establishment.
    Second, TCP is designed so that once a connection is set up, each of the devices
    tells the other how much data it is ready to accept at any given time. If the
    data is lower than the MSS value, the device must send a smaller segment. This
    is part of the sliding window system described a little later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP Data Identification: Sequence Numbers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fact that TCP treats data coming from an application as a stream of octets
    has a couple of very significant implications for the operation of the protocol.
    The first is related to data identification. Since TCP is reliable, it needs to
    keep track of all the data it receives from an application so it can make sure
    that the destination receives all the data. Furthermore, TCP must make sure that
    the destination receives the data in the order that the application sent it, and
    the destination must retransmit any lost data.
  prefs: []
  type: TYPE_NORMAL
- en: If a device conveyed data to TCP in block-like messages, it would be fairly
    simple to keep track of the data by adding an identifier to each message. Because
    TCP is stream-oriented, however, that identification must be done for each byte
    of data! This may seem surprising, but it is actually what TCP does through the
    use of sequence numbers. Each byte of data is assigned a sequence number that
    is used to keep track of it through the process of transmission, reception, and
    acknowledgment (though in practice, blocks of many bytes are managed using the
    sequence numbers of bytes at the start and end of the block). These sequence numbers
    are used to ensure that the sending application transmits and reassembles the
    segmented data into the original stream of data. The sequence numbers are required
    to implement the sliding window system, which enables TCP to provide reliability
    and data flow control.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP data stream processing and segment packaging TCP is different from most
    protocols because it does not require applications that use it to send data to
    it in messages. Once a TCP connection is set up, an application protocol can send
    TCP a steady stream of bytes that does not need to conform to any particular structure.
    TCP packages these bytes into segments that are sized based on a number of different
    parameters. These segments are passed to IP, where they are encapsulated into
    IP datagrams and transmitted. The receiving device reverses the process: Segments
    are removed from IP datagrams, and then the bytes are taken from the segments
    and passed up to the appropriate recipient application protocol as a byte stream.](httpatomoreillycomsourcenostarchimages288089.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 46-1. TCP data stream processing and segment packaging TCP is different
    from most protocols because it does not require applications that use it to send
    data to it in messages. Once a TCP connection is set up, an application protocol
    can send TCP a steady stream of bytes that does not need to conform to any particular
    structure. TCP packages these bytes into segments that are sized based on a number
    of different parameters. These segments are passed to IP, where they are encapsulated
    into IP datagrams and transmitted. The receiving device reverses the process:
    Segments are removed from IP datagrams, and then the bytes are taken from the
    segments and passed up to the appropriate recipient application protocol as a
    byte stream.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Since TCP works with individual bytes of data rather than discrete
    messages, it must use an identification scheme that works at the byte level to
    implement its data transmission and tracking system. This is accomplished by assigning
    a sequence number to each byte that TCP processes.'
  prefs: []
  type: TYPE_NORMAL
- en: The Need for Application Data Delimiting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When TCP treats incoming data as a stream, the data the application using TCP
    receives is called *unstructured*. For transmission, a stream of data goes into
    TCP on the sending device, and on reception, a stream of data goes back to the
    application on the receiving device. Even though TCP breaks the stream into segments
    for transmission, these segments are TCP-level details that remain hidden from
    the application. When a device wants to send multiple pieces of data, TCP provides
    no mechanism for indicating where the dividing line is between the pieces, since
    TCP doesn't examine the meaning of the data. The application must provide a means
    for doing this.
  prefs: []
  type: TYPE_NORMAL
- en: Consider, for example, an application that is sending database records. It needs
    to transmit record 579 from the Employees database table, followed by record 581
    and record 611\. It sends these records to TCP, which treats them all collectively
    as a stream of bytes. TCP will package these bytes into segments, but in a way
    that the application cannot predict. It is possible that each byte will end up
    in a different segment, but more likely that they will all be in one segment,
    or that part of each will end up in different segments, depending on their length.
    The records must have some sort of explicit markers so that the receiving device
    can tell where one record ends and the next starts.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Since applications send data to TCP as a stream of bytes as
    opposed to prepackaged messages, each application must use its own scheme to determine
    where one application data element ends and the next begins.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Sliding Window Acknowledgment System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What differentiates TCP from simpler transport protocols like UDP is the quality
    of the manner in which it sends data between devices. Rather than just sticking
    data in a message and saying, "off you go," TCP carefully keeps track of the data
    it sends. This management of data is required to facilitate the following two
    key requirements of the protocol:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reliability** Ensuring that data that is sent actually arrives at its destination,
    and if it doesn''t arrive, detecting this and resending it.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Flow Control** Managing the rate at which data is sent so that it does
    not overwhelm the device that is receiving it.'
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish these tasks, the entire operation of the protocol is oriented
    around something called the *sliding window acknowledgment system*. It is no exaggeration
    to say that comprehending how sliding windows work is critical to understanding
    just about everything else in TCP. It is also, unfortunately, a bit hard to follow
    if you try to grasp it all at once. I wanted to make sure that I explained the
    mechanism thoroughly without assuming that you already understood it. For this
    reason, I am going to start by explaining the concepts behind sliding windows,
    particularly how the technique works and why it is so powerful.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Problem with Unreliable Protocols: Lack of Feedback'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A simple "send and forget" protocol like IP is unreliable and includes no flow
    control for one main reason: It is an open-loop system in which the transmitter
    receives no feedback from the recipient. (I am ignoring error reports using ICMP
    and the like for the purpose of this discussion.) A datagram is sent, and it may
    or may not get there, but the transmitter will never have any way of knowing because
    there is no mechanism for feedback. This concept is illustrated in [Figure 46-2](ch46s02.html#operation_of_an_unreliable_protocol_in_a
    "Figure 46-2. Operation of an unreliable protocol In a system such as the one
    that IP uses, if a message gets to its destination, that''s great; otherwise,
    nobody will have a clue. Some external mechanism is needed to take care of the
    lost message, unless the protocol doesn''t really care whether a few bits and
    pieces are missing from its message stream.").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Operation of an unreliable protocol In a system such as the one that IP uses,
    if a message gets to its destination, that''s great; otherwise, nobody will have
    a clue. Some external mechanism is needed to take care of the lost message, unless
    the protocol doesn''t really care whether a few bits and pieces are missing from
    its message stream.](httpatomoreillycomsourcenostarchimages288091.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 46-2. Operation of an unreliable protocol In a system such as the one
    that IP uses, if a message gets to its destination, that's great; otherwise, nobody
    will have a clue. Some external mechanism is needed to take care of the lost message,
    unless the protocol doesn't really care whether a few bits and pieces are missing
    from its message stream.
  prefs: []
  type: TYPE_NORMAL
- en: Providing Basic Reliability Using Positive Acknowledgment with Retransmission
    (PAR)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Basic reliability in a protocol running over an unreliable protocol like IP
    can be implemented by closing the loop so the recipient provides feedback to the
    sender. This is most easily done with a simple acknowledgment system. Device A
    sends a piece of data to Device B, which receives the data and sends back an acknowledgment
    saying, "Device A, I received your message." Device A then knows its transmission
    was successful.
  prefs: []
  type: TYPE_NORMAL
- en: But since IP is unreliable, that message may in fact never get to where it is
    going. Device A will sit and wait for the acknowledgment and never receive it.
    Conversely, it is also possible that Device B gets the message from Device A,
    but the acknowledgment itself vanishes somehow. In either case, we don't want
    Device A to sit forever waiting for an acknowledgment that is never going to arrive.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent this from happening, Device A starts a timer when it first sends
    the message to Device B, which allows sufficient time for the message to get to
    Device B and for the acknowledgment to travel back, plus some reasonable time
    to allow for possible delays. If the timer expires before the acknowledgment is
    received, Device A assumes that there was a problem and retransmits its original
    message. Since this method involves positive acknowledgments ("Yes, I got your
    message") and a facility for retransmission when needed, it is commonly called
    *positive acknowledgment with retransmission (PAR)*, as shown in [Figure 46-3](ch46s02.html#basic_reliability_positive_acknowledgmen
    "Figure 46-3. Basic reliability: positive acknowledgment with retransmission (PAR)
    This diagram shows one of the most common and simple techniques for ensuring reliability.
    Each time Device A sends a message, it starts a timer. Device B sends an acknowledgment
    back to Device A when it receives a message, so that Device A knows that it successfully
    transmitted the message. If a message is lost, the timer goes off, and Device
    A retransmits the data. Note that only one message can be outstanding at any time,
    making this system rather slow.").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Basic reliability: positive acknowledgment with retransmission (PAR) This
    diagram shows one of the most common and simple techniques for ensuring reliability.
    Each time Device A sends a message, it starts a timer. Device B sends an acknowledgment
    back to Device A when it receives a message, so that Device A knows that it successfully
    transmitted the message. If a message is lost, the timer goes off, and Device
    A retransmits the data. Note that only one message can be outstanding at any time,
    making this system rather slow.](httpatomoreillycomsourcenostarchimages288093.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 46-3. Basic reliability: positive acknowledgment with retransmission
    (PAR) This diagram shows one of the most common and simple techniques for ensuring
    reliability. Each time Device A sends a message, it starts a timer. Device B sends
    an acknowledgment back to Device A when it receives a message, so that Device
    A knows that it successfully transmitted the message. If a message is lost, the
    timer goes off, and Device A retransmits the data. Note that only one message
    can be outstanding at any time, making this system rather slow.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A basic technique for ensuring reliability in communications
    uses a rule that requires a device to send back an acknowledgment each time it
    successfully receives a transmission. If a device doesn''t acknowledge the transmission
    after a period of time, its sender retransmits the acknowledgment. This system
    is called *positive acknowledgment with retransmission (PAR)*. One drawback with
    this basic scheme is that the transmitter cannot send a second message until after
    the first device has acknowledged the first.'
  prefs: []
  type: TYPE_NORMAL
- en: PAR is a technique that is used widely in networking and communications for
    protocols that exchange relatively small amounts of data, or protocols that exchange
    data infrequently. The basic method is functional, but it is not well suited to
    a protocol like TCP. One main reason is that it is *inefficient*. Device A sends
    a message, and then waits for the acknowledgment. Device A cannot send another
    message to Device B until it hears that Device B received its original message,
    which is very wasteful and would make the protocol extremely slow.
  prefs: []
  type: TYPE_NORMAL
- en: Improving PAR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first improvement we can make to the PAR system is to provide some means
    of identification to the messages that were sent, as well as the acknowledgments.
    For example, we could put a message ID field in the message header. The device
    sending the message would uniquely identify it, and the recipient would use this
    identifier in the acknowledgment. For example, Device A might send a piece of
    data in a message with the message ID 1\. Device B would receive the message and
    then send its own message back to Device A, saying "Device A, I received your
    message 1." The advantage of this system is that Device A can send multiple messages
    at once. It must keep track of each one that it sends, and whether or not Device
    B sent an acknowledgment. Each device also requires a separate timer, but that's
    not a big problem.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we also need to consider this exchange from the standpoint of Device
    B. Before, Device B had to deal with only one message at a time from Device A.
    Now it may have several show up all at once. What if it is already busy with transmis-sions
    from another device (or ten)? We need some mechanism that lets Device B say, "I
    am only willing to handle the following number of messages from you at a time."
    We could do that by having the acknowledgment message contain a field, such as
    send limit, which specifies the maximum number of unacknowledged messages Device
    A was allowed to have in transit to Device B at one time.
  prefs: []
  type: TYPE_NORMAL
- en: Device A would use this send limit field to restrict the rate at which it sent
    messages to Device B. Device B could adjust this field depending on its current
    load and other factors to maximize performance in its discussions with Device
    A. This enhanced system would thus provide reliability, efficiency, and basic
    data flow control, as illustrated in [Figure 46-4](ch46s02.html#enhanced_par_this_diagram_shows_two_enha
    "Figure 46-4. Enhanced PAR This diagram shows two enhancements to the basic PAR
    scheme from Figure 46-3\. First, each message now has an identification number;
    each can be acknowledged individually, so more than one message can be in transit
    at a given time. Second, Device B regularly communicates to Device A a send limit
    parameter, which restricts the number of messages Device A can have outstanding
    at once. Device B can adjust this parameter to control the flow of data from Device
    A.").
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The basic PAR reliability scheme can be enhanced by identifying
    each message to be sent, so multiple messages can be in transit at once. The use
    of a send limit allows the mechanism to also provide flow control capabilities,
    by allowing each device to control the rate at which other devices send data to
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP's Stream-Oriented Sliding Window Acknowledgment System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So does TCP use this variation on PAR? Of course not! That would be too simple.
    Conceptually, the TCP sliding window system is very similar to this method, which
    is why it is important that you understand it. However, it requires some adjustment.
    The main reason has to do with the way TCP handles data: the matter of stream
    orientation compared to message orientation discussed earlier in this chapter.
    The technique I have outlined involves explicit acknowledgments and (if necessary)
    retransmissions for messages. Thus, it would work well for a protocol that exchanged
    reasonably large messages on a fairly infrequent basis.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP, on the other hand, deals with individual bytes of data as a stream. Transmitting
    each byte one at a time and acknowledging each one at a time would quite obviously
    be absurd. It would require too much work, and even with overlapped transmissions
    (that is, not waiting for an acknowledgment before sending the next piece of data),
    the result would be horribly slow.
  prefs: []
  type: TYPE_NORMAL
- en: '![Enhanced PAR This diagram shows two enhancements to the basic PAR scheme
    from . First, each message now has an identification number; each can be acknowledged
    individually, so more than one message can be in transit at a given time. Second,
    Device B regularly communicates to Device A a send limit parameter, which restricts
    the number of messages Device A can have outstanding at once. Device B can adjust
    this parameter to control the flow of data from Device A.](httpatomoreillycomsourcenostarchimages288095.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 46-4. Enhanced PAR This diagram shows two enhancements to the basic
    PAR scheme from [Figure 46-3](ch46s02.html#basic_reliability_positive_acknowledgmen
    "Figure 46-3. Basic reliability: positive acknowledgment with retransmission (PAR)
    This diagram shows one of the most common and simple techniques for ensuring reliability.
    Each time Device A sends a message, it starts a timer. Device B sends an acknowledgment
    back to Device A when it receives a message, so that Device A knows that it successfully
    transmitted the message. If a message is lost, the timer goes off, and Device
    A retransmits the data. Note that only one message can be outstanding at any time,
    making this system rather slow."). First, each message now has an identification
    number; each can be acknowledged individually, so more than one message can be
    in transit at a given time. Second, Device B regularly communicates to Device
    A a send limit parameter, which restricts the number of messages Device A can
    have outstanding at once. Device B can adjust this parameter to control the flow
    of data from Device A.'
  prefs: []
  type: TYPE_NORMAL
- en: This slowness is why TCP does not send bytes individually but divides them into
    segments. All of the bytes in a segment are sent together and received together,
    and thus acknowledged together. TCP uses a variation on the method I described
    earlier, in which the sequence numbers I discussed earlier identify the data sent
    and acknowledged. Instead of acknowledging the use of something like a message
    ID field, we acknowledge data using the sequence number of the last byte of data
    in the segment. Thus, we are dealing with a range of bytes in each case, and the
    range represents the sequence numbers of all the bytes in the segment.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptual Division of TCP Transmission Stream into Categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Imagine a newly established TCP connection between Device A and Device B. Device
    A has a long stream of bytes that it will transmit, but Device B can't accept
    them all at once, so it limits Device A to sending a particular number of bytes
    at once in segments, until the bytes in the segments already sent have been acknowledged.
    Then Device A is allowed to send more bytes. Each device keeps track of which
    bytes have been sent and which have not, and which have been acknowledged.
  prefs: []
  type: TYPE_NORMAL
- en: 'At any point in time, we can take a "snapshot" of the process. If we do, we
    can conceptually divide the bytes that the sending TCP has in its buffer into
    the following four categories, and view them as a timeline (see [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories")):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bytes Sent and Acknowledged** The earliest bytes in the stream will have
    been sent and acknowledged. These bytes are basically viewed from the standpoint
    of the device sending data. In the example in [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    31 bytes of data have already been sent and acknowledged. These would fall into
    category 1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bytes Sent but Not Yet Acknowledged** These are the bytes that the device
    has sent but for which it has not yet received an acknowledgment. The sender cannot
    consider these handled until they are acknowledged. In [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    there are 14 bytes here, in category 2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bytes Not Yet Sent for Which Recipient Is Ready** These are bytes that the
    device has not sent, but which the recipient has room for based on its most recent
    communication to the sender regarding how many bytes it is willing to handle at
    once. The sender will try to send these immediately (subject to certain algorithmic
    restrictions that you''ll explore later). In [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    there are 6 bytes in category 3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bytes Not Yet Sent for Which Recipient Is Not Ready** These are the bytes
    further down the stream, which the sender is not yet allowed to send because the
    receiver is not ready. In [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    there are 44 bytes in category 4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Conceptual division of TCP transmission stream into categories](httpatomoreillycomsourcenostarchimages288097.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 46-5. Conceptual division of TCP transmission stream into categories
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*I am using very small numbers here to keep the example simple and to make
    the diagrams a bit easier to construct! TCP does not normally send tiny numbers
    of bytes around for efficiency reasons*.'
  prefs: []
  type: TYPE_NORMAL
- en: The receiving device uses a similar system in order to differentiate between
    data received and acknowledged, data not yet received but ready to receive, and
    data not yet received and not yet ready to be received. In fact, both devices
    maintain a separate set of variables to keep track of the categories into which
    bytes fall in the stream they are sending, as well as the stream they are receiving.
    This is explored further in [Chapter 48](ch48.html "Chapter 48. TCP MESSAGE FORMATTING
    AND DATA TRANSFER")'s section named "TCP Sliding Window Data Transfer and Acknowledgment
    Mechanics," which describes the detailed sliding window data transfer procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The TCP *sliding* window system is a variation on the enhanced
    PAR system, with changes made to support TCP''s stream orientation. Each device
    keeps track of the status of the byte stream that it needs to transmit. The device
    keeps track by dividing the byte streams into four conceptual categories: bytes
    sent and acknowledged, bytes sent but not yet acknowledged, bytes not yet sent
    but that can be sent immediately, and bytes not yet sent that cannot be sent until
    the recipient signals that it is ready for them.'
  prefs: []
  type: TYPE_NORMAL
- en: Sequence Number Assignment and Synchronization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The sender and receiver must agree on the sequence numbers that they will assign
    to the bytes in the stream. This is called *synchronization* and is done when
    the TCP connection is established. For simplicity, let''s assume that the first
    byte was sent with sequence number 1 (this is not normally the case). Thus, in
    the example shown in [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    the byte ranges for the four categories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The bytes sent and acknowledged are bytes 1 to 31.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes sent but not yet acknowledged are bytes 32 to 45.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is ready are bytes 46 to 51.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is not ready are bytes 52 to
    95.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Send Window and Usable Window
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key to the operation of the entire process is the number of bytes that the
    recipient is allowing the transmitter to have unacknowledged at one time. This
    is called the *send window*, or often, just the *window*. The window is what determines
    how many bytes the sender is allowed to transmit, and is equal to the sum of the
    number of bytes in category 2 and category 3\. Thus, the dividing line between
    the last two categories (bytes not sent that the recipient is ready for and bytes
    the recipient is not ready for) is determined by adding the window to the byte
    number of the first unacknowledged byte in the stream. In the example shown in
    [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001 "Figure 46-5. Conceptual
    division of TCP transmission stream into categories"), the first unacknowledged
    byte is 32\. The total window size is 20.
  prefs: []
  type: TYPE_NORMAL
- en: The term *usable window* is defined as the amount of data the transmitter is
    still allowed to send given the amount of data that is outstanding. It is thus
    exactly equal to the size of category 3\. You may also commonly hear the *edges*
    of the window mentioned. The left edge marks the first byte in the window (byte
    32). The right edge marks the last byte in the window (byte 51). See [Figure 46-6](ch46s02.html#tcp_transmission_stream_categories_and_s
    "Figure 46-6. TCP transmission stream categories and send window terminology This
    diagram shows the same categories as the ones in Figure 46-5, except that it shows
    the send window as well. The black box is the overall send window (categories
    2 and 3 combined); the light gray box represents the bytes already sent (category
    2), and the dark gray box is the usable window (category 3).") for an illustration
    of these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The send *window* is the key to the entire TCP sliding window
    system. It represents the maximum number of unacknowledged bytes that a device
    is allowed to have outstanding at one time. The *usable window* is the amount
    of the send window that the sender is still allowed to send at any point in time;
    it is equal to the size of the send window less the number of unacknowledged bytes
    already transmitted.'
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP transmission stream categories and send window terminology This diagram
    shows the same categories as the ones in , except that it shows the send window
    as well. The black box is the overall send window (categories 2 and 3 combined);
    the light gray box represents the bytes already sent (category 2), and the dark
    gray box is the usable window (category 3).](httpatomoreillycomsourcenostarchimages288099.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 46-6. TCP transmission stream categories and send window terminology
    This diagram shows the same categories as the ones in [Figure 46-5](ch46s02.html#conceptual_division_of_tcp_transmi-id001
    "Figure 46-5. Conceptual division of TCP transmission stream into categories"),
    except that it shows the send window as well. The black box is the overall send
    window (categories 2 and 3 combined); the light gray box represents the bytes
    already sent (category 2), and the dark gray box is the usable window (category
    3).
  prefs: []
  type: TYPE_NORMAL
- en: Changes to TCP Categories and Window Sizes After Sending Bytes in the Usable
    Window
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now let''s suppose that in the example shown in [Figure 46-6](ch46s02.html#tcp_transmission_stream_categories_and_s
    "Figure 46-6. TCP transmission stream categories and send window terminology This
    diagram shows the same categories as the ones in Figure 46-5, except that it shows
    the send window as well. The black box is the overall send window (categories
    2 and 3 combined); the light gray box represents the bytes already sent (category
    2), and the dark gray box is the usable window (category 3).") there is nothing
    stopping the sender from immediately transmitting the 6 bytes in category 3 (the
    usable window). When the sender transmits them, the 6 bytes will shift from category
    3 to category 2\. The byte ranges will now be as follows (see [Figure 46-7](ch46s02.html#tcp_stream_categories_and_window_after_s
    "Figure 46-7. TCP stream categories and window after sending usable window bytes
    This diagram shows the result of the device sending all the bytes that it is allowed
    to transmit in its usable window. It is the same as Figure 46-6, except that all
    the bytes in category 3 have moved to category 2\. The usable window is now zero
    and will remain so until it receives an acknowledgment for bytes in category 2.")):'
  prefs: []
  type: TYPE_NORMAL
- en: The bytes sent and acknowledged are bytes 1 to 31.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes sent but not yet acknowledged are bytes 32 to 51.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is ready are none.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is not ready are bytes 52 to
    95.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![TCP stream categories and window after sending usable window bytes This diagram
    shows the result of the device sending all the bytes that it is allowed to transmit
    in its usable window. It is the same as , except that all the bytes in category
    3 have moved to category 2\. The usable window is now zero and will remain so
    until it receives an acknowledgment for bytes in category 2.](httpatomoreillycomsourcenostarchimages288101.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 46-7. TCP stream categories and window after sending usable window bytes
    This diagram shows the result of the device sending all the bytes that it is allowed
    to transmit in its usable window. It is the same as [Figure 46-6](ch46s02.html#tcp_transmission_stream_categories_and_s
    "Figure 46-6. TCP transmission stream categories and send window terminology This
    diagram shows the same categories as the ones in Figure 46-5, except that it shows
    the send window as well. The black box is the overall send window (categories
    2 and 3 combined); the light gray box represents the bytes already sent (category
    2), and the dark gray box is the usable window (category 3)."), except that all
    the bytes in category 3 have moved to category 2\. The usable window is now zero
    and will remain so until it receives an acknowledgment for bytes in category 2.
  prefs: []
  type: TYPE_NORMAL
- en: Processing Acknowledgments and Sliding the Send Window
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some time later, the destination device sends back a message to the sender and
    provides an acknowledgment. The destination device will not specifically list
    out the bytes that it has acknowledged, because as I said earlier, listing the
    bytes would be inefficient. Instead, the destination device will acknowledge a
    range of bytes that represents the longest contiguous sequence of bytes it has
    received since the ones it had previously acknowledged.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's suppose that the bytes already sent but not yet acknowledged
    at the start of the example (bytes 32 to 45) were transmitted in four different
    segments. These segments carried bytes 32 to 34, 35 to 36, 37 to 41, and 42 to
    45, respectively. The first, second, and fourth segments arrived, but the third
    did not. The receiver will send back an acknowledgment only for bytes 32 to 36
    (32 to 34 and 35 to 36). The receiver will hold bytes 42 to 45 but won't acknowledge
    them, because this would imply that the receiver has received bytes 37 to 41,
    which have not shown up yet. This is necessary because TCP is a cumulative acknowledgment
    system that can use only a single number to acknowledge data. That number is the
    number of the last contiguous byte in the stream that was successfully received.
    Let's also say that the destination keeps the window size the same at 20 bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*An optional feature called* selective acknowledgments *does allow noncontiguous
    blocks of data to be acknowledged. This is explained in [Chapter 49](ch49.html
    "Chapter 49. TCP RELIABILITY AND FLOW CONTROL FEATURES")''s section named "TCP
    Noncontiguous Acknowledgment Handling and Selective Acknowledgment (SACK)"; we''ll
    ignore this complication for now*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the sending device receives this acknowledgment, it will be able to transfer
    some of the bytes from category 2 to category 1, because they have now been acknowledged.
    When it does so, something interesting will happen. Since 5 bytes have been acknowledged,
    and the window size didn''t change, the sender is allowed to send 5 more bytes.
    In effect, the window shifts or slides over to the right in the timeline. At the
    same time 5 bytes move from category 2 to category 1, 5 bytes move from category
    4 to category 3, creating a new usable window for subsequent transmission. So,
    after the groups receive the acknowledgment, they will look like what you see
    in [Figure 46-8](ch46s02.html#sliding_the_tcp_send_window_after_receiv "Figure 46-8. Sliding
    the TCP send window After receiving acknowledgment for bytes 32 to 36, the bytes
    move from category 2 to 1 (shown in dark shading). The send window shown in Figure 46-7
    slides right by 5 bytes; shifting 5 bytes from category 4 to 3, and opening a
    new usable window."). The byte ranges will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The bytes sent and acknowledged are bytes 1 to 36.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes sent but not yet acknowledged are bytes 37 to 51.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is ready are bytes 52 to 56.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The bytes not yet sent for which the recipient is not ready are bytes 57 to
    95.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Sliding the TCP send window After receiving acknowledgment for bytes 32 to
    36, the bytes move from category 2 to 1 (shown in dark shading). The send window
    shown in slides right by 5 bytes; shifting 5 bytes from category 4 to 3, and opening
    a new usable window.](httpatomoreillycomsourcenostarchimages288103.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 46-8. Sliding the TCP send window After receiving acknowledgment for
    bytes 32 to 36, the bytes move from category 2 to 1 (shown in dark shading). The
    send window shown in [Figure 46-7](ch46s02.html#tcp_stream_categories_and_window_after_s
    "Figure 46-7. TCP stream categories and window after sending usable window bytes
    This diagram shows the result of the device sending all the bytes that it is allowed
    to transmit in its usable window. It is the same as Figure 46-6, except that all
    the bytes in category 3 have moved to category 2\. The usable window is now zero
    and will remain so until it receives an acknowledgment for bytes in category 2.")
    slides right by 5 bytes; shifting 5 bytes from category 4 to 3, and opening a
    new usable window.
  prefs: []
  type: TYPE_NORMAL
- en: This process will occur each time an acknowledgment is received, thereby causing
    the window to slide across the entire stream in order to be transmitted. And thus,
    ladies and gentlemen, you have the TCP sliding window acknowledgment system!
  prefs: []
  type: TYPE_NORMAL
- en: It is a very powerful technique that allows TCP to easily acknowledge an arbitrary
    number of bytes using a single acknowledgment number. It provides reliability
    to the byte-oriented protocol without spending time on an excessive number of
    acknowledgments. For simplicity, the example I've used here leaves the window
    size constant, but in reality, it can be adjusted to allow a recipient to control
    the rate at which data is sent, thereby enabling flow control and congestion handling.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** When a device gets an acknowledgment for a range of bytes,
    it knows the destination has successfully received them. It moves them from the
    "sent but unacknowledged" to the "sent and acknowledged" category. This causes
    the send window to slide to the right, allowing the device to send more data.'
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Missing Acknowledgments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: But what about bytes 42 through 45 in the example shown in [Figure 46-8](ch46s02.html#sliding_the_tcp_send_window_after_receiv
    "Figure 46-8. Sliding the TCP send window After receiving acknowledgment for bytes
    32 to 36, the bytes move from category 2 to 1 (shown in dark shading). The send
    window shown in Figure 46-7 slides right by 5 bytes; shifting 5 bytes from category
    4 to 3, and opening a new usable window.")? Until segment 3 (containing bytes
    37 to 41) shows up, the receiving device will not send an acknowledgment for those
    bytes, and it won't send any others that show up after it. The sending device
    will be able to send the new bytes that were added to category 3, namely, bytes
    52 to 56\. The sending device will then stop, and the window will be stuck on
    bytes 37 to 41.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP acknowledgments are cumulative and tell a transmitter that
    the receiving device successfully received all the bytes up to the sequence number
    indicated in the acknowledgment. Thus, if the receiving device receives bytes
    out of order, the device cannot acknowledge them until all the preceding bytes
    are received.'
  prefs: []
  type: TYPE_NORMAL
- en: Like the PAR system, TCP includes a system for timing transmissions and retransmitting.
    Eventually, the TCP device will resend the lost segment. Unfortunately, one drawback
    of TCP is that since it does not separately acknowledge segments, it may have
    to retransmit other segments that the recipient actually received (such as the
    segment with bytes 42 to 45). This starts to get very complex, as I discussed
    in the topic on TCP retransmissions in [Chapter 49](ch49.html "Chapter 49. TCP
    RELIABILITY AND FLOW CONTROL FEATURES").
  prefs: []
  type: TYPE_NORMAL
- en: More Information on TCP Sliding Windows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the length of this explanation, the preceding is just a summary description
    of the overall operation of sliding windows. This chapter does not include all
    of the modifications used in modern TCP! As you can see, the sliding window mechanism
    is at the heart of the operation of TCP as a whole. In the chapter that describes
    segments and discusses data transfer, you will see in more detail how TCP transmitters
    decide how and when to create segments for transmission. [Chapter 49](ch49.html
    "Chapter 49. TCP RELIABILITY AND FLOW CONTROL FEATURES") provides much more information
    about how sliding windows enable a device to manage the flow of data to it on
    a TCP connection. It also discusses special problems that can arise if window
    size is not carefully managed and how you can avoid problems such as congestion
    in TCP implementations through key changes to the basic sliding window mechanism
    described in this section.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Ports, Connections, and Connection Identification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The two TCP/IP transport layer protocols, TCP and UDP, play the same architectural
    role in the protocol suite, but do it in very different ways. In fact, one of
    the few functions that the two have in common is that they both provide a method
    of transport layer addressing and multiplexing. Through the use of *ports*, both
    protocols allow the data from many different application processes to be aggregated
    and sent through the IP layer, and then returned up the stack to the proper application
    process on the destination device. I explain TCP ports in detail in [Chapter 43](ch43.html
    "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS").'
  prefs: []
  type: TYPE_NORMAL
- en: Despite this commonality, TCP and UDP diverge somewhat even in how they deal
    with processes. UDP is a connectionless protocol, which means that devices do
    not set up a formal connection before sending data. UDP does not have to use sliding
    windows or keep track of how long it has been since UDP sent a transmission and
    so forth. When the UDP layer on a device receives data, it just sends it to the
    process that the destination port indicates, and that's that. UDP can seamlessly
    handle any number of processes that are sending it messages because UDP handles
    them all identically.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, since TCP is connection-oriented, it has many more responsibilities.
    Each TCP software layer needs to be able to support connections to several other
    TCPs simultaneously. The operation of each connection is separate from of each
    other connection, and the TCP software must manage each operation independently.
    TCP must be sure that it not only routes data to the right process, but that it
    also manages transmitted data on each connection without any overlap or confusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first consequence of this is that TCP must uniquely identify each connection.
    It does this by using the pair of socket identifiers that correspond to the two
    endpoints of the connection, where a socket is simply the combination of the IP
    address and the port number of each process. This means a socket pair contains
    four pieces of information: source address, source port, destination address,
    and destination port. Thus, TCP connections are sometimes said to be described
    by this addressing quadruple.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I introduced this concept in [Chapter 43](ch43.html "Chapter 43. TCP AND UDP
    ADDRESSING: PORTS AND SOCKETS"), where I gave the example of a Hypertext Transfer
    Protocol (HTTP) request that a client sends at 177.41.72.6 to a website at 41.199.222.3\.
    The server for that website will use well-known port number 80, so the server''s
    socket is 41.199.222.3:80\. If the server assigns a client ephemeral port number
    3022 for the web browser, the client socket is 177.41.72.6:3022\. The overall
    connection between these devices can be described using this socket pair: (41.199.222.3:80,
    177.41.72.6:3022).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This identification of connections using both client and server sockets is
    what provides the flexibility in allowing multiple connections between devices
    that we probably take for granted on the Internet. For example, busy application
    server processes (such as web servers) must be able to handle connections from
    more than one client; otherwise, the Web would be pretty much unusable. Since
    the client and server''s socket identify the connection, this is no problem. At
    the same time that the web server maintains the connection, it can easily have
    another connection to say, port 2199 at IP address 219.31.0.44\. The connection
    identifier that represents this as follows: (41.199.222.3:80, 219.31.0.44:2199).'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, you can have multiple connections from the same client to the same
    server. Each client process will be assigned a different ephemeral port number,
    so even if they all try to access the same server process (such as the web server
    process at 41.199.222.3:80), they will all have a different client socket and
    represent unique connections. This difference is what lets you make several simultaneous
    requests to the same website from your computer.
  prefs: []
  type: TYPE_NORMAL
- en: Again, TCP keeps track of each of these connections independently, so each connection
    is unaware of the others. TCP can handle hundreds or even thousands of simultaneous
    connections. The only limit is the capacity of the computer running TCP, and the
    bandwidth of the physical connections to it—the more connections running at once,
    the more each one has to share limited resources.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Each device can handle simultaneous TCP connections to many
    different processes on one or more devices. The socket numbers of the devices
    in the connection, called the connection''s *endpoints*, identify each connection.
    Each endpoint consists of the device''s IP address and port number, so the four-way
    communication between client IP address and port number, and server IP address
    and port number identifies each connection.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Common Applications and Server Port Assignments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the overview of TCP in [Chapter 45](ch45.html "Chapter 45. TCP OVERVIEW,
    FUNCTIONS, AND CHARACTERISTICS"), you saw that the protocol originally included
    the functions of both modern TCP and IP. TCP was split into TCP and IP in order
    to allow applications that didn't need TCP's complexity to bypass it, using the
    much simpler UDP as a transport layer protocol instead. This bypass was an important
    step in the development of the TCP/IP protocol suite, since there are several
    important protocols for which UDP is ideally suited, and even some for which TCP
    is more of a nuisance than a benefit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most commonly, however, UDP is used only in special cases. I describe the two
    types of applications that may be better suited to UDP than TCP in [Chapter 44](ch44.html
    "Chapter 44. TCP/IP USER DATAGRAM PROTOCOL (UDP)"): applications where speed is
    more important than reliability, and applications that send only short messages
    infrequently. The majority of TCP/IP applications do not fall into these categories.
    Thus, even though the layering of TCP and IP means that most protocols aren''t
    required to use TCP, most of them do anyway. The majority of the protocols that
    use TCP employ all, or at least most, of the features that it provides. The establishment
    of a persistent connection is necessary for many interactive protocols, such as
    Telnet, as well as for ones that send commands and status replies, like HTTP.
    Reliability and flow control are essential for protocols like the File Transfer
    Protocol (FTP) or the email protocols, which send large files.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 46-1](ch46s04.html#common_tcp_applications_and_server_port_ "Table 46-1. Common
    TCP Applications and Server Port Assignments") shows some of the more significant
    application protocols that run on TCP. For each protocol, I have shown the well-known
    or registered port number that''s reserved for that protocol''s server process
    (clients use ephemeral ports, not the port numbers in the table). I have also
    shown the special keyword shortcut for each port assignment and provided brief
    comments on why the protocol is well matched to TCP.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 46-1. Common TCP Applications and Server Port Assignments
  prefs: []
  type: TYPE_NORMAL
- en: '| Port # | Keyword | Protocol | Comments |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 20 and 21 | ftp-data/ftp | File Transfer Protocol (FTP, data and control)
    | Used to send large files, so it is ideally suited for TCP. |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | telnet | Telnet Protocol | Interactive session-based protocol. Requires
    the connection-based nature of TCP. |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | smtp | Simple Mail Transfer Protocol (SMTP) | Uses an exchange of commands,
    and sends possibly large files between devices. |'
  prefs: []
  type: TYPE_TB
- en: '| 53 | domain | Domain Name Server (DNS) | An example of a protocol that uses
    both UDP and TCP. For simple requests and replies, DNS uses UDP. For larger messages,
    especially zone transfers, DNS uses TCP. |'
  prefs: []
  type: TYPE_TB
- en: '| 70 | gopher | Gopher Protocol | A messaging protocol that has been largely
    replaced by the WWW. |'
  prefs: []
  type: TYPE_TB
- en: '| 80 | http | Hypertext Transfer Protocol (HTTP/World Wide Web) | The classic
    example of a TCP-based messaging protocol. |'
  prefs: []
  type: TYPE_TB
- en: '| 110 | pop3 | Post Office Protocol (POP version 3) | Email message retrieval
    protocols that use TCP to exchange commands and data. |'
  prefs: []
  type: TYPE_TB
- en: '| 119 | nntp | Network News Transfer Protocol (NNTP) | Used for transferring
    NetNews (Usenet) messages, which can be lengthy. |'
  prefs: []
  type: TYPE_TB
- en: '| 139 | netbios-ssn | NetBIOS Session Service | A session protocol, clearly
    better suited to TCP than UDP. |'
  prefs: []
  type: TYPE_TB
- en: '| 143 | imap | Internet Message Access Protocol (IMAP) | Another email message
    retrieval protocol. |'
  prefs: []
  type: TYPE_TB
- en: '| 179 | bgp | Border Gateway Protocol (BGP) | While interior routing protocols
    like RIP and OSPF use either UDP or IP directly, BGP runs over TCP. This allows
    BGP to assume reliable communication even as it sends data over potentially long
    distances. |'
  prefs: []
  type: TYPE_TB
- en: '| 194 | irc | Internet Relay Chat (IRC) | IRC is like Telnet in that it is
    an interactive protocol that is strongly based on the notion of a persistent connection
    between a client and server. |'
  prefs: []
  type: TYPE_TB
- en: '| 2049 | nfs | Network File System (NFS) | NFS was originally implemented using
    UDP for performance reasons. Given that it is responsible for large transfers
    of files and given UDP''s unreliability, NFS was probably not the best idea, so
    developers created TCP versions. The latest version of NFS uses TCP exclusively.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 6000–6063 | TCP | x11 | Used for the X Window graphical system. Multiple
    ports are dedicated to allow many sessions. |'
  prefs: []
  type: TYPE_TB
- en: A couple of the protocols in [Table 46-1](ch46s04.html#common_tcp_applications_and_server_port_
    "Table 46-1. Common TCP Applications and Server Port Assignments") use both TCP
    and UDP in order to get the best of both worlds. UDP can send short, simple messages,
    while TCP moves larger files. Many of the protocols that use both TCP and UDP
    are actually utility/diagnostic protocols (such as Echo, Discard, and the Time
    Protocol). These are special cases, because they developers designed them to use
    both UDP and TCP specifically to allow their use for diagnostics on both protocols.
  prefs: []
  type: TYPE_NORMAL
- en: I have not included an exhaustive list of TCP applications in [Table 46-1](ch46s04.html#common_tcp_applications_and_server_port_
    "Table 46-1. Common TCP Applications and Server Port Assignments"). See [Chapter 42](ch42.html
    "Chapter 42. OVERVIEW AND COMPARISON OF TCP AND UDP") for common TCP/IP applications
    and port numbers, and also a reference to the full (massive) list of well-known
    and registered TCP server ports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 47. TCP BASIC OPERATION: CONNECTION ESTABLISHMENT, MANAGEMENT, AND
    TERMINATION'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: While I have described the Transmission Control Protocol (TCP) as *connection-oriented*,
    this term isn't just any old characteristic of TCP. The overall operation of the
    entire protocol can be described in terms of how TCP software prepares, negotiates,
    establishes, manages, and terminates connections. TCP implementations certainly
    do more than handle connections, but the other major tasks they perform, such
    as data handling and providing reliability and flow control, can occur only over
    a stable connection. This stability makes connections the logical place to begin
    exploring the details of how TCP works.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I describe TCP connections from start to finish. I begin with
    an overview of TCP's operation by providing a summary of the *finite state machine*
    that formally defines the stages of a connection. State machines can be a bit
    mind-boggling when you read about them in standards, but a simplified, explained
    version provides an excellent high-level view of the life of a connection, so
    it is a good place to start.
  prefs: []
  type: TYPE_NORMAL
- en: From there, I move on to provide details about TCP's handling of connections.
    I describe how you prepare and set up connections and *transmission control blocks
    (TCBs)*, and explain the difference between a passive and an active socket Open.
    I explain the three-way handshake that you can use to create a connection and
    the method by which parameters are exchanged and sequence numbers synchronized.
    I talk about how an established connection is managed, including the method by
    which TCP handles problem conditions and resets the connection when necessary.
    Finally, I describe how a connection can be terminated when it is no longer needed.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**BACKGROUND INFORMATION** *The following detailed sections assume that you''re
    familiar with the concepts in the previous chapter, especially the notion of sequence
    numbers*.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Operational Overview and the TCP Finite State Machine (FSM)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is essential that all devices that implement a networking protocol do so
    in a consistent manner. Otherwise, one device might behave in a manner that the
    other would not expect. Naturally, this inconsistency is why there are standards
    that describe the operation of each protocol. The problem with a protocol like
    TCP is that it performs so many tasks that it is difficult to specify the exact
    operation of all aspects of the protocol succinctly.
  prefs: []
  type: TYPE_NORMAL
- en: One way that computer scientists describe how a complex protocol works is through
    a theoretical tool called a *finite state machine (FSM)*. An FSM attempts to describe
    a protocol or algorithm by considering it like a virtual machine that progresses
    through a series of stages of operation in response to various occurrences.
  prefs: []
  type: TYPE_NORMAL
- en: Basic FSM Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You need to understand the following four essential concepts to comprehend
    the workings of an FSM:'
  prefs: []
  type: TYPE_NORMAL
- en: '**State** The particular circumstance or status that describes the protocol
    software on a machine at a given time.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transition** The act of moving from one state to another.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event** Something that causes a transition to occur between states.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Action** Something a device does in response to an event before it transitions
    to another state.'
  prefs: []
  type: TYPE_NORMAL
- en: An FSM describes the protocol by explaining all the different states the protocol
    can be in, the events that can occur in each state, what actions are taken in
    response to the events, and what transitions happen as a result. The protocol
    usually starts in a particular *beginning state* when it is first run. It then
    follows a sequence of steps that get it into a regular operating state, and moves
    to other states in response to particular types of input or other circumstances.
    The state machine is called *finite* because there are a limited number of states.
  prefs: []
  type: TYPE_NORMAL
- en: The Simplified TCP FSM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the case of TCP, the FSM describes the life stages of a connection. Each
    connection between one TCP device and another begins in a null state where there
    is no connection and then proceeds through a series of states until a connection
    is established. The connection remains in that state until something occurs to
    cause the connection to be closed again, at which point it proceeds through another
    sequence of transitional states and returns to the closed state.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Many computer scientists use the *finite state machine (FSM)*
    to describe the operation of a protocol or algorithm. The FSM describes the different
    actions that a piece of software takes over time by defining a finite number of
    operating *states*, *events* that can cause *transitions* between states, and
    *actions* taken in response to events.'
  prefs: []
  type: TYPE_NORMAL
- en: The full description of the states, events, and transitions in a TCP connection
    is lengthy and complicated. This is not surprising, because those three elements
    would cover much of the entire TCP standard. That level of detail would be a good
    cure for insomnia, but not much else. However, a simplified look at the TCP FSM
    will help give you a nice overall feel for how TCP establishes connections and
    then functions when a connection has been created.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 47-1](ch47.html#tcp_finite_state_machine_fsm_states_even "Table 47-1. TCP
    Finite State Machine (FSM) States, Events, and Transitions") briefly explains
    each of the TCP states in a TCP connection, the main events that occur in each
    state, and what actions and transitions occur as a result. For brevity, three
    abbreviations are used for the three types of messages that control transitions
    between states, which correspond to the TCP header flags that are set to indicate
    that a message is serving that function. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SYN** A *Synchronize* message; initiates and establishes a connection. It
    is so named since one of its functions is to synchronize sequence numbers between
    devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '**FIN** A *Finish* message, which is a TCP segment with the FIN bit set; it
    indicates that a device wants to terminate the connection.'
  prefs: []
  type: TYPE_NORMAL
- en: '**ACK** An *Acknowledgment message*; indicates receipt of a message such as
    a SYN or a FIN.'
  prefs: []
  type: TYPE_NORMAL
- en: Again, I have not shown every possible transition, just the ones normally followed
    in the life of a connection. Error conditions also cause transitions, but including
    these would move us well beyond a simplified state machine. The FSM, including
    how state transitions occur, is illustrated in [Figure 47-1](ch47.html#the_tcp_finite_state_machine_fsm_this_di
    "Figure 47-1. The TCP finite state machine (FSM) This diagram illustrates the
    simplified TCP FSM. The shadings are not an official part of the definition of
    the FSM; I have added them to show more clearly the sequences the two devices
    took to open and close a link. For establishment and termination, there is a regular
    sequence, in which the initiating and responding devices go through different
    states, and a simultaneous sequence, in which each uses the same sequence.").
  prefs: []
  type: TYPE_NORMAL
- en: It's important to remember that this state machine is followed for each connection.
    This means that, at any given time, TCP may be in one state for one connection
    to socket *X*, and in another for its connection to socket *Y*. Also, the typical
    movement between states for the two processes in a particular connection is not
    symmetric, because the roles of the devices are not symmetric. For example, one
    device initiates a connection, and the other responds; one device starts termination,
    and the other replies. There is also an alternate path taken for connection establishment
    and termination if both devices initiate simultaneously (which is unusual, but
    can happen). This is shown by the shading in [Figure 47-1](ch47.html#the_tcp_finite_state_machine_fsm_this_di
    "Figure 47-1. The TCP finite state machine (FSM) This diagram illustrates the
    simplified TCP FSM. The shadings are not an official part of the definition of
    the FSM; I have added them to show more clearly the sequences the two devices
    took to open and close a link. For establishment and termination, there is a regular
    sequence, in which the initiating and responding devices go through different
    states, and a simultaneous sequence, in which each uses the same sequence.").
  prefs: []
  type: TYPE_NORMAL
- en: Table 47-1. TCP Finite State Machine (FSM) States, Events, and Transitions
  prefs: []
  type: TYPE_NORMAL
- en: '| State | State Description | Event and Transition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | The default state that each connection starts in before the process
    of establishing it begins. The state is called "fictional" in the standard because
    this state represents the situation in which there is no connection between devices.
    It either hasn''t been created yet or has just been destroyed (if that makes sense).
    | Passive Open: A server begins the process of connection setup by doing a passive
    open on a TCP port. At the same time, it sets up the data structure (transmission
    control block, or TCB) that it needs in order to manage the connection. It then
    transitions to the LISTEN state. |'
  prefs: []
  type: TYPE_TB
- en: '|   |   | Active Open, Send SYN: A client begins the connection setup by sending
    a SYN message, and it sets up a TCB for this connection. It then transitions to
    the SYN-SENT state. |'
  prefs: []
  type: TYPE_TB
- en: '| LISTEN | A device (normally a server) is waiting to receive a SYN message
    from a client. It has not yet sent its own SYN message. | Receive Client SYN,
    Send SYN+ACK: The server device receives a SYN from a client. It sends back a
    message that contains its own SYN and acknowledges the one it received. The server
    moves to the SYN-RECEIVED state. |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-SENT | The device (normally a client) has sent a SYN message and is waiting
    for a matching SYN from the other device (usually a server). | Receive SYN, Send
    ACK: If the device that has sent its SYN message receives a SYN from the other
    device but not an ACK for its own SYN, it acknowledges the SYN it receives and
    then transitions to SYN-RECEIVED in order to wait for the acknowledgment to its
    own SYN. |'
  prefs: []
  type: TYPE_TB
- en: '|   |   | Receive SYN+ACK, Send ACK: If the device that sent the SYN receives
    both an acknowledgment to its SYN and a SYN from the other device, it acknowledges
    the SYN received and then moves straight to the ESTABLISHED state. |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-RECEIVED | The device has received a SYN (connection request) from its
    partner and sent its own SYN. It is now waiting for an ACK to its SYN in order
    to finish the connection setup. | Receive ACK: When the device receives the ACK
    to the SYN that it sent, it transitions to the ESTABLISHED state. |'
  prefs: []
  type: TYPE_TB
- en: '| ESTABLISHED | The steady state of an open TCP connection. Both devices can
    exchange data freely once both devices in the connection enter this state. This
    will continue until they close the connection. | Close, Send FIN: A device can
    close the connection by sending a message with the FIN bit sent, and then it can
    transition to the FIN-WAIT-1 state. |'
  prefs: []
  type: TYPE_TB
- en: '|   |   | Receive FIN: A device may receive a FIN message from its connection
    partner asking that the connection be closed. It will acknowledge this message
    and transition to the CLOSE-WAIT state. |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSE-WAIT | The device has received a close request (FIN) from the other
    device. It must now wait for the application on the local device to acknowledge
    this request and generate a matching request. | Close, Send FIN: The application
    using TCP, having been informed that the other process wants to shut down, sends
    a close request to the TCP layer on the machine on which it is running. TCP then
    sends a FIN to the remote device that already asked to terminate the connection.
    This device now transitions to LAST-ACK. |'
  prefs: []
  type: TYPE_TB
- en: '| LAST-ACK | A device that has already received a close request and acknowledged
    has sent its own FIN and is waiting for an ACK to this request. | Receive ACK
    for FIN: The device receives an acknowledgment for its close request. We have
    now sent our FIN and had it acknowledged, and received the other device''s FIN
    and acknowledged it, so we go straight to the CLOSED state. |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-1 | A device in this state is waiting for an ACK for a FIN it has
    sent, or is waiting for a connection termination request from the other device.
    | Receive ACK for FIN: The device receives an acknowledgment for its close request.
    It transitions to the FIN-WAIT-2 state. |'
  prefs: []
  type: TYPE_TB
- en: '|   |   | Receive FIN, Send ACK: The device does not receive an ACK for its
    own FIN, but receives a FIN from the other device. It acknowledges it and then
    moves to the CLOSING state. |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-2 | A device in this state has received an ACK for its request to
    terminate the connection and is now waiting for a matching FIN from the other
    device. | Receive FIN, Send ACK: The device receives a FIN from the other device.
    It acknowledges it and then moves to the TIME-WAIT state. |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSING | The device has received a FIN from the other device and has sent
    an ACK for it, but has not yet received an ACK for its own FIN message. | Receive
    ACK for FIN: The device receives an acknowledgment for its close request. It transitions
    to the TIME-WAIT state. |'
  prefs: []
  type: TYPE_TB
- en: '| TIME-WAIT | The device has now received a FIN from the other device and acknowledged
    it, and sent its own FIN and received an ACK for it. We are finished, except for
    waiting to ensure the ACK is received and preventing potential overlap with new
    connections. (See the "TCP Connection Termination" section later in this chapter
    for more details on this state.) | Timer Expiration: After a designated wait period,
    the device transitions to the CLOSED state. |'
  prefs: []
  type: TYPE_TB
- en: Thus, for example, at the start of connection establishment, the two devices
    will take different routes to get to the ESTABLISHED state. One device (the server
    usually) will pass through the LISTEN state, while the other (the client) will
    go through SYN-SENT state. Similarly, one device will initiate connection termination
    and take the path through the FIN-WAIT-1 state in order to get back to the CLOSED
    state; the other will go through the CLOSE-WAIT and LAST-ACK states. However,
    if both try to open at once, they each proceed through SYN-SENT and SYN-RECEIVED
    states, and if both try to close at once, they go through FIN-WAIT-1, CLOSING,
    and TIME-WAIT states roughly simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Although FSM may seem a bit intimidating at first, if you spend a few minutes
    with it, you can get a good handle on how TCP works. The FSM will be of great
    use in making sense of the connection establishment and termination processes
    discussed later in this chapter, and reading those sections will help you make
    sense of the FSM.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The TCP finite state machine (FSM) describes the sequence of
    steps that both devices take in a TCP session as they establish, manage, and close
    the connection. Each device may take a different path through the states, because
    under normal circumstances, the operation of the protocol is not symmetric—one
    device initiates connection establishment or termination, and the other responds.'
  prefs: []
  type: TYPE_NORMAL
- en: '![The TCP finite state machine (FSM) This diagram illustrates the simplified
    TCP FSM. The shadings are not an official part of the definition of the FSM; I
    have added them to show more clearly the sequences the two devices took to open
    and close a link. For establishment and termination, there is a regular sequence,
    in which the initiating and responding devices go through different states, and
    a simultaneous sequence, in which each uses the same sequence.](httpatomoreillycomsourcenostarchimages288105.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-1. The TCP finite state machine (FSM) This diagram illustrates the
    simplified TCP FSM. The shadings are not an official part of the definition of
    the FSM; I have added them to show more clearly the sequences the two devices
    took to open and close a link. For establishment and termination, there is a regular
    sequence, in which the initiating and responding devices go through different
    states, and a simultaneous sequence, in which each uses the same sequence.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Connection Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 43](ch43.html "Chapter 43. TCP AND UDP ADDRESSING: PORTS AND SOCKETS"),
    I raised an important point about TCP operation, particularly that it must be
    capable of handling many connections simultaneously. For this reason, we must
    uniquely identify each connection using the *quadruple* of the socket identifiers
    (IP address and port number) for each of the two devices on the connection. The
    process of setting up, managing, and terminating a connection is performed independently
    for each connection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Storing Connection Data: The Transmission Control Block (TCB)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since each connection is distinct, we must maintain data about each connection
    separately. TCP uses a special data structure for this purpose, called a *transmission
    control block (TCB)*. The TCB contains all the important information about the
    connection, such as the two socket numbers that identify it and pointers to buffers
    that hold incoming and outgoing data. The TCB also implements the sliding window
    mechanism. It holds variables that keep track of the number of bytes received
    and acknowledged, bytes received and not yet acknowledged, current window size,
    and so forth. Each device maintains its own TCB for the connection.
  prefs: []
  type: TYPE_NORMAL
- en: Before the process of setting up a TCP connection can begin, the devices on
    each end must perform some "prep work." One of the tasks required in order to
    prepare for the connection is to set up the TCB that will be used to hold information
    about it. This is done right at the very start of the connection establishment
    process, when each device transitions out of the CLOSED state.
  prefs: []
  type: TYPE_NORMAL
- en: Active and Passive Opens
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TCP/IP is based on the client/server model of operation, and TCP connection
    setup is based on the existence of these roles as well. The client and server
    each prepare for the connection by performing an *Open* operation. However, there
    are two different kinds of Open operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Active Open** A client process using TCP takes the active role and initiates
    the connection by sending a TCP message to start the connection (a SYN message).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passive Open** A server process designed to use TCP takes a more "laid-back"
    approach. It performs a *passive Open* by contacting TCP and saying, "I''m here,
    and I''m waiting for clients that may wish to talk to me to send me a message
    on the following port number." The Open is called *passive* because, aside from
    indicating that the process is listening, the server process does nothing. A passive
    Open can specify that the server is waiting for an active Open from a specific
    client, though not all TCP/IP APIs support this capability. More commonly, a server
    process is willing to accept connections from all comers. Such a passive Open
    is said to be *unspecified*.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A client process initiates a TCP connection by performing an
    active *Open*, sending a SYN message to a server. A server process using TCP prepares
    for an incoming connection request by performing a *passive Open*. For each TCP
    session, both devices create a data structure, called a *transmission control
    block (TCB)*, that is used to hold important data related to the connection.'
  prefs: []
  type: TYPE_NORMAL
- en: Preparation for Connection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Both the client and the server create the TCB for the connection at the time
    that they perform the Open. The client already knows the IP addresses and port
    numbers for both the client process and the server process it is trying to reach,
    so it can use these to uniquely identify the connection and the TCB that goes
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: For the server, the concept of a TCB at this stage of the game is a bit more
    complex. If the server is waiting for a particular client, it can identify the
    connection using its own socket and the socket of the client for which it is waiting.
    Normally, however, the server doesn't know which client is trying to reach it.
    In fact, more than one client could contact it at nearly the same time.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the server creates a TCB with an unspecified (zero) client socket
    number and waits to receive an active Open. It then *binds* the socket number
    of the client to the TCB for the passive Open as part of the connection process.
    To allow the server to handle multiple incoming connections, the server process
    may perform several unspecified passive Opens simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: The TCB for a connection is maintained throughout the connection and destroyed
    when the connection is completely terminated, and the device returns to the CLOSED
    state. TCP does include a procedure that handles the situation in which both devices
    perform an active Open simultaneously, as I discuss the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP Connection Establishment Process: The Three-Way Handshake'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before TCP can be employed for any actually useful purpose—that is, sending
    data—a connection must be set up between the two devices that wish to communicate.
    This process, usually called *connection establishment*, involves an exchange
    of messages that transitions both devices from their initial connection state
    (CLOSED) to the normal operating state (ESTABLISHED).
  prefs: []
  type: TYPE_NORMAL
- en: Connection Establishment Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The connection establishment process actually accomplishes the following tasks
    as it creates a connection suitable for data exchange:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Contact and Communication** The client and server make contact with each
    other and establish communication by sending each other messages. The server usually
    doesn''t even know which client it will be talking to before this point, so it
    discovers this during connection establishment.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sequence Number Synchronization** Each device lets the other know what initial
    sequence number it wants to use for its first transmission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Parameter Exchange** The two devices exchange certain parameters that control
    the operation of the TCP connection.'
  prefs: []
  type: TYPE_NORMAL
- en: I'll discuss the sequence number synchronization and parameter exchange tasks
    in the "TCP Connection Establishment Sequence Number Synchronization and Parameter
    Exchange" section later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Control Messages Used for Connection Establishment: SYN and ACK'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TCP uses control messages to manage the process of contact and communication.
    There aren''t, however, any special TCP control message types; all TCP messages
    use the same segment format. A set of control flags in the TCP header indicates
    whether a segment is being used for control purposes or just to carry data. As
    I introduced in the discussion of the TCP FSM earlier in the chapter, two control
    message types are used in connection setup, which are specified by setting the
    following two flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SYN** Indicates that the segment is being used to initialize a connection.
    SYN stands for *synchronize*, in reference to the sequence number synchronization
    task in the connection establishment process.'
  prefs: []
  type: TYPE_NORMAL
- en: '**ACK** Indicates that the device sending the segment is conveying an *acknowledgment*
    for a message it has received (such as a SYN).'
  prefs: []
  type: TYPE_NORMAL
- en: There are also other control bits (*FIN*, *RST*, *PSH*, and *URG*) that aren't
    important to connection establishment, so I will discuss them in other topics.
    In common TCP parlance, a message with a control bit set is often named for that
    bit. For example, if the SYN control bit is set, the segment is often called a
    SYN message. Similarly, a segment with the ACK bit set is an ACK message, or even
    just an ACK.
  prefs: []
  type: TYPE_NORMAL
- en: 'Normal Connection Establishment: The Three-Way Handshake'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To establish a connection, each device must send a SYN message and receive an
    ACK message for it from the other device. Thus, conceptually, we need to have
    four control messages pass between the devices. However, it's inefficient to send
    a SYN and an ACK in separate messages when one could communicate both simultaneously.
    Thus, in the normal sequence of events in connection establishment, one of the
    SYNs and one of the ACKs are sent together by setting both of the relevant bits
    (a message sometimes called a *SYN+ACK*). This makes a total of three messages,
    and for this reason the connection procedure is called a *three-way handshake*.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The normal process of establishing a connection between a TCP
    client and server involves the following three steps: The client sends a *SYN*
    message. The server sends a message that combines an *ACK* for the client''s *SYN*
    and contains the server''s SYN. And the client sends an ACK for the server''s
    SYN. This is called the *TCP three-way handshake*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 47-2](ch47s03.html#tcp_three-way_handshake_connection_estab "Table 47-2. TCP
    Three-Way Handshake Connection Establishment Procedure") describes in detail how
    the three-way handshake works (including a summary of the preparation discussed
    in the previous section). It is adapted from the table describing the TCP FSM
    ([Table 47-1](ch47.html#tcp_finite_state_machine_fsm_states_even "Table 47-1. TCP
    Finite State Machine (FSM) States, Events, and Transitions")), but shows what
    happens for both the server and the client over time. Each row shows the state
    the device begins in, what action it takes in that state, and the state to which
    it transitions. The transmit and receive parts of each of the three steps of the
    handshake process are shown as well. The same process is also illustrated in 47-2.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 47-2. TCP Three-Way Handshake Connection Establishment Procedure
  prefs: []
  type: TYPE_NORMAL
- en: '| Client | Server |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Start State | Action | Move to State | Start State | Action | Move to State
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | The client cannot do anything until the server has performed a passive
    Open and is ready to accept a connection. | — | CLOSED | The server performs a
    passive Open, creating a TCB for the connection and readying itself for the receipt
    of a connection request (SYN) from a client. | LISTEN |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | Step 1 Transmit: The client performs an active Open, creating a
    TCB) for the connection and sending a SYN message to the server. | SYN-SENT |
    LISTEN | The server waits for contact from a client. | — |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-SENT | The client waits to receive an ACK to the SYN that it has sent,
    as well as the server''s SYN. | — | LISTEN | Step 1 Receive, Step 2 Transmit:
    The server receives the SYN from the client. It sends a single SYN+ACK message
    back to the client that contains an ACK for the client''s SYN, as well as the
    server''s own SYN. | SYN-RECEIVED |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-SENT | Step 2 Receive, Step 3 Transmit: The client receives from the
    server the SYN+ACK containing the ACK to the client''s SYN, and the SYN from the
    server. It sends the server an ACK for the server''s SYN. The client is now finished
    with the connection establishment. | ESTABLISHED | SYN-RECEIVED | The server waits
    for an ACK to the SYN it sent previously. | — |'
  prefs: []
  type: TYPE_TB
- en: '| ESTABLISHED | The client is waiting for the server to finish connection establishment
    so they can operate normally. |   | SYN-RECEIVED | Step 3 Receive: The server
    receives the ACK to its SYN and is now finished with connection establishment.
    | ESTABLISHED |'
  prefs: []
  type: TYPE_TB
- en: '| ESTABLISHED | The client is ready for normal data transfer operations. |
      | ESTABLISHED | The server is ready for normal data transfer operations. |  |'
  prefs: []
  type: TYPE_TB
- en: '![TCP three-way handshake connection establishment procedure This diagram illustrates
    how a client and server establish a conventional connection. It shows how the
    three messages sent during the process and how each device transitions from the
    CLOSED state through intermediate states until the session is in the ESTABLISHED
    state.](httpatomoreillycomsourcenostarchimages288107.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-2. TCP three-way handshake connection establishment procedure This
    diagram illustrates how a client and server establish a conventional connection.
    It shows how the three messages sent during the process and how each device transitions
    from the CLOSED state through intermediate states until the session is in the
    ESTABLISHED state.
  prefs: []
  type: TYPE_NORMAL
- en: Simultaneous Open Connection Establishment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP is also set up to handle the situation in which both devices perform an
    active Open instead of one doing a passive Open. This may occur if two clients
    are trying to reach each other instead of a client and a server. It is uncommon,
    however, and only happens under certain circumstances. Simultaneous connection
    establishment can also happen only if one of the devices uses a well-known port
    as its source port.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of simultaneous open connection establishment, the steps are different
    for both devices. Each client will perform an active Open and will then proceed
    through both the SYN-SENT and SYN-RECEIVED states until the clients acknowledge
    each other's SYNs. This means that there is no three-way handshake; instead, there
    is something like two simultaneous two-way handshakes. Each client sends a SYN,
    receives the other's SYN, acknowledges the SYN with an ACK it, and then waits
    for its own ACK.
  prefs: []
  type: TYPE_NORMAL
- en: I have described the transaction for establishing open connections simultaneously,
    in a simplified way, in [Table 47-3](ch47s03.html#tcp_simultaneous_open_connection_establi
    "Table 47-3. TCP Simultaneous Open Connection Establishment Procedure") and illustrated
    it in [Figure 47-3](ch47s03.html#tcp_simultaneous_open_connection_e-id001 "Figure 47-3. TCP
    simultaneous open connection establishment procedure This diagram shows what happens
    when two devices try to open a connection to each other at the same time. In this
    case, instead of a three-way handshake, each sends a SYN and receives an ACK.
    They each follow the same sequence of states, which differs from both sequences
    in the normal three-way handshake."). To limit the table size, I have shown the
    activities performed by the two devices occurring simultaneously (in the same
    row). In reality, the actions don't need to occur at exactly the same time and
    probably won't. All that must happen for the simultaneous procedure to be followed
    is that each device receives a SYN before getting an ACK for its own SYN, as [Figure 47-3](ch47s03.html#tcp_simultaneous_open_connection_e-id001
    "Figure 47-3. TCP simultaneous open connection establishment procedure This diagram
    shows what happens when two devices try to open a connection to each other at
    the same time. In this case, instead of a three-way handshake, each sends a SYN
    and receives an ACK. They each follow the same sequence of states, which differs
    from both sequences in the normal three-way handshake.") shows.
  prefs: []
  type: TYPE_NORMAL
- en: Table 47-3. TCP Simultaneous Open Connection Establishment Procedure
  prefs: []
  type: TYPE_NORMAL
- en: '| Client A | Client B |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Start State | Action | Move to State | Start State | Action | Move to State
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | Client A Step 1 Transmit: Client A performs an active Open, creating
    a TCB and sending a SYN to the server. | SYN-SENT | CLOSED | Client B Step 1 Transmit:
    Client B performs an active Open, creating a TCB and sending a SYN to the server.
    | SYN-SENT |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-SENT | Client B Step 1 Receive and Step 2 Transmit: Client A receives
    Client B''s SYN and sends it an ACK. It is still waiting for an ACK to its own
    SYN. | SYN-RECEIVED | SYN-SENT | Client A Step 1 Receive and Step 2 Transmit:
    Client B receives Client A''s SYN and sends it an ACK. It is still waiting for
    an ACK to its own SYN. | SYN-RECEIVED |'
  prefs: []
  type: TYPE_TB
- en: '| SYN-RECEIVED | Client A Step 2 Receive: Client A receives the ACK from Client
    B for its SYN and finishes connection establishment. | ESTABLISHED | SYN-RECEIVED
    | Client B Step 2 Receive: Client B receives the ACK from Client A for its SYN
    and finishes connection establishment. | ESTABLISHED |'
  prefs: []
  type: TYPE_TB
- en: '![TCP simultaneous open connection establishment procedure This diagram shows
    what happens when two devices try to open a connection to each other at the same
    time. In this case, instead of a three-way handshake, each sends a SYN and receives
    an ACK. They each follow the same sequence of states, which differs from both
    sequences in the normal three-way handshake.](httpatomoreillycomsourcenostarchimages288109.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-3. TCP simultaneous open connection establishment procedure This diagram
    shows what happens when two devices try to open a connection to each other at
    the same time. In this case, instead of a three-way handshake, each sends a SYN
    and receives an ACK. They each follow the same sequence of states, which differs
    from both sequences in the normal three-way handshake.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** If one device setting up a TCP connection sends a SYN and then
    receives a SYN from the another device before it acknowledges its SYN, the two
    devices perform a *simultaneous OPEN*, which consists of the exchange of two independent
    SYN and ACK message sets. The end result is the same as the conventional three-way
    handshake, but the process of getting to the ESTABLISHED state is different.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Connection Establishment Sequence Number Synchronization and Parameter Exchange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TCP three-way handshake describes the mechanism of message exchange that
    allows a pair of TCP devices to move from a closed state to one that is a ready-to-use,
    established connection. Connection establishment is about more than just passing
    messages between devices in order to establish communication. The TCP layers on
    the devices must also exchange information about the sequence numbers each device
    wants to use for its first data transmission. The layers must also exchange information
    about the parameters that will control how the connection operates. The sequence
    numbers exchange is usually called *sequence number synchronization*, and it is
    such an important part of connection establishment that the messages that each
    device sends to start the connection are called *SYN (synchronization)* messages.
  prefs: []
  type: TYPE_NORMAL
- en: You may recall from the TCP fundamentals discussion in [Chapter 46](ch46.html
    "Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION")
    that TCP refers to each byte of data individually and uses sequence numbers to
    keep track of which bytes have been sent and received. Since each byte has a sequence
    number, we can acknowledge each byte, or more efficiently, use a single number
    to acknowledge a range of bytes received.
  prefs: []
  type: TYPE_NORMAL
- en: In the example I gave in [Chapter 46](ch46.html "Chapter 46. TRANSMISSION CONTROL
    PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION"), I assumed that each device
    would start a connection by giving the first byte of data sent between them sequence
    number 1\. A valid question is why wouldn't we *always* just start off each TCP
    connection by sending the first byte of data with a sequence number of 1? The
    sequence numbers are arbitrary, after all, and this is the simplest method. In
    an ideal world, this would probably work, but we don't live in an ideal world.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with starting off each connection with a sequence number of 1 is
    that it introduces the possibility of segments from different connections getting
    mixed up. Suppose we established a TCP connection and sent a segment containing
    bytes 1 through 30\. However, a problem with the internetwork caused a delay with
    this segment, and eventually, the TCP connection itself was terminated. We then
    started up a new connection and again used a starting sequence number of 1\. As
    soon as this new connection was started, however, the old segment with bytes labeled
    1 to 30 showed up. The other device would erroneously think those bytes were part
    of the *new* connection.
  prefs: []
  type: TYPE_NORMAL
- en: This is but one of several similar problems that could occur. To avoid them,
    each TCP device, at the time a connection is initiated, chooses a 32-bit *initial
    sequence number (ISN)* for the connection. Each device has its own ISN, and those
    ISNs normally won't be the same.
  prefs: []
  type: TYPE_NORMAL
- en: Initial Sequence Number Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Traditionally, each device chose the ISN by making use of a timed counter, like
    a clock of sorts, that was incremented every 4 microseconds. TCP initialized the
    counter when it started up, and then the counter's value increased by one every
    4 microseconds until it reached the largest 32-bit value possible (4,294,967,295),
    at which point it wrapped around to 0 and resumed incrementing. Any time a new
    connection was set up, the ISN was taken from the current value of this timer.
    Since it takes over 4 hours to count from 0 to 4,294,967,295 at 4 microseconds
    per increment, this virtually ensured that each connection would not conflict
    with any previous ones.
  prefs: []
  type: TYPE_NORMAL
- en: One issue with this method is that it made ISNs predictable. A malicious person
    could write code to analyze ISNs and then predict the ISN of a subsequent TCP
    connection based on the ISNs used in earlier ones. Malicious hackers have exploited
    this security risk in the past (such as in the case of the famous Mitnick attack).
    To defeat the malicious hackers, implementations now use a random number in their
    ISN selection process.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Sequence Number Synchronization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once each device chooses its ISN, it sends the ISN value to the other device
    in the Sequence Number field in the device's initial SYN message. The device receiving
    the SYN responds with an ACK message that acknowledges the SYN (which may also
    contain its own SYN, as in step 2 of the three-way handshake). In the ACK message,
    the Acknowledgment Number field is set to the value of the ISN that is received
    from the other device *plus one*. This represents the next sequence number the
    device expects to receive from its peer; the ISN actually represents the sequence
    number of the last byte received (fictitious in this case, since the connection
    is new and nothing yet has been received).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** As part of the process of connection establishment, each of
    the two devices in a TCP connection informs the other of the sequence number it
    plans to use for its first data transmission. Each device informs the other by
    putting the preceding sequence number in the Sequence Number field of its SYN
    message. The other device confirms this by incrementing that value and putting
    it into the Acknowledgment Number field of its ACK message, telling the other
    device that it is the sequence number it is expecting for the first data transmission.
    This process is called *sequence number synchronization*.'
  prefs: []
  type: TYPE_NORMAL
- en: Here's a simplified example of the three-way handshake steps (see [Figure 47-4](ch47s04.html#tcp_sequence_number_synchronization_this
    "Figure 47-4. TCP sequence number synchronization This diagram illustrates the
    same three-way handshake connection establishment procedure that I introduced
    in Figure 47-2, except this time I have shown the Sequence Number and Acknowledgment
    Number fields in each message, so that you can see how each of the two devices
    use them to establish initial sequence numbers for data exchange.")). I chose
    small ISNs for readability, but remember that ISNs can be any 32-bit number.
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection Request by Client** The client chooses an ISN for its transmissions
    of 4,567\. It sends a SYN with the Sequence Number field set to 4,567.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Acknowledgment and Connection Request by Server** The server chooses an ISN
    for its transmissions of 12,998\. It receives the client''s SYN. It sends a SYN+ACK
    with an Acknowledgment Number field value of 4,568 (one more than the client''s
    ISN). This message has a Sequence Number field value of 12,998.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Acknowledgment by Client** The client sends an ACK with the Acknowledgment
    Number field set to 12,999.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the connection now established, the client will send data whose first byte
    will be given sequence number 4,568\. The server's first byte of data will be
    numbered 12,999.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP sequence number synchronization This diagram illustrates the same three-way
    handshake connection establishment procedure that I introduced in , except this
    time I have shown the Sequence Number and Acknowledgment Number fields in each
    message, so that you can see how each of the two devices use them to establish
    initial sequence numbers for data exchange.](httpatomoreillycomsourcenostarchimages288111.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-4. TCP sequence number synchronization This diagram illustrates the
    same three-way handshake connection establishment procedure that I introduced
    in [Figure 47-2](ch47s03.html#tcp_three-way_handshake_connection-id001 "Figure 47-2. TCP
    three-way handshake connection establishment procedure This diagram illustrates
    how a client and server establish a conventional connection. It shows how the
    three messages sent during the process and how each device transitions from the
    CLOSED state through intermediate states until the session is in the ESTABLISHED
    state."), except this time I have shown the Sequence Number and Acknowledgment
    Number fields in each message, so that you can see how each of the two devices
    use them to establish initial sequence numbers for data exchange.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Parameter Exchange
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the initial sequence numbers, SYN messages also are designed
    to convey important parameters about how the connection should operate. TCP includes
    a flexible scheme for carrying these parameters, in the form of a variable-length
    *Options* field in the TCP segment format, which can be expanded to carry multiple
    parameters. In RFC 793, only a single parameter is defined to be exchanged during
    connection setup: *maximum segment size (MSS)*. I explain the significance of
    this parameter in the TCP data transfer discussion in [Chapter 48](ch48.html "Chapter 48. TCP
    MESSAGE FORMATTING AND DATA TRANSFER").'
  prefs: []
  type: TYPE_NORMAL
- en: Each device sends the other the MSS that it wants to use for the connection;
    that is, if the device wishes to use a nondefault value. When receiving the SYN,
    the server records the MSS value that the client sent, and it will never send
    a segment larger than that value to the client. The client does the same for the
    server. The client and server MSS values are independent, so they can establish
    a connection where the client can receive larger segments than the server or vice
    versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'Later RFCs have defined additional parameters that may be exchanged during
    connection setup. Some of these include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Window Scale Factor** Allows a pair of devices to specify larger window sizes
    than would normally be possible given the 16-bit size of the TCP *Window* field.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selective Acknowledgment Permitted** Allows a pair of devices to use the
    optional selective acknowledgment feature to allow only certain lost segments
    to be retransmitted.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Alternate Checksum Method** Lets devices specify an alternative method of
    performing checksums than the standard TCP checksum mechanism.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Connection Management and Problem Handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once both of the devices in a TCP connection have completed connection setup
    and have entered the ESTABLISHED state, the TCP software is in its normal operating
    mode. The TCP software will package bytes of data into segments for transmission
    using the mechanisms described in [Chapter 48](ch48.html "Chapter 48. TCP MESSAGE
    FORMATTING AND DATA TRANSFER"). TCP will use the sliding windows scheme to control
    segment size and to provide flow control, congestion handling, and retransmissions
    as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once in the sliding windows mode, both devices can remain there indefinitely.
    Some TCP connections can be very long-lived—in fact, some users maintain certain
    connections like Telnet sessions for hours or even days at a time. The following
    two circumstances can cause a connection to move out of the ESTABLISHED state:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection Termination** Either of the devices decides to terminate the connection.
    This involves a specific procedure that I cover in the "TCP Connection Termination"
    section later in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Connection Disruption** A problem of some sort occurs and interrupts the
    connection.'
  prefs: []
  type: TYPE_NORMAL
- en: The TCP Reset Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order for it to live up to its job of being a reliable and robust protocol,
    TCP includes intelligence that allows it to detect and respond to various problems
    that can occur during an established connection. One of the most common is the
    *half-open connection*. This situation occurs when, due to some sort of problem,
    one device closes or aborts the connection without the other one knowing about
    it. This means one device is in the ESTABLISHED state, while the other may be
    in the CLOSED state (no connection) or some other transient state. This could
    happen if, for example, one device had a software crash and someone restarted
    it in the middle of a connection, or if some sort of glitch caused the states
    of the two devices to become unsynchronized.
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle half-open connections and other problem situations, TCP includes
    a special *reset function*. A *reset* is a TCP segment that TCP sends with the
    *RST* flag set to 1 in its header. Generally speaking, the TCP software generates
    a reset whenever something unexpected happens. The following are some of the most
    common cases in which the TCP software generates a reset:'
  prefs: []
  type: TYPE_NORMAL
- en: Receipt of any TCP segment from any device with which the device receiving the
    segment does not currently have a connection (other than a SYN requesting a new
    connection)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Receipt of a message with an invalid or incorrect Sequence Number or Acknowledgment
    Number field, indicating that the message may belong to a prior connection or
    is spurious in some other way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Receipt of a SYN message on a port where there is no process listening for connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling Reset Segments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a device receives a segment with the RST bit, it tells the other device
    to reset the connection so that the device can reestablish the connection. Like
    all segments, the reset itself must be checked to ensure that it is valid (by
    looking at the value of its Sequence Number field). This check prevents a spurious
    reset from shutting down a connection. Assuming the reset is valid, the handling
    of the message depends on the state of the device that receives it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If the device is in the LISTEN state, it ignores the reset and remains in that
    state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the device is in the SYN-RECEIVED state but was previously in the LISTEN
    state (which is the normal course of events for a server setting up a new connection),
    it returns to the LISTEN state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In any other situation, the reset causes the device to abort the connection
    and the device returns to the CLOSED state for that connection. The device will
    advise the higher-layer process that is using TCP that it has closed the connection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP includes a special *connection reset feature* that allows
    devices to deal with problem situations, such as *half-open connections* or the
    receipt of unexpected message types. To use the feature, the device detecting
    the problem sends a TCP segment with the RST (reset) flag set to 1\. The receiving
    device either returns to the LISTEN state, if it was in the process of connection
    establishment, or closes the connection and returns to the CLOSED state pending
    a new session negotiation.'
  prefs: []
  type: TYPE_NORMAL
- en: Idle Connection Management and Keepalive Messages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One final connection management issue in TCP is how to handle an idle connection;
    that is, a TCP session that is active but that has no data being transmitted by
    either device for a prolonged period of time. The TCP standard specifies that
    the appropriate action to take in this situation is nothing. The reason is that,
    strictly speaking, there is no need to do anything to maintain an idle connection
    in TCP. The protocol is perfectly happy to allow both devices to stop transmitting
    for a very long period of time. Then it simply allows both devices to resume transmissions
    of data and acknowledgment segments when each one has data to send.
  prefs: []
  type: TYPE_NORMAL
- en: However, in the same way that people become antsy when they are on a telephone
    call and don't hear anything for a long time, some TCP implementors were concerned
    that an idle TCP connection might mean that something had broken the connection.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, TCP software often includes an unofficial feature that allows a device
    with a TCP link to periodically send a null segment, which contains no data, to
    its peer on the connection. If the connection is still valid, the other device
    responds with a segment that contains an acknowledgment; if it is not, the other
    device will reply with a connection reset segment as I described earlier. These
    segments are sometimes called TCP *keepalive messages*, or just *keepalives*.
    They are analogous to Border Gateway Protocol (BGP) Keepalive messages (described
    in [Chapter 40](ch40.html "Chapter 40. BORDER GATEWAY PROTOCOL (BGP/BGP-4)")).
  prefs: []
  type: TYPE_NORMAL
- en: The use of these messages is quite controversial, and therefore, not universal.
    Those who oppose using them argue that they are not really necessary, and that
    sending them represents a waste of internetwork bandwidth and a possible additional
    cost on metered links (those that charge for each datagram sent). Their key point
    is that if the connection is not presently being used, it doesn't matter if it
    is still valid or not; as soon as the connection is used again, if it has broken,
    in the meantime, TCP can handle that using the reset function mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Sending a keepalive message can, in theory, break a good TCP session unnecessarily.
    This may happen if the keepalive is sent during a time when there is an intermittent
    failure between the client and server. The failure might otherwise have corrected
    itself by the time the next piece of real data must be sent. In addition, some
    TCP implementations may not properly deal with the receipt of these segments.
  prefs: []
  type: TYPE_NORMAL
- en: Those in favor of using keepalives point out that each TCP connection consumes
    a certain amount of resources, and this can be an issue, especially for busy servers.
    If many clients connect to such a server and don't terminate the TCP connection
    properly, the server may sit for a long time with an idle connection, using system
    memory and other resources that it could apply elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: Since there is no wide acceptance on the use of this feature, devices implementing
    it include a way to disable it if necessary. Devices are also programmed so that
    they will not terminate a connection simply because they did not receive a response
    to a single keepalive message. They may terminate the connection if they do not
    receive a reply after several such messages have been sent over a period of time.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Connection Termination
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the saying goes, all good things must come to an end, and so it is with TCP
    connections. The link between a pair of devices can remain open for a considerable
    period of time, assuming that a problem doesn't force the device to abort the
    connection. Eventually, however, one or both of the processes in the connection
    will run out of data to send and will shut down the TCP session, or the user will
    instruct the device to shut down.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements and Issues In Connection Termination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just as TCP follows an ordered sequence of operations in order to establish
    a connection, it also includes a specific procedure for terminating a connection.
    As with connection establishment, each of the devices moves from one state to
    the next in order to terminate the connection. This process is more complicated
    than you might imagine. In fact, an examination of the TCP FSM shows that there
    are more distinct states involved in shutting down a connection than in setting
    one up.
  prefs: []
  type: TYPE_NORMAL
- en: The reason that connection termination is complex is that during normal operation,
    both devices are sending and receiving data simultaneously. Usually, connection
    termination begins with one device indicating to TCP that it wants to close the
    connection. The matching process on the other device may not be aware that its
    peer wants to end the connection at all. Several steps are required to ensure
    that both devices shut down the connection gracefully and that no data is lost
    in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, shutting down a TCP connection requires the application processes
    on both ends of the connection to recognize that "the end is nigh" for the connection
    and that they should stop sending data. For this reason, connection termination
    is implemented so that each device terminates its end of the connection separately.
    The act of closing the connection by one device means that device will no longer
    send data, but can continue to receive it until the other device has decided to
    stop sending. This allows all data that is pending to be sent by both sides of
    the communication to be flushed before the connection is ended.
  prefs: []
  type: TYPE_NORMAL
- en: Normal Connection Termination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the normal case, each side terminates its end of the connection by sending
    a special message with the FIN (finish) bit set. The FIN message serves as a connection
    termination request to the other device, while also possibly carrying data like
    a regular segment. The device receiving the FIN responds with an acknowledgment
    to the FIN that indicates that it received the acknowledgment. Neither side considers
    the connection terminated until they both have sent a FIN and received an ACK,
    thereby finishing the shutdown procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, termination isn't a three-way handshake as with establishment. It is a
    pair of two-way handshakes. The states that the two devices in the connection
    move through during a normal connection shutdown are different because the device
    initiating the shutdown must behave differently than the one that receives the
    termination request. In particular, the TCP on the device receiving the initial
    termination request must inform its application process and wait for a signal
    that the process is ready to proceed. The initiating device doesn't need to do
    this, since the application started the ball rolling in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A TCP connection is terminating using a special procedure by
    which each side independently closes its end of the link. The connection normally
    begins with one of the application processes signaling to its TCP layer that the
    session is no longer needed. That device sends a FIN message to tell the other
    device that it wants to end the connection, which the other device acknowledges.
    When the responding device is ready, it too sends a FIN that the other device
    acknowledges; after waiting a period of time for the device to receive the ACK,
    the device closes the session.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 47-4](ch47s06.html#tcp_connection_termination_procedure "Table 47-4. TCP
    Connection Termination Procedure") describes in detail how the connection termination
    process works. You can also see the progression of states and messages exchanged
    in [Figure 47-5](ch47s06.html#tcp_connection_termination_procedure_thi "Figure 47-5. TCP
    connection termination procedure This diagram shows the conventional termination
    procedure for a TCP session, with one device initiating termination and the other
    responding. In this case, the client initiates; it sends a FIN, which the server
    acknowledges. The server waits for the server process to be ready to close and
    then sends its FIN, which the client acknowledges. The client waits for a period
    of time in order to ensure that the device receives its ACK, before proceeding
    to the CLOSED state."). The table is adapted from [Table 47-1](ch47.html#tcp_finite_state_machine_fsm_states_even
    "Table 47-1. TCP Finite State Machine (FSM) States, Events, and Transitions"),
    which describes the TCP FSM, but shows what happens for both the server and the
    client over time during connection shutdown. Either device can initiate connection
    termination; in this example, I am assuming the client does it. Each row shows
    the state each device begins in, what action it takes in that state, and what
    state it transitions to. I have also shown the send and receive stages of both
    of the steps for each of the client and server''s close operations.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 47-4. TCP Connection Termination Procedure
  prefs: []
  type: TYPE_NORMAL
- en: '| Client | Server |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Start State | Action | Transitions to State | Start State | Action | Transitions
    to State |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ESTABLISHED | Client Close Step 1 Transmit: The application using TCP signals
    that the connection is no longer needed. The client TCP sends a segment with the
    FIN bit set to request that the connection be closed. | FIN-WAIT-1 | ESTABLISHED
    | At this stage the server is still in normal operating mode. | — |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-1 | The client, having sent a FIN, is waiting for a device to acknowledge
    it and for the server to send its own FIN. In this state, the client can still
    receive data from the server but will no longer accept data from its local application
    to be sent to the server. | — | ESTABLISHED | Client Close Step 1 Receive and
    Step 2 Transmit: The server receives the client''s FIN. It sends an ACK to acknowledge
    the FIN. The server must wait for the application using it to be told that the
    other end is closing, so the application here can finish what it is doing. | CLOSE-WAIT
    |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-1 | Client Close Step 2 Receive: The client receives the ACK for
    its FIN. It must now wait for the server to close. | FIN-WAIT-2 | CLOSE-WAIT |
    The server waits for the application process on its end to signal that it is ready
    to close. | — |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-2 | The client is waiting for the server''s FIN. | — | CLOSE-WAIT
    | Server Close Step 1 Transmit: The server''s TCP receives a notice from the local
    application that it is done. The server sends its FIN to the client. | LAST-ACK
    |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-2 | Server Close Step 1 Receive and Step 2 Transmit: The client
    receives the server''s FIN and sends back an ACK. | TIME-WAIT | LAST-ACK | The
    server is waiting for an ACK for the FIN that it sent. | — |'
  prefs: []
  type: TYPE_TB
- en: '| TIME-WAIT | The client waits for a period of time equal to double the maximum
    segment life (MSL) time; this wait ensures that the ACK it sent was received.
    | — | LAST-ACK | Server Close Step 2 Receive: The server receives the ACK to its
    FIN and closes the connection. | CLOSED |'
  prefs: []
  type: TYPE_TB
- en: '| TIME-WAIT | The timer expires after double the MSL time. | CLOSED | CLOSED
    | The connection is closed on the server''s end. |   |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | The connection is closed. |   | CLOSED | The connection is closed.
    |   |'
  prefs: []
  type: TYPE_TB
- en: '![TCP connection termination procedure This diagram shows the conventional
    termination procedure for a TCP session, with one device initiating termination
    and the other responding. In this case, the client initiates; it sends a FIN,
    which the server acknowledges. The server waits for the server process to be ready
    to close and then sends its FIN, which the client acknowledges. The client waits
    for a period of time in order to ensure that the device receives its ACK, before
    proceeding to the CLOSED state.](httpatomoreillycomsourcenostarchimages288113.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-5. TCP connection termination procedure This diagram shows the conventional
    termination procedure for a TCP session, with one device initiating termination
    and the other responding. In this case, the client initiates; it sends a FIN,
    which the server acknowledges. The server waits for the server process to be ready
    to close and then sends its FIN, which the client acknowledges. The client waits
    for a period of time in order to ensure that the device receives its ACK, before
    proceeding to the CLOSED state.
  prefs: []
  type: TYPE_NORMAL
- en: The device receiving the initial FIN may have to wait a fairly long time (in
    networking terms) in the CLOSE-WAIT state for the application it is serving to
    indicate that it is ready to shut down. TCP cannot make any assumptions about
    how long this will take. During this period of time, the server in the previous
    example may continue sending data, and the client will receive it. However, the
    client will not send data to the server.
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, the second device (the server in the example) will send a FIN to
    close its end of the connection. The device that originally initiated the close
    (the client) will send an ACK for this FIN. However, the client cannot immediately
    go to the CLOSED state right after sending that ACK because it must allow time
    for the ACK to travel to the server. Normally, this will be quick, but delays
    might slow it down somewhat.
  prefs: []
  type: TYPE_NORMAL
- en: The TIME-WAIT State
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The TIME-WAIT state is required for two main reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: To provide enough time to ensure that the other device receives the ACK, and
    to retransmit it if it is lost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To provide a buffering period between the end of this connection and any subsequent
    ones. If not for this period, it is possible that packets from different connections
    could be mixed, thereby creating confusion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standard specifies that the client should wait double a particular length
    of time, called the *maximum segment lifetime (MSL)*, before closing the connection.
    The TCP standard defines MSL as being a value of 120 seconds (2 minutes). In modern
    networks, this is an eternity, so TCP allows implementations to choose a lower
    value if it believes that will lead to better operation.
  prefs: []
  type: TYPE_NORMAL
- en: Simultaneous Connection Termination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just as it is possible to change the normal connection establishment process
    if two devices decide to actively open a connection to each other, it is also
    possible for two devices to try to terminate a connection simultaneously. This
    term *simultaneously* does not mean that they both decide to shut down at exactly
    the same time—variances in network delays mean nothing can be simultaneous on
    an internetwork anyway. It simply means that, in the previous example, the client
    decides to shut down and sends a FIN, but the server sends its own FIN before
    the client's FIN shows up at the server. In that case, a different procedure is
    followed, as described in [Table 47-5](ch47s06.html#tcp_simultaneous_connection_termin-id001
    "Table 47-5. TCP Simultaneous Connection Termination Procedure") and illustrated
    in [Figure 47-6](ch47s06.html#tcp_simultaneous_connection_termination_ "Figure 47-6. TCP
    simultaneous connection termination procedure Under certain circumstances, both
    devices may decide to terminate a connection simultaneously, or nearly simultaneously.
    In this case, each sends a FIN and, before getting an ACK for it, receives the
    other device's FIN. Each acknowledges the other's FIN and waits for a period of
    time before closing the connection. Note the transition through the CLOSING state,
    which is used only as part of simultaneous termination.").
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP simultaneous connection termination procedure Under certain circumstances,
    both devices may decide to terminate a connection simultaneously, or nearly simultaneously.
    In this case, each sends a FIN and, before getting an ACK for it, receives the
    other device''s FIN. Each acknowledges the other''s FIN and waits for a period
    of time before closing the connection. Note the transition through the CLOSING
    state, which is used only as part of simultaneous termination.](httpatomoreillycomsourcenostarchimages288115.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 47-6. TCP simultaneous connection termination procedure Under certain
    circumstances, both devices may decide to terminate a connection simultaneously,
    or nearly simultaneously. In this case, each sends a FIN and, before getting an
    ACK for it, receives the other device's FIN. Each acknowledges the other's FIN
    and waits for a period of time before closing the connection. Note the transition
    through the CLOSING state, which is used only as part of simultaneous termination.
  prefs: []
  type: TYPE_NORMAL
- en: Table 47-5. TCP Simultaneous Connection Termination Procedure
  prefs: []
  type: TYPE_NORMAL
- en: '| Client | Server |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Start State | Action | Transitions to State | Start State | Action | Transitions
    to State |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ESTABLISHED | Client Close Step 1 Transmit: The application using TCP signals
    that the connection is no longer needed. The TCP on the client sends the next
    segment with the FIN bit set, indicating a request to close the connection. |
    FIN-WAIT-1 | ESTABLISHED | Server Close Step 1 Transmit: Before the server can
    receive the FIN that the client sent, the application on the server also signals
    a close. The server also sends a FIN. | FIN-WAIT-1 |'
  prefs: []
  type: TYPE_TB
- en: '| FIN-WAIT-1 | Server Close Step 1 Receive and Step 2 Transmit: The client
    has sent a FIN and is waiting for it to be acknowledged. Instead, it receives
    the FIN that the server sends. It acknowledges the server''s close request with
    an ACK and continues to wait for its own ACK. | CLOSING | FIN-WAIT-1 | Client
    Close Step 1 Receive and Step 2 Transmit: The server has sent a FIN and is waiting
    for it to be acknowledged. Instead, it receives the FIN that the client sends.
    It acknowledges the client''s close request with an ACK and continues to wait
    for its own ACK. | CLOSING |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSING | Client Close Step 2 Receive: The client receives the ACK for its
    FIN. | TIME-WAIT | CLOSING | Server Close Step 2 Receive: The server receives
    the ACK for its FIN. | TIME-WAIT |'
  prefs: []
  type: TYPE_TB
- en: '| TIME-WAIT | The client waits for a period of time equal to double the MSL
    time. This gives enough time to ensure that the ACK it sent to the server was
    received. | — | TIME-WAIT | The server waits for a period of time equal to double
    the MSL time. This gives enough time to ensure the ACK it sent to the client was
    received. | — |'
  prefs: []
  type: TYPE_TB
- en: '| TIME-WAIT | The timer expires after double the MSL time. | CLOSED | TIME-WAIT
    | The timer expires after double the MSL time. | CLOSED |'
  prefs: []
  type: TYPE_TB
- en: '| CLOSED | The connection is closed. | — | CLOSED | The connection is closed.
    | — |'
  prefs: []
  type: TYPE_TB
- en: As you can see, the process is much more symmetric in this case, with both devices
    transitioning through the same states. In either case the end result is the same,
    with the connection in the CLOSED state—meaning no connection. Each TCP will make
    sure all outstanding data is sent to the application, sometimes referred to as
    an implied *push* (see the description of the push function in [Chapter 48](ch48.html
    "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER") for an explanation of
    this term). The TCBs established for the connection in both devices are destroyed
    when the connection is closed down.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Just as two devices can simultaneously open a TCP session,
    they can terminate it simultaneously as well. In this case, a different state
    sequence is followed, with each device responding to the other''s FIN with an
    ACK, then waiting for receipt of its own ACK, and pausing for a period of time
    to ensure that the other device received its ACK before ending the connection.'
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The previous chapter described how two devices using the Transmission Control
    Protocol (TCP) establish a TCP connection, as well as how that connection is managed
    and eventually terminated. While connections are a key part of how TCP works,
    they are really just a means to the ultimate end of the protocol: sending data.
    By employing the TCP sliding window mechanism, a special segment format, and several
    features, TCP devices are able to package and send data over the connection, enabling
    applications to communicate.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter describes the actual mechanism by which TCP messages are formatted
    and data is transferred between devices. I begin with a look at the important
    *TCP segment format*, which describes the fields in each TCP message and how they
    are used. Next, I provide a description of the method used to calculate the checksum
    in TCP (as well as UDP) messages, and explain the reason why a special pseudo
    header is used. Then I discuss the maximum segment size (MSS) parameter and its
    significance. Following that, I talk about exactly how the sliding window mechanism
    is used to transfer and acknowledge data. I conclude with a description of two
    special data transfer features: the push feature, for immediate data transfer,
    and the urgent feature for priority data transfer.'
  prefs: []
  type: TYPE_NORMAL
- en: '**BACKGROUND INFORMATION** This chapter assumes that you are already familiar
    with TCP concepts such as sequence numbers, segments, and the basics of the TCP
    sliding window mechanism. If you are not, read [Chapter 46](ch46.html "Chapter 46. TRANSMISSION
    CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION") before proceeding
    with this one.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Message (Segment) Format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the TCP overview in [Chapter 45](ch45.html "Chapter 45. TCP OVERVIEW, FUNCTIONS,
    AND CHARACTERISTICS"), I described one of the most interesting jobs that TCP performs:
    It allows an application to send data as an unstructured sequence of bytes, transparently
    packaging that data in distinct messages as required by the underlying protocol
    that TCP uses (normally IP, of course). TCP messages are called *segments*, the
    name referring to the fact that each is a portion of the overall data stream passing
    between the devices.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP segments are very much jack-of-all-trade messages—they are flexible and
    serve a variety of purposes. A single field format is used for all segments, with
    a number of header fields that implement the many functions and features for which
    TCP is responsible. One of the most notable characteristics of TCP segments is
    that they are designed to carry both control information and data simultaneously.
    This reduces the number of segments sent, since a segment can perform more than
    one function.
  prefs: []
  type: TYPE_NORMAL
- en: For example, there is no need to send separate acknowledgments in TCP, because
    each TCP message includes a field for an acknowledgment byte number. Similarly,
    one can request that a connection be closed while sending data in the same message.
    The nature of each TCP segment is indicated through the use of several special
    control bits. More than one bit can be sent to allow a segment to perform multiple
    functions, such as when a bit is used to specify an initial sequence number (ISN)
    and acknowledge receipt of another such segment at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The price we pay for this flexibility is that the TCP header is large: 20 bytes
    for regular segments and more for those carrying options. This is one of the reasons
    why some protocols prefer to use the User Datagram Protocol (UDP) if they don''t
    need TCP''s features. The TCP header fields are used for the following general
    purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Process Addressing** The processes on the source and destination devices
    are identified using port numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementing the Sliding Window System** Sequence Number, Acknowledgment
    Number, and Window Size fields implement the TCP sliding window system (discussed
    in the "TCP Sliding Window Data Transfer and Acknowledgment Mechanics" section
    later in this chapter).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting Control Bits and Fields** These are special bits that implement various
    control functions and fields that carry pointers and other data needed for them.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Carrying Data** The Data field carries the actual bytes of data being sent
    between devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performing Miscellaneous Functions** These include a checksum for data protection
    and options for connection setup.'
  prefs: []
  type: TYPE_NORMAL
- en: The format for TCP messages (segments) is described fully in Tables [Table 48-1](ch48.html#tcp_segment_format
    "Table 48-1. TCP Segment Format") through [Table 48-3](ch48.html#tcp_segment_option_subfields
    "Table 48-3. TCP Segment Option Subfields") and illustrated in [Figure 48-1](ch48.html#tcp_segment_format-id001
    "Figure 48-1. TCP segment format").
  prefs: []
  type: TYPE_NORMAL
- en: Table 48-1. TCP Segment Format
  prefs: []
  type: TYPE_NORMAL
- en: '| Field Name | Size (Bytes) | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Source Port | 2 | This is the 16-bit port number of the process that originated
    the TCP segment on the source device. This will normally be an ephemeral (client)
    port number for a request sent by a client to a server, or a well-known/registered
    (server) port number for a reply from a server to a client. |'
  prefs: []
  type: TYPE_TB
- en: '| Destination Port | 2 | This is the 16-bit port number of the process that
    is the ultimate intended recipient of the message on the destination device. This
    will usually be a well-known/registered (server) port number for a client request,
    or an ephemeral (client) port number for a server reply. |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence Number | 4 | For normal transmissions, this is the sequence number
    of the first byte of data in this segment. In a connection request (SYN) message,
    this carries the ISN of the source TCP. The first byte of data will be given the
    next sequence number after the contents of this field, as described in [Chapter 47](ch47.html
    "Chapter 47. TCP BASIC OPERATION: CONNECTION ESTABLISHMENT, MANAGEMENT, AND TERMINATION").
    |'
  prefs: []
  type: TYPE_TB
- en: '| Acknowledgment Number | 4 | When the ACK bit is set, this segment is serving
    as an acknowledgment (in addition to other possible duties), and this field contains
    the sequence number the source is next expecting the destination to send. See
    the "TCP Sliding Window Data Transfer and Acknowledgment Mechanics" section later
    in this chapter for details. |'
  prefs: []
  type: TYPE_TB
- en: '| Data Offset | 1/2 (4 bits) | This specifies the number of 32-bit words of
    data in the TCP header. In other words, this value times four equals the number
    of bytes in the header, which must always be a multiple of four. It is called
    a data offset since it indicates by how many 32-bit words the start of the data
    is offset from the beginning of the TCP segment. |'
  prefs: []
  type: TYPE_TB
- en: '| Reserved | 3/4 (6 bits) | This field is 6 bits reserved for future use; sent
    as zero. |'
  prefs: []
  type: TYPE_TB
- en: '| Control Bits | 3/4 (6 bits) | TCP does not use a separate format for control
    messages. Instead, certain bits are set to indicate the communication of control
    information. The 6 bits are described in [Table 48-2](ch48.html#tcp_segment_control_bits
    "Table 48-2. TCP Segment Control Bits"). |'
  prefs: []
  type: TYPE_TB
- en: '| Window | 2 | This indicates the number of octets of data the sender of this
    segment is willing to accept from the receiver at one time. This normally corresponds
    to the current size of the buffer allocated to accept data for this connection.
    In other words, this field is the current receive window size for the device sending
    this segment, which is also the send window for the recipient of the segment.
    See the "TCP Sliding Window Data Transfer and Acknowledgment Mechanics" section
    later in this chapter for details. |'
  prefs: []
  type: TYPE_TB
- en: '| Checksum | 2 | This is a 16-bit checksum for data integrity protection, computed
    over the entire TCP datagram, plus a special pseudo header of fields. It is used
    to protect the entire TCP segment against errors in transmission as well as errors
    in delivery. Optional alternate checksum methods are also supported. |'
  prefs: []
  type: TYPE_TB
- en: '| Urgent Pointer | 2 | This is used in conjunction with the URG control bit
    for priority data transfer (see [Table 48-2](ch48.html#tcp_segment_control_bits
    "Table 48-2. TCP Segment Control Bits")). This field contains the sequence number
    of the last byte of urgent data. See the "TCP Priority Data Transfer: Urgent Function"
    section later in this chapter for details. |'
  prefs: []
  type: TYPE_TB
- en: '| Options | Variable | TCP includes a generic mechanism for including one or
    more sets of optional data in a TCP segment. Each of the options can be either
    one byte in length or variable in length. The first byte is the Option-Kind subfield,
    and its value specifies the type of option, which in turn indicates whether the
    option is just a single byte or multiple bytes. Options that are many bytes consist
    of three fields, which are described in [Table 48-3](ch48.html#tcp_segment_option_subfields
    "Table 48-3. TCP Segment Option Subfields"). |'
  prefs: []
  type: TYPE_TB
- en: '| Padding | Variable | If the Options field is not a multiple of 32 bits in
    length, enough zeros are added to pad the header so it is a multiple of 32 bits.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Data | Variable | This is the bytes of data being sent in the segment. |'
  prefs: []
  type: TYPE_TB
- en: Table 48-2. TCP Segment Control Bits
  prefs: []
  type: TYPE_NORMAL
- en: '| Subfield Name | Size (Bytes) | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| URG | 1/8 (1 bit) | Urgent bit: When set to 1, indicates that the priority
    data transfer feature has been invoked for this segment, and that the Urgent Pointer
    field is valid. |'
  prefs: []
  type: TYPE_TB
- en: '| ACK | 1/8 (1 bit) | Acknowledgment bit: When set to 1, indicates that this
    segment is carrying an acknowledgment, and the value of the Acknowledgment Number
    field is valid and carrying the next sequence expected from the destination of
    this segment. |'
  prefs: []
  type: TYPE_TB
- en: '| PSH | 1/8 (1 bit) | Push bit: The sender of this segment is using the TCP
    push feature, requesting that the data in this segment be immediately pushed to
    the application on the receiving device. |'
  prefs: []
  type: TYPE_TB
- en: '| RST | 1/8 (1 bit) | Reset bit: The sender has encountered a problem and wants
    to reset the connection. |'
  prefs: []
  type: TYPE_TB
- en: '| SYN | 1/8 (1 bit) | Synchronize bit: This segment is a request to synchronize
    sequence numbers and establish a connection; the Sequence Number field (see [Table 48-1](ch48.html#tcp_segment_format
    "Table 48-1. TCP Segment Format")) contains the ISN of the sender of the segment.
    |'
  prefs: []
  type: TYPE_TB
- en: '| FIN | 1/8 (1 bit) | Finish bit: The sender of the segment is requesting that
    the connection be closed. |'
  prefs: []
  type: TYPE_TB
- en: '![TCP segment format](httpatomoreillycomsourcenostarchimages288117.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-1. TCP segment format
  prefs: []
  type: TYPE_NORMAL
- en: Table 48-3. TCP Segment Option Subfields
  prefs: []
  type: TYPE_NORMAL
- en: '| Subfield Name | Size (Bytes) | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Option-Kind | 1 | This specifies the option type. |'
  prefs: []
  type: TYPE_TB
- en: '| Option-Length | 1 | This is the length of the entire option in bytes, including
    the Option-Kind and Option-Length fields. |'
  prefs: []
  type: TYPE_TB
- en: '| Option-Data | Variable | This field contains the option data itself. In at
    least one oddball case, this field is omitted (making Option-Length equal to 2).
    |'
  prefs: []
  type: TYPE_TB
- en: '[Table 48-4](ch48.html#some_tcp_options "Table 48-4. Some TCP Options") shows
    the main options currently defined for TCP'
  prefs: []
  type: TYPE_NORMAL
- en: Table 48-4. Some TCP Options
  prefs: []
  type: TYPE_NORMAL
- en: '| Option-Kind | Option-Length | Option-Data | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | — | — | End of Option List: A single-byte option that marks the end of
    all options included in this segment. This needs to be included only when the
    end of the options doesn''t coincide with the end of the TCP header. |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | — | — | No-Operation: A "spacer" that can be included between options
    to align a subsequent option on a 32-bit boundary if needed. |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | Maximum Segment Size Value | Maximum Segment Size: Conveys the size
    of the largest segment the sender of the segment wishes to receive. Used only
    in connection request (SYN) messages. |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 3 | Window Size Shift Bits | Window Scale: Implements the optional window
    scale feature, which allows devices to specify much larger window sizes than would
    be possible with the normal Window field. The value in Option-Data specifies the
    power of 2 that the Window field should be multiplied by to get the true window
    size the sender of the option is using. For example, if the value of Option-Data
    is 3, this means values in the Window field should be multiplied by 8, assuming
    both devices agree to use this feature. This allows very large windows to be advertised
    when needed on high-performance links. See the "TCP Sliding Window Data Transfer
    and Acknowledgment Mechanics" section later in this chapter for details. |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 2 | — | Selective Acknowledgment Permitted: Specifies that this device
    supports the selective acknowledgment (SACK) feature. This was implemented as
    a 2-byte option with no Option-Data field, instead of a single-byte option like
    End of Option List or No-Operation. This was necessary because it was defined
    after the original TCP specification, so an explicit option length needed to be
    indicated for backward compatibility. |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Variable | Blocks of Data Selectively Acknowledged | Selective Acknowledgment:
    Allows devices supporting the optional selective acknowledgment feature to specify
    noncontiguous blocks of data that have been received so they are not retransmitted
    if intervening segments do not show up and need to be retransmitted. |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 3 | Alternate Checksum Algorithm | Alternate Checksum Request: Lets
    a device request that a checksum-generation algorithm other than the standard
    TCP algorithm be used for this connection. Both devices must agree to the algorithm
    for it to be used. |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | Variable | Alternate Checksum | Alternate Checksum: If the checksum
    value needed to implement an alternate checksum is too large to fit in the standard
    16-bit Checksum field, it is placed in this option. |'
  prefs: []
  type: TYPE_TB
- en: The table does not include every TCP option; it just shows the basic ones defined
    in RFC 793 and a few others that are interesting and correspond to features described
    elsewhere in this book. Note that most options are sent only in connection request
    (SYN) segments. This includes the Maximum Segment Size, Window Scale, Selective
    Acknowledgment Permitted, and Alternate Checksum Request options. In contrast,
    the Selective Acknowledgment and Alternate Checksum options appear in regular
    data segments when they are used.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Checksum Calculation and the TCP Pseudo Header
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TCP is designed to provide reliable data transfer between a pair of devices
    on an IP internetwork. Much of the effort required to ensure reliable delivery
    of data segments is focused on the problem of ensuring that data is not lost in
    transit. But there''s another important critical impediment to the safe transmission
    of data: the risk of *errors* being introduced into a TCP segment during its travel
    across the internetwork.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Transmission Errors Using Checksums
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If the data gets where it needs to go but is corrupted, and we do not detect
    the corruption, this is in some ways worse than it never showing up at all. To
    provide basic protection against errors in transmission, TCP includes a 16-bit
    Checksum field in its header. The idea behind a checksum is very straightforward:
    Take a string of data bytes and add them all together, then send this sum with
    the data stream and have the receiver check the sum. In TCP, the device sending
    the segment uses a special algorithm to calculate this checksum. The recipient
    then employs the same algorithm to check the data it received and ensure that
    there were no errors.'
  prefs: []
  type: TYPE_NORMAL
- en: The checksum calculation used by TCP is a bit different than a regular checksum
    algorithm. A conventional checksum is performed over all the bytes that the checksum
    is intended to protect, and it can detect most bit errors in any of those fields.
    The designers of TCP wanted this bit-error protection, but they also wanted protection
    against other types of problems. To this end, a change was made in how the TCP
    checksum is computed. This special TCP checksum algorithm was eventually also
    adopted for use by UDP; see [Chapter 44](ch44.html "Chapter 44. TCP/IP USER DATAGRAM
    PROTOCOL (UDP)").
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing the Scope of Detected Errors: The TCP Pseudo Header'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of computing the checksum over only the actual data fields of the TCP
    segment, a 12-byte TCP *pseudo header* is created prior to checksum calculation.
    This header contains important information taken from fields in both the TCP header
    and the Internet Protocol (IP) datagram into which the TCP segment will be encapsulated
    (see [Chapter 21](ch21.html "Chapter 21. INTERNET PROTOCOL DATAGRAM ENCAPSULATION
    AND FORMATTING") for a description of the IP datagram format). The TCP pseudo
    header has the format described in [Table 48-5](ch48s02.html#tcp_pseudo_header_for_checksum_calculati
    "Table 48-5. TCP Pseudo Header for Checksum Calculations") and illustrated in
    [Figure 48-2](ch48s02.html#tcp_pseudo_header_for_checksum_cal-id001 "Figure 48-2. TCP
    pseudo header for checksum calculation").
  prefs: []
  type: TYPE_NORMAL
- en: Table 48-5. TCP Pseudo Header for Checksum Calculations
  prefs: []
  type: TYPE_NORMAL
- en: '| Field Name | Size (Bytes) | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Source Address | 4 | This is the 32-bit IP address of the originator of the
    datagram, taken from the IP header. |'
  prefs: []
  type: TYPE_TB
- en: '| Destination Address | 4 | This is the 32-bit IP address of the intended recipient
    of the datagram, also from the IP header. |'
  prefs: []
  type: TYPE_TB
- en: '| Reserved | 1 | This consists of 8 bits of zeros. |'
  prefs: []
  type: TYPE_TB
- en: '| Protocol | 1 | This is the Protocol field from the IP header. This indicates
    the higher-layer protocol that is carried in the IP datagram. Of course, we already
    know that this protocol is TCP. So, this field will normally have the value 6.
    |'
  prefs: []
  type: TYPE_TB
- en: '| TCP Length | 2 | This is the length of the TCP segment, including both header
    and data. Note that this is not a specific field in the TCP header; it is computed.
    |'
  prefs: []
  type: TYPE_TB
- en: '![TCP pseudo header for checksum calculation](httpatomoreillycomsourcenostarchimages288119.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-2. TCP pseudo header for checksum calculation
  prefs: []
  type: TYPE_NORMAL
- en: Once this 96-bit header has been formed, it is placed in a buffer, followed
    by the TCP segment itself. Then the checksum is computed over the entire set of
    data (pseudo header plus TCP segment). The value of the checksum is placed in
    the Checksum field of the TCP header, and the pseudo header is discarded; it is
    *not* an actual part of the TCP segment and is not transmitted. This process is
    illustrated in [Figure 48-3](ch48s02.html#tcp_header_checksum_calculation_to_calcu
    "Figure 48-3. TCP header checksum calculation To calculate the TCP segment header's
    Checksum field, the TCP pseudo header is first constructed and placed, logically,
    before the TCP segment. The checksum is then calculated over both the pseudo header
    and the TCP segment. The pseudo header is then discarded.").
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Checksum field is itself part of the TCP header and thus one of the fields
    over which the checksum is calculated, creating a "chicken-and-egg" situation
    of sorts. This field is assumed to be all zeros during calculation of the checksum.
  prefs: []
  type: TYPE_NORMAL
- en: When the TCP segment arrives at its destination, the receiving TCP software
    performs the same calculation. It forms the pseudo header, prepends it to the
    actual TCP segment, and then performs the checksum (setting the Checksum field
    to zero for the calculation as before). If there is a mismatch between its calculation
    and the value the source device put in the Checksum field, this indicates that
    an error of some sort occurred, and the segment is normally discarded.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP header checksum calculation To calculate the TCP segment header''s Checksum
    field, the TCP pseudo header is first constructed and placed, logically, before
    the TCP segment. The checksum is then calculated over both the pseudo header and
    the TCP segment. The pseudo header is then discarded.](httpatomoreillycomsourcenostarchimages288121.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-3. TCP header checksum calculation To calculate the TCP segment header's
    Checksum field, the TCP pseudo header is first constructed and placed, logically,
    before the TCP segment. The checksum is then calculated over both the pseudo header
    and the TCP segment. The pseudo header is then discarded.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of the Pseudo Header Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, why bother with this pseudo header? The source and destination devices
    both compute the checksum using the fields in this pseudo header. This means that
    if, for any reason, the two devices don''t use the same values for the pseudo
    header, the checksum will fail. When we consider what''s in the header, we find
    that this means the checksum now protects against not just errors in the TCP segment
    fields, but also against the following problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incorrect Segment Delivery** If there is a mismatch in the Destination Address
    between what the source specified and what the destination that received the segment
    used, the checksum will fail. The same will happen if the Source Address does
    not match.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incorrect Protocol** If a datagram is routed to TCP that actually belongs
    to a different protocol for whatever reason, this can be immediately detected.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incorrect Segment Length** If part of the TCP segment has been omitted by
    accident, the lengths the source and destination used won''t match, and the checksum
    will fail.'
  prefs: []
  type: TYPE_NORMAL
- en: What's clever about the pseudo header is that by using it for the checksum calculation,
    we can provide this protection without actually needing to send the fields in
    the pseudo header itself. This eliminates duplicating the IP fields used in the
    pseudo header within the TCP header, which would be redundant and wasteful of
    bandwidth. The drawback of the pseudo header method is that it makes checksum
    calculation take more time and effort (though this is not much of an issue today).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP checksums are computed over not just the TCP segment, but
    also over a TCP *pseudo header* that contains the length of the TCP segment as
    well as the IP Source Address, Destination Address, and Protocol fields. Since
    these fields are part of the checksum, if the segment is received by the wrong
    device or has the incorrect Protocol field or segment length, it will be rejected.
    The technique is clever because the checksum can provide this protection, even
    though the pseudo header itself is not actually transmitted.'
  prefs: []
  type: TYPE_NORMAL
- en: In the context of today's modern, high-speed, highly reliable networks, the
    use of the pseudo header sometimes seems archaic. How likely is it that a datagram
    will be delivered to the wrong address? Not very. At the time TCP was created,
    however, there was significant concern that there might not be proper end-to-end
    checking of the delivery of datagrams at the IP level. Including IP information
    in the TCP checksum was seen as a useful additional level of protection.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is one interesting implication of the TCP pseudo header: It violates
    the architectural layering principles that the designers of TCP sought to respect
    in splitting up TCP and IP. For the checksum, TCP must know IP information that
    technically it shouldn''t know. TCP checksum calculation requires, for example,
    that the protocol number from the IP header be given to the TCP layer on the receiving
    device from the IP datagram that carried the segment. The TCP pseudo header is
    a good example of a case where strict layering was eschewed in favor of practicality.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP also supports an optional method of having two devices agree on an alternative
    checksum algorithm. This must be negotiated during connection establishment.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Maximum Segment Size (MSS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TCP *segments* are the messages that carry data between TCP devices. The Data
    field is where the actual data being transmitted is carried, and since the length
    of the Data field in TCP is variable, this raises an interesting question: How
    much data should we put into each segment? TCP accepts data as a constant stream
    from the applications that use it, which means that it must decide how many bytes
    to put into each message that it sends.'
  prefs: []
  type: TYPE_NORMAL
- en: A primary determinant of how much data to send in a segment is the current status
    of the sliding window mechanism on the part of the receiver. When Device A receives
    a TCP segment from Device B, it examines the value of the Window field to know
    the limit on how much data Device B is allowing Device A to send in its next segment.
    (This process is described in the "TCP Sliding Window Data Transfer and Acknowledgment
    Mechanics" section later in this chapter.) There are also important issues in
    the selection and adjustment of window size that impact the operation of the TCP
    system as a whole, which are discussed in [Chapter 46](ch46.html "Chapter 46. TRANSMISSION
    CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION").
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the dictates of the current window size, each TCP device also
    has associated with it a *ceiling* on TCP size—a segment size that will never
    be exceeded, regardless of how large the current window is. This is called the
    *maximum segment size (MSS)*. When deciding how much data to put into a segment,
    each device in the TCP connection will choose the amount based on the current
    window size, in conjunction with the various algorithms described in [Chapter 46](ch46.html
    "Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION"),
    but it will never be so large that the amount of data exceeds the MSS of the device
    to which it is sending.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The name maximum segment size is misleading. The value actually refers to the
    maximum amount of data that a segment can hold. It does not include the TCP headers.
    So if the MSS is 100, the actual maximum segment size could be 120 (for a regular
    TCP header) or larger (if the segment includes TCP options).
  prefs: []
  type: TYPE_NORMAL
- en: MSS Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The selection of the MSS is based on the need to balance various competing performance
    and implementation issues in the transmission of data on TCP/IP networks. The
    main TCP standard, RFC 793, doesn't say much about MSS, so there was potential
    for confusion about how the parameter should be used. RFC 879 was published a
    couple of years after the TCP standard to clarify this parameter and the issues
    surrounding it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some issues with the MSS are fairly mundane; for example, certain devices are
    limited in the amount of space they have for buffers to hold TCP segments, and
    therefore may wish to limit segment size to a relatively small value. In general,
    though, the MSS must be chosen by balancing two competing performance issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overhead Management** The TCP header takes up 20 bytes of data (or more if
    options are used); the IP header also uses 20 or more bytes. This means that between
    them, a minimum of 40 bytes is needed for headers, and all of that is nondata
    overhead. If we set the MSS too low, this results in very inefficient use of bandwidth.
    For example, if we set it to 40 bytes, a *maximum* of 50 percent of each segment
    could actually be data; the rest would just be headers. Many segment datagrams
    would be even worse in terms of efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: '**IP Fragmentation** TCP segments will be packaged into IP datagrams. As you
    saw in [Chapter 22](ch22.html "Chapter 22. IP DATAGRAM SIZE, FRAGMENTATION, AND
    REASSEMBLY"), datagrams have their own size limit issues: the matter of the maximum
    transmission unit (MTU) of an underlying network. If a TCP segment is too large,
    it will lead to an IP datagram that is too large to be sent without fragmentation.
    Fragmentation reduces efficiency and increases the chances of part of a TCP segment
    being lost, resulting in the entire segment needing to be retransmitted.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Default MSS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The solution to the two competing issues of overhead management and IP fragmentation
    was to establish a default MSS for TCP that was as large as possible, while avoiding
    fragmentation for most transmitted segments. This was computed by starting with
    the minimum MTU for IP networks of 576 bytes. All networks are required to be
    able to handle an IP datagram of this size without fragmenting. From this number,
    we subtract 20 bytes for the TCP header and 20 bytes for the IP header, leaving
    536 bytes. This is the standard MSS for TCP.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT**TCP is designed to restrict the size of the segments it sends
    to a certain maximum limit, to reduce the likelihood that segments will need to
    be fragmented for transmission at the IP level. The TCP *maximum segment size
    (MSS)* specifies the maximum number of bytes in the TCP segment''s Data field,
    regardless of any other factors that influence segment size. The default MSS for
    TCP is 536 bytes, which is calculated by starting with the minimum IP MTU of 576
    bytes and subtracting 20 bytes each for the IP and TCP headers.'
  prefs: []
  type: TYPE_NORMAL
- en: The selection of this MSS value was a compromise of sorts. It means that most
    TCP segments will be sent unfragmented across an IP internetwork. However, if
    any TCP or IP options are used, the minimum MTU of 576 bytes will be exceeded,
    and fragmentation will occur. Still, it makes more sense to allow some segments
    to be fragmented, rather than use a much smaller MSS to ensure that none are ever
    fragmented. If we chose, say, an MSS of 400 bytes, we would probably never have
    fragmentation, but we would lower the data/header ratio from 536:40 (93 percent
    data) to 400:40 (91 percent data) for all segments.
  prefs: []
  type: TYPE_NORMAL
- en: Nondefault MSS Value Specification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Naturally, there will be cases where the default MSS is not ideal. TCP provides
    a means for a device to specify that the MSS it wants to use is either smaller
    or larger than the default value of 536 bytes. A device can inform the other device
    of the MSS it wants to use through parameter exchange during the connection establishment
    process. A device that chooses to do so includes in its SYN message the TCP option
    called, appropriately, Maximum Segment Size. The other device receives this option
    and records the MSS for the connection. Each device can specify the MSS it wants
    for the segments it receives independently.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The exchange of MSS values during setup is sometimes called MSS negotiation.
    This is actually a misleading term, because it implies that the two devices must
    agree on a common MSS value, which is not the case. The MSS value used by each
    may be different, and there is no negotiation at all.
  prefs: []
  type: TYPE_NORMAL
- en: Devices may wish to use a larger MSS if they know that the MTUs of the networks
    the segments will pass over are larger than the IP minimum of 576 bytes. This
    is most commonly the case when large amounts of data are sent on a local network.
    The process of MTU path discovery, as described in [Chapter 22](ch22.html "Chapter 22. IP
    DATAGRAM SIZE, FRAGMENTATION, AND REASSEMBLY"), is used to determine the appropriate
    MSS. Devices might use a smaller MSS if they know that TCP segments use a particular
    optional feature that would consistently increase the size of the IP header, such
    as when the segments employ IPsec for security (see [Chapter 29](ch29.html "Chapter 29. IP
    SECURITY (IPSEC) PROTOCOLS")).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Devices can indicate that they wish to use a different MSS
    value from the default by including a Maximum Segment Size option in the SYN message
    they use to establish a connection. Each device in the connection may use a different
    MSS value.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Sliding Window Data Transfer and Acknowledgment Mechanics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TCP connection establishment process is employed by a pair of devices to
    create a TCP connection between them. Once all the setup is done—transmission
    control blocks (TCBs) have been set up, parameters have been exchanged, and so
    forth—the devices are ready to get down to the business of transferring data.
  prefs: []
  type: TYPE_NORMAL
- en: The sending of data between TCP devices on a connection is accomplished using
    the sliding window system we explored in [Chapter 46](ch46.html "Chapter 46. TRANSMISSION
    CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION"). Here, we will take
    a more detailed look at exactly how sliding windows are implemented to allow data
    to be sent and received. For ease of explanation, we'll assume that our connection
    is between a client and a server—this is easier than the whole "Device A/Device
    B" business.
  prefs: []
  type: TYPE_NORMAL
- en: Sliding Window Transmit and Receive Categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each of the two devices on a connection must keep track of the data it is sending,
    as well as the data it is receiving from the other device. This is done by conceptually
    dividing the bytes into *categories*. For data being transmitted, there are four
    transmit categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transmit Category 1** Bytes sent and acknowledged'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transmit Category 2** Bytes sent but not yet acknowledged'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transmit Category 3** Bytes not yet sent for which recipient is ready'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transmit Category 4** Bytes not yet sent for which recipient is not ready'
  prefs: []
  type: TYPE_NORMAL
- en: 'For data being received, there is no need to separate into "received and acknowledged"
    and "received and unacknowledged," the way the transmitter separates its first
    two categories into "sent and acknowledged" and "sent but not yet acknowledged."
    The reason is that the transmitter must wait for acknowledgment of each transmission,
    but the receiver doesn''t need acknowledgment that it received something. Thus,
    one receive category corresponds to Transmit Categories 1 and 2, while the other
    two correspond to Transmit Category 3 and Transmit Category 4, respectively, for
    a total of three receive categories. To help make more clear how the categories
    relate, I number them as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receive Category 1+2** Bytes received and acknowledged. This is the receiver''s
    complement to Transmit Categories 1 and 2.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receive Category 3** Bytes not yet received for which recipient is ready.
    This is the receiver''s complement to Transmit Category 3.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receive Category 4** Bytes not yet received for which recipient is not ready.
    This is the receiver''s complement to Transmit Category 4.'
  prefs: []
  type: TYPE_NORMAL
- en: Send (SND) and Receive (RCV) Pointers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Both the client and server must keep track of both streams being sent over the
    connection. This is done using a set of special variables called *pointers*, which
    carve the byte stream into the categories described in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The four transmit categories are divided using three send (SND) pointers. Two
    of the pointers are absolute (refer to a specific sequence number), and one is
    an offset that is added to one of the absolute pointers, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Send Unacknowledged (SND.UNA)** The sequence number of the first byte of
    data that has been sent but not yet acknowledged. This marks the first byte of
    Transmit Category 2; all previous sequence numbers refer to bytes in Transmit
    Category 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Send Next (SND.NXT)** The sequence number of the next byte of data to be
    sent to the other device (the server, in this case). This marks the first byte
    of Transmit Category 3.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Send Window (SND.WND)** The size of the send window. Recall that the window
    specifies the total number of bytes that any device may have outstanding *(unacknowledged)*
    at any one time. Thus, adding the sequence number of the first unacknowledged
    byte (SND.UNA) and the send window (SND.WND) marks the first byte of Transmit
    Category 4.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another way of looking at these pointers is how they indicate the number of
    bytes a transmitting device can send at any point in time—that is, the number
    of bytes in Transmit Category 3\. The start of Transmit Category 3 is marked by
    SND.NXT. The end is marked by the first byte of Transmit Category 4, given by
    SND.UNA+SND.WND. Thus, the number of bytes in Transmit Category 3 is given by
    the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: SND.UNA + SND.WND - SND.NXT
  prefs: []
  type: TYPE_NORMAL
- en: This is called the *usable window*, since it indicates how many bytes the transmitter
    can use at any point in time. When data is acknowledged, this causes bytes to
    move from Transmit Category 2 to Transmit Category 1, by increasing the value
    of SND.UNA. Assuming that the send window size doesn't change, this causes the
    window to *slide* to the right, permitting more data to be sent. [Figure 48-4](ch48s04.html#tcp_transmission_categories_send_window_
    "Figure 48-4. TCP transmission categories, send window, and pointers This diagram
    is the same as Figure 46-6 (in Chapter 46), but shows the TCP send pointers. SND.UNA
    points to the start of Transmit Category 2, SND.NXT points to the start of Transmit
    Category 3, and SND.WND is the size of the send window. The size of the usable
    window (the hatched rectangle) can be calculated as shown from those three pointers.")
    illustrates the SND pointers.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The TCP sliding windows scheme uses three pointers that keep
    track of which bytes are in each of the four transmit categories. SND.UNA points
    to the first unacknowledged byte and indicates the start of Transmit Category
    2; SND.NXT points to the next byte of data to be sent and marks the start of Transmit
    Category 3\. SND.WND contains the size of the send window; it is added to SND.NXT
    to mark the start of Transmit Category 4\. Adding SND.WND to SND.UNA and then
    subtracting SND.NXT yields the current size of the usable transmit window.'
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP transmission categories, send window, and pointers This diagram is the
    same as (in ), but shows the TCP send pointers. SND.UNA points to the start of
    Transmit Category 2, SND.NXT points to the start of Transmit Category 3, and SND.WND
    is the size of the send window. The size of the usable window (the hatched rectangle)
    can be calculated as shown from those three pointers.](httpatomoreillycomsourcenostarchimages288123.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-4. TCP transmission categories, send window, and pointers This diagram
    is the same as [Figure 46-6](ch46s02.html#tcp_transmission_stream_categories_and_s
    "Figure 46-6. TCP transmission stream categories and send window terminology This
    diagram shows the same categories as the ones in Figure 46-5, except that it shows
    the send window as well. The black box is the overall send window (categories
    2 and 3 combined); the light gray box represents the bytes already sent (category
    2), and the dark gray box is the usable window (category 3).") (in [Chapter 46](ch46.html
    "Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS AND GENERAL OPERATION")),
    but shows the TCP send pointers. SND.UNA points to the start of Transmit Category
    2, SND.NXT points to the start of Transmit Category 3, and SND.WND is the size
    of the send window. The size of the usable window (the hatched rectangle) can
    be calculated as shown from those three pointers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The three receive categories are divided using two pointers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receive Next (RCV.NXT)** The sequence number of the next byte of data that
    is expected from the other device. This marks the first byte in Receive Category
    3\. All previous sequence numbers refer to bytes already received and acknowledged,
    in Receive Categories 1 and 2.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Receive Window (RCV.WND)** The size of the receive window advertised to the
    other device. This refers to the number of bytes the device is willing to accept
    at one time from its peer, which is usually the size of the buffer allocated for
    receiving data for this connection. When added to the RCV.NXT pointer, this pointer
    marks the first byte of Receive Category 4.'
  prefs: []
  type: TYPE_NORMAL
- en: The receive categories and pointers are illustrated in [Figure 48-5](ch48s04.html#tcp_receive_categories_and_pointers_this
    "Figure 48-5. TCP receive categories and pointers This diagram is the complement
    of Figure 48-4, showing how the categories are set up for the receiving device.
    Categories 1 and 2 have been combined since there is no differentiation between
    "received and unacknowledged" and "received and acknowledged." This example shows
    the state of the receiving device prior to receipt of the 14 bytes that in Figure 48-4
    have already been sent.").
  prefs: []
  type: TYPE_NORMAL
- en: 'The SND and RCV pointers are complementary, just as the categories are, with
    each device managing both the sending of its data and receiving of data from its
    peer. Assuming we have a client and a server, the relationship between these pointers
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Client** The SND pointers keep track of the client''s outgoing data stream;
    the RCV pointers refer to the data coming in from the server. The client''s SND
    categories correspond to the server''s RCV categories.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Server** The SND pointers keep track of the server''s outgoing data stream;
    the RCV pointers refer to the data being received from the client. The server''s
    SND categories correspond to the client''s RCV categories.'
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP receive categories and pointers This diagram is the complement of , showing
    how the categories are set up for the receiving device. Categories 1 and 2 have
    been combined since there is no differentiation between "received and unacknowledged"
    and "received and acknowledged." This example shows the state of the receiving
    device prior to receipt of the 14 bytes that in have already been sent.](httpatomoreillycomsourcenostarchimages288125.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-5. TCP receive categories and pointers This diagram is the complement
    of [Figure 48-4](ch48s04.html#tcp_transmission_categories_send_window_ "Figure 48-4. TCP
    transmission categories, send window, and pointers This diagram is the same as
    Figure 46-6 (in Chapter 46), but shows the TCP send pointers. SND.UNA points to
    the start of Transmit Category 2, SND.NXT points to the start of Transmit Category
    3, and SND.WND is the size of the send window. The size of the usable window (the
    hatched rectangle) can be calculated as shown from those three pointers."), showing
    how the categories are set up for the receiving device. Categories 1 and 2 have
    been combined since there is no differentiation between "received and unacknowledged"
    and "received and acknowledged." This example shows the state of the receiving
    device prior to receipt of the 14 bytes that in [Figure 48-4](ch48s04.html#tcp_transmission_categories_send_window_
    "Figure 48-4. TCP transmission categories, send window, and pointers This diagram
    is the same as Figure 46-6 (in Chapter 46), but shows the TCP send pointers. SND.UNA
    points to the start of Transmit Category 2, SND.NXT points to the start of Transmit
    Category 3, and SND.WND is the size of the send window. The size of the usable
    window (the hatched rectangle) can be calculated as shown from those three pointers.")
    have already been sent.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A set of *receive (RCV) pointers* is maintained by each device.
    These receive pointers are the complement of the *send (SND) pointers*. A device''s
    send pointers keep track of its outgoing data, and its receive pointers keep track
    of the incoming data. The two receive pointers are RCV.NXT, which indicates the
    number of the next byte of data expected from the other device, and RCV.WND, which
    is the size of the receive window for that device. The RCV.WND of one device equals
    the SND.WND of the other device on the connection.'
  prefs: []
  type: TYPE_NORMAL
- en: Since the SND and RCV values are complementary, the send window of one device
    is the receive window of the other, and vice versa. Note, however, that the values
    of the pointers do not always match exactly on the two devices, because at any
    given time, some bytes may be in transit between the two. [Figure 48-5](ch48s04.html#tcp_receive_categories_and_pointers_this
    "Figure 48-5. TCP receive categories and pointers This diagram is the complement
    of Figure 48-4, showing how the categories are set up for the receiving device.
    Categories 1 and 2 have been combined since there is no differentiation between
    "received and unacknowledged" and "received and acknowledged." This example shows
    the state of the receiving device prior to receipt of the 14 bytes that in Figure 48-4
    have already been sent."), for example, shows the receive pointers of the recipient
    *prior* to receiving bytes 32 to 45, which are shown in transit in [Figure 48-4](ch48s04.html#tcp_transmission_categories_send_window_
    "Figure 48-4. TCP transmission categories, send window, and pointers This diagram
    is the same as Figure 46-6 (in Chapter 46), but shows the TCP send pointers. SND.UNA
    points to the start of Transmit Category 2, SND.NXT points to the start of Transmit
    Category 3, and SND.WND is the size of the send window. The size of the usable
    window (the hatched rectangle) can be calculated as shown from those three pointers.").
  prefs: []
  type: TYPE_NORMAL
- en: TCP Segment Fields Used to Exchange Pointer Information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Both SND and RCV pointers are maintained in the TCB for the connection held
    by each device. As data is exchanged, the pointers are updated, and information
    about the state of the send and receive streams is exchanged using control fields
    in the TCP segment format. The following are the three most important TCP segment
    fields used to exchange pointer information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sequence Number** Identifies the sequence number of the first byte of data
    in the segment being transmitted. This will normally be equal to the value of
    the SND.UNA pointer at the time that data is sent.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledgment Number** Acknowledges the receipt of data by specifying the
    sequence number that the sender of the segment expects in the segment recipient''s
    next transmission. This field will normally be equal to the RCV.NXT pointer of
    the device that sends it.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Window** The size of the receive window of the device sending the segment
    (and thus, the send window of the device receiving the segment).'
  prefs: []
  type: TYPE_NORMAL
- en: The Acknowledgment Number field is critical because a device uses this field
    to tell its peer which segments it has received. The system is *cumulative*. The
    Acknowledgment Number field says, "I have received all data bytes with sequence
    numbers less than this value." This means if a client receives many segments of
    data from a server in rapid succession, it can acknowledge all of them using a
    single number, as long as they are contiguous. If they are not contiguous, then
    things get more complicated; see "TCP Noncontiguous Acknowledgment Handling and
    Selective Acknowledgment (SACK)" in [Chapter 49](ch49.html "Chapter 49. TCP RELIABILITY
    AND FLOW CONTROL FEATURES").
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Three essential fields in the TCP segment format are used to
    implement the sliding windows system. The Sequence Number field indicates the
    number of the first byte of data being transmitted. The Acknowledgment Number
    is used to acknowledge data received by the device sending this segment. The Window
    field tells the recipient of the segment the size to which it should set its send
    window.'
  prefs: []
  type: TYPE_NORMAL
- en: An Example of TCP Sliding Window Mechanics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To see how all of this works, let's consider an example of a client and server
    using a mythical file-retrieval protocol. This protocol specifies that the client
    sends a request and receives an immediate response from the server. The server
    then sends the file requested when it is ready.
  prefs: []
  type: TYPE_NORMAL
- en: The two devices will first establish a connection and synchronize sequence numbers.
    For simplicity, let's say the client uses an ISN of 0, and the server uses an
    ISN of 240\. The server will send the client an ACK with an Acknowledgment Number
    of 1, indicating it is the sequence number it expects to receive next. Let's say
    the server's receive window size is set to 350, so this is the client's send window
    size. The client will send its ACK with an Acknowledgment Number of 241\. Let's
    say its receive window size is 200 (and the server's client window size is thus
    200). Let's assume that both devices maintain the same window size throughout
    the transaction. This won't normally happen, especially if the devices are busy,
    but the example is complicated enough. Let's also say the MSS is 536 bytes in
    both directions. This means that the MSS won't affect the size of actual segments
    in this example (since the MSS is larger than the send window sizes for both devices).
  prefs: []
  type: TYPE_NORMAL
- en: We'll follow a sample transaction to show how the send and receive pointers
    are created and changed as messages are exchanged between client and server. [Table 48-6](ch48s04.html#tcp_transaction_example_with_send_and_re
    "Table 48-6. TCP Transaction Example with Send and Receive Pointers") describes
    the process in detail, showing for each step what the send and receive pointers
    are for both devices. It is rather large, so beware. The transaction is also graphically
    illustrated in Figures [Figure 48-6](ch48s04.html#tcp_transaction_example_showing_the_serv
    "Figure 48-6. TCP transaction example showing the server's send pointers The transaction
    of Table 48-6 from the perspective of the server. See Figure 48-7 for the client's
    pointers.") and [Figure 48-7](ch48s04.html#tcp_transaction_example_showing_clients_
    "Figure 48-7. TCP transaction example showing client's send pointers The transaction
    of Table 48-6 from the perspective of the client. See Figure 48-6 for the server's
    pointers."). Both illustrate the same exchange of messages, using the step numbers
    of [Table 48-6](ch48s04.html#tcp_transaction_example_with_send_and_re "Table 48-6. TCP
    Transaction Example with Send and Receive Pointers"), but from the perspective
    of one of the devices. [Figure 48-6](ch48s04.html#tcp_transaction_example_showing_the_serv
    "Figure 48-6. TCP transaction example showing the server's send pointers The transaction
    of Table 48-6 from the perspective of the server. See Figure 48-7 for the client's
    pointers.") shows the server's send pointers and client's receive pointers. [Figure 48-7](ch48s04.html#tcp_transaction_example_showing_clients_
    "Figure 48-7. TCP transaction example showing client's send pointers The transaction
    of Table 48-6 from the perspective of the client. See Figure 48-6 for the server's
    pointers.") shows the client's send pointers and server's receive pointers. (I
    would have put them all in one diagram, but they wouldn't fit!)
  prefs: []
  type: TYPE_NORMAL
- en: Table 48-6. TCP Transaction Example with Send and Receive Pointers
  prefs: []
  type: TYPE_NORMAL
- en: '|   |   |   |   |   |   |   |   |   |   | Client | Server |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Process Step | SND.UNA | SND.NXT | SND.WND | RCV.NXT | RCV.WND | Process
    Step | SND.UNA | SND.NXT | SND.WND | RCV.NXT | RCV.WND |   |   |   |   |   |  
    |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | Description | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **(setup)** | 1 | 1 | 360 | 241 | 200 | **(setup)** | 241 | 241 | 200 | 1
    | 360 |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | During connection establishment,
    the client sets up its pointers based on the parameters exchanged during setup.
    Notice that the SND.UNA and SND.NXT values are the same. No data has been sent
    yet, so nothing is unacknowledged. RCV.NXT is the value of the first byte of data
    expected from the server. | The server sets up its pointers just as the client
    does. Notice how its values are the complement of the client''s. |'
  prefs: []
  type: TYPE_TB
- en: '| **1\. Send Request** | 1 | 141 | 360 | 241 | 200 | **(wait)** | 241 | 241
    | 200 | 1 | 360 |   |   |   |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client transmits a request to
    the server. Let''s say the request is 140 bytes in length. It will form a segment
    with a data field of this length and transmit it with the Sequence Number set
    to 1, the sequence number of the first byte. Once this data has been sent, the
    client''s SND.NXT pointer will be incremented to the value 141 to indicate this
    is the next data to be sent to the server. | The server does nothing, waiting
    for a request. |'
  prefs: []
  type: TYPE_TB
- en: '| **(wait)** | 1 | 141 | 360 | 241 | 200 | **2\. Receive Request, Send Ack
    & Reply** | 241 | 321 | 200 | 141 | 360 |   |   |   |   |   |   |   |   |   |
      |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | At this point, the client hasn''t
    received an acknowledgment for its request. At present, SND.UNA+SND.WND is 361,
    while SND.NXT is 141\. This means the current usable window is 220 bytes. The
    client could send up to 220 more bytes of data before getting back an acknowledgment.
    For now, let''s say it has nothing more to transmit. | The server receives the
    140-byte request from the client. The server sends back an 80-byte response that
    also acknowledges the client''s TCP segment. The Sequence Number field will be
    241, the first sequence number of the server''s 80 bytes of data. The Acknowledgment
    Number will be 141, telling the client that is the next sequence number the server
    expects to hear, and thereby implicitly acknowledging receipt of bytes 1 through
    140.The server increases its RCV.NXT pointer to 141 to reflect the 140 bytes of
    data received. It increases its SND.NXT pointer by 80. |'
  prefs: []
  type: TYPE_TB
- en: '| **3\. Receive Ack & Reply, Send Ack** | 141 | 141 | 360 | 321 | 200 | **4\.
    Send Part 1 of File** | 241 | 441 | 200 | 141 | 360 |   |   |   |   |   |   |
      |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client receives the server''s
    response. It sees the Acknowledgment Number of 141 and knows bytes 1 to 140 were
    successfully received. It increases its SND.UNA to 141, effectively "sliding the
    send window" by 140.The client also accepts the 80 bytes of data the server sent,
    increasing its RCV.NXT pointer by 80\. Assuming it has no more data to send, it
    sends back a TCP segment that is a pure acknowledgment of the server''s response.
    This segment has no data and an Acknowledgment Number value of 321. | While the
    client was receiving its response, the server''s TCP was supplied with a 280-byte
    file to be sent to the client. It cannot send all this in one segment, however.
    The current value of SND.UNA+SND.WND is 441, while SND.NXT is 321\. Thus, the
    server''s usable window contains 120 bytes of data. It creates a TCP segment with
    this much data and a Sequence Number of 321\. It increases the SND.NXT pointer
    to 441\. The server has now filled the send window.Note that the server does not
    need to wait for an acknowledgment to the reply it sent in step 2\. This is a
    key factor in TCP''s ability to ensure high throughput. |'
  prefs: []
  type: TYPE_TB
- en: '| **5\. Receive Part 1 of File, Send Ack** | 141 | 141 | 360 | 441 | 200 |
    **6\. Receive Ack for Reply** | 321 | 441 | 200 | 141 | 360 |   |   |   |   |
      |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client receives the first 120-byte
    part of the file the server was sending. It increases the RCV.NXT pointer to 441
    and sends an acknowledgment back with an Acknowledgment Number of 441\. Again,
    if it had another request to make of the server, it could include it here, but
    we''ll assume it does not. | The server receives the client''s acknowledgment
    of its earlier 80-byte response (sent in step 2). It increases its SND.UNA to
    321\. Since it just received acknowledgment of 80 bytes (and the client''s window
    didn''t change), the server''s usable window is now 80 bytes. However, as we will
    see in [Chapter 49](ch49.html "Chapter 49. TCP RELIABILITY AND FLOW CONTROL FEATURES"),
    sending small segments like this can lead to performance issues. Let''s say the
    server has been programmed to not send segments under 100 bytes when it has a
    lot of data to transmit. It decides to wait. |'
  prefs: []
  type: TYPE_TB
- en: '| **(wait)** | 141 | 141 | 360 | 441 | 200 | **7\. Receive Ack for Part 1 of
    File** | 441 | 441 | 200 | 141 | 360 |   |   |   |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client waits for the rest of
    the file. | The server receives the acknowledgment for the first part of the file.
    It increases SND.UNA to 441\. This now restores the full 200-byte window. |'
  prefs: []
  type: TYPE_TB
- en: '| **(still waiting?)** | 141 | 141 | 360 | 441 | 200 | **8\. Send Part 2 of
    File** | 441 | 601 | 200 | 141 | 360 |   |   |   |   |   |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client continues to wait for
    the rest of the file. | The server sends the remaining 160 bytes of data in the
    file in one segment. It increases SND.NXT by 160, and sends the data with a Sequence
    Number value of 441. |'
  prefs: []
  type: TYPE_TB
- en: '| **9\. Receive Part 2 of File, Send Ack** | 141 | 141 | 360 | 601 | 200 |
    **(wait)** | 441 | 601 | 200 | 141 | 360 |   |   |   |   |   |   |   |   |   |
      |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client receives the rest of the
    file and acknowledges it. It increases RCV.NXT to 601 and sends back a segment
    with an Acknowledgment Number of 601. | The server is done for now. It waits for
    the acknowledgment of the second part of the file. |'
  prefs: []
  type: TYPE_TB
- en: '| **(done)** | 141 | 141 | 360 | 601 | 200 | **10\. Receive Ack for Part 2
    of File** | 601 | 601 | 200 | 141 | 360 |   |   |   |   |   |   |   |   |   |
      |'
  prefs: []
  type: TYPE_TB
- en: '|   |   |   |   |   |   |   |   |   |   | The client is done with this exchange.
    | The server receives the second acknowledgment and slides its send window forward
    by 160 bytes. The transaction is now completed. |'
  prefs: []
  type: TYPE_TB
- en: '![TCP transaction example showing the server''s send pointers The transaction
    of from the perspective of the server. See for the client''s pointers.](httpatomoreillycomsourcenostarchimages288127.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-6. TCP transaction example showing the server's send pointers The
    transaction of [Table 48-6](ch48s04.html#tcp_transaction_example_with_send_and_re
    "Table 48-6. TCP Transaction Example with Send and Receive Pointers") from the
    perspective of the server. See [Figure 48-7](ch48s04.html#tcp_transaction_example_showing_clients_
    "Figure 48-7. TCP transaction example showing client's send pointers The transaction
    of Table 48-6 from the perspective of the client. See Figure 48-6 for the server's
    pointers.") for the client's pointers.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP transaction example showing client''s send pointers The transaction of
    from the perspective of the client. See for the server''s pointers.](httpatomoreillycomsourcenostarchimages288129.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 48-7. TCP transaction example showing client's send pointers The transaction
    of [Table 48-6](ch48s04.html#tcp_transaction_example_with_send_and_re "Table 48-6. TCP
    Transaction Example with Send and Receive Pointers") from the perspective of the
    client. See [Figure 48-6](ch48s04.html#tcp_transaction_example_showing_the_serv
    "Figure 48-6. TCP transaction example showing the server's send pointers The transaction
    of Table 48-6 from the perspective of the server. See Figure 48-7 for the client's
    pointers.") for the server's pointers.
  prefs: []
  type: TYPE_NORMAL
- en: Real-World Complications of the Sliding Window Mechanism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I''m sure the process outlined in the previous section seems rather complicated,
    but in fact, the example is highly *simplified*, to show you how the basic data
    transfer mechanism works without too much going on. Scary, isn''t it? A real-world
    connection would include several complications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overlapping Transmissions** I intentionally showed only one request from
    the client and the response from the server. In reality, the client and server
    could be pumping many requests and responses at each other in rapid-fire succession.
    The client would be acknowledging segments received from the server with segments
    that themselves contained new requests, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledgment of Multiple Segments** I also didn''t show a case where two
    segments are received by a device and acknowledged with a single acknowledgment,
    although this can certainly happen. Suppose that, in the example, the two parts
    of the 280-byte file were sent at once and received by the client at the same
    time. The client would acknowledge both by sending a single segment with an Acknowledgment
    Number of 601\. Remember that this field is a *cumulative* acknowledgment of all
    segments containing data through the number preceding it, so this would acknowledge
    all data up to byte 600.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fluctuating Window Sizes for Flow Control** The window sizes in the example
    remained constant, but in a real connection, this will not always be the case.
    A very busy server may not be able to process and remove data from its buffer
    as fast as it acknowledges it. It may need to shrink its receive window to reduce
    the amount of data the client sends it, and then increase the window when more
    space becomes available. This is how TCP implements flow control, as you will
    see in the next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lost Transmissions** In a real connection, some transmitted segments will
    be lost and need to be retransmitted. This is handled by TCP''s retransmission
    scheme (described in [Chapter 49](ch49.html "Chapter 49. TCP RELIABILITY AND FLOW
    CONTROL FEATURES")).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Avoiding Small Window Problems** I hinted in the description of the example
    that we don''t necessarily always want to send data as fast as we can, to avoid
    sending a very small segment. The reason is that this can lead to performance
    degradation, including a phenomenon called *silly window syndrome*. This will
    also be explored in the next chapter, where we will see how handling it requires
    that we change the simple sliding windows scheme we examined so far.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Congestion Handling and Avoidance** The basic sliding window mechanism has
    been changed over the years to avoid having TCP connections cause internetwork
    congestion and to have them handle congestion when it is detected. Congestion
    issues are discussed, as you may have guessed, in the next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP Immediate Data Transfer: Push Function'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fact that TCP takes incoming data from a process as an unstructured stream
    of bytes gives it great flexibility in meeting the needs of most applications.
    There is no need for an application to create blocks or messages; it just sends
    the data to TCP when it is ready for transmission. For its part, TCP has no knowledge
    or interest in the meaning of the bytes of data in this stream. They are just
    bytes, and TCP sends them without any real concern for their structure or purpose.
  prefs: []
  type: TYPE_NORMAL
- en: This has a couple of interesting effects on how applications work. One is that
    TCP does not provide any natural indication of the dividing point between pieces
    of data, such as database records or files. The application must take care of
    this. Another result of TCP's byte orientation is that TCP cannot decide when
    to form a segment and send bytes between devices based on the contents of the
    data. TCP will generally accumulate data sent to it by an application process
    in a buffer. It chooses when and how to send data based solely on the sliding
    window system discussed in the previous section, in combination with logic that
    helps to ensure efficient operation of the protocol.
  prefs: []
  type: TYPE_NORMAL
- en: This means that while an application can control the rate and timing with which
    it sends data to TCP, it cannot inherently control the timing with which TCP itself
    sends the data over the internetwork. Now, if we are sending a large file, for
    example, this isn't a big problem. As long as we keep sending data, TCP will keep
    forwarding it over the internetwork. It's generally fine in such a case to let
    TCP fill its internal transmit buffer with data and form a segment to be sent
    when TCP feels it is appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are situations where letting TCP accumulate data before transmitting
    it can cause serious application problems. The classic example of this is an interactive
    application such as the Telnet protocol (see [Chapter 87](ch87.html "Chapter 87. TCP/IP
    INTERACTIVE AND REMOTE APPLICATION PROTOCOLS")). When you are using such a program,
    you want each keystroke to be sent immediately to the other application; you don't
    want TCP to accumulate hundreds of keystrokes and then send them all at once.
    The latter may be more efficient, but it makes the application unusable, which
    is really putting the cart before the horse.
  prefs: []
  type: TYPE_NORMAL
- en: Even with a more mundane protocol that transfers files, there are many situations
    in which we need to say, "Send the data *now*." For example, many protocols begin
    with a client sending a request to a server—like the hypothetical one in the preceding
    example or a request for a web page sent by a web browser. In that case, we want
    the client's request sent immediately; we don't want to wait until enough requests
    have been accumulated by TCP to fill an optimal-sized segment.
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, the designers of TCP realized that we needed a way to handle these
    situations. When an application has data that it needs to have sent across the
    internetwork immediately, it sends the data to TCP, and then uses the TCP *push*
    function. This tells the sending TCP to immediately "push" all the data it has
    to the recipient's TCP as soon as it is able to do so, without waiting for more
    data.
  prefs: []
  type: TYPE_NORMAL
- en: When this function is invoked, TCP will create a segment (or segments) that
    contains all the data it has outstanding and then transmit it with the PSH control
    bit set to 1\. The destination device's TCP software, seeing this bit sent, will
    know that it should not just take the data in the segment it received and buffer
    it, but rather push it through directly to the application.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP includes a special *push* function to handle cases where
    data given to TCP needs to be sent immediately. An application can send data to
    its TCP software and indicate that it should be pushed. The segment will be sent
    right away rather than being buffered. The pushed segment''s PSH control bit will
    be set to 1 to tell the receiving TCP that it should immediately pass the data
    up to the receiving application.'
  prefs: []
  type: TYPE_NORMAL
- en: It's important to realize that the push function only forces immediate delivery
    of data. It does not change the fact that TCP provides no boundaries between data
    elements. It may seem that an application could send one record of data and then
    push it to the recipient, then send the second record and push that, and so on.
    However, the application cannot assume that because it sets the PSH bit for each
    piece of data it gives to TCP, each piece of data will be in a single segment.
    It is possible that the first push may contain data given to TCP earlier that
    wasn't yet transmitted, and it's also possible that two records pushed in this
    manner may end up in the same segment anyway.
  prefs: []
  type: TYPE_NORMAL
- en: 'TCP Priority Data Transfer: Urgent Function'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As noted earlier, the fact that TCP treats data to be transmitted as just an
    unstructured stream of bytes has some important implications on how it used. One
    aspect of this characteristic is that since TCP doesn't understand the content
    of the data it sends, it normally treats all the data bytes in a stream as *equals*.
    The data is sent to TCP in a particular sequence, and it is transmitted in that
    same order. This makes TCP, in this regard, like those annoying voice mail systems
    that tell you not to hang up because they will answer calls in the order received.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, while waiting on hold is irritating, this *first-in, first-out* behavior
    is usually how we want TCP to operate. If we are transmitting a message or a file,
    we want to be able to give TCP the bytes that compose that file and have TCP transmit
    that data in the order we gave it. However, just as special circumstances can
    require the use of the push function described in the previous section, there
    are cases where we may not want to always send all data in the exact sequence
    it was given to TCP.
  prefs: []
  type: TYPE_NORMAL
- en: The most common example of this is when it is necessary to interrupt an application's
    data transfer. Suppose we have an application that sends large files in both directions
    between two devices. The user of the application realizes that the wrong file
    is being transferred. When she tells the application to stop the file being sent,
    she wants this to be communicated to the other end of the TCP connection immediately.
    She doesn't want the abort command to just be placed at the end of the line after
    the file she is trying to send!
  prefs: []
  type: TYPE_NORMAL
- en: TCP provides a means for a process to prioritize the sending of data in the
    form of its *urgent* function. To use it, the process that needs to send urgent
    data enables the function and sends the urgent data to its TCP layer. TCP then
    creates a special TCP segment that has the URG control bit set to 1\. It also
    sets the Urgent Pointer field to an offset value that points to the last byte
    of urgent data in the segment. So, for example, if the segment contained 400 bytes
    of urgent data followed by 200 bytes of regular data, the URG bit would be set,
    and the Urgent Pointer field would have a value of 400.
  prefs: []
  type: TYPE_NORMAL
- en: Upon receipt of a segment with the URG flag set to 1, the receiving device looks
    at the Urgent Pointer and from its value determines which data in the segment
    is urgent. It then forwards the urgent data to the process with an indication
    that the data is marked as urgent by the sender. The rest of the data in the segment
    is processed normally.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** To deal with situations where a certain part of a data stream
    needs to be sent with a higher priority than the rest, TCP incorporates an *urgent*
    function. When critical data needs to be sent, the application signals this to
    its TCP layer, which transmits it with the URG bit set in the TCP segment, bypassing
    any lower-priority data that may have already been queued for transmission.'
  prefs: []
  type: TYPE_NORMAL
- en: Since we typically want to send urgent data, well, urgently, it makes sense
    that when such data is given to TCP, the push function is usually also invoked.
    This ensures that the urgent data is sent as soon as possible by the transmitting
    TCP and also forwarded up the protocol stack right away by the receiving TCP.
    Again, we need to remember that this does not guarantee the contents of the urgent
    segment. Using the push function may mean the segment contains only urgent data
    with no regular data following, but again, an application cannot assume that this
    will always be the case.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 49. TCP RELIABILITY AND FLOW CONTROL FEATURES
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages287681.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The main task of the Transmission Control Protocol (TCP) is simple: packaging
    and sending data. Of course, almost every protocol packages and sends data! What
    distinguishes TCP from these protocols is the sliding window mechanism we explored
    in the previous chapter, which controls the flow of data between devices. This
    system not only manages the basic data transfer process, but it also ensures that
    data is sent reliably and manages the flow of data between devices to transfer
    data efficiently, without either device sending data faster than the other can
    receive it.'
  prefs: []
  type: TYPE_NORMAL
- en: To enable TCP to provide the features and quality of data transfer that applications
    require, the protocol needed to be enhanced beyond the simplified data transfer
    mechanism we saw in preceding chapters. The developers needed to give extra "smarts"
    to the protocol to handle potential problems and make changes to the basic way
    that devices send data, to avoid inefficiencies that might otherwise have resulted.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I describe how TCP ensures that devices on a TCP connection
    communicate in a reliable and efficient manner. I begin with an explanation of
    the basic method by which TCP detects lost segments and retransmits them. I discuss
    some of the issues associated with TCP's acknowledgment scheme and an optional
    feature for improving its efficiency. I then describe the system by which TCP
    adjusts how long it will wait before deciding that a segment is lost. I discuss
    how the window size can be adjusted to implement flow control and some of the
    issues involved in window size management. This includes a look at the infamous
    "silly window syndrome" problem and special heuristics for addressing issues related
    to small window size that modify the basic sliding windows scheme. I conclude
    with a discussion of TCP's mechanisms for handling and avoiding congestion.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**BACKGROUND INFORMATION** This section assumes that you are already familiar
    with TCP sequence numbers and segments, and the basics of the TCP sliding window
    mechanism. It also assumes you have already read the section on TCP message formatting
    and data transfer. If not, you may want to review at least the section about TCP
    data transfer mechanics in [Chapter 48](ch48.html "Chapter 48. TCP MESSAGE FORMATTING
    AND DATA TRANSFER"). Several of the sections in this chapter extend that simplified
    discussion of TCP data transfer to show what happens in nonideal conditions.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Segment Retransmission Timers and the Retransmission Queue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TCP's basic data transfer and acknowledgment mechanism uses a set of variables
    maintained by each device to implement the sliding window system. These pointers
    keep track of the bytes of data sent and received by each device, as well as differentiating
    between acknowledged and unacknowledged transmissions. In the preceding chapter,
    I described this mechanism and gave a simplified example showing how a client
    and server use it for basic data transfer.
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons why that example is simplified is that every segment that
    was transmitted by the server was received by the client and vice versa. It would
    be nice if we could always count on this happening, but as we know, in an Internet
    environment, this is not realistic. Due to any number of conditions—such as hardware
    failure, corruption of an Internet Protocol (IP) datagram, or router congestion—a
    TCP segment may be sent but never received. To qualify as a reliable transport
    protocol, TCP must be able detect lost segments and *retransmit* them.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Retransmissions Using the Retransmission Queue
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The method for detecting lost segments and retransmitting them is conceptually
    simple. Each time we send a segment, we start a *retransmission timer*. This timer
    starts at a predetermined value and counts down over time. If the timer expires
    before an acknowledgment is received for the segment, we retransmit the segment.
  prefs: []
  type: TYPE_NORMAL
- en: TCP uses this basic technique, but implements it in a slightly different way.
    The reason for this is the need to efficiently deal with many segments that may
    be unacknowledged at once, to ensure that they are each retransmitted at the appropriate
    time if needed. The TCP system works according to the following specific sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '**Placement on Retransmission Queue, Timer Start** As soon as a segment containing
    data is transmitted, a copy of the segment is placed in a data structure called
    the *retransmission queue*. A retransmission timer is started for the segment
    when it is placed on the queue. Thus, at some point, *every* segment is placed
    in this queue. The queue is kept sorted by the time remaining in the retransmission
    timer, so the TCP software can keep track of which timers have the least time
    remaining before they expire.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledgment Processing** If an acknowledgment is received for a segment
    before its timer expires, the segment is removed from the retransmission queue.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Retransmission Timeout** If an acknowledgment is *not* received before the
    timer for a segment expires, a *retransmission timeout* occurs, and the segment
    is automatically retransmitted.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we have no more guarantee that a retransmitted segment will be received
    than we had for the original segment. For this reason, after retransmitting a
    segment, it remains in the retransmission queue. The retransmission timer is reset,
    and the countdown begins again. If an acknowledgment is not received for the retransmission,
    the segment will be retransmitted again and the process repeated.
  prefs: []
  type: TYPE_NORMAL
- en: Certain conditions may cause even repeated retransmissions of a segment to fail.
    We don't want TCP to just keep retransmitting forever, so TCP will retransmit
    a lost segment only a certain number of times before concluding that there is
    a problem and terminating the connection.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** To provide basic reliability for sent data, each device''s
    TCP implementation uses a *retransmission queue*. Each sent segment is placed
    in the queue and a *retransmission timer* started for it. When an acknowledgment
    is received for the data in the segment, it is removed from the retransmission
    queue. If the timer goes off before an acknowledgment is received, the segment
    is retransmitted and the timer restarted.'
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing When a Segment Is Fully Acknowledged
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: But how do we know when a segment has been fully acknowledged? Retransmissions
    are handled on a segment basis, but TCP acknowledgments, as we have seen, are
    done on a cumulative basis using sequence numbers. Each time a segment is sent
    by Device A to Device B, Device B looks at the value of the Acknowledgment Number
    field in the segment. All bytes with sequence numbers lower than the value of
    this field have been received by Device A. Thus, a segment sent by Device B to
    Device A is considered acknowledged when all of the bytes that were sent in the
    segment have a lower sequence number than the latest Acknowledgment Number sent
    by Device B to Device A. This is determined by calculating the last sequence number
    of the segment using its first byte number (in the Sequence Number field) and
    length of the segment's Data field.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP uses a *cumulative acknowledgment* system. The Acknowledgment
    Number field in a segment received by a device indicates that all bytes of data
    with sequence numbers less than that value have been successfully received by
    the other device. A segment is considered acknowledged when all of its bytes have
    been acknowledged; in other words, when an Acknowledgment Number containing a
    value larger than the sequence number of its last byte is received.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the example illustrated in [Figure 49-1](ch49.html#tcp_transaction_example_with_retransmiss
    "Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server''s send pointers and client''s receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged.") to
    clarify how acknowledgments and retransmissions work in TCP. Suppose the server
    in a connection sends out four contiguous segments (numbered starting with 1 for
    clarity):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Segment 1** Sequence Number field is 1 and segment length is 80\. So the
    last sequence number in Segment 1 is 80.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Segment 2** Sequence Number field is 81 and segment length is 120\. The last
    sequence number in Segment 2 is 200.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Segment 3** Sequence Number field is 201 and segment length is 160\. The
    last sequence number in Segment 3 is 360.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Segment 4** Sequence Number field is 361 and segment length is 140\. The
    last sequence number in Segment 4 is 500.'
  prefs: []
  type: TYPE_NORMAL
- en: Again, these segments can be sent one after the other, without needing to wait
    for each preceding transmission to be acknowledged. This is a major benefit of
    TCP's sliding window mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's say the client receives the first two transmissions. It will send
    back an acknowledgment with an Acknowledgment Number field value of 201\. This
    tells the server that the first two segments have been successfully received by
    the client; they will be removed from the retransmission queue (and the server's
    send window will slide 200 bytes to the right). Segment 3 will remain on the retransmission
    queue until a segment with an Acknowledgment Number field value of 361 or higher
    is received; Segment 4 requires an acknowledgment value of 501 or greater.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's further suppose in this example that Segment 3 gets lost in transit,
    but Segment 4 is received. The client will store Segment 4 in its receive buffer,
    but will not be able to acknowledge it, because of TCP's cumulative acknowledgment
    system—acknowledging Segment 4 would imply receipt of Segment 3 as well, which
    never showed up. So, the client will need to wait for Segment 3\. Eventually,
    the retransmission timer that the server started for Segment 3 will expire. The
    server will then retransmit Segment 3\. It will be received by the client, which
    will then be able to acknowledge both Segments 3 and 4 to the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s another important issue here, however: How exactly should the server
    handle Segment 4? While the client is waiting for the missing Segment 3, the server
    is receiving no feedback, so it doesn''t know that Segment 3 is lost, and it also
    doesn''t know what happened to Segment 4 (or any subsequent transmissions). It
    is possible that the client has already received Segment 4 but just couldn''t
    acknowledge it. Then again, maybe Segment 4 got lost as well. Some implementations
    may choose to resend only Segment 3, while some may choose to resend both Segments
    3 and 4\. This is an important issue that we will discuss next.'
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP transaction example with retransmission This diagram illustrates a simple
    transaction and shows the server''s send pointers and client''s receive pointers.
    The server sends three segments to the client in rapid succession, setting a retransmission
    timer for each. Parts 1 and 2 are received, and the client sends an acknowledgment
    for them. Upon receipt of this ACK, Parts 1 and 2 are taken off the retransmission
    queue. However, Part 3 is lost in transit. When Part 4 is received, the client
    cannot acknowledge it; this would imply receipt of the missing Part 3\. Eventually,
    the retransmission timer for Part 3 expires and it is retransmitted, at which
    time both Part 3 and Part 4 are acknowledged.](httpatomoreillycomsourcenostarchimages288131.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server's send pointers and client's receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged.
  prefs: []
  type: TYPE_NORMAL
- en: A final issue is what value we should use for the retransmission timer when
    we put a segment on the retransmission queue. If it is set too low, excessive
    retransmissions occur; if set too high, performance is reduced due to extraneous
    delays in resending lost segments. In fact, TCP cannot use a single number for
    this value. It must determine the value dynamically using a process called adaptive
    retransmission, which we will examine later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Noncontiguous Acknowledgment Handling and Selective Acknowledgment (SACK)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer science people sometimes use the term *elegant* to describe a simple
    but effective solution to a problem or need. I think the term applies fairly well
    to the cumulative acknowledgment method that is part of the TCP sliding window
    system. With a single number, returned in the Acknowledgment Number field of a
    TCP segment, the device sending the segment can acknowledge not just a single
    segment it has received from its connection peer, but possibly several of them.
    We saw how this works in the discussion of the fundamentals of sliding windows
    in [Chapter 46](ch46.html "Chapter 46. TRANSMISSION CONTROL PROTOCOL (TCP) FUNDAMENTALS
    AND GENERAL OPERATION"), and again in the previous discussion of retransmissions.
  prefs: []
  type: TYPE_NORMAL
- en: Even the most elegant technique has certain weaknesses, however. In the case
    of the TCP acknowledgment system, it is the inability to effectively deal with
    the receipt of *noncontiguous* TCP segments. The Acknowledgment Number specifies
    that *all* sequence numbers lower than its value have been received by the device
    sending that number. If we receive bytes with sequence numbers in two noncontiguous
    ranges, there is no way to specify this with a single number.
  prefs: []
  type: TYPE_NORMAL
- en: This can lead to potentially serious performance problems, especially on internetworks
    that operate at high speed or over inherently unreliable physical networks. To
    see what the problem is, let's go back to the example illustrated in [Figure 49-1](ch49.html#tcp_transaction_example_with_retransmiss
    "Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server's send pointers and client's receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged."). There,
    the server sent four segments and received back an acknowledgment with an Acknowledgment
    Number value of 201\. Segment 1 and Segment 2 were thus considered acknowledged.
    They would be removed from the retransmission queue, and this would also allow
    the server's send window to slide 80+120 bytes to the right, allowing 200 more
    bytes of data to be sent.
  prefs: []
  type: TYPE_NORMAL
- en: However, let's again imagine that Segment 3, starting with sequence number 201,
    is somehow lost in transit. Since the client never receives this segment, it can
    never send back an acknowledgment with an Acknowledgment Number higher than 201\.
    This causes the sliding window system to get stuck. The server can continue to
    send additional segments until it fills up the client's receive window, but until
    the client sends another acknowledgment, the server's send window will not slide.
  prefs: []
  type: TYPE_NORMAL
- en: The other problem we saw is that if Segment 3 gets lost, the client has no way
    to tell the server that it has received any *subsequent* segments. It's entirely
    possible that the client has received the server's Segment 4 and later segments,
    until the window filled up. But the client can't send an acknowledgment with a
    value of 501 to indicate receipt of Segment 4, *because this implies receipt of
    Segment 3 as well*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases, the client may still send an acknowledgment upon receipt of Segment
    4, but containing only a repeated acknowledgment of the bytes up to the end of
    Segment 2\. See the coverage of congestion avoidance later in this chapter for
    an explanation.
  prefs: []
  type: TYPE_NORMAL
- en: And here we see the drawback of the single-number, cumulative acknowledgment
    system of TCP. We could imagine a worst-case scenario, in which the server is
    told it has a window of 10,000 bytes, and sends 20 segments of 500 bytes each.
    The first segment is lost, and the other 19 are received. But since it is the
    first segment that never showed up, none of the other 19 segments can be acknowledged!
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP''s acknowledgment system is *cumulative*. This means that
    if a segment is lost in transit, no subsequent segments can be acknowledged until
    the missing one is retransmitted and successfully received.'
  prefs: []
  type: TYPE_NORMAL
- en: Policies for Dealing with Outstanding Unacknowledged Segments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do we handle retransmissions when there are subsequent segments outstanding
    beyond the lost segment? In our example, when the server experiences a retransmission
    timeout on Segment 3, it must decide what to do about Segment 4, when it simply
    doesn't know whether or not the client received it. In our worst-case scenario,
    we have 19 segments that may or may not have shown up at the client after the
    first one that was lost.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two possible ways to handle this situation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Retransmit Only Timed-Out Segments** This is the more conservative, or if
    you prefer, optimistic approach. We retransmit only the segment that timed out,
    hoping that the other segments beyond it were successfully received. This method
    is best if the segments after the timed-out segment actually showed up. It doesn''t
    work so well if they did not. In the latter case, each segment would need to time
    out individually and be retransmitted. Imagine that in our worst-case scenario,
    all twenty 500-byte segments were lost. We would need to wait for Segment 1 to
    time out and be retransmitted. This retransmission would be acknowledged (we hope),
    but then we would get stuck waiting for Segment 2 to time out and be resent. We
    would need to do this many times.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Retransmit All Outstanding Segments** This is the more aggressive, or pessimistic,
    method. Whenever a segment times out, we resend not only that segment, but all
    other segments that are still unacknowledged. This method ensures that any time
    there is a holdup with acknowledgments, we refresh all outstanding segments to
    give the other device an extra chance at receiving them, in case they, too, were
    lost. In the case where all 20 segments were lost, this saves substantial amounts
    of time over the alternative, optimistic approach. The problem here is that these
    retransmissions may not be necessary. If the first of 20 segments was lost and
    the other 19 were actually received, we would be resending 9500 bytes of data
    (plus headers) for no reason.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since TCP doesn''t know whether these other segments showed up, it cannot know
    which method is better. It must simply make an executive decision to use one approach
    or the other and hope for the best. In the example shown in [Figure 49-1](ch49.html#tcp_transaction_example_with_retransmiss
    "Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server''s send pointers and client''s receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged."), I
    demonstrated the conservative, optimistic approach: Only the lost segment of the
    file was retransmitted. [Figure 49-2](ch49s02.html#tcp_aggressive_retransmission_example_th
    "Figure 49-2. TCP aggressive retransmission example This example is the same as
    that shown in Figure 49-1, except that here the server is taking an "aggressive"
    approach to retransmitting lost segments. When Segment 3 times out, both Segments
    3 and 4 are retransmitted, and their retransmission timers restarted. (In this
    case, Segment 4 already arrived, so this extra transmission was not useful.)")
    illustrates the alternative aggressive, pessimistic approach to retransmission.'
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP aggressive retransmission example This example is the same as that shown
    in , except that here the server is taking an "aggressive" approach to retransmitting
    lost segments. When Segment 3 times out, both Segments 3 and 4 are retransmitted,
    and their retransmission timers restarted. (In this case, Segment 4 already arrived,
    so this extra transmission was not useful.)](httpatomoreillycomsourcenostarchimages288133.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-2. TCP aggressive retransmission example This example is the same
    as that shown in [Figure 49-1](ch49.html#tcp_transaction_example_with_retransmiss
    "Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server's send pointers and client's receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged."), except
    that here the server is taking an "aggressive" approach to retransmitting lost
    segments. When Segment 3 times out, both Segments 3 and 4 are retransmitted, and
    their retransmission timers restarted. (In this case, Segment 4 already arrived,
    so this extra transmission was not useful.)
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** There are two approaches to handling retransmission in TCP.
    In the more conservative approach, only the segments whose timers expire are retransmitted.
    This saves bandwidth, but it may cause performance degradation if many segments
    in a row are lost. The alternative is that when a segment''s retransmission timer
    expires, both it and all subsequent unacknowledged segments are retransmitted.
    This provides better performance if many segments are lost, but it may waste bandwidth
    on unnecessary retransmissions.'
  prefs: []
  type: TYPE_NORMAL
- en: This lack of knowledge about noncontiguous segments is the core of the problem.
    The solution is to extend the basic TCP sliding window algorithm with an optional
    feature that allows a device to acknowledge noncontiguous segments individually.
    This feature, introduced in RFC 1072 and refined in RFC 2018, is called TCP *selective
    acknowledgment*, abbreviated *SACK*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Better Solution: Selective Acknowledgment (SACK)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use SACK, the two devices on the connection must both support the feature,
    and must enable it by negotiating the Selective Acknowledge Permitted (SACK-Permitted)
    option in the SYN segment they use to establish the connection. Assuming this
    is done, either device is then permitted to include in a regular TCP segment a
    Selective Acknowledgment (SACK) option. This option contains a list of sequence
    number ranges of segments of data that have been received but have not been acknowledged,
    since they are noncontiguous.
  prefs: []
  type: TYPE_NORMAL
- en: Each device modifies its retransmission queue so that each segment includes
    a flag that is set to 1 if the segment has been selectively acknowledged—the SACK
    bit. The device then uses a modified version of the aggressive method illustrated
    in [Figure 49-2](ch49s02.html#tcp_aggressive_retransmission_example_th "Figure 49-2. TCP
    aggressive retransmission example This example is the same as that shown in Figure 49-1,
    except that here the server is taking an "aggressive" approach to retransmitting
    lost segments. When Segment 3 times out, both Segments 3 and 4 are retransmitted,
    and their retransmission timers restarted. (In this case, Segment 4 already arrived,
    so this extra transmission was not useful.)"), where upon retransmission of a
    segment, all later segments are also retransmitted *unless* their SACK bits are
    set to 1.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The optional TCP *selective acknowledgment* feature provides
    a more elegant way of handling subsequent segments when a retransmission timer
    expires. When a device receives a noncontiguous segment, it includes a special
    *Selective Acknowledgment* (SACK) option in its regular acknowledgment that identifies
    noncontiguous segments that have already been received, even if they are not yet
    acknowledged. This saves the original sender from needing to retransmit them.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, in our four-segment case, if the client receives Segment 4 but
    not Segment 3, when it sends back a segment with an Acknowledgment Number field
    value of 201 (for Segments 1 and 2), it can include a SACK option that specifies,
    "I have received bytes 361 through 500, but they are not yet acknowledged." This
    can also be done in a second acknowledgment segment if Segment 4 arrives well
    after Segments 1 and 2\. The server recognizes this as the range of bytes for
    Segment 4, and turns on the SACK bit for Segment 4\. When Segment 3 is retransmitted,
    the server sees that the SACK bit for Segment 4 is on and does not retransmit
    it. This is illustrated in [Figure 49-3](ch49s02.html#tcp_retransmission_with_selective_acknow
    "Figure 49-3. TCP retransmission with selective acknowledgment (SACK) This is
    the example from Figures Figure 49-1 and Figure 49-2, changed to use the optional
    selective acknowledge feature. After receiving Parts 1, 2, and 4 of the file,
    the client sends an acknowledgment for 1 and 2 that includes a SACK for Part 4\.
    This tells the server not to resend Part 4 when Part 3's timer expires.").
  prefs: []
  type: TYPE_NORMAL
- en: After Segment 3 is retransmitted, the SACK bit for Segment 4 is cleared. This
    is done for robustness, to handle cases where, for whatever reason, the client
    changes its mind about having received Segment 4\. The client *should* send an
    acknowledgment with an Acknowledgment Number of 501 or higher, officially indicating
    receipt of Segments 3 and 4\. If this does not happen, the server must receive
    another selective acknowledgment for Segment 4 to turn its SACK bit back on. Otherwise,
    it will be automatically resent when its timer expires or when Segment 3 is retransmitted.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP retransmission with selective acknowledgment (SACK) This is the example
    from Figures and , changed to use the optional selective acknowledge feature.
    After receiving Parts 1, 2, and 4 of the file, the client sends an acknowledgment
    for 1 and 2 that includes a SACK for Part 4\. This tells the server not to resend
    Part 4 when Part 3''s timer expires.](httpatomoreillycomsourcenostarchimages288135.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-3. TCP retransmission with selective acknowledgment (SACK) This is
    the example from Figures [Figure 49-1](ch49.html#tcp_transaction_example_with_retransmiss
    "Figure 49-1. TCP transaction example with retransmission This diagram illustrates
    a simple transaction and shows the server's send pointers and client's receive
    pointers. The server sends three segments to the client in rapid succession, setting
    a retransmission timer for each. Parts 1 and 2 are received, and the client sends
    an acknowledgment for them. Upon receipt of this ACK, Parts 1 and 2 are taken
    off the retransmission queue. However, Part 3 is lost in transit. When Part 4
    is received, the client cannot acknowledge it; this would imply receipt of the
    missing Part 3\. Eventually, the retransmission timer for Part 3 expires and it
    is retransmitted, at which time both Part 3 and Part 4 are acknowledged.") and
    [Figure 49-2](ch49s02.html#tcp_aggressive_retransmission_example_th "Figure 49-2. TCP
    aggressive retransmission example This example is the same as that shown in Figure 49-1,
    except that here the server is taking an "aggressive" approach to retransmitting
    lost segments. When Segment 3 times out, both Segments 3 and 4 are retransmitted,
    and their retransmission timers restarted. (In this case, Segment 4 already arrived,
    so this extra transmission was not useful.)"), changed to use the optional selective
    acknowledge feature. After receiving Parts 1, 2, and 4 of the file, the client
    sends an acknowledgment for 1 and 2 that includes a SACK for Part 4\. This tells
    the server not to resend Part 4 when Part 3's timer expires.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Adaptive Retransmission and Retransmission Timer Calculations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever a TCP segment is transmitted, a copy of it is also placed on the retransmission
    queue. When the segment is placed on the queue, a retransmission timer is started
    for the segment, which starts from a particular value and counts down to zero.
    This timer controls how long a segment can remain unacknowledged before the sender
    gives up, concludes that the segment is lost, and sends it again.
  prefs: []
  type: TYPE_NORMAL
- en: The length of time we use for retransmission timer is thus very important. If
    it is set too low, we might start retransmitting a segment that was actually received,
    because we didn't wait long enough for the acknowledgment of that segment to arrive.
    Conversely, if we set the timer too long, we waste time waiting for an acknowledgment
    that will never arrive, reducing overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ideally, we would like to set the retransmission timer to a value just slightly
    larger than the *round-trip time (RTT)* between the two TCP devices; that is,
    the typical time it takes to send a segment from a client to a server and the
    server to send an acknowledgment back to the client (or the other way around,
    of course). The problem is that there *is* no such typical RTT. There are two
    main reasons for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Differences in Connection Distance** Suppose you are at work in the United
    States, and during your lunch hour, you transfer a large file between your workstation
    and a local server connection using 100 Mbps Fast Ethernet. At the same time,
    you are downloading a picture of your nephew from your sister''s personal website,
    which is connected to the Internet using an analog modem to an ISP in a small
    town near Lima, Peru. Would you want both of these TCP connections to use the
    same retransmission timer value? I certainly hope not!'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transient Delays and Variability** The amount of time it takes to send data
    between any two devices will vary over time due to various happenings on the internetwork:
    fluctuations in traffic, router loads, and so on. To see an example of this for
    yourself, try typing `ping www.tcpipguide.com` from the command line of an Internet-connected
    PC, and you''ll see how the reported times can vary.'
  prefs: []
  type: TYPE_NORMAL
- en: It is for these reasons that TCP does not attempt to use a static, single number
    for its retransmission timers. Instead, TCP uses a dynamic, or *adaptive*retransmission
    scheme.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive Retransmission Based on RTT Calculations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP attempts to determine the approximate RTT between the devices and adjusts
    it over time to compensate for increases or decreases in the average delay. The
    practical issues of how this is done are important, but they are not covered in
    much detail in the main TCP standard. However, RFC 2988, "Computing TCP's Retransmission
    Timer," discusses the issue extensively.
  prefs: []
  type: TYPE_NORMAL
- en: 'RTTs can bounce up and down, so we want to aim for an *average* RTT value for
    the connection. This average should respond to consistent movement up or down
    in the RTT, without overreacting to a few very slow or fast acknowledgments. To
    allow this to happen, the RTT calculation uses a *smoothing* formula:'
  prefs: []
  type: TYPE_NORMAL
- en: New RTT = (α * Old RTT) + ( (1-α) * Newest RTT Measurement)
  prefs: []
  type: TYPE_NORMAL
- en: where α (alpha) is a *smoothing factor* between 0 and 1\. Higher values of α
    (closer to 1) provide better smoothing and avoiding sudden changes as a result
    of one very fast or very slow RTT measurement. Conversely, this also slows down
    how quickly TCP reacts to more sustained changes in RTT. Lower values of alpha
    (closer to 0) make the RTT change more quickly in reaction to changes in measured
    RTT, but can cause overreaction when RTTs fluctuate wildly.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgment Ambiguity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Measuring the RTT between two devices is simple in concept: Note the time that
    a segment is sent, note the time that an acknowledgment is received, and subtract
    the two. The measurement is more tricky in actual implementation, however.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the main potential "gotchas" occurs when a segment is assumed lost and
    is retransmitted. The retransmitted segment carries nothing that distinguishes
    it from the original. When an acknowledgment is received for this segment, it's
    unclear whether this corresponds to the retransmission or the original segment.
    Even though we decided the segment was lost and retransmitted it, it's possible
    the segment eventually got there, after taking a long time, or that the segment
    got their quickly but the *acknowledgment* took a long time!
  prefs: []
  type: TYPE_NORMAL
- en: This is called *acknowledgment ambiguity*, and it is not trivial to resolve.
    We can't just decide to assume that an acknowledgment always goes with the oldest
    copy of the segment sent, because this makes the RTT appear too high. We also
    don't want to just assume an acknowledgment always goes with the latest sending
    of the segment, as that may artificially lower the average RTT.
  prefs: []
  type: TYPE_NORMAL
- en: Refinements to RTT Calculation and Karn's Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TCP's solution is based on the use of a technique called *Karn's algorithm*,
    after its inventor, Phil Karn. The main change this algorithm makes is the separation
    of the calculation of average RTT from the calculation of the value to use for
    timers on retransmitted segments.
  prefs: []
  type: TYPE_NORMAL
- en: The first change made under Karn's algorithm is to not use measured RTT for
    any segments that are retransmitted in the calculation of the overall average
    RTT for the connection. This completely eliminates the problem of acknowledgment
    ambiguity.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this by itself, would not allow increased delays due to retransmissions
    to affect the average RTT. For this, we need the second change: incorporation
    of a *timer backoff* scheme for retransmitted segments. We start by setting the
    retransmission timer for each newly transmitted segment based on the current average
    RTT. When a segment is retransmitted, the timer is not reset to the same value
    it was set for the initial transmission. It is "backed off," or increased, using
    a multiplier (typically 2) to give the retransmission more time to be received.
    The timer continues to be increased until a retransmission is successful, up to
    a certain maximum value. This prevents retransmissions from being sent too quickly
    and further adding to network congestion.'
  prefs: []
  type: TYPE_NORMAL
- en: Once the retransmission succeeds, the RTT is kept at the longer (backed-off)
    value until a valid RTT can be measured on a segment that is sent and acknowledged
    without retransmission. This permits a device to respond with longer timers to
    occasional circumstances that cause delays to persist for a period of time on
    a connection, while eventually having the RTT settle back to a long-term average
    when normal conditions resume.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP uses an *adaptive* retransmission scheme that automatically
    adjusts the amount of time to which retransmission timers are set, based on the
    average amount of time it takes to send segments between devices. This helps avoid
    retransmitting potentially lost segments too quickly or too slowly.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Window Size Adjustment and Flow Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen the importance of the concept of *window size* to TCP's sliding
    window mechanism. In a connection between a client and a server, the client tells
    the server the number of bytes it is willing to receive at one time from the server;
    this is the client's *receive window*, which becomes the server's *send window*.
    Likewise, the server tells the client how many bytes of data it is willing to
    take from the client at one time; this is the server's *receive window* and the
    client's *send window*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The use of these windows is demonstrated in [Chapter 48](ch48.html "Chapter 48. TCP
    MESSAGE FORMATTING AND DATA TRANSFER"), where we discussed TCP''s basic data transfer
    and acknowledgment mechanism. However, just as the example in that chapter was
    simplified because I didn''t show what happens with lost segments, there''s another
    way that it doesn''t reflect the real-world conditions of an actual Internet:
    the send and receive window sizes never changed during the course of communication.'
  prefs: []
  type: TYPE_NORMAL
- en: To understand why the window size may fluctuate, we need to understand what
    it represents. The simplest way of considering the window size is that it indicates
    the size of the device's receive buffer for the particular connection. That is,
    window size represents how much data a device can handle from its peer at one
    time before it is passed to the application process. Let's consider the example
    in [Chapter 48](ch48.html "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER").
    I said that the server's window size was 360\. This means the server is willing
    to take no more than 360 bytes at a time from the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the server receives data from the client, it places it into this buffer.
    The server must then do two distinct things with this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledgment** The server must send an acknowledgment back to the client
    to indicate that the data was received.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transfer** The server must process the data, transferring it to the destination
    application process.'
  prefs: []
  type: TYPE_NORMAL
- en: It is critically important that we differentiate between these two activities.
    Unfortunately, the TCP standards don't do a great job in this regard, which makes
    them very difficult to understand. The key point is that in the basic sliding
    window system, data is acknowledged when received, but *not necessarily* immediately
    transferred out of the buffer. This means that is possible for the buffer to fill
    up with received data faster than the receiving TCP can empty it. When this occurs,
    the receiving device may need to adjust the window size to prevent the buffer
    from being overloaded.
  prefs: []
  type: TYPE_NORMAL
- en: Since the window size can be used in this manner to manage the rate at which
    data flows between the devices at the ends of the connection, it is the method
    by which TCP implements *flow control*, one of the classic jobs of the transport
    layer. Flow control is vitally important to TCP, as it is the method by which
    devices communicate their status to each other. By reducing or increasing window
    size, the server and client each ensure that the other device sends data just
    as fast as the recipient can deal with it.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing Send Window Size to Reduce the Rate Data Is Sent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand window size adjustment, let''s go back to our earlier example
    in [Chapter 48](ch48.html "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER"),
    but with a few changes. First, to keep things simple, let''s just look at the
    transmissions made from the client to the server, not the server''s replies (other
    than acknowledgments)—this is illustrated in [Figure 48-7](ch48s04.html#tcp_transaction_example_showing_clients_
    "Figure 48-7. TCP transaction example showing client''s send pointers The transaction
    of Table 48-6 from the perspective of the client. See Figure 48-6 for the server''s
    pointers."). As before, the client sends 140 bytes to the server. After sending
    the 140 bytes, the client has 220 bytes remaining in its usable window: 360 bytes
    in the send window less the 140 bytes it just sent.'
  prefs: []
  type: TYPE_NORMAL
- en: Sometime later, the server receives the 140 bytes and puts them in the buffer.
    Now, in an ideal world, the 140 bytes go into the buffer, and they are acknowledged
    and immediately removed from the buffer. Another way of thinking of this is that
    the buffer is of infinite size and can hold as much as the client can send. The
    buffer's free space remains 360 bytes in size, so the same window size can be
    advertised back to the client. This was the simplification in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: As long as the server can process the data as fast as it comes in, it will keep
    the window size at 360 bytes. The client, upon receipt of the acknowledgment of
    140 bytes and the same window size it had before, slides the full 360-byte window
    140 bytes to the right. Since there are now 0 unacknowledged bytes, the client
    can now once again send 360 bytes of data. These correspond to the 220 bytes that
    were formerly in the usable window, plus 140 new bytes for the ones that were
    just acknowledged.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, however, that server might be dealing with dozens, hundreds,
    or even thousands of TCP connections. TCP might not be able to process the data
    immediately. Alternatively, it is possible the application itself might not be
    ready for the 140 bytes for whatever reason. In either case, the server's TCP
    may not be able to immediately remove all 140 bytes from the buffer. If so, upon
    sending an acknowledgment back to the client, the server will want to change the
    window size that it advertises to the client, to reflect the fact that the buffer
    is partially filled.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that we receive 140 bytes, but are able to send only 40 bytes to the
    application, leaving 100 bytes in the buffer. When we send back the acknowledgment
    for the 140 bytes, the server can reduce its send window by 100 bytes, to 260
    bytes. When the client receives this segment from the server, it will see the
    acknowledgment of the 140 bytes sent and slide its window 140 bytes to the right.
    However, as it slides this window, it reduces its size to only 260 bytes. We can
    consider this as sliding the *left edge* of the window 140 bytes, but the *right
    edge* only 40 bytes. The new, smaller window ensures that the server receives
    a maximum of 260 bytes from the client, which will fit in the 260 bytes remaining
    in its receive buffer. This is illustrated in the first exchange of messages (steps
    1 through 3) at the top of [Figure 49-4](ch49s04.html#tcp_window_size_adjustments_and_flow_con
    "Figure 49-4. TCP window size adjustments and flow control This diagram shows
    three message cycles, each of which results in the server reducing its receive
    window. In the first cycle, the server reduces it from 360 to 260 bytes, so the
    client's usable window can increase by only 40 bytes when it gets the server's
    acknowledgment. In the second and third cycles, the server reduces the window
    size by the amount of data it receives, which temporarily freezes the client's
    send window size, halting it from sending new data.").
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP window size adjustments and flow control This diagram shows three message
    cycles, each of which results in the server reducing its receive window. In the
    first cycle, the server reduces it from 360 to 260 bytes, so the client''s usable
    window can increase by only 40 bytes when it gets the server''s acknowledgment.
    In the second and third cycles, the server reduces the window size by the amount
    of data it receives, which temporarily freezes the client''s send window size,
    halting it from sending new data.](httpatomoreillycomsourcenostarchimages288137.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-4. TCP window size adjustments and flow control This diagram shows
    three message cycles, each of which results in the server reducing its receive
    window. In the first cycle, the server reduces it from 360 to 260 bytes, so the
    client's usable window can increase by only 40 bytes when it gets the server's
    acknowledgment. In the second and third cycles, the server reduces the window
    size by the amount of data it receives, which temporarily freezes the client's
    send window size, halting it from sending new data.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing Send Window Size to Stop the Sending of New Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if the server is so bogged down that it cannot process *any* of the bytes
    received? Let's suppose that the next transmission from the client is 180 bytes
    in size, but the server is so busy it cannot remove any of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the server could buffer the 180 bytes and, in the acknowledgment
    it sends for those bytes, reduce the window size by the same amount: from 260
    to 80 bytes. When the client received the acknowledgment for 180 bytes, it would
    see the window size had reduced by 180 bytes as well. It would slide its window
    by the same amount as the window size was reduced! This is effectively like the
    server saying, "I acknowledge receipt of 180 bytes, but I am not allowing you
    to send any new bytes to replace them." Another way of looking at this is that
    the left edge of the window slides 180 bytes, while the right edge remains fixed.
    And as long as the right edge of the window doesn''t move, the client cannot send
    any more data than it could before receipt of the acknowledgment. This is the
    middle exchange (steps 4 to 6) in [Figure 49-4](ch49s04.html#tcp_window_size_adjustments_and_flow_con
    "Figure 49-4. TCP window size adjustments and flow control This diagram shows
    three message cycles, each of which results in the server reducing its receive
    window. In the first cycle, the server reduces it from 360 to 260 bytes, so the
    client''s usable window can increase by only 40 bytes when it gets the server''s
    acknowledgment. In the second and third cycles, the server reduces the window
    size by the amount of data it receives, which temporarily freezes the client''s
    send window size, halting it from sending new data.").'
  prefs: []
  type: TYPE_NORMAL
- en: Closing the Send Window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This process of window adjustment can continue, and, of course, can be done
    by both devices, even though we are considering only the client-sends-to-server
    side of the equation here. If the server continues to receive data from the client
    faster than it can pump it out to the application, it will continue to reduce
    the size of its receive window.
  prefs: []
  type: TYPE_NORMAL
- en: To continue our example, suppose that after the send window is reduced to 80
    bytes, the client sends a third request, this one 80 bytes in length, but the
    server is still busy. The server then reduces its window all the way down to 0,
    which is called *closing* the window. This tells the client the server is very
    overloaded, and it should stop routine sending of data entirely, as shown in the
    bottom third of [Figure 49-4](ch49s04.html#tcp_window_size_adjustments_and_flow_con
    "Figure 49-4. TCP window size adjustments and flow control This diagram shows
    three message cycles, each of which results in the server reducing its receive
    window. In the first cycle, the server reduces it from 360 to 260 bytes, so the
    client's usable window can increase by only 40 bytes when it gets the server's
    acknowledgment. In the second and third cycles, the server reduces the window
    size by the amount of data it receives, which temporarily freezes the client's
    send window size, halting it from sending new data."). Later on, when the server
    is less loaded down, it can increase the window size for this connection again,
    permitting more data to be transferred.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The TCP sliding window system is used not just for ensuring
    reliability through acknowledgments and retransmissions, but it is also the basis
    for TCP''s flow control mechanism. By increasing or reducing the size of its receive
    window, a device can raise or lower the rate at which its connection partner sends
    it data. In the case where a device becomes extremely busy, it can even reduce
    the receive window to zero. This will close the window and halt any further transmissions
    of data until the window is reopened.'
  prefs: []
  type: TYPE_NORMAL
- en: While conceptually simple, flow control using window size adjustment can be
    very tricky. If we aren't careful about how we make changes to window size, we
    can introduce serious problems in the operation of TCP. There are also special
    situations that can occur, especially in cases where the window size is made small
    in response to a device becoming busy. The next two sections explore window management
    issues and changes that need to be made to the basic sliding window system to
    address them.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Window Management Issues
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each of the two devices on a TCP connection can adjust the window size it advertises
    to the other, to control the flow of data over the connection. Reducing the size
    of the window forces the other device to send less data; increasing the window
    size lets more data flow. In theory, we should be able to just let the TCP software
    on each of the devices change the window size as needed to match the speed at
    which data both enters the buffer and is removed from it to be sent to the receiving
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, certain changes in window size can lead to undesirable consequences.
    These can occur both when the size of the window is reduced and when it is increased.
    For this reason, there are a few issues related to *window size management* that
    we need to consider. As in previous sections, we'll use for illustration a modification
    of the same client/server example introduced in [Chapter 48](ch48.html "Chapter 48. TCP
    MESSAGE FORMATTING AND DATA TRANSFER").
  prefs: []
  type: TYPE_NORMAL
- en: Problems Associated with Shrinking the TCP Window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One window size management matter is related to just how quickly a device reduces
    the size of its receive window when it gets busy. Let's say the server starts
    with a 360-byte receive window, as in the aforementioned example, and receives
    140 bytes of data that it acknowledges but cannot remove from the buffer immediately.
    The server can respond by reducing the size of the window it advertises back to
    the client. In the case where no bytes can be removed from the buffer at all,
    the window size is reduced by the same 140 bytes that were added to the buffer.
    This freezes the right edge of the client's send window, so it cannot send any
    additional data when it gets an acknowledgment.
  prefs: []
  type: TYPE_NORMAL
- en: What if the server were so overloaded that we actually needed to reduce the
    size of the *buffer* itself? Say memory was short and the operating system said,
    "I know you have 360 bytes allocated for the receive buffer for this connection,
    but I need to free up memory, so now you only have 240." The server still cannot
    immediately process the 140 bytes it received, so it would need to drop the window
    size it sent back to the client all the way from 360 bytes down to 100 bytes (240
    in the total buffer less the 140 already received).
  prefs: []
  type: TYPE_NORMAL
- en: In effect, doing this actually moves the right edge of the client's send window
    *back to the left*. It says, "Not only can't you send more data when you receive
    this acknowledgment, but you now can send *less*when you do send data." In TCP
    parlance, this is called *shrinking the window*.
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s a very serious problem with doing this, however: While the original
    140 bytes were in transit from the client to the server, the client still thought
    it had 360 bytes of total window, of which 220 bytes were *usable* (360 less 140).
    The client may well have already sent some of those 220 bytes of data to the server
    before it got the notification that the server had shrunk the window! If so, and
    the server reduced its buffer to 240 bytes with 140 used, when those 220 bytes
    showed up at the server, only 100 would fit, and any additional ones would need
    to be discarded. This would force the client to need to retransmit that data,
    which is inefficient. [Figure 49-5](ch49s05.html#the_problem_with_shrinking_the_tcp_windo
    "Figure 49-5. The problem with shrinking the TCP window In this modification of
    the example of Figure 49-4, the client begins with a usable window size of 360
    bytes. It sends a 140-byte segment and then a short time thereafter sends one
    of 180 bytes. The server is busy, however, and when it receives the first transmission,
    it decides to reduce its buffer to 240 bytes. It holds the 140 bytes just received
    and reduces its receive window all the way down to 100 bytes. When the client''s
    180-byte segment arrives, there is room for only 100 of the 180 bytes in the server''s
    buffer. When the client gets the new window size advertisement of 100, it will
    have a problem, because it already has 180 bytes sent but not acknowledged.")
    illustrates graphically how this situation would play out.'
  prefs: []
  type: TYPE_NORMAL
- en: '![The problem with shrinking the TCP window In this modification of the example
    of , the client begins with a usable window size of 360 bytes. It sends a 140-byte
    segment and then a short time thereafter sends one of 180 bytes. The server is
    busy, however, and when it receives the first transmission, it decides to reduce
    its buffer to 240 bytes. It holds the 140 bytes just received and reduces its
    receive window all the way down to 100 bytes. When the client''s 180-byte segment
    arrives, there is room for only 100 of the 180 bytes in the server''s buffer.
    When the client gets the new window size advertisement of 100, it will have a
    problem, because it already has 180 bytes sent but not acknowledged.](httpatomoreillycomsourcenostarchimages288139.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-5. The problem with shrinking the TCP window In this modification
    of the example of [Figure 49-4](ch49s04.html#tcp_window_size_adjustments_and_flow_con
    "Figure 49-4. TCP window size adjustments and flow control This diagram shows
    three message cycles, each of which results in the server reducing its receive
    window. In the first cycle, the server reduces it from 360 to 260 bytes, so the
    client's usable window can increase by only 40 bytes when it gets the server's
    acknowledgment. In the second and third cycles, the server reduces the window
    size by the amount of data it receives, which temporarily freezes the client's
    send window size, halting it from sending new data."), the client begins with
    a usable window size of 360 bytes. It sends a 140-byte segment and then a short
    time thereafter sends one of 180 bytes. The server is busy, however, and when
    it receives the first transmission, it decides to reduce its buffer to 240 bytes.
    It holds the 140 bytes just received and reduces its receive window all the way
    down to 100 bytes. When the client's 180-byte segment arrives, there is room for
    only 100 of the 180 bytes in the server's buffer. When the client gets the new
    window size advertisement of 100, it will have a problem, because it already has
    180 bytes sent but not acknowledged.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing Buffer Size Without Shrinking the Window
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To prevent the problems associated with shrinking windows from occurring, TCP
    adds a simple rule to the basic sliding window mechanism: A device is not allowed
    to shrink the window.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is a potential terminology ambiguity here. The words *shrinking*
    and *reducing* are sometimes used synonymously in colloquial discussions. As we've
    seen, there's nothing wrong with *reducing* the size of the window. The problem
    of *shrinking* the window refers only to the case where we reduce the window size
    so much that we contradict a prior window advertisement by *taking back* permission
    to send a certain number of bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Another way of looking at this is that *shrinking* occurs whenever the server
    sends back a window size advertisement smaller than what the client considers
    its usable window size to be at that time. In this case, the server shrunk the
    window, because at the time it was acknowledging the 140 bytes, it sent back a
    window size of 100, which is less than the 220-byte usable window the client had
    then.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there may be cases where we *do* need to reduce a buffer, so how
    should this be handled? Instead of shrinking the window, the server must be more
    patient. In the example in the previous section, where the buffer needs to be
    reduced to 240 bytes, the server must send back a window size of 220, freezing
    the right edge of the client's send window. The client can still fill the 360-byte
    buffer, but it cannot send more than that. As soon as 120 bytes are removed from
    the server's receive buffer, the buffer can then be reduced in size to 240 bytes
    with no data loss. Then the server can resume normal operation, increasing the
    window size as bytes are taken from the receive buffer.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A phenomenon called *shrinking* the *window* occurs when a
    device reduces its receive window so much that its partner device''s usable transmit
    window shrinks in size (meaning that the right edge of its send window moves to
    the left). Since this can result in data already in transit needing to be discarded,
    devices must instead reduce their receive window size more gradually.'
  prefs: []
  type: TYPE_NORMAL
- en: Handling a Closed Window and Sending Probe Segments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another special window management problem is how to deal with the case where
    a device must reduce the send window size all the way down to zero. As noted earlier,
    this is called *closing the receive window*. Since the server's receive window
    is the client's send window, reducing its size to zero means the client cannot
    send any more data. This situation continues until the client receives from the
    server a new acknowledgment with a nonzero Window field, which reopens the window.
    Then the client is able to send again.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this situation is that the client must depend on receipt of
    the "window opening" segment from the server. Like all TCP segments, this segment
    is carried over IP, which is unreliable. Remember that TCP is reliable only because
    it acknowledges sent data and retransmits lost data if necessary, but it can never
    *guarantee* that any particular segment gets to its destination. This means that
    when the server tries to reopen the window with an acknowledgment segment containing
    a larger Window field, it's possible that the client will never get the message.
    The client might conclude that a problem had occurred and terminate the connection.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent this from happening, the client can regularly send special *probe*
    segments to the server. The purpose of these probes is to prompt the server to
    send back a segment containing the current window size. The probe segment can
    contain either zero or one byte of data, even when the window is closed. The probes
    will continue to be sent periodically until the window reopens, with the particular
    implementation determining the rate at which the probes are generated.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** A device that reduces its receive window to zero is said to
    have *closed* the window. The other device''s send window is thus closed; it may
    not send regular data segments. It may, however, send probe segments to check
    the status of the window, thus making sure it does not miss notification when
    the window reopens.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the server decides to reopen the closed window, there is another potential
    pitfall: opening the window to too small a value. In general, when the receive
    window is too small, this leads to the generation of many small segments, greatly
    reducing the overall efficiency of TCP. The next section explores this well-known
    problem and how it is resolved through changes to the basic sliding window mechanism.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Silly Window Syndrome
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the description of TCP's maximum segment size (MSS) parameter in [Chapter 48](ch48.html
    "Chapter 48. TCP MESSAGE FORMATTING AND DATA TRANSFER"), I explained the trade-off
    in determining the optimal size of TCP segments. If segments are too large, we
    risk having them become fragmented at the IP level. If they're too small, we get
    greatly reduced performance, because we are sending a small amount of data in
    a segment with at least 40 bytes of header overhead. We also use up valuable processing
    time that is required to handle each of these small segments.
  prefs: []
  type: TYPE_NORMAL
- en: The MSS parameter ensures that we don't send segments that are too large; TCP
    is not allowed to create a segment larger than the MSS. Unfortunately, the basic
    sliding windows mechanism doesn't provide any *minimum* size of segment that can
    be transmitted. In fact, not only is it *possible* for a device to send very small,
    inefficient segments, the simplest implementation of flow control using unrestricted
    window size adjustments *ensures* that under conditions of heavy load, window
    size will become small, leading to significant performance reduction!
  prefs: []
  type: TYPE_NORMAL
- en: How Silly Window Syndrome Occurs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To see how the *silly window syndrome (SWS)* can happen, let's consider an example
    that is a variation on the one we've been using so far in this section. We'll
    assume the MSS is 360 bytes and a client/server pair where the server's initial
    receive window is set to this same value, 360\. This means the client can send
    a full-sized segment to the server. As long as the server can keep removing the
    data from the buffer as fast as the client sends it, we should have no problem.
    (In reality, the buffer size would normally be larger than the MSS.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, imagine that instead, the server is bogged down for whatever reason while
    the client needs to send it a great deal of data. For simplicity, let''s say that
    the server is able to remove only 1 byte of data from the buffer for every 3 bytes
    it receives. Let''s say it also removes 40 additional bytes from the buffer during
    the time it takes for the next client''s segment to arrive. Here''s what will
    happen:'
  prefs: []
  type: TYPE_NORMAL
- en: The client's send window is 360 bytes, and it has a lot of data to send. It
    immediately sends a 360-byte segment to the server. This uses up its entire send
    window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the server gets this segment, it acknowledges it. However, it can remove
    only 120 bytes, so the server reduces the window size from 360 to 120 bytes. It
    sends this in the Window field of the acknowledgment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client receives an acknowledgment of 360 bytes and sees that the window
    size has been reduced to 120\. It wants to send its data as soon as possible,
    so it sends off a 120-byte segment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The server has removed 40 more bytes from the buffer by the time the 120-byte
    segment arrives. The buffer thus contains 200 bytes (240 from the first segment,
    less the 40 removed). The server is able to immediately process one-third of those
    120 bytes, or 40 bytes. This means 80 bytes are added to the 200 that already
    remain in the buffer, so 280 bytes are used up. The server must reduce the window
    size to 80 bytes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client will see this reduced window size and send an 80-byte segment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The server started with 280 bytes and removed 40, so 240 bytes remain. It receives
    80 bytes from the client and removes one-third, so 53 are added to the buffer,
    which becomes 293 bytes. It reduces the window size to 67 bytes (360 minus 293).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process, which is illustrated in [Figure 49-6](ch49s06.html#tcp_silly_window_syndrome_sws_this_diagr
    "Figure 49-6. TCP silly window syndrome (SWS) This diagram shows one example of
    how the phenomenon known as TCP silly window syndrome can arise. The client is
    trying to send data as fast as possible to the server, which is very busy and
    cannot clear its buffers promptly. Each time the client sends data, the server
    reduces its receive window. The size of the messages the client sends shrinks
    until it is sending only very small, inefficient segments. Note that in this diagram,
    I have shown the server's buffer fixed in position, rather than sliding to the
    right, as in the other diagrams in this chapter. This way, you can see the receive
    window decreasing in size more easily."), will continue for many rounds, with
    the window size getting smaller and smaller, especially if the server gets even
    more overloaded. Its rate of clearing the buffer may decrease even more, and the
    window may close entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Let's suppose this happens. Now, eventually, the server will remove some of
    the data from this buffer. Let's say it removes 40 bytes by the time the first
    closed-window probe from the client arrives. The server then reopens the window
    to a size of 40 bytes. The client is still desperate to send data as fast as possible,
    so it generates a 40-byte segment. And so it goes, with likely all the remaining
    data passing from the client to the server in tiny segments, until either the
    client runs out of data or the server clears the buffer more quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine the worst-case scenario. This time, it is the application process
    on the server that is overloaded. It is drawing data from the buffer one byte
    at a time. Every time it removes a byte from the server's buffer, the server's
    TCP opens the window with a window size of exactly 1 and puts this in the Window
    field in an acknowledgment to the client. The client then sends a segment with
    exactly one byte, refilling the buffer until the application draws off the next
    byte.
  prefs: []
  type: TYPE_NORMAL
- en: None of this represents a *failure* per se of the sliding window mechanism.
    It is working properly to keep the server's receive buffer filled and to manage
    the flow of data. The problem is that the sliding window mechanism is concerned
    only with managing the buffer. It doesn't take into account the inefficiency of
    the small segments that result when the window size is micromanaged in this way.
    In essence, by sending small window size advertisements, we are winning the battle
    but losing the war.
  prefs: []
  type: TYPE_NORMAL
- en: Early TCP/IP researchers who discovered this phenomenon called it *silly window
    syndrome (SWS)*, a play on the phrase *sliding window system*, which expresses
    their opinion on how it behaves when it gets into this state.
  prefs: []
  type: TYPE_NORMAL
- en: '![TCP silly window syndrome (SWS) This diagram shows one example of how the
    phenomenon known as TCP silly window syndrome can arise. The client is trying
    to send data as fast as possible to the server, which is very busy and cannot
    clear its buffers promptly. Each time the client sends data, the server reduces
    its receive window. The size of the messages the client sends shrinks until it
    is sending only very small, inefficient segments. Note that in this diagram, I
    have shown the server''s buffer fixed in position, rather than sliding to the
    right, as in the other diagrams in this chapter. This way, you can see the receive
    window decreasing in size more easily.](httpatomoreillycomsourcenostarchimages288141.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 49-6. TCP silly window syndrome (SWS) This diagram shows one example
    of how the phenomenon known as TCP silly window syndrome can arise. The client
    is trying to send data as fast as possible to the server, which is very busy and
    cannot clear its buffers promptly. Each time the client sends data, the server
    reduces its receive window. The size of the messages the client sends shrinks
    until it is sending only very small, inefficient segments. Note that in this diagram,
    I have shown the server's buffer fixed in position, rather than sliding to the
    right, as in the other diagrams in this chapter. This way, you can see the receive
    window decreasing in size more easily.
  prefs: []
  type: TYPE_NORMAL
- en: The examples discussed show how SWS can be caused by the advertisement of small
    window sizes by a receiving device. It is also possible for SWS to happen if the
    sending device isn't careful about how it generates segments for transmission,
    regardless of the state of the receiver's buffers. For example, suppose the client
    TCP in the example shown in [Figure 49-6](ch49s06.html#tcp_silly_window_syndrome_sws_this_diagr
    "Figure 49-6. TCP silly window syndrome (SWS) This diagram shows one example of
    how the phenomenon known as TCP silly window syndrome can arise. The client is
    trying to send data as fast as possible to the server, which is very busy and
    cannot clear its buffers promptly. Each time the client sends data, the server
    reduces its receive window. The size of the messages the client sends shrinks
    until it is sending only very small, inefficient segments. Note that in this diagram,
    I have shown the server's buffer fixed in position, rather than sliding to the
    right, as in the other diagrams in this chapter. This way, you can see the receive
    window decreasing in size more easily.") was receiving data from the sending application
    in blocks of 10 bytes at a time. However, the sending TCP was so impatient to
    get the data to the client that it took each 10-byte block and immediately packaged
    it into a segment, even though the next 10-byte block was coming shortly thereafter.
    This would result in a needless swarm of inefficient 10-byte segments.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** The basic TCP sliding window system sets no minimum size on
    transmitted segments. Under certain circumstances, this can result in a situation
    where many small, inefficient segments are sent, rather than a smaller number
    of large ones. Affectionately termed silly *window syndrome* (SWS), this phenomenon
    can occur either as a result of a recipient advertising window sizes that are
    too small or a transmitter being too aggressive in immediately sending out very
    small amounts of data.'
  prefs: []
  type: TYPE_NORMAL
- en: Silly Window Syndrome Avoidance Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since SWS is caused by the basic sliding window system not paying attention
    to the result of decisions that create small segments, dealing with SWS is conceptually
    simple: Change the system so that we avoid small window size advertisements, and
    at the same time, also avoid sending small segments. Since both the sender and
    recipient of data contribute to SWS, changes are made to the behavior of both
    to avoid SWS. These changes are collectively termed *SWS avoidance algorithms*.'
  prefs: []
  type: TYPE_NORMAL
- en: Receiver SWS Avoidance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's start with SWS avoidance by the receiver. As we saw in the previous example,
    the receiver contributed to SWS by reducing the size of its receive window to
    smaller and smaller values. This caused the right edge of the sender's send window
    to move by ever-smaller increments, leading to smaller and smaller segments. To
    avoid SWS, we simply make the rule that the receiver may not update its advertised
    receive window in such a way that this leaves too little usable window space on
    the part of the sender. In other words, we restrict the receiver from moving the
    right edge of the window by too small an amount. The usual minimum that the edge
    may be moved is either the value of the MSS parameter or one-half the buffer size,
    whichever is less.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how we might use this in the example shown in [Figure 49-6](ch49s06.html#tcp_silly_window_syndrome_sws_this_diagr
    "Figure 49-6. TCP silly window syndrome (SWS) This diagram shows one example of
    how the phenomenon known as TCP silly window syndrome can arise. The client is
    trying to send data as fast as possible to the server, which is very busy and
    cannot clear its buffers promptly. Each time the client sends data, the server
    reduces its receive window. The size of the messages the client sends shrinks
    until it is sending only very small, inefficient segments. Note that in this diagram,
    I have shown the server's buffer fixed in position, rather than sliding to the
    right, as in the other diagrams in this chapter. This way, you can see the receive
    window decreasing in size more easily."). When the server receives the initial
    360-byte segment from the client and can process only 120 bytes, it does not reduce
    the window size to 120\. It reduces it all the way to zero, closing the window.
    It sends this back to the client, which will then stop and not send a small segment.
    Once the server has removed 60 more bytes from the buffer, it will now have 180
    bytes free, half the size of the buffer. It now opens the window up to 180 bytes
    in size and sends the new window size to the client.
  prefs: []
  type: TYPE_NORMAL
- en: It will continue to advertise only either 0 bytes or 180 or more bytes, not
    smaller values in between. This seems to slow down the operation of TCP, but it
    really doesn't. Because the server is overloaded, the limiting factor in overall
    performance of the connection is the rate at which the server can clear the buffer.
    We are just exchanging many small segments for a few larger ones.
  prefs: []
  type: TYPE_NORMAL
- en: Sender SWS Avoidance and Nagle's Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'SWS avoidance by the sender is accomplished generally by imposing "restraint"
    on the part of the transmitting TCP. Instead of trying to immediately send data
    as soon as we can, we wait to send it until we have a segment of a reasonable
    size. The specific method for doing this is called *Nagle''s algorithm*, named
    for its inventor, John Smith. (Just kidding, it was John Nagle.) Simplified, this
    algorithm works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: As long as there is no unacknowledged data outstanding on the connection, as
    soon as the application wants, data can be immediately sent. For example, in the
    case of an interactive application like Telnet, a single keystroke can be pushed
    in a segment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there *is* unacknowledged data, all subsequent data to be sent is held
    in the transmit buffer and not transmitted until either all the unacknowledged
    data is acknowledged or we have accumulated enough data to send a full-sized (MSS-sized)
    segment. This applies even if a push is requested by the user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This might seem strange, especially the part about buffering data despite a
    push request! You might think this would cause applications like Telnet to break.
    In fact, Nagle's algorithm is a very clever method that suits the needs of both
    low-data-rate interactive applications like Telnet and high-bandwidth file-transfer
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using something like Telnet where the data is arriving very slowly
    (humans are very slow compared to computers), the initial data (first keystroke)
    can be pushed right away. The next keystroke must wait for an acknowledgment,
    but this will probably come reasonably soon relative to how long it takes to hit
    the next key. In contrast, more conventional applications that generate data in
    large amounts will automatically have the data accumulated into larger segments
    for efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Nagle's algorithm is actually far more complex than this description, but this
    section is already getting too long. RFC 896 discusses it in (much) more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** Modern TCP implementations incorporate a set of *SWS avoidance
    algorithms*. When receiving, devices are programmed not to advertise very small
    windows, waiting instead until there is enough room in the buffer for one of a
    reasonable size. Transmitters use *Nagle''s algorithm* to ensure that small segments
    are not generated when there are unacknowledged bytes outstanding.'
  prefs: []
  type: TYPE_NORMAL
- en: TCP Congestion Handling and Congestion Avoidance Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By changing the window size that a device advertises to a peer on a TCP connection,
    the device can increase or decrease the rate at which its peer sends it data.
    This is how the TCP sliding window system implements flow control between the
    two connected devices. We've seen how this works in this chapter, including the
    changes required to the basic mechanism to ensure performance remains high by
    reducing the number of small segments sent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Flow control is a very important part of regulating the transmission of data
    between devices, but it is limited in the following respect: It considers only
    what is going on within each of the devices on the connection, and *not* what
    is happening in devices between them. In fact, this "self-centeredness" is symptomatic
    of architectural layering. Since we are dealing with how TCP works between a typical
    server and client at layer 4, we don''t worry about how data gets between them;
    that''s the job of IP at layer 3.'
  prefs: []
  type: TYPE_NORMAL
- en: Congestion Considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, what is going on at layer 3 can be quite important. Considered
    from an abstract point of view, our server and client may be connected directly
    using TCP, but all the segments we transmit are carried across an internetwork
    of networks and routers between them. These networks and routers are also carrying
    data from many other connections and higher-layer protocols. If the internetwork
    becomes very busy, the speed at which segments are carried between the endpoints
    of our connection will be reduced, and they could even be dropped. This is called
    *congestion*.
  prefs: []
  type: TYPE_NORMAL
- en: Again, at the TCP level, there is no way to directly comprehend what is causing
    congestion or why. It is perceived simply as inefficiencies in moving data from
    one device to another, through the need for some segments to be retransmitted.
    However, even though TCP is mostly oblivious to what is happening on the internetwork,
    it *must* be smart enough to understand how to deal with congestion and not exacerbate
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that each segment that is transmitted is placed in the retransmission
    queue with a retransmission timer. Now, suppose congestion dramatically increased
    on the internetwork, and there were no mechanisms in place to handle congestion.
    Segments would be delayed or dropped, which would cause them to time out and be
    retransmitted. This would increase the amount of traffic on the internetwork between
    our client and server. Furthermore, there might be thousands of other TCP connections
    behaving similarly. Each would keep retransmitting more and more segments, increasing
    congestion further, leading to a vicious circle. Performance of the entire internetwork
    would decrease dramatically, resulting in a condition called *congestion collapse*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The message is clear: TCP cannot just ignore what is happening on the internetwork
    between its connection endpoints. To this end, TCP includes several specific algorithms
    that are designed to respond to congestion or avoid it in the first place. Many
    of these techniques can be considered, in a way, to be methods by which a TCP
    connection is made less selfish; that is, it tries to take into account the existence
    of other users of the internetwork over which it operates. While no single connection
    by itself can solve congestion of an entire internetwork, having all devices implement
    these measures collectively reduces congestion due to TCP.'
  prefs: []
  type: TYPE_NORMAL
- en: The first issue is that we need to know when congestion is taking place. By
    definition, congestion means intermediate devices—routers—are overloaded. Routers
    respond to overloading by dropping datagrams. When these datagrams contain TCP
    segments, the segments don't reach their destination, and they are therefore left
    unacknowledged and will eventually expire and be retransmitted. This means that
    when a device sends TCP segments and does not receive acknowledgments for them,
    it can be assumed that, in most cases, they have been dropped by intermediate
    devices due to congestion. By detecting the rate at which segments are sent and
    not acknowledged, a TCP device can infer the level of congestion on the network
    between itself and its TCP connection peer.
  prefs: []
  type: TYPE_NORMAL
- en: TCP Congestion-Handling Mechanisms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After getting information about congestion, we must then decide what to do with
    that information. The main TCP standard, RFC 793, includes very little information
    about TCP congestion-handling issues. That is because early versions of TCP based
    solely on this standard didn't include congestion-handling measures. Problems
    with these early implementations led to the discovery that congestion was an important
    issue. The measures used in modern devices were developed over the years, and
    eventually documented in RFC 2001, "TCP Slow Start, Congestion Avoidance, Fast
    Retransmit, and Fast Recovery Algorithms."
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEY CONCEPT** TCP flow control is an essential part of regulating the traffic
    flow between TCP devices, but takes into account only how busy the two TCP endpoints
    are. It is also important to take into account the possibility of *congestion*
    of the networks over which any TCP session is established, which can lead to inefficiency
    through dropped segments. To deal with congestion and avoid contributing to it
    unnecessarily, modern TCP implementations include a set of Congestion Avoidance
    algorithms that alter the normal operation of the sliding window system to ensure
    more efficient overall operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RFC 2001 refers to four algorithms: Slow Start, Congestion Avoidance, Fast
    Retransmit, and Fast Recovery. In practice, these features are all related to
    each other. Slow Start and Congestion Avoidance are distinct algorithms but are
    implemented using a single mechanism, involving the definition of a *congestion
    window* that limits the size of transmissions and whose size is increased or decreased
    depending on congestion levels. Fast Retransmit and Fast Recovery are implemented
    as changes to the mechanism that implements Slow Start and Congestion Avoidance.'
  prefs: []
  type: TYPE_NORMAL
- en: The following sections provide simplified summaries of how these algorithms
    work. My goal is simply to help you get a feel for how congestion is handled in
    TCP in general terms.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Congestion handling is a rather complex process. If you want to learn more,
    RFC 2001 contains the technical details, showing how each of the algorithms is
    implemented in each device.
  prefs: []
  type: TYPE_NORMAL
- en: Slow Start
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the original implementation of TCP, as soon as a connection was established
    between two devices, they could each go "hog wild," sending segments as fast as
    they liked as long as there was room in the other device's receive window. In
    a busy internetwork, the sudden appearance of a large amount of new traffic could
    exacerbate any existing congestion. To alleviate this, modern TCP devices are
    restrained in the rate at which they initially send segments.
  prefs: []
  type: TYPE_NORMAL
- en: Each sender is at first restricted to sending only an amount of data equal to
    one full-sized segment—that is, equal to the MSS value for the connection. Each
    time an acknowledgment is received, the amount of data the device can send is
    increased by the size of another full-sized segment. Thus, the device starts slow
    in terms of how much data it can send, with the amount it sends increasing until
    either the full window size is reached or congestion is detected on the link.
    In the latter case, the Congestion Avoidance feature, described next, is used.
  prefs: []
  type: TYPE_NORMAL
- en: Congestion Avoidance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When potential congestion is detected on a TCP link, a device responds by throttling
    back the rate at which it sends segments. A special algorithm is used that allows
    the device to drop the rate at which segments are sent quickly when congestion
    occurs. The device then uses the Slow Start algorithm to gradually increase the
    transmission rate back up again to try to maximize throughput without congestion
    occurring again.
  prefs: []
  type: TYPE_NORMAL
- en: Fast Retransmit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We've already seen in our look at TCP segment retransmission that when segments
    are received by a device out of order (noncontiguously), the recipient will acknowledge
    only the ones received contiguously. The Acknowledgment Number field will specify
    the sequence number of the byte it expects to receive next. So, in the example
    given in that section, Segments 1 and 2 were acknowledged, while Segment 4 was
    not because Segment 3 was not received.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible for a TCP device to respond with an acknowledgment when it receives
    an out-of-order segment, simply reiterating that it is stuck waiting for a particular
    byte number. So, when the client in that example receives Segment 4 and not Segment
    3, it could send back an acknowledgment saying, "I am expecting the first byte
    of Segment 3 next."
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose this happens over and over. The server, not realizing that Segment
    3 was lost, sends Segments 5, 6, and so on. Each time a segment is received, the
    client sends back an acknowledgment specifying the first byte number of Segment
    3\. Eventually, the server can reasonably conclude that Segment 3 is lost, even
    if its retransmission timer has not expired.
  prefs: []
  type: TYPE_NORMAL
- en: The Fast Retransmit feature dictates that if three or more of these acknowledgments
    are received, all saying, "I want the segment starting with byte *N*," then it's
    probable that the segment starting with byte *N* has been lost, usually because
    it was dropped due to congestion. In this case, the device will immediately retransmit
    the missing segment, without going through the normal retransmission queue process.
    This improves performance by eliminating delays that would suspend effective data
    flow on the link.
  prefs: []
  type: TYPE_NORMAL
- en: Fast Recovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When Fast Retransmit is used to resend a lost segment, the device using it performs
    Congestion Avoidance, but does not use Slow Start to increase the transmission
    rate back up again. The rationale for this is that since multiple ACKs were received
    by the sender, all indicating receipt of out-of-order segments, this indicates
    that several segments have already been removed from the flow of segments between
    the two devices. For efficiency reasons, then, the transmission rate can be increased
    more quickly than when congestion occurs in other ways. This improves performance
    compared to using the regular Congestion Avoidance algorithm after Fast Retransmit.
  prefs: []
  type: TYPE_NORMAL
