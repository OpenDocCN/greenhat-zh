<html><head></head><body><section class="chapter" epub:type="chapter" id="more_filesystems" title="Chapter&#xA0;9.&#xA0;More Filesystems"><div class="titlepage"><div><div><h2 class="title">Chapter 9. More Filesystems</h2></div></div></div><div class="epigraph" epub:type="epigraph"><div class="literallayout"><p><span class="emphasis"><em>Encrypt your hard drive?</em></span><br/>
<span class="emphasis"><em>Software RAID can save your day,</em></span><br/>
<span class="emphasis"><em>or ruin your life.</em></span></p></div></div><p><span class="inlinemediaobject"><a id="inline_id00010"/><img alt="" src="httpatomoreillycomsourcenostarchimages1616079.png"/></span> Disk management isn’t complicated, but there’s enough material that it gets two chapters. Lucky you! In this chapter, we’ll start with how to automatically back up your vital root partition to a second disk. Then we’ll explore how OpenBSD can use additional memory as disk space via a memory filesystem and how to set that up. Next, we’ll access disks formatted for other operating systems, such as NTFS, ext2, and FAT. Removable media isn’t difficult to work with, but has its own concerns. If you don’t need the actual media, but can work with disk images, you can access those. Both topics are covered in this chapter. We’ll also discuss using NFS, as both a server and a client. Our final topic is OpenBSD’s disk redundancy and disk encryption features.</p><div class="sect1" title="Backing Up to the /altroot Partition"><div class="titlepage"><div><div><h2 class="title" id="backing_up_to_the_altroot_partition" style="clear: both">Backing Up to the /altroot Partition</h2></div></div></div><p><a class="indexterm" id="idx0046"/><a class="indexterm" id="idx0103"/><a class="indexterm" id="idx0548"/><a class="indexterm" id="idx0580"/><a class="indexterm" id="idx0849"/><a class="indexterm" id="idx1349"/><a class="indexterm" id="idx1364"/><a class="indexterm" id="idx1982"/>You can lose most of your partitions and still hope to recover the rest of the system. If you lose your root filesystem, however, recovery becomes a much more difficult task. While you could back up critical files from <span class="emphasis"><em>/etc</em></span> and use them to restore your system, OpenBSD provides the <span class="emphasis"><em>/altroot</em></span> partition as an easy way to automatically duplicate the root partition on a second disk.</p><p>An emergency root partition on a second disk gives you an easier path to recovery in the event of a disk failure. Booting to the second disk lets you pull any data off that disk, and possibly even from undamaged partitions on the first disk, before replacing the failed disk. There’s no reason to back up your root partition to the same disk, however, as the whole disk will probably be unusable.</p><p>This backup requires a free disk partition the same size as your root partition, located on a different disk. The OpenBSD installer defaults assume that you have only one disk. If you have a second disk during installation, you need to use a custom install process to create the <span class="emphasis"><em>/altroot</em></span> partition, as we did in the multiple disk installation in <a class="xref" href="ch03.html" title="Chapter 3. Installation Walk-Through">Chapter 3</a>. While configuring partitions is easiest during the installation, you can add more disks later if needed, as discussed in <a class="xref" href="ch08.html" title="Chapter 8. Disks and Filesystems">Chapter 8</a>.</p><p>Your <span class="emphasis"><em>/altroot</em></span> partition needs an <span class="emphasis"><em>/etc/fstab</em></span> entry. If you created the partition during the install process, that <span class="emphasis"><em>/etc/fstab</em></span> entry already exists but has the wrong mount type. If you created this partition after installation, you’ll need to create an <span class="emphasis"><em>/etc/fstab</em></span> entry yourself. The /<span class="emphasis"><em>altroot</em></span> partition needs a mount type of <code class="literal">xx</code>, as shown here:</p><a id="I_programlisting9_id451025"/><pre class="programlisting">a914f9a264fa64e6.a /altroot ffs xx 0 0</pre><p>You cannot mount this partition from its <span class="emphasis"><em>/etc/fstab</em></span> entry, as <code class="literal">xx</code> is not a valid mount type. (You could run, say, <code class="literal">mount /dev/sd1a /altroot</code> if you want to manually mount this partition.) The daily system maintenance job <span class="emphasis"><em>/etc/daily</em></span> uses this mount option to identify the root backup partition.</p><p>To enable the <span class="emphasis"><em>/altroot</em></span> backup, add <code class="literal">ROOTBACKUP=1</code> to your <span class="emphasis"><em>/etc/daily.local</em></span> file.</p></div><div class="sect1" title="Memory Filesystems"><div class="titlepage"><div><div><h2 class="title" id="memory_filesystems" style="clear: both">Memory Filesystems</h2></div></div></div><p>In addition to creating partitions on raw disk, OpenBSD lets you create partitions in system memory. A <span class="emphasis"><em>memory filesystem</em></span> (<span class="emphasis"><em>MFS</em></span>), or <span class="emphasis"><em>memory disk</em></span>, lives in your machine’s RAM, rather than on a physical disk. Reading and writing files to and from such a filesystem is much faster than accessing those same files on a spinning disk, which makes a memory-backed filesystem a huge optimization for certain applications.</p><p>If MFSs sound too good to be true for high-performance environments, that’s because they are. Understand their limits before you implement them everywhere. First, RAM does not persist across reboots or shutdowns, so either will erase the contents of an MFS. While this might seem obvious, I’ve surprised myself more than once by losing a file stored on a filesystem I had forgotten was an MFS. Furthermore, if your system crashes, you’ll lose any data stored on an MFS.</p><p><a class="indexterm" id="idx0561"/><a class="indexterm" id="idx0605"/><a class="indexterm" id="idx1350"/><a class="indexterm" id="idx1351"/><a class="indexterm" id="idx1403"/><a class="indexterm" id="idx1407"/><a class="indexterm" id="idx1713"/>You can use an MFS partition as scratch space to rapidly compile, compress, decompress, or otherwise manipulate temporary files. I’ve seen news server histories, database locks, and other application-specific files stored on MFSs.</p><p>An MFS works even in situations where the system regularly swaps. The kernel retains any information being actively used in memory, while transferring unused information to swap space. This is excellent for small partitions like <span class="emphasis"><em>/tmp</em></span>, in which small, frequently used files can be quickly accessed. Files that are less frequently accessed end up in swap space, which gives performance similar to accessing a physical disk.</p><p>One last word of caution: Don’t make heavy use of MFSs if you don’t have RAM to spare. If you run short on combined memory and swap space, your system will perform very poorly.</p><div class="sect2" title="Creating MFS Partitions"><div class="titlepage"><div><div><h3 class="title" id="creating_mfs_partitions">Creating MFS Partitions</h3></div></div></div><p>Create temporary MFS partitions with <code class="literal">mount_mfs(8)</code>. Like other <code class="literal">mount_</code> commands, <code class="literal">mount_mfs</code> takes two arguments: the physical device and a mount point. Unlike physical disks, memory doesn’t have a device node, so use the device node of the system swap space. If you have multiple swap partitions, pick whichever you like.</p><p>Here is how you can create a memory-backed filesystem by passing a swap partition, <span class="emphasis"><em>/dev/sd0b</em></span>, and a desired mount point, <span class="emphasis"><em>/mnt</em></span>, as arguments to <code class="literal">mount_mfs</code>:</p><a id="I_programlisting9_id451219"/><pre class="programlisting"># <span class="strong"><strong>mount_mfs /dev/sd0b /mnt</strong></span></pre><p>The size of this partition will be limited only by the size of your swap partition.</p><p>You can create smaller memory-backed filesystems, so that you will have memory and/or swap space available if you fill the memory disk. Specify the size with the <code class="literal">-s</code> flag and a number of sectors, or with a trailing <code class="literal">b</code> (bytes), <code class="literal">m</code> (megabytes), or <code class="literal">g</code> (gigabytes). Here’s how to create a 128MB MFS on <span class="emphasis"><em>/mnt</em></span>:</p><a id="I_programlisting9_id451256"/><pre class="programlisting"># <span class="strong"><strong>mount_mfs -s 128m /dev/sd0b /mnt</strong></span></pre><p>If you request an MFS larger than your system can support, you’ll get a warning like <code class="literal">mmap: Cannot allocate memory</code>. Try again, this time with a more reasonable size.</p></div><div class="sect2" title="Mounting an MFS at Boot"><div class="titlepage"><div><div><h3 class="title" id="mounting_an_mfs_at_boot">Mounting an MFS at Boot</h3></div></div></div><p>You can mount an MFS at boot by adding an <span class="emphasis"><em>/etc/fstab</em></span> entry. You only need a mount point and the partition size.</p><a id="I_programlisting9_id451290"/><pre class="programlisting"><span class="strong"><strong>1</strong></span>swap   <span class="strong"><strong>2</strong></span>/mnt   <span class="strong"><strong>3</strong></span>mfs   <span class="strong"><strong>4</strong></span>rw,async,-s=128m   <span class="strong"><strong>5</strong></span>0   <span class="strong"><strong>6</strong></span>0</pre><p><a class="indexterm" id="idx0818"/><a class="indexterm" id="idx0843"/><a class="indexterm" id="idx0880"/><a class="indexterm" id="idx1034"/><a class="indexterm" id="idx1370"/><a class="indexterm" id="idx1554"/><a class="indexterm" id="idx2635"/>You don’t need to specify a specific swap device; OpenBSD is smart enough to let you say the memory disk is generically swap-backed <span class="strong"><strong>1</strong></span>. Just as with any other partition, you also need to specify the mount point <span class="strong"><strong>2</strong></span> and the filesystem type <span class="strong"><strong>3</strong></span>.</p><p>When dealing with a memory disk, you can use different options than you would for a traditional disk <span class="strong"><strong>4</strong></span>. Since a system crash would destroy all files on the MFS anyway, you can safely mount an MFS partition as asynchronous using the <code class="literal">async</code> option. You might also want to use <code class="literal">nodev</code> and <code class="literal">nosuid</code> mount options on this partition. You can specify the size with the <code class="literal">-s</code> option, but make sure that you put an equal sign (<code class="literal">=</code>) between the <code class="literal">-s</code> and the size. Because <span class="emphasis"><em>/etc/fstab</em></span> uses whitespace to separate fields, OpenBSD will think the dump level is 128m if you don’t use an equal sign.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.id344921" id="id344921">21</a>]</sup></p><p>Data on a memory disk is by definition disposable, so don’t back it up <span class="strong"><strong>5</strong></span>. Similarly, never use <code class="literal">fsck(8)</code> with a memory disk at boot <span class="strong"><strong>6</strong></span>. The memory disk is created anew at each boot, so it is automatically internally consistent.</p></div></div><div class="sect1" title="Foreign Filesystems"><div class="titlepage"><div><div><h2 class="title" id="foreign_filesystems" style="clear: both">Foreign Filesystems</h2></div></div></div><p>Any partition that uses a non-FFS filesystem is foreign to OpenBSD. Although OpenBSD can access many foreign filesystems, don’t expect it to be seamless.</p><p>Support for some filesystems is incomplete. For example, you can mount Microsoft NTFS partitions only as read-only. Other filesystems don’t support the full range of OpenBSD commands. Because FAT filesystems don’t have any concept of file ownership or permissions, commands like <code class="literal">chmod</code> and <code class="literal">chown</code> won’t change anything on the disk.</p><p>Each supported filesystem has its own mount program to handle the vagaries of that filesystem. To simplify your life, <code class="literal">mount</code> can usually recognize supported filesystems from the on-disk format and call the correct mount program as needed. To mount a foreign filesystem, you need the device node and a mount point. Depending on the filesystem, you may also need to know the type of filesystem you’ll be mounting.</p><div class="sect2" title="Inodes vs. Vnodes"><div class="titlepage"><div><div><h3 class="title" id="inodes_vs_vnodes">Inodes vs. Vnodes</h3></div></div></div><p>Before we talk about foreign filesystems, let’s touch on something that confused me for a long time: the difference between inodes and vnodes.</p><p>The FFS uses index nodes, or <span class="emphasis"><em>inodes</em></span>, to map blocks of disk that contain data. This worked just dandy when hard drives were big, expensive things that no one moved between computers. Over the years, however, swapping disks between machines has become more popular.</p><p>Although Unix-like systems think in terms of accessing files via inodes, the FAT32 filesystem doesn’t use inodes, ext2fs’s inodes don’t map directly onto FFS inodes, and CDs use a completely different layout. To access all of these filesystems in a consistent way, BSD needed another layer of abstraction.</p><p><a class="indexterm" id="idx1408"/><a class="indexterm" id="idx1409"/><a class="indexterm" id="idx1414"/><a class="indexterm" id="idx1553"/><a class="indexterm" id="idx2568"/><a class="indexterm" id="idx2614"/><a class="indexterm" id="idx2632"/>The virtual node, or <span class="emphasis"><em>vnode</em></span>, is an abstraction layer the kernel uses to access all filesystems. Users never manipulate vnodes directly, but you’ll see references to them throughout OpenBSD’s documentation. Every tool that reads or writes to disks does so through vnodes, which map the requests to the filesystem. When you write to an FFS block or inode, the kernel addresses data to a vnode, which in turn maps to an inode. When you write to a FAT32 filesystem, the kernel addresses data to a vnode mapped to a point in the FAT32 filesystem. You use inodes only when dealing with FFS systems, but your data will pass through a vnode when accessing any filesystem.</p><p>Don’t let references to vnodes on non-FFS systems confuse you. They’re part of OpenBSD, not the filesystem.</p></div><div class="sect2" title="Common Foreign Filesystems"><div class="titlepage"><div><div><h3 class="title" id="common_foreign_filesystems">Common Foreign Filesystems</h3></div></div></div><p>Common foreign filesystems include MS-DOS, NTFS, ext2fs, and CD. We’ll look at how to access disks formatted for those operating systems with OpenBSD.</p><div class="sect3" title="MS-DOS"><div class="titlepage"><div><div><h4 class="title" id="ms-dos">MS-DOS</h4></div></div></div><p>OpenBSD supports the FAT, FAT16, and FAT32 filesystems. These formats are commonly found on flash media, old Microsoft operating systems, and floppy disks.</p><p>To mount a filesystem with a FAT filesystem partition, use <code class="literal">mount_msdos(8)</code>.</p><a id="I_programlisting9_id451638"/><pre class="programlisting"># <span class="strong"><strong>mount_msdos /dev/sd3i /mnt</strong></span></pre><p>Not sure which partition on the disk is the FAT filesystem? Run <code class="literal">disklabel(8)</code> on the drive and see. FAT filesystems are often located on the <span class="emphasis"><em>i</em></span> partition. And even if you try inserting your USB drive and mounting its <span class="emphasis"><em>i</em></span> partition, OpenBSD will probably figure out that it’s a FAT system.</p><p>If you work with FAT disks often, you might investigate <span class="emphasis"><em>/usr/ports/sysutils/mtools</em></span>, a collection of software for working with FAT filesystems without mounting them. While <code class="literal">mount_msdos</code> is quite reliable, mtools offers a more elegant interface.</p></div><div class="sect3" title="NTFS"><div class="titlepage"><div><div><h4 class="title" id="ntfs">NTFS</h4></div></div></div><p>To mount disks formatted for modern Microsoft operating systems, use <code class="literal">mount_ntfs(8)</code>.</p><a id="I_programlisting9_id451693"/><pre class="programlisting"># <span class="strong"><strong>mount_ntfs /dev/sd3k /mnt</strong></span></pre><p>As I write this, OpenBSD supports NTFS4 (from Windows NT) and NTFS5 (in Windows 2000 and XP). Windows Vista and newer systems are not yet supported, but they might be by the time you read this.</p><p>If you need to view file attributes specific to the NTFS filesystem, check the <code class="literal">mount_ntfs</code> man page for details.</p></div><div class="sect3" title="ext2fs"><div class="titlepage"><div><div><h4 class="title" id="ext2fs">ext2fs</h4></div></div></div><p><a class="indexterm" id="idx0233"/><a class="indexterm" id="idx0238"/><a class="indexterm" id="idx0791"/><a class="indexterm" id="idx0792"/><a class="indexterm" id="idx1130"/><a class="indexterm" id="idx1385"/><a class="indexterm" id="idx1393"/><a class="indexterm" id="idx1397"/><a class="indexterm" id="idx1647"/>To mount ext2fs and ext3fs filesystems, use <code class="literal">mount_ext2fs(8)</code>. (The one program mounts both types of filesystem.)</p><a id="I_programlisting9_id451791"/><pre class="programlisting"># <span class="strong"><strong>mount_ext2fs /dev/sd3l /mnt</strong></span></pre><p>Owing to their shared Unix heritage, the Linux ext2fs and ext3fs filesystems support many FFS-like features. Unlike with NTFS, you can safely read and write ext2fs and ext3fs disks in OpenBSD. You cannot, however, read ext4fs partitions using OpenBSD.</p></div><div class="sect3" title="CD"><div class="titlepage"><div><div><h4 class="title" id="cd">CD</h4></div></div></div><p>Compact discs formatted for data use the ISO-9660 filesystem. To mount a CD, use <code class="literal">mount_cd9660(8)</code>.</p><a id="I_programlisting9_id451823"/><pre class="programlisting"># <span class="strong"><strong>mount_cd9660 /dev/cd0a /mnt</strong></span></pre><p>Mount CDs using either the <span class="emphasis"><em>a</em></span> or <span class="emphasis"><em>c</em></span> partition on the device. If you would like to save yourself a few keystrokes, <code class="literal">mount(8)</code> is very good at automatically detecting ISO-9660 filesystems. The device node for a CD is tied to the CD drive, not the disk itself, so the node shouldn’t change unless you add another drive.</p><p>If you’re interested in burning a CD, look at <code class="literal">mkhybrid(8)</code> and <code class="literal">cdio(1)</code>.</p></div></div><div class="sect2" title="Foreign Filesystem Ownership"><div class="titlepage"><div><div><h3 class="title" id="foreign_filesystem_ownership">Foreign Filesystem Ownership</h3></div></div></div><p>Most foreign filesystems either have no concept of file ownership or have an ownership scheme incompatible with that of Unix-like operating systems. (Notable among these filesystems are FAT and NTFS.) The programs that mount these kinds of filesystems thoughtfully allow you to specify the ownership of files on the filesystem. The <code class="literal">-u</code> flag lets you specify a file owner, and the <code class="literal">-g</code> flag lets you specify the group.</p><p>For example, here’s how I would mount a FAT filesystem as owned by my account:</p><a id="I_programlisting9_id451886"/><pre class="programlisting"># <span class="strong"><strong>mount_msdos -u mwlucas -g mwlucas /dev/sd3c /mnt</strong></span></pre><p>Some other filesystems use permissions schemes compatible with OpenBSD’s permissions. For example, all of the information OpenBSD needs to assign permissions to files and directories is contained within an ext2fs filesystem. That doesn’t mean that an ext2fs filesystem will perform seamlessly on OpenBSD, however. Though OpenBSD will respect the ext2fs disk’s permissions, the user ID numbers probably won’t match up between the operating systems.</p></div></div><div class="sect1" title="Removable Media"><div class="titlepage"><div><div><h2 class="title" id="removable_media" style="clear: both">Removable Media</h2></div></div></div><p><a class="indexterm" id="idx0235"/><a class="indexterm" id="idx0271"/><a class="indexterm" id="idx0607"/><a class="indexterm" id="idx0852"/><a class="indexterm" id="idx0870"/><a class="indexterm" id="idx1400"/><a class="indexterm" id="idx1956"/><a class="indexterm" id="idx2630"/>These days, the removable media you’ll most likely deal with are external hard drives, flash drives, and CDs. The CD is the simplest, because you know how to use <code class="literal">mount(8)</code> and <code class="literal">umount(8)</code>, and you know its device node and filesystem type will always be the same. But how do you identify the device name of a removable hard drive?</p><p>When you attach a drive to your machine, OpenBSD automatically assigns your drive a device node to your console and prints a message to the console. You can check the console as you attach the drive, or you can watch your messages log by running <code class="literal">tail -f /var/log/messages</code> before attaching the drive.</p><p>If you frequently use a particular removable disk, you can simplify your routine by making an <span class="emphasis"><em>/etc/fstab</em></span> entry for it. Here are some sample <span class="emphasis"><em>/etc/fstab</em></span> entries for a CD and a FAT flash drive.</p><a id="I_programlisting9_id452008"/><pre class="programlisting">/dev/cd0c /cdrom cd9660 ro,noauto
/dev/sd3i /mnt msdos rw,noauto</pre><p>You can’t use DUIDs for removable media, because the actual media might change.</p><p>Now you can mount your CD on <span class="emphasis"><em>/cdrom</em></span> by entering <code class="literal">mount /cdrom</code>, and your FAT flash drive on <span class="emphasis"><em>/mnt</em></span> by entering mount <code class="literal">/mnt</code>.</p><p>Note that OpenBSD does not create a <span class="emphasis"><em>/cdrom</em></span> directory by default; you’ll need to create it yourself. You could point both of these at <span class="emphasis"><em>/mnt</em></span>, but I like having a dedicated CD mount point on my systems, and having two devices share a mount point risks concealing one of the filesystems. (Remember that OpenBSD has stackable mounts, as discussed in <a class="xref" href="ch08.html" title="Chapter 8. Disks and Filesystems">Chapter 8</a>.)</p></div><div class="sect1" title="Mounting Filesystem Images"><div class="titlepage"><div><div><h2 class="title" id="mounting_filesystem_images" style="clear: both">Mounting Filesystem Images</h2></div></div></div><p>You can mount a disk image and access the image just as you would a disk partition. This is very useful for those times you want to extract a few files from an ISO but don’t want to bother burning the image to physical media. The trick to mounting a disk image is attaching the image to a device node so that you can use the proper <code class="literal">mount</code> command.</p><p>OpenBSD uses the <code class="literal">vnconfig(8)</code> program to attach disk images to device nodes. (Remember that a vnode is an abstraction layer between the kernel and a filesystem.) Use <code class="literal">vnconfig</code> to “wire” vnodes between a file and a device node, and then access them through OpenBSD’s <span class="emphasis"><em>/dev/svnd</em></span> devices. Depending on the disk image type, the image might have MBR partitions, disklabel partitions, or just a filesystem.</p><p>The default kernel has four vnode devices. If you need to mount more than four disk images simultaneously, edit your kernel binary using <code class="literal">config(8)</code>’s <code class="literal">-e</code> option, as discussed in <a class="xref" href="ch18.html" title="Chapter 18. Kernel Configuration">Chapter 18</a>.</p><div class="sect2" title="Attaching Vnode Devices to Disk Images"><div class="titlepage"><div><div><h3 class="title" id="attaching_vnode_devices_to_disk_images">Attaching Vnode Devices to Disk Images</h3></div></div></div><p><a class="indexterm" id="idx0420"/><a class="indexterm" id="idx0463"/><a class="indexterm" id="idx1389"/><a class="indexterm" id="idx1535"/><a class="indexterm" id="idx2631"/><a class="indexterm" id="idx2633"/><a class="indexterm" id="idx2634"/>The <code class="literal">vnconfig(8)</code> command takes two arguments: the device node you want to use and the disk image you want to mount.</p><a id="I_programlisting9_id452179"/><pre class="programlisting"># <span class="strong"><strong>vnconfig /dev/svnd<span class="emphasis"><em>X</em></span>c /path/to/file</strong></span></pre><p>Note that this example uses the <span class="emphasis"><em>c</em></span> partition of the device. This allows you to treat the disk image as a whole disk.</p><p>Suppose you have an ISO image named <span class="emphasis"><em>install52.iso</em></span> that you would like to mount. First, use <code class="literal">vnconfig</code> to attach this image to vnode device 0.</p><a id="I_programlisting9_id452210"/><pre class="programlisting"># <span class="strong"><strong>vnconfig /dev/vnd0c install52.iso</strong></span></pre><p>You can then use <code class="literal">mount</code> to attach the vnode to an <span class="emphasis"><em>/mnt</em></span> directory.</p><a id="I_programlisting9_id452230"/><pre class="programlisting"># <span class="strong"><strong>mount /dev/vnd0c /mnt/</strong></span></pre><p>OpenBSD’s <code class="literal">mount(8)</code> is smart enough to recognize this as a CD filesystem and mount it as such. If you’re mounting a disk image that uses a less detectable filesystem, you need to use the specific <code class="literal">mount</code> command for that filesystem.</p></div><div class="sect2" title="Detaching Vnode Devices from Images"><div class="titlepage"><div><div><h3 class="title" id="detaching_vnode_devices_from_images">Detaching Vnode Devices from Images</h3></div></div></div><p>Vnode devices attached to a file remain attached until specifically disconnected, and you can attach a vnode device to only one file at a time. To disconnect the vnode device from the file, use the <code class="literal">-u</code> flag with <code class="literal">vnconfig</code>. For example, to disconnect the vnode device located at <span class="emphasis"><em>vnd0c</em></span>, run this command:</p><a id="I_programlisting9_id452278"/><pre class="programlisting"># <span class="strong"><strong>vnconfig -u vnd0c</strong></span></pre><p>You can now attach this vnode device to another file.</p><p>Using the full path to the device is optional in <code class="literal">vnconfig</code>. If you know the device name, you can use it without the leading <span class="emphasis"><em>/dev</em></span>, as in the preceding example.</p></div></div><div class="sect1" title="Basic NFS Setup"><div class="titlepage"><div><div><h2 class="title" id="basic_nfs_setup" style="clear: both">Basic NFS Setup</h2></div></div></div><p>NFS allows one machine to access files on another machine. NFS has its origins in UNIX, but today appears in most operating systems, including those from Microsoft and Apple. OpenBSD supports NFS versions 1 through 3 as both a client and a server.</p><p>Entire books can be—and have been—written about NFS. We won’t go into the intimate details of NFS, but rather focus on getting a basic NFS share working on OpenBSD. Configuring NFS the first time can be intimidating, but after setting up a file share or two, you’ll find it straightforward.</p><p><a class="indexterm" id="idx0562"/><a class="indexterm" id="idx0804"/><a class="indexterm" id="idx0805"/><a class="indexterm" id="idx0841"/><a class="indexterm" id="idx1395"/><a class="indexterm" id="idx1537"/><a class="indexterm" id="idx1538"/><a class="indexterm" id="idx1816"/><a class="indexterm" id="idx2241"/>If you have a complicated NFS environment—involving multiple versions of multiple operating systems—or if you want to share a directory among hundreds of active clients, you should do further research, but even a basic setup will help to simplify parts of your job.</p><p>NFS works on the client/server model. One computer, the server, offers filesystems to other computers. The server is <span class="emphasis"><em>exporting</em></span> a filesystem, and the filesystems on offer are called <span class="emphasis"><em>exports</em></span>. NFS clients can mount exports in a manner almost identical to that used to mount local filesystems.</p><p>One important thing to remember about NFS is that it is <span class="emphasis"><em>stateless</em></span>, which means that NFS does not track the condition of a connection. You can reboot an NFS server, and the client won’t throw a fit. The client cannot access files on the server while the server is down, but once the server returns, the client will pick up right where things left off. Other network filesystems are not always so resilient. Statelessness causes its own problems as well. For example, clients cannot know when a file they are currently reading has been modified by another client.</p><p>If you’re just learning NFS (or OpenBSD’s implementation of NFS), check <span class="emphasis"><em>/var/log/messages</em></span> for NFS-related error messages. If you’ve repeatedly reconfigured your NFS server as part of learning, and things just don’t work correctly, reboot your NFS server and/or client. NFS is complicated, and sometimes starting with a clean stack clears up a lot of problems. Once you understand how all the pieces fit together, a reboot to resolve problems should never be necessary.</p><div class="note" title="Note"><h3 class="title"><a id="ch09note01"/>Note</h3><p>The NFS protocol has evolved over the years, and every operating system has implemented a slightly different version of NFS. Other BSDs, Illumos, Linux, Apple, Microsoft, and most other operating systems can work with OpenBSD’s NFS support, but each may require an occasional tweak for specific environments. If you’re having trouble getting NFS to work with OpenBSD and another operating system, read <code class="literal">mount_nfs(8)</code> and feed the details to your favorite search engine. The odds that someone else has experienced this problem before are good.</p></div></div><div class="sect1" title="The OpenBSD NFS Server"><div class="titlepage"><div><div><h2 class="title" id="the_openbsd_nfs_server" style="clear: both">The OpenBSD NFS Server</h2></div></div></div><p>By default, OpenBSD includes all the programs necessary to act as an NFS server, but you must turn it on. The NFS server requires three daemons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p title="portmap(8)"><span class="title"><strong><span class="strong"><strong><code class="literal">portmap(8)</code></strong></span></strong></span>. Maps requests for remote procedure call (RPC) services to TCP/IP port numbers.</p></li><li class="listitem" style="list-style-type: none"><p title="mountd(8)"><span class="title"><strong><span class="strong"><strong><code class="literal">mountd(8)</code></strong></span></strong></span>. Listens for incoming NFS mount requests.</p></li><li class="listitem" style="list-style-type: none"><p title="nfsd(8)"><span class="title"><strong><span class="strong"><strong><code class="literal">nfsd(8)</code></strong></span></strong></span>. Processes requests for filesystem actions.</p></li></ul></div><p>The <code class="literal">portmap(8)</code> daemon has its own <span class="emphasis"><em>rc.conf</em></span> flag, as it can be used by many other RPC services. The <code class="literal">mountd(8)</code> and <code class="literal">nfsd(8)</code> daemons are controlled by a single <span class="emphasis"><em>rc.conf</em></span> flag.</p><p><a class="indexterm" id="idx0043"/><a class="indexterm" id="idx0597"/><a class="indexterm" id="idx0842"/><a class="indexterm" id="idx1704"/>Add the following entries to <span class="emphasis"><em>rc.conf.local</em></span> to start all three processes at boot time:</p><a id="I_programlisting9_id452574"/><pre class="programlisting">portmap=YES
nfs_server=YES</pre><p>You can start these three daemons from scripts in <span class="emphasis"><em>/etc/rc.d</em></span>. If you try to start these daemons now, however, they won’t run. You must configure at least one export before the NFS server daemons will start.</p><div class="sect2" title="Exporting Filesystems"><div class="titlepage"><div><div><h3 class="title" id="exporting_filesystems">Exporting Filesystems</h3></div></div></div><p>To export filesystems, define which clients may mount which filesystems and/or directories in <span class="emphasis"><em>/etc/exports</em></span>. This file takes a separate line for each disk device on the server and each client or group of clients that can access that disk device. Each line has up to three parts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Directories or partitions to be exported</p></li><li class="listitem"><p>Options on that export</p></li><li class="listitem"><p>Clients permitted to connect</p></li></ul></div><p>Of the three components of an <span class="emphasis"><em>/etc/exports</em></span> entry, only the directory is mandatory. The directory path cannot contain symlinks, double dots, or single dots.</p><p>If I wanted to export my home directory as read-write to every host on the Internet, I could use an <span class="emphasis"><em>exports</em></span> line containing only the path to my <span class="emphasis"><em>/home</em></span> folder:</p><a id="I_programlisting9_id452646"/><pre class="programlisting">/home/mwlucas</pre><p>This perfectly valid (but perfectly foolish) entry contains no options and no host restrictions.</p><p>To export multiple directories that reside on the same partition, separate them with a single space.</p><a id="I_programlisting9_id452659"/><pre class="programlisting">/home/mwlucas /home/lasnyder</pre><p>You can list any number of directories on one line, as long as they exist on the same partition.</p><p>NFS clients can mount only exactly the directory specified in <span class="emphasis"><em>/etc/exports</em></span>. If you export <span class="emphasis"><em>/home/mwlucas</em></span>, clients can attach only <span class="emphasis"><em>/home/mwlucas</em></span> to a mount point. They cannot mount, say, <span class="emphasis"><em>/home/mwlucas/bin</em></span> instead. If you would like to export an entire partition, you can do that, too. If you want to let clients mount any directories beneath that mount point, specify the mount point and the <code class="literal">-alldirs</code> option. You cannot use <code class="literal">-alldirs</code> with a subdirectory; it must be the actual mount point. This next entry lets anyone mount any directory in <span class="emphasis"><em>/home</em></span>:</p><a id="I_programlisting9_id452700"/><pre class="programlisting">/home -alldirs</pre><p><a class="indexterm" id="idx0090"/><a class="indexterm" id="idx1135"/><a class="indexterm" id="idx1184"/><a class="indexterm" id="idx1191"/><a class="indexterm" id="idx1394"/><a class="indexterm" id="idx1533"/><a class="indexterm" id="idx1536"/><a class="indexterm" id="idx1930"/><a class="indexterm" id="idx2478"/><a class="indexterm" id="idx2534"/><a class="indexterm" id="idx2552"/>To export multiple partitions, or directories from multiple partitions, specify them on separate lines.</p><a id="I_programlisting9_id452793"/><pre class="programlisting">/home -alldirs
/var/log</pre><p>Any time you change <span class="emphasis"><em>/etc/exports</em></span>, you must signal <code class="literal">mountd</code> to reread its configuration. You can do this by passing the <code class="literal">reload</code> argument to the <code class="literal">mountd</code> startup script:</p><a id="I_programlisting9_id452816"/><pre class="programlisting"># <span class="strong"><strong>/etc/rc.d/mountd reload</strong></span></pre><p>While these simple mounts give you an idea of how NFS works, they’re very insecure. To make an intelligent export, you need a few options and an access list. Let’s take a look at some of NFS’s more commonly used options.</p></div><div class="sect2" title="Read-Only Mounts"><div class="titlepage"><div><div><h3 class="title" id="read-only_mounts-id00002">Read-Only Mounts</h3></div></div></div><p>You might want to share files without worrying about whether your underlings will delete, modify, or otherwise undo your hard work. You can share files as read-only by using the <code class="literal">-ro</code> option. Here, I offer my home directory to all the computers in the world, but as a read-only share:</p><a id="I_programlisting9_id452846"/><pre class="programlisting">/home/mwlucas -ro</pre><p>This is slightly more intelligent than offering my NFS exports to the entire world read-write, but only slightly.</p></div><div class="sect2" title="NFS and Users"><div class="titlepage"><div><div><h3 class="title" id="nfs_and_users">NFS and Users</h3></div></div></div><p>You already know that file ownership and permissions are tied to UID numbers. Unlike many other file-sharing protocols, NFS also uses UIDs to identify file ownership. For example, on my test server, my account <code class="literal">mwlucas</code> uses the UID 1000; on my client, my <code class="literal">mwlucas</code> account also uses the UID 1000. This simplifies my life, as I don’t need to worry too much about file ownership; files owned by <code class="literal">mwlucas</code> on the server are owned by <code class="literal">mwlucas</code> on the client.</p><p>On a small network with only a few users and machines,<sup>[<a class="footnote" epub:type="noteref" href="#ftn.id330714" id="id330714">22</a>]</sup> you can probably keep UID numbers synchronized without a problem by assigning the same UID to the same user on all of your systems. But on a large network, with more than one user and where users have root on their own machines, file ownership can quickly become a serious problem. The best way around this is to maintain a central repository of authorized users via LDAP or Kerberos.</p><p>Regardless of how you manage your users, NFS handles the root account differently. An NFS server cannot trust root on client machines to execute commands or write files as root on the server; if that were the case, a breach on one NFS client would mean a breach on the NFS server. By default, requests from root on the client are mapped to UID and GID 32767 (also known as <code class="literal">nobody</code>).</p><p><a class="indexterm" id="idx1531"/><a class="indexterm" id="idx1545"/>If you want to map root to a specific user rather than the generic UID <code class="literal">nobody</code>, use the <code class="literal">-maproot</code> option and specify either a username or UID. Here, we map incoming requests from root on the client to the user <code class="literal">nfsroot</code> on the server:</p><a id="I_programlisting9_id452950"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot</pre><p>You can give the mapped root user a list of groups that the remote root account can access by specifying them after the username, separated by colons. Here, we give the client’s root user access to the server as the user <code class="literal">nfsroot</code> and the groups <code class="literal">customers</code> and <code class="literal">webmasters</code>:</p><a id="I_programlisting9_id452970"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot:customers:webmasters</pre><p>If you want to explicitly remove the mapped root user from all groups, put a colon after the username or UID, as in this example:</p><a id="I_programlisting9_id452979"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot:</pre><p>Suppose you want all the NFS clients, regardless of username on the client system, to use a single user ID on the NFS server. The <code class="literal">-mapall</code> option allows you to do this. This option uses the same format as the <code class="literal">-maproot</code> option. Here, we map all NFS users to the username <code class="literal">nfsuser</code> on the server:</p><a id="I_programlisting9_id453000"/><pre class="programlisting">/home/mwlucas -mapall=nfsuser</pre><p>Correct control of user access will help protect your NFS server.</p></div><div class="sect2" title="Permitted Clients"><div class="titlepage"><div><div><h3 class="title" id="permitted_clients">Permitted Clients</h3></div></div></div><p>By default, every host can access your NFS server. For many reasons, that’s not a great idea. You can restrict the clients permitted to access your NFS server by listing their IP addresses at the end of the export entry.</p><a id="I_programlisting9_id453021"/><pre class="programlisting">/home/mwlucas 192.0.2.1</pre><p>You can also specify clients by their hostname, but if the server has a DNS failure, it won’t allow any clients access.</p><a id="I_programlisting9_id453029"/><pre class="programlisting">/home/mwlucas treble.blackhelicopters.org</pre><p>To permit access to an entire network, use the <code class="literal">-network</code> and <code class="literal">-mask</code> options. The next example permits access to the addresses 192.0.2.0 through 192.0.2.15, using a subnet mask. (If you’re not familiar with subnet masks, read <a class="xref" href="ch11.html" title="Chapter 11. Overview of TCP/IP">Chapter 11</a>.)</p><a id="I_programlisting9_id453050"/><pre class="programlisting">/home/mwlucas -network=192.0.2.0 -mask=255.255.255.240</pre><p><a class="indexterm" id="idx0853"/><a class="indexterm" id="idx1484"/><a class="indexterm" id="idx1530"/><a class="indexterm" id="idx1532"/><a class="indexterm" id="idx1717"/><a class="indexterm" id="idx1952"/>When setting up your NFS server, I recommend you grant access to only the hosts who need it.</p></div><div class="sect2" title="Multiple Exports for One Partition"><div class="titlepage"><div><div><h3 class="title" id="multiple_exports_for_one_partition">Multiple Exports for One Partition</h3></div></div></div><p>You can have only one line for each combination of partition and permitted clients. If <span class="emphasis"><em>/home</em></span> is a single partition, you can’t have an exports file that looks like this:</p><a id="I_programlisting9_id453122"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot: 192.0.2.1
/home/pkdick 192.0.2.1</pre><p>If two directories are located on the same partition, NFS will not allow you to export them to the same host using different permissions. You can, however, export directories on one partition to different hosts with different permissions, as shown here:</p><a id="I_programlisting9_id453132"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot: 192.0.2.1
/home/pkdick 192.0.2.2</pre><p>You can export directories on a partition to different hosts with different permissions.</p><a id="I_programlisting9_id453140"/><pre class="programlisting">/home/mwlucas -maproot=nfsroot: 192.0.2.1
/home/mwlucas -maproot=root 192.0.2.2</pre><p>Only by combining IP restrictions and controlling user permissions can you can effectively control NFS server access.</p></div></div><div class="sect1" title="NFS Clients"><div class="titlepage"><div><div><h2 class="title" id="nfs_clients" style="clear: both">NFS Clients</h2></div></div></div><p>OpenBSD’s NFS client doesn’t need any daemons or configuration. Just <code class="literal">mount</code> the remote filesystem. Here, I mount my home directory from my server <code class="literal">treble</code> on <span class="emphasis"><em>/mnt</em></span>:</p><a id="I_programlisting9_id453176"/><pre class="programlisting"># <span class="strong"><strong>mount treble:/home/mwlucas /mnt</strong></span></pre><p>When mounting remote filesystems over NFS, enter the hostname or IP address, a colon, and the directory. Because I have the same UID on both the client and server, I can access, alter, remove, and add files in <span class="emphasis"><em>/mnt</em></span> exactly as if I were dealing with files on a local filesystem.</p><p>Verify your mount with <code class="literal">df(1)</code> or <code class="literal">mount(8)</code>.</p><a id="I_programlisting9_id453205"/><pre class="programlisting">$ <span class="strong"><strong>df -h</strong></span>
Filesystem             Size    Used   Avail Capacity  Mounted on
/dev/sd0a             1005M    266M    689M    28%    /
…
treble:/home/mwlucas  26.9G   21.5M   25.5G     0%    /mnt</pre><p><a class="indexterm" id="idx0066"/><a class="indexterm" id="idx0137"/><a class="indexterm" id="idx0525"/><a class="indexterm" id="idx0608"/><a class="indexterm" id="idx0890"/><a class="indexterm" id="idx1880"/><a class="indexterm" id="idx1916"/><a class="indexterm" id="idx2170"/><a class="indexterm" id="idx2188"/>The NFS-mounted directory shows up like any other mount point.</p><p>To mount an NFS share automatically at boot, or just record it for future convenience, you may use an <span class="emphasis"><em>/etc/fstab</em></span> entry. If your system might not have DNS available to it at boot time, use an IP address for the NFS server. The following example specifies two <span class="emphasis"><em>fstab</em></span> entries: one using a hostname and one using an IP address:</p><a id="I_programlisting9_id453309"/><pre class="programlisting">treble:/home/mwlucas /mnt nfs,noauto rw 0 0
192.0.2.88:/usr/ports /usr/ports nfs,noauto ro 0 0</pre><p>Give all NFS partitions dump and <code class="literal">fsck</code> numbers of <code class="literal">0</code>. Do not run <code class="literal">fsck</code> or <code class="literal">dump</code> on an NFS mount, as those programs require raw disk access that NFS doesn’t provide.</p><p>Use any other mount options you like. The OpenBSD folks recommend using <code class="literal">noexec</code>, <code class="literal">nodev</code>, and <code class="literal">nosuid</code> “when applicable.” I recommend <code class="literal">noauto</code> on NFS partitions that aren’t required for normal server operation, so that an unavailable NFS server does not hang your machine’s boot process.</p><p>NFS performance depends a great deal on your hardware, your local network, the clients and servers involved, the phase of the moon, and any number of other factors. If you’re not happy with your NFS performance, read <code class="literal">mount_nfs(8)</code> and experiment with using TCP or UDP, the read and write sizes, and perhaps the timeout. If you need a complicated NFS environment, you should definitely invest some time in learning more about NFS.</p></div><div class="sect1" title="Software RAID"><div class="titlepage"><div><div><h2 class="title" id="software_raid" style="clear: both">Software RAID</h2></div></div></div><p>The Redundant Array of Independent Disks (RAID) technology has become the standard way of mirroring hard drives within a machine or combining multiple hard drives to form one giant partition. In many types of RAID arrays, if one disk fails, the system can continue to run without data loss until you replace the failed disk or a second disk fails.</p><p>You can get RAID from the hardware or have the operating system perform the RAID operations. Hardware RAID controllers seem nice, but are in reality just decent disk controllers that run special software. Using the <code class="literal">softraid(4)</code> driver, OpenBSD can do the same thing, letting you build RAID arrays out of plain disks. You can do just about everything you can with a hardware RAID controller with a bunch of disks and OpenBSD’s RAID management program <code class="literal">bioctl(8)</code> and the <code class="literal">softraid(4)</code> software RAID driver.</p><div class="note" title="Note"><h3 class="title"><a id="ch09note02"/>Note</h3><p>In addition to managing software RAID, OpenBSD’s <code class="literal">bioctl(8)</code> can manage most sorts of hardware RAID controllers. If you’re planning to use hardware RAID, reading the <code class="literal">bioctl</code> manual is definitely worth your time.</p></div><div class="sect2" title="RAID Types"><div class="titlepage"><div><div><h3 class="title" id="raid_types">RAID Types</h3></div></div></div><p><a class="indexterm" id="idx1373"/><a class="indexterm" id="idx1917"/><a class="indexterm" id="idx2255"/><a class="indexterm" id="idx2256"/><a class="indexterm" id="idx2257"/>OpenBSD supports the following RAID configurations:</p><div class="blockquote" title="RAID-0, or striping"><blockquote class="blockquote" title="RAID-0, or striping"><div class="blockquote-title"><span class="strong"><strong>RAID-0, or</strong></span> <span class="bolditalic">striping</span></div><p>This type is not redundant. It requires at least two disks of the same size, and data is shared between the disks to increase partition size and throughput. You can use RAID-0 to combine five 4TB disks into a 20TB virtual disk, but be warned: If one hard drive in the array fails, you’ll lose all your data. RAID-0 is useful when you need a really big filesystem, but it’s more vulnerable than a single disk because it provides multiple points of failure (or as one of my quasi-literary, quasi-humorous friends once said, “RAID-0 gives a whole new meaning to the phrase one disk to rule them all”). The size of a RAID-0 array is the size of all the hard drives combined.</p></blockquote></div><div class="blockquote" title="RAID-1, or mirroring"><blockquote class="blockquote" title="RAID-1, or mirroring"><div class="blockquote-title"><span class="strong"><strong>RAID-1, or</strong></span> <span class="bolditalic">mirroring</span></div><p>With this type, the contents of one disk are duplicated on another. Mirroring requires at least two disks of the same size, and the size of a RAID-1 array is equal to the size of the smallest drive in the array. I use mirroring to protect all vital data, as it gives even a cheap desktop-chassis server some measure of data protection. OpenBSD’s software RAID fully supports this level.</p></blockquote></div><div class="blockquote" title="RAID-4, or striping data across disks, with a dedicated parity disk"><blockquote class="blockquote" title="RAID-4, or striping data across disks, with a dedicated parity disk"><div class="blockquote-title"><span class="strong"><strong>RAID-4, or</strong></span> <span class="bolditalic">striping data across disks, with a dedicated parity disk</span></div><p>This type requires at least three disks of the same size. Parity data lets a RAID array recover data on missing disks, and RAID-4 stores that parity data on a specific disk. This means that you can lose any one of the disks without losing data. As I write this, <code class="literal">bioctl</code>’s RAID-4 support is experimental. Hopefully this support will be complete before the book reaches you, but if not, you’ll need to use a hardware RAID card to get RAID-4.</p></blockquote></div><div class="blockquote" title="RAID-5, or striping with parity shared across all drives"><blockquote class="blockquote" title="RAID-5, or striping with parity shared across all drives"><div class="blockquote-title"><span class="strong"><strong>RAID-5, or</strong></span> <span class="bolditalic">striping with parity shared across all drives</span></div><p>This is the current industry standard for redundancy. Parity data provides data redundancy—the loss of a single drive doesn’t destroy any data. It requires at least three disks of the same size. Unlike RAID-4, RAID-5 shares the parity data across all the drives simultaneously. While throughput isn’t as good as that of RAID-0, a RAID-5 array can simultaneously serve multiple I/O requests. The size of your RAID-5 array is the combined size of all but one of your hard drives. If you have five 4TB drives, the array will be 16TB ((5 – 1) × 4TB). Like RAID-4, RAID-5 support in <code class="literal">bioctl</code> is incomplete and experimental. I hope it will be complete before you read this, but if not, you’ll need to use a hardware RAID card for RAID-5.</p></blockquote></div><p>According to the RAID standards, each of these levels requires disks of the same size. That said, OpenBSD’s <code class="literal">softraid</code> uses partitions rather than disks. You can use disks of different sizes, but your RAID array will use only an amount of space on each disk equal to the smallest drive. If you want to mirror a 1TB drive and a 2TB drive, your mirror will offer only 1TB of space. The excess space on the larger drive is wasted.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.id367975" id="id367975">23</a>]</sup></p><p><a class="indexterm" id="idx0276"/><a class="indexterm" id="idx0468"/><a class="indexterm" id="idx1338"/><a class="indexterm" id="idx2176"/>In addition to the standard RAID methods, <code class="literal">softraid</code> also allows you to encrypt your data across all disks in a RAID array (as described in <a class="xref" href="ch09.html#encrypted_disk_partitions" title="Encrypted Disk Partitions">Encrypted Disk Partitions</a>). It also lets you <span class="emphasis"><em>concatenate</em></span> disks. Concatenated disks are just run together to create one large virtual disk. You could concatenate two 500GB disks and a 1TB disk to create a single 2TB partition. These disks don’t need to be the same size, but as with RAID-0, they are vulnerable. Damage to any one disk will completely wreck the virtual disk and lose all data. As the process for creating a concatenated disk closely resembles that of creating a RAID-0 disk, we’ll cover it in <a class="xref" href="ch09.html#creating_softraid_devices" title="Creating softraid Devices">Creating softraid Devices</a>.</p></div><div class="sect2" title="Preparing Disks for softraid"><div class="titlepage"><div><div><h3 class="title" id="preparing_disks_for_softraid">Preparing Disks for softraid</h3></div></div></div><p>The <code class="literal">softraid</code> software RAID device builds its virtual disks out of disklabel partitions. To use a disk in a <code class="literal">softraid</code> array, prepare it just as you would a disk for a regular filesystem.</p><p>On i386 and amd64, disks underlying a <code class="literal">softraid</code> device need an MBR partition. To mark a whole disk with a single MBR partition, run <code class="literal">fdisk -i</code> on the disk.</p><p>Suppose you have five disks to use in a RAID array: <code class="literal">sd2</code>, <code class="literal">sd3</code>, <code class="literal">sd4</code>, <code class="literal">sd5</code>, and <code class="literal">sd6</code>. You’ll need to prepare each of them as follows:</p><a id="I_programlisting9_id453709"/><pre class="programlisting"># <span class="strong"><strong>fdisk -i sd2</strong></span>
Do you wish to write new MBR and partition table? [n] <span class="strong"><strong>y</strong></span>
Writing MBR at offset 0.</pre><p>Repeat this for every disk in your array.</p><p>Once you’ve added an MBR to all your disks, you’ll need to put a disklabel partition on each disk. I tend to use partition letter <span class="emphasis"><em>p</em></span> (the last available partition letter) for <code class="literal">softraid</code> devices. Here’s how to set up a disk for <code class="literal">softraid</code>:</p><a id="I_programlisting9_id453745"/><pre class="programlisting">  # <span class="strong"><strong>disklabel -E sd2</strong></span>
  Label editor (enter '?' for help at any prompt)
<span class="strong"><strong>1</strong></span> &gt; <span class="strong"><strong>a</strong></span>
<span class="strong"><strong>2</strong></span> partition: [a] <span class="strong"><strong>p</strong></span>
  offset: [64]
  size: [104856191]
<span class="strong"><strong>3</strong></span> FS type: [4.2BSD] <span class="strong"><strong>RAID</strong></span>
<span class="strong"><strong>4</strong></span> &gt; <span class="strong"><strong>q</strong></span>
<span class="strong"><strong>5</strong></span> Write new label?: [y] <span class="strong"><strong>y</strong></span></pre><p><a class="indexterm" id="idx2172"/>First, we add a partition with <code class="literal">a</code> <span class="strong"><strong>1</strong></span> and assign it partition letter <code class="literal">p</code> <span class="strong"><strong>2</strong></span>. Instead of our usual filesystem type of 4.2BSD, we assign a filesystem type of <code class="literal">RAID</code> <span class="strong"><strong>3</strong></span>. Then we quit <span class="strong"><strong>4</strong></span> and let <code class="literal">disklabel</code> write the changes to the disklabel partition <span class="strong"><strong>5</strong></span>.</p><p>If you have multiple identical disks, you can use <code class="literal">disklabel</code> to save this disk’s configuration, as follows:</p><a id="I_programlisting9_id453882"/><pre class="programlisting"># <span class="strong"><strong>disklabel sd2 &gt; disklabel.sd2.raid</strong></span></pre><p>This saves the label on disk <code class="literal">sd2</code> to the file <span class="emphasis"><em>disklabel.sd2.raid</em></span>. You can make <code class="literal">disklabel(8)</code> copy this partitioning to other disks, and <code class="literal">disklabel</code> will assign each disk a unique DUID as it copies. This saves you from needing to walk through the interactive editor for each disk. Let’s apply this disklabel to each partition:</p><a id="I_programlisting9_id453911"/><pre class="programlisting"># <span class="strong"><strong>disklabel -R sd3 disklabel.sd2.raid</strong></span>
# <span class="strong"><strong>disklabel -R sd4 disklabel.sd2.raid</strong></span>
# <span class="strong"><strong>disklabel -R sd5 disklabel.sd2.raid</strong></span>
# <span class="strong"><strong>disklabel -R sd6 disklabel.sd2.raid</strong></span></pre><p>Disks <code class="literal">sd2</code> through <code class="literal">sd6</code> are now ready for assimilation into <code class="literal">softraid</code>.</p></div><div class="sect2" title="Creating softraid Devices"><div class="titlepage"><div><div><h3 class="title" id="creating_softraid_devices">Creating softraid Devices</h3></div></div></div><p>Use <code class="literal">bioctl(8)</code> to drag disks into a software RAID. You’ll need the disk partitions you want to include in the RAID. OpenBSD software RAID arrays are named <code class="literal">softraid</code>, followed by a number. Use the <code class="literal">-c</code> argument to give a RAID type, and <code class="literal">-l</code> to give the partitions, and end with the name of the <code class="literal">softraid</code> you’re creating.</p><a id="I_programlisting9_id453986"/><pre class="programlisting"># <span class="strong"><strong>bioctl -c <span class="emphasis"><em>raidlevel</em></span> -l <span class="emphasis"><em>partition1,partition2</em></span>… softraid<span class="emphasis"><em>X</em></span></strong></span></pre><p>We have five disk partitions—<code class="literal">sd2p</code>, <code class="literal">sd3p</code>, <code class="literal">sd4p</code>, <code class="literal">sd5p</code>, and <code class="literal">sd6p</code>—to add to a <code class="literal">softraid</code> device. To build a RAID-5 device out of these partitions, run this command:</p><a id="I_programlisting9_id454032"/><pre class="programlisting"># <span class="strong"><strong>bioctl -c 5 -l sd2p,sd3p,sd4p,sd5p,sd6p softraid0</strong></span>
softraid0: SR <span class="strong"><strong>1</strong></span> RAID 5 volume attached as <span class="strong"><strong>2</strong></span> sd7</pre><p>The response indicates that we’ve successfully created a RAID-5 device <span class="strong"><strong>1</strong></span>, and it’s available as device <code class="literal">/dev/sd7</code> <span class="strong"><strong>2</strong></span>. On a blank RAID disk, which you need to prepare just as you would any other new disk, run <code class="literal">fdisk -i sd7</code> and <code class="literal">disklabel</code> to create MBR and OpenBSD partitions, use <code class="literal">newfs</code> to create a filesystem on the new partitions, and you’re ready to go. (See the instructions for adding a new disk in <a class="xref" href="ch08.html" title="Chapter 8. Disks and Filesystems">Chapter 8</a> for details.)</p><p><a class="indexterm" id="idx1914"/><a class="indexterm" id="idx1938"/><a class="indexterm" id="idx2174"/><a class="indexterm" id="idx2175"/><a class="indexterm" id="idx2178"/>You could have made this a RAID-0, RAID-1, or RAID-4 device by choosing a different <code class="literal">-c</code> option. The tricky one is a concatenated <code class="literal">softraid</code>. To dump all the disks together into a single concatenated virtual partition, use <code class="literal">-c c</code>.</p><a id="I_programlisting9_id454161"/><pre class="programlisting"># <span class="strong"><strong>bioctl -c c -l sd2p,sd3p,sd4p,sd5p,sd6p softraid0</strong></span>
softraid0: SR CONCAT volume attached as sd7</pre></div><div class="sect2" title="softraid Status"><div class="titlepage"><div><div><h3 class="title" id="softraid_status">softraid Status</h3></div></div></div><p>To check the health of each device in a RAID array, give <code class="literal">bioctl</code> the device name of the <code class="literal">softraid</code> device.</p><a id="I_programlisting9_id454193"/><pre class="programlisting"># <span class="strong"><strong>bioctl softraid0</strong></span>
Volume      Status               Size Device
softraid0 0 Online       214744170496 sd7     RAID5
          0 Online        53686099456 0:0.0   noencl &lt;sd2p&gt;
          1 Online        53686099456 0:1.0   noencl &lt;sd3p&gt;
          2 Online        53686099456 0:2.0   noencl &lt;sd4p&gt;
          3 Online        53686099456 0:3.0   noencl &lt;sd5p&gt;
          4 Online        53686099456 0:4.0   noencl &lt;sd6p&gt;</pre><p>We see that the five drives are in use, all assembled into a RAID-5 virtual drive. Everything here is healthy. Anything that doesn’t look roughly like this indicates a problem.</p></div><div class="sect2" title="Identifying Failed softraid Volumes"><div class="titlepage"><div><div><h3 class="title" id="identifying_failed_softraid_volumes">Identifying Failed softraid Volumes</h3></div></div></div><p>If you have a RAID-1, RAID-4, or RAID-5 <code class="literal">softraid</code> volume, you can lose a drive and not lose your data. <code class="literal">bioctl</code> tells you if a drive fails. Here, one of the drives in my <code class="literal">softraid</code> volume has failed:</p><a id="I_programlisting9_id454236"/><pre class="programlisting"># <span class="strong"><strong>bioctl softraid0</strong></span>
Volume      Status               Size Device
softraid0 0 Degraded     214744170496 sd7     RAID5
          0 Online        53686099456 0:0.0   noencl &lt;sd2p&gt;
          <span class="strong"><strong>1 Offline</strong></span>                  <span class="strong"><strong>0 0:1.0</strong></span>   <span class="strong"><strong>noencl &lt;&gt;</strong></span>
          2 Online        53686099456 0:2.0   noencl &lt;sd3p&gt;
          3 Online        53686099456 0:3.0   noencl &lt;sd4p&gt;
          4 Online        53686099456 0:4.0   noencl &lt;sd6p&gt;</pre><p>Looking closely at this, I can see that drives <code class="literal">sd2</code>, <code class="literal">sd3</code>, <code class="literal">sd4</code>, and <code class="literal">sd6</code> are still available and in use. All my data should still be intact, but I need to replace <code class="literal">sd5</code> before another disk fails.</p></div><div class="sect2" title="Rebuilding Failed softraid Volumes"><div class="titlepage"><div><div><h3 class="title" id="rebuilding_failed_softraid_volumes">Rebuilding Failed softraid Volumes</h3></div></div></div><p>As of this writing, you cannot rebuild a failed <code class="literal">softraid</code> RAID-4 or RAID-5 device. You must back up your data, replace the failed drive, delete the <code class="literal">softraid</code> device, re-create the filesystem, and restore from backup. You can, however, rebuild a RAID-1 device.</p><p><a class="indexterm" id="idx0138"/><a class="indexterm" id="idx0402"/><a class="indexterm" id="idx2173"/>Let’s look at replacing a disk in a RAID-1 device. Here’s what a healthy, three-disk <code class="literal">softraid</code> mirror might look like:</p><a id="I_programlisting9_id454357"/><pre class="programlisting"># <span class="strong"><strong>bioctl softraid0</strong></span>
Volume      Status               Size Device
softraid0 0 Online        53686099456 sd5<span class="strong"><strong>1</strong></span>  RAID1
          0 Online        53686099456 0:0.0   noencl &lt;sd2p&gt;<span class="strong"><strong>2</strong></span>
          1 Online        53686099456 0:1.0   noencl &lt;sd3p&gt;
          2 Online        53686099456 0:2.0   noencl &lt;sd4p&gt;</pre><p>Note that this RAID device has device node <code class="literal">sd5</code> <span class="strong"><strong>1</strong></span> and includes the partitions <span class="emphasis"><em>sd2p</em></span>, <span class="emphasis"><em>sd3p</em></span>, and <span class="emphasis"><em>sd4p</em></span> <span class="strong"><strong>2</strong></span>.</p><p>We replace two disks and reboot this machine. Suddenly, the <span class="emphasis"><em>softraid</em></span> device looks very different.</p><a id="I_programlisting9_id454419"/><pre class="programlisting"># <span class="strong"><strong>bioctl softraid0</strong></span>
Volume      Status               Size Device
softraid0 0 Degraded      53686099456 sd5     RAID1
          0 Offline                 0 0:0.0   noencl &lt;&gt;
          1 Offline                 0 0:1.0   noencl &lt;&gt;
          2 Online        53686099456 0:2.0   noencl &lt;sd2p&gt;</pre><p>Partitions <span class="emphasis"><em>sd3p</em></span> and <span class="emphasis"><em>sd4p</em></span> are missing. That’s because the underlying disks have been replaced.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.id433352" id="id433352">24</a>]</sup> Prepare the replacement disks for software RAID, as discussed in <a class="xref" href="ch09.html#preparing_disks_for_softraid" title="Preparing Disks for softraid">Preparing Disks for softraid</a>. Then run <code class="literal">bioctl</code>, using the <code class="literal">-R</code> flag to specify the disk to replace in the <code class="literal">softraid</code> device.</p><a id="I_programlisting9_id454465"/><pre class="programlisting"># <span class="strong"><strong>bioctl -R /dev/sd3p sd5</strong></span>
softraid0: rebuild of sd5 started on sd3p</pre><p>If you check the status of the device using <code class="literal">bioctl</code>, you’ll see the disk status now says “Rebuilding.”</p><p>If you have a mirror with more than two disks, you must rebuild each disk separately. Rebuild the first disk, and then rebuild the second disk.</p></div><div class="sect2" title="Deleting softraid Devices"><div class="titlepage"><div><div><h3 class="title" id="deleting_softraid_devices">Deleting softraid Devices</h3></div></div></div><p>To remove a <code class="literal">softraid</code> device from your system, pass <code class="literal">bioctl</code> the <code class="literal">-d</code> flag and the device name for the <code class="literal">softraid</code> device. Here’s how to remove the RAID-5 device we just created:</p><a id="I_programlisting9_id454513"/><pre class="programlisting"># <span class="strong"><strong>bioctl -d sd7</strong></span></pre><div class="warning" epub:type="warning" title="Warning"><h3 class="title"><a id="ch09note03"/>Warning</h3><p>Once you delete the RAID device, you can’t get it back unless you re-create it and restore your data from backup.</p></div></div><div class="sect2" title="Reusing softraid Disks"><div class="titlepage"><div><div><h3 class="title" id="reusing_softraid_disks">Reusing softraid Disks</h3></div></div></div><p><a class="indexterm" id="idx0183"/><a class="indexterm" id="idx0553"/><a class="indexterm" id="idx1362"/><a class="indexterm" id="idx1703"/><a class="indexterm" id="idx2171"/><a class="indexterm" id="idx2177"/><code class="literal">softraid</code> writes metadata at the beginning of the disks it uses. You need to overwrite this metadata before you can use the disks in another <code class="literal">softraid</code> device. Overwrite the first megabyte or so of the disk with <code class="literal">dd(1)</code>.</p><a id="I_programlisting9_id454616"/><pre class="programlisting"># <span class="strong"><strong>dd if=/dev/zero of=/dev/sd2c bs=1k count=1024</strong></span>
1024+0 records in
1024+0 records out
1048576 bytes transferred in 0.594 secs (1765074 bytes/sec)</pre><p>This erases the MBR partitions, any initial disklabels, and any filesystem information on the disk. You can now reuse these disks in <code class="literal">softraid</code> devices as normal disks.</p></div><div class="sect2" title="Booting from a softraid Device"><div class="titlepage"><div><div><h3 class="title" id="booting_from_a_softraid_device">Booting from a softraid Device</h3></div></div></div><p>The <code class="literal">softraid</code> feature is still in development. Eventually, you’ll be able to use the installer to build a software RAID device, install OpenBSD on that device, and run a full RAID configuration out of the box. But as I write this, you’ll need to jump through some hoops to make that happen. Rather than document a specific procedure that will change as OpenBSD completes <code class="literal">softraid</code> development, I’m going to tell you to search the Internet and the <span class="emphasis"><em>misc@OpenBSD.org</em></span> archives for the most recent instructions.</p></div></div><div class="sect1" title="Encrypted Disk Partitions"><div class="titlepage"><div><div><h2 class="title" id="encrypted_disk_partitions" style="clear: both">Encrypted Disk Partitions</h2></div></div></div><p>Sometimes I can see the future. When someone says, “I’ve encrypted my hard drive!” I have a psychic vision of them saying “I’ve lost all my data!” While encrypting a hard drive partition is warranted in some cases, most of the time, it’s just pretentious. In this section, I will do you the courtesy of assuming that you understand when you truly need disk encryption if you will do me the courtesy of not complaining to me when you lose your data.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.id458279" id="id458279">25</a>]</sup></p><div class="sect2" title="Creating Encrypted Partitions"><div class="titlepage"><div><div><h3 class="title" id="creating_encrypted_partitions">Creating Encrypted Partitions</h3></div></div></div><p>OpenBSD includes disk encryption as a <code class="literal">bioctl(8)</code> option—specifically, like a RAID discipline. Where disk activity would normally be passed through a RAID discipline, here they pass through an encryption discipline. The encrypted disk even shows up as a <code class="literal">softraid</code> device. Much like the support for RAID-5, support for encrypted filesystems is experimental. Although it <span class="emphasis"><em>should</em></span> work, don’t be shocked if some features are not yet included or if it eats your entire disk. Keep good backups. Reread the previous paragraph. And again—<span class="emphasis"><em>please</em></span> don’t complain to me when it doesn’t work.</p><p><a class="indexterm" id="idx0381"/><a class="indexterm" id="idx1724"/><a class="indexterm" id="idx2497"/>Under OpenBSD, an encrypted volume can include only a single partition. Use the RAID type <code class="literal">C</code> to specify an encrypted volume. Here’s, how to create an encrypted volume on the <span class="emphasis"><em>sd4p</em></span> partition:</p><a id="I_programlisting9_id454752"/><pre class="programlisting">  # <span class="strong"><strong>bioctl -c C -l sd4p softraid0</strong></span>
<span class="strong"><strong>1</strong></span> New passphrase:
  Re-type passphrase:
  softraid0: SR CRYPTO volume attached as sd5</pre><p>When prompted <span class="strong"><strong>1</strong></span>, enter a passphrase twice. A good passphrase is several words long, and includes a mix of characters, symbols, numbers, punctuation, and whitespace. The passphrase is the secret code used to encrypt and decrypt data, so the longer and more varied it is, the better. Remember this passphrase; you must enter it again to recover your data. Once you’ve entered your passphrase twice, <code class="literal">bioctl</code> creates the encrypted disk device. In this case, it has created encrypted disk <code class="literal">softraid0</code> as <code class="literal">disk sd5</code>.</p></div><div class="sect2" title="Using Encrypted Partitions"><div class="titlepage"><div><div><h3 class="title" id="using_encrypted_partitions">Using Encrypted Partitions</h3></div></div></div><p>Do not mount this new disk yet! Instead, use <code class="literal">fdisk</code> to check our new, encrypted partition.</p><a id="I_programlisting9_id454810"/><pre class="programlisting"># <span class="strong"><strong>fdisk sd5</strong></span>
Disk: sd5       geometry: 6526/255/63 [104855663 Sectors]
Offset: 0       Signature: 0x8BF9
            Starting         Ending         LBA Info:
 #: id      C   H   S -      C   H   S [       start:        size ]
------------------------------------------------------------------------------
 0: D9 230285  63  36 - 134263  55  58 [  3699532529:  2752373385 ] &lt;Unknown ID&gt;
 1: 8C  73068 221  44 - 176434  56  49 [  1173851386:  1660564401 ] &lt;Unknown ID&gt;
 2: C9 218148  78  47 - 141866 243  13 [  3504552580:  3069507328 ] &lt;Unknown ID&gt;
 3: AC 125252   6   1 - 245307  77  22 [  2012173758:  1928688070 ] &lt;Unknown ID&gt;</pre><p>The underlying disk is blank, and our <code class="literal">fdisk</code> output looks like garbage, but this disk is now an encrypted volume.</p><p>Now that the encrypted disk exists, create an MBR partition and add disklabel partitions, just as when you add any other disk. Then you can mount your encrypted device partition using the device node—again, just as with any other disk.</p><p>To unmount the decrypted partition, destroy the <code class="literal">softraid</code> device by passing <code class="literal">bioctl</code> the <code class="literal">-d</code> argument.</p><a id="I_programlisting9_id454854"/><pre class="programlisting"># <span class="strong"><strong>bioctl -d sd5</strong></span></pre><p>To anyone who doesn’t have the passphrase, this partition now looks like random garbage.</p></div><div class="sect2" title="Automatic Decryption"><div class="titlepage"><div><div><h3 class="title" id="automatic_decryption">Automatic Decryption</h3></div></div></div><p><a class="indexterm" id="idx0380"/><a class="indexterm" id="idx0554"/><a class="indexterm" id="idx1725"/>If you have an encrypted partition, presumably you don’t want OpenBSD to automatically decrypt and mount it when the system boots. (The whole point of an encrypted partition is that only a person who has the passphrase can access the encrypted data.) Still, I’m not one to tell you not to shoot yourself in the foot, so if you must automatically decrypt the partition, you can do so.</p><p>First, create a file containing your passphrase. Give ownership of this file to root and set the permissions to <code class="literal">600</code> (read-write by owner; no access by other users), and then give this file to <code class="literal">bioctl(8)</code> with the <code class="literal">-p</code> flag. In this example, the encrypted disk is created as <span class="emphasis"><em>/dev/sd5</em></span> and there is a partition on <span class="emphasis"><em>/dev/sd5a</em></span>. I’ve stored my passphrase in the file <span class="emphasis"><em>/etc/passphrase</em></span>, so I could run something like this:</p><a id="I_programlisting9_id454934"/><pre class="programlisting"># <span class="strong"><strong>bioctl -c C -l sd4p -p /etc/passphrase softraid0</strong></span>
# <span class="strong"><strong>mount /dev/sd5a /home/mwlucas</strong></span></pre><p>Adding this to <span class="emphasis"><em>/etc/rc.securelevel</em></span> will mount this encrypted partition at boot.</p><p>You should now have a good idea of how to manage OpenBSD disks and filesystems. Next, we’ll look at some of OpenBSD’s special security features.</p></div></div><div class="footnotes" epub:type="footnotes"><br/><hr style="width: 100; align: left;"/><div class="footnote" epub:type="footnote" id="ftn.id344921"><p><sup>[<a class="para" href="#id344921">21</a>] </sup>I don’t know what a dump level of 128m means, other than “not what I want.”</p></div><div class="footnote" epub:type="footnote" id="ftn.id330714"><p><sup>[<a class="para" href="#id330714">22</a>] </sup>How many users do I mean by “a few?” When synchronizing UIDs across all of your systems begins to really, <span class="emphasis"><em>really</em></span> annoy you, you no longer have a few users.</p></div><div class="footnote" epub:type="footnote" id="ftn.id367975"><p><sup>[<a class="para" href="#id367975">23</a>] </sup>You could add a non-RAID partition in the unused space on the larger drive, but that would do terrible things to your system’s performance. Just buy more hard drives, you cheapskate.</p></div><div class="footnote" epub:type="footnote" id="ftn.id433352"><p><sup>[<a class="para" href="#id433352">24</a>] </sup>If you need to force an error on a hard disk, removing the disk from the machine will certainly do it.</p></div><div class="footnote" epub:type="footnote" id="ftn.id458279"><p><sup>[<a class="para" href="#id458279">25</a>] </sup>Not that I can help you—all I can do is say “I told you so.” On a related note: You can get tired of anything, no matter how pleasant, if you have to do it often enough.</p></div></div></section></body></html>