<html><head></head><body>
  <h1><span class="chapter">Appendix D -</span><br/>
  Getting Started with FPGAs</h1>

  <p>Integration is the bane of hardware hackers. We like to take things apart, modify them, and improve them, but the trend has been to cram everything into one or two ASICs (Application Specific Integrated Circuit). <span style="font-size: 1em;">This kind of integration is out of the reach of mere mortals, as the cost of a set of masks used for defining the features on chips is rapidly</span> <span style="font-size: 1em;">approaching one million dollars. That’s one million dollars</span> <i class="calibre4" style="font-size: 1em;">per unique</i> <i class="calibre4" style="font-size: 1em;">revision</i> <span style="font-size: 1em;">of the chip. If a mistake is made that requires a new mask set, you have to spend yet another million dollars to fix it.</span></p>

  <p>Fortunately, a million dollars cash upfront for a chip is too much even for many corporations, and this has created a market for FPGAs — general-purpose, programmable (“reconfigurable”) hardware devices that can be used in place of an ASIC in many applications.</p>

  <h2 id="sigil_toc_id_149"><b class="calibre3">What Is an FPGA?</b></h2>

  <p>FPGA stands for field programmable gate array. In other words, it is an <span style="font-size: 1em;">array of gates that can be programmed in the field by end users. You can</span> <span style="font-size: 1em;">think of FPGAs as custom silicon that you can build in the comfort of</span> <span style="font-size: 1em;">your own home, although the trend toward partial reconfigurability and</span> <span style="font-size: 1em;">context-sensitive reconfiguration adds a dimension to FPGAs that is not</span> <span style="font-size: 1em;">found in ASICs. While ASICs are cheaper per unit in volume, and they</span> <span style="font-size: 1em;">can have much higher clock speed performance, FPGAs have established</span> <span style="font-size: 1em;">themselves as the tool of choice for low to moderate volume applica</span><span style="font-size: 1em;">tions and for prototyping.</span></p>

  <p>The FPGA’s basic architecture is that of an array of hardware primitives <span style="font-size: 1em;">embedded in a flexible routing network. The power of the FPGA comes</span> <span style="font-size: 1em;">from the fact that complex computations can be broken down into a</span> <span style="font-size: 1em;">sequence of simpler logic functions. These simpler functions can each be</span> <span style="font-size: 1em;">broken down in turn, until the entire computation is described by nothing</span> <span style="font-size: 1em;">more than a sequence of basic logic operations that can be mapped into</span> <span style="font-size: 1em;">the FPGA’s hardware primitives. Thus, the same FPGA can be used to</span> <span style="font-size: 1em;">implement a microprocessor, a video controller, or a tic-tac-toe game</span> <span style="font-size: 1em;">just by changing the configuration of the hardware primitives and the</span> <span style="font-size: 1em;">routing network.</span></p>

  <p>The kinds of hardware primitives implemented by an FPGA architecture <span style="font-size: 1em;">strongly influence the FPGA’s implementation efficiency for a given</span> <span style="font-size: 1em;">target application. Modern FPGAs provide designers with mostly one</span> <span style="font-size: 1em;">bit wide primitives: a 4 or 5 input to 1-bit output lookup table, and a</span> <span style="font-size: 1em;">single bit of time-synchronized storage known as a flip flop. Lookup</span> <span style="font-size: 1em;">tables are used as the logic primitive because they can be programmed to</span> <span style="font-size: 1em;">perform any logic operation with as many terms as there are inputs to the</span> <span style="font-size: 1em;">lookup table. These primitives are then wired into a vast programmable</span> <span style="font-size: 1em;">network of wires; a typical high-end FPGA might have many tens of</span> <span style="font-size: 1em;">thousands of these primitive elements.</span></p>

  <p>It turns out that while single bit-wide structures are very general, they can be very resource-inefficient in applications where the natural data width is large. <span style="font-size: 1em;">In particular, the area dedicated to the actual logic primitives is around 1</span> <span style="font-size: 1em;">percent in many cases, with the remainder being configuration memory</span> <span style="font-size: 1em;">and interconnect. All of this wire is required to handle the many routing</span> <span style="font-size: 1em;">permutations that you might require for single-bit wide applications.</span></p>

  <div>
    <img alt="figure_d-1" class="drawing" src="../Images/figure_d-1.png"/><br/>
  </div>

  <p class="caption"><b class="calibre3">Figure D-1</b>: Block diagram of a typical FPGA structure, illustrating the disparity between the amount of wire on an FPGA versus the amount of computational logic. <span style="font-size: 1em;">A typical modern FPGA will contain several tens of thousands of these basic cells.</span></p>

  <p><span style="font-size: 1em;">In order to boost area efficiency, many FPGAs also include a few coarse-</span><span style="font-size: 1em;">grain primitives, such as chunks of RAM or a multiplier block. Xilinx’s</span> <span style="font-size: 1em;">Virtex II-Pro FPGAs even include several PowerPC cores on-chip. While</span> <span style="font-size: 1em;">this sounds impressive, the actual area consumed by such a core is</span> <span style="font-size: 1em;">surprisingly small: A PowerPC processor probably consumes a little</span> <span style="font-size: 1em;">more than 1mm2 of silicon area, whereas the area of the FPGA is</span> <span style="font-size: 1em;">hundreds of square millimeters.</span></p>

  <p>The most recent FPGAs on the market have very flexible I/Os in <span style="font-size: 1em;">addition to having very flexible computational hardware. A typical</span> <span style="font-size: 1em;">FPGA can interface to all of the most popular high-speed signaling</span> <span style="font-size: 1em;">standards, including PCI, AGP, LVDS, HSTL, SSTL, and GTL. In</span> <span style="font-size: 1em;">addition, most FPGAs can handle DDR clocked signals as well. In case</span> <span style="font-size: 1em;">those acronyms didn’t mean anything to you, the basic idea is that an</span> <span style="font-size: 1em;">FPGA can be used to talk to just about any piece of hardware you might</span> <span style="font-size: 1em;">find on a typical PC motherboard, such as the Xbox. This is extremely</span> <span style="font-size: 1em;">good news to hardware hackers, because it means that an FPGA can be</span> <span style="font-size: 1em;">used to emulate or monitor almost any chip found in a PC. (Of course,</span> <span style="font-size: 1em;">the PC may have to be down-clocked in cases where the FPGA cannot</span> <span style="font-size: 1em;">keep up with the speed of the PC.)</span></p>

  <h2 id="sigil_toc_id_150"><b class="calibre3">Designing for an FPGA</b></h2>

  <p>You have a number of design entry options to choose from for a typical <span style="font-size: 1em;">FPGA design flow. If you prefer to think graphically, most design flows</span> <span style="font-size: 1em;">support a schematic-capture tool. While schematic capture is often more</span> <span style="font-size: 1em;">intuitive for hardware designs, they can be more difficult to maintain and</span> <span style="font-size: 1em;">modify. For example, changing al instances of a net name can be tedious</span> <span style="font-size: 1em;">if you have to click on every wire and type in the new name. Further</span><span style="font-size: 1em;">more, the size of any single level of design hierarchy is limited to the size of a schematic sheet, so a complex design will require a good deal of</span> <span style="font-size: 1em;">planning and forethought for just the schematic capture.</span></p>

  <p>As a result, hardware description languages (HDLs) are the tool of <span style="font-size: 1em;">choice for implementing complex designs. HDLs look very similar at</span> <span style="font-size: 1em;">first glance to normal programming languages. For example, the syntax</span> <span style="font-size: 1em;">of Verilog looks very similar to that of C or Java. However, the seman</span><span style="font-size: 1em;">tics of the language can be a bit of a challenge to understand.</span></p>

  <p><span style="font-size: 1em;">Hardware has an inherent parallelism that procedural languages such as C</span> <span style="font-size: 1em;">cannot express. If you think about it, every gate and every flip flop on an FPGA can compute in parallel, whereas in a C program, a single thread</span> <span style="font-size: 1em;">of execution is nominally assumed. As a result, HDLs represent hard</span><span style="font-size: 1em;">ware as a collection of processes that operate in parallel; it is up to the coder to group all of the functions into the correct processes so that the</span> <span style="font-size: 1em;">compiler can understand how to turn a process into gates.</span></p>

  <p class="caption"><img alt="figure_d-2" class="drawing" src="../Images/figure_d-2.png"/><b><br/></b></p>

  <p class="caption"><b>Figure D-2:</b> Typical FPGA design flow.</p>

  <p><span style="font-size: 1em;">For example, a single clocked storage element (a flip-flop) in Verilog is a</span> <span style="font-size: 1em;">“process” that typically has a structure similar to this:</span></p>
  <pre>
input inData;        // declare your inputs and outputs
input clock;
reg   bitOfStorage;  // declare the storage bit as a reg
type

always @(posedge clock) begin
  bitOfStorage &lt;= inData;
end

</pre>

  <p>This code takes the value on input port inData, and on every rising clock <span style="font-size: 1em;">edge, stores inData in a flip flop whose output is called bitOfStorage.</span> <span style="font-size: 1em;">Multiple processes delimited by always @( ... ) begin ... end syntax</span> <span style="font-size: 1em;">can exist in a single design, and all processes execute in parallel.</span> <span style="font-size: 1em;">Combinational logic can also be expressed as a process. For example, the</span> <span style="font-size: 1em;">following Verilog code implements a two-input multiplexer that has no</span> <span style="font-size: 1em;">clock:</span></p>
  <pre>
input  a;
input  b;
input  select;
output out;
reg    c;
always @(a or b or select) begin
  if( select == 1’b1 ) begin
    c &lt;= a;
  end else begin
    c &lt;= b;
  end 
end
assign out = c;  // assign statements can contain logic
                 // functions as well
                       
</pre>

  <p>In this example, the contents of the parenthesized block following the <span style="font-size: 1em;">always keyword contains a</span> <i class="calibre4" style="font-size: 1em;">sensitivity list</i> <span style="font-size: 1em;">that includes all of the inputs that might affect the output. Leaving a parameter out of the sensitivity list means that the output will not change, even if that parameter changes. For</span> <span style="font-size: 1em;">example, if you omitted a and b from the sensitivity list, then the only time the output would change would be when select changed: you would have</span> <span style="font-size: 1em;">built a latch that stores either a or b depending upon the state of select.</span> <span style="font-size: 1em;">However, the desired operation of a multiplexer is to relay changes on</span> <span style="font-size: 1em;">either a or b to the output at al times, even when select does not</span> <span style="font-size: 1em;">transition, so a and b must both be part of the sensitivity list.</span></p>

  <p><span style="font-size: 1em;">There are a number of subtleties when learning an HDL that are beyond the</span> <span style="font-size: 1em;">scope of this book, but the two code segments above should give you a</span> <span style="font-size: 1em;">flavor for what to expect. A skilled software programmer may have more</span> <span style="font-size: 1em;">trouble adjusting to an HDL than a novice, because many software tricks</span> <span style="font-size: 1em;">that are taken for granted translate very poorly to direct hardware</span> <span style="font-size: 1em;">implementation. Arrays, structures, multiplication, and division primi</span><span style="font-size: 1em;">tives are all taken for granted in the software world, but each of these</span> <span style="font-size: 1em;">constructs translate to potentially large and inefficient blocks of hard</span><span style="font-size: 1em;">ware. Furthermore, in a hardware implementation, all possible cases in a</span> <span style="font-size: 1em;">case statement exist whether or not you intend for it; neglecting to fully</span> <span style="font-size: 1em;">specify a case statement with a default case often means that extra</span> <span style="font-size: 1em;">hardware will be synthesized to handle the implicit cases. Numerous</span> <span style="font-size: 1em;">tutorials and syntax reference manuals for Verilog are indexed in Google;</span> <span style="font-size: 1em;">verilog syntax and verilog tutorial are both good sets of keywords to</span> <span style="font-size: 1em;">start out with when searching for syntax references or tutorials. Xilinx’s</span> <span style="font-size: 1em;">website also has a good Verilog reference for FPGA designers, and</span> <span style="font-size: 1em;">Sutherland HDL, Inc. has a free Verilog quick reference guide at http://</span><span style="font-size: 1em;">www.sutherland-hdl.com/on-line_ref_guide/vlog_ref_body.html.</span></p>

  <div class="infobox">
    <h2 id="sigil_toc_id_151"><b class="calibre3">Overclocking FPGA Designs</b></h2>

    <p>It is worth noting that the timing models used for an FPGA are <span style="font-size: 1em;">quite conservative. This means that it is quite likely that an</span> <span style="font-size: 1em;">FPGA will operate properly at frequencies much higher than</span> <span style="font-size: 1em;">the timing analyzer will admit. In fact, careful hand-layout of</span> <span style="font-size: 1em;">an FPGA’s logic can stretch the performance of the FPGA much</span> <span style="font-size: 1em;">further than its stated specifications.</span></p>

    <p>For example, the FPGA (Xilinx Virtex-E) used to implement the <span style="font-size: 1em;">Xbox Hypertransport bus tap is only specified to handle data</span> <span style="font-size: 1em;">rates of around 200 Mbits/s/pin, but the application demanded</span> <span style="font-size: 1em;">400 Mbits/s/pin. The reason I could pull this off is that the ac</span><span style="font-size: 1em;">tual logic and storage elements can run very fast, but most of</span> <span style="font-size: 1em;">the performance is burned off in the wires and repeaters that</span> <span style="font-size: 1em;">carry the signals between logic elements. Specifically, some</span> <span style="font-size: 1em;">wires will have so much delay at 400 Mbits/s that they effec</span><span style="font-size: 1em;">tively store data for a single clock cycle.</span></p>

    <p>I determined which wires were slower than the rest by captur<span style="font-size: 1em;">ing a sequence of data and comparing it against a pattern</span> <span style="font-size: 1em;">that I had previously discovered using an oscilloscope. Once</span> <span style="font-size: 1em;">the slow paths were identified, I inverted the clock and/or in</span><span style="font-size: 1em;">serted flip-flops on channels that had too little delay. The end</span> <span style="font-size: 1em;">result was a set of signals that were time-skew corrected. These</span> <span style="font-size: 1em;">signals could then be trivially demultiplexed to a lower clock</span> <span style="font-size: 1em;">rate where conventionally compiled HDL design techniques</span> <span style="font-size: 1em;">could be used.</span></p>

    <p>While this technique is very powerful, it is not generally appli<span style="font-size: 1em;">cable because the amount of delay caused by a wire varies</span> <span style="font-size: 1em;">from chip to chip and can depend on parameters such as</span> <span style="font-size: 1em;">the ambient temperature and the quality of the power supply</span> <span style="font-size: 1em;">voltage. However, for one specific chip under controlled cir</span><span style="font-size: 1em;">cumstances, I was able to get 2x the rated performance. An</span><span style="font-size: 1em;">other important difference between this application and a</span> <span style="font-size: 1em;">more general application is that bit error rates on the order of</span> <span style="font-size: 1em;">1 error in a few thousand was tolerable, since I could just take</span> <span style="font-size: 1em;">three traces and XOR them to recover any information lost to</span> <span style="font-size: 1em;">random noise sources. However, 1 in 10,000 bit error rates are</span> <span style="font-size: 1em;">not acceptable for normal applications; unrecoverable error</span> <span style="font-size: 1em;">rates better than 1 in 10,000,000,000,000 are more typical. This</span> <span style="font-size: 1em;">all goes back to a saying that I have: “It is easy to do some</span><span style="font-size: 1em;">thing once, but doing something a million times perfectly is</span> <span style="font-size: 1em;">hard.”</span></p>
  </div>

  <p>Another advantage of the HDL design entry approach is the availability <span style="font-size: 1em;">of free and paid “softcores.” Websites such as www.opencores.org offer</span> <span style="font-size: 1em;">general-public licensed HDL cores for functions such as USB interfaces, DES</span> <span style="font-size: 1em;">and AES crypto-engines, and various microprocessors. In addition, almost</span> <span style="font-size: 1em;">every standard function is offered by third-party vendors who will sell you cores for a fee.</span></p>

  <p>After design entry, I highly recommended that you simulate your design <span style="font-size: 1em;">before compiling it into hardware. Trying to track down bugs by</span> <span style="font-size: 1em;">twiddling code, pushing it to hardware and probing for changes is very</span> <span style="font-size: 1em;">inefficient. Simulation allows you to probe any node of the circuit with</span> <span style="font-size: 1em;">the push of a button. In addition, the effort required to simulate a code</span> <span style="font-size: 1em;">change is very small, especially when compared to the effort of pushing a</span> <span style="font-size: 1em;">change all the way through to hardware.</span></p>

  <p>Once the design has been entered and simulated, it needs to be compiled or <span style="font-size: 1em;">translated into a common netlist format. This netlist format is fed into a</span> <span style="font-size: 1em;">program that maps the netlist primitives into the target FPGA hardware p</span><span style="font-size: 1em;">rimitives, after which the mapped primitives are placed and routed. The</span> <span style="font-size: 1em;">resulting design is analyzed for compliance with a set of constraints</span> <span style="font-size: 1em;">specified by the designer. If the design does not meet the designer’s</span> <span style="font-size: 1em;">specifications, it is iteratively refined through successive place and route passes. Once the design passes its design constraints, it goes to a configuration bitstream generator where the internal representation of the FPGA is translated into a binary file that the FPGA can use to configure</span> <span style="font-size: 1em;">itself. (All of these steps happen fairly seamlessly at the touch of a button in the later versions of the FPGA design tools.)</span></p>

  <h3 id="sigil_toc_id_152"><b class="calibre3">Project Ideas</b></h3>

  <p>Now that you know a little bit about what an FPGA is and how you can <span style="font-size: 1em;">program them, what sorts of things can you do with them?</span></p>

  <p>As it turns out, FPGAs have enough logic capacity and performance <span style="font-size: 1em;">these days to accomplish a very impressive range of tasks. The obvious</span> <span style="font-size: 1em;">industrial application of FPGAs is in the emulation of designs intended</span> <span style="font-size: 1em;">for hard-wired silicon. The cost of building a custom chip has been</span> <span style="font-size: 1em;">skyrocketing, and it will soon be the case where a single critical mistake</span> <span style="font-size: 1em;">can cost hundreds of thousands of dollars, if not millions, to fix.</span></p>

  <p><span style="font-size: 1em;">On the other hand, fixing a mistake made in an FPGA HDL description p</span><span style="font-size: 1em;">retty much only costs time and design effort; you don’t throw away any</span> <span style="font-size: 1em;">parts, and you don’t have to buy any new parts. Thus, many companies</span> <span style="font-size: 1em;">have adopted the strategy of fully simulating a mock-up of the design in</span> <span style="font-size: 1em;">FPGAs before taping out the final silicon. A side benefit from this</span> <span style="font-size: 1em;">approach is that the software and hardware teams that are users of the</span> <span style="font-size: 1em;">custom silicon can begin validating their designs using the FPGA mock-</span><span style="font-size: 1em;">up while the custom silicon is being fabricated; a process that can</span> <span style="font-size: 1em;">sometimes take a couple of months.</span></p>

  <p>For hackers, FPGAs are sort of a panacea for all kinds of complex <span style="font-size: 1em;">projects. They are excellent choices for implementing cryptographic</span> <span style="font-size: 1em;">functions if you are interested in doing brute-force keysearches or</span> <span style="font-size: 1em;">encrypting large amounts of data quickly. They are also very useful for</span> <span style="font-size: 1em;">implementing signal processing functions, especially given the existence</span> <span style="font-size: 1em;">of free multiplier and digital filter cores. FPGAs can achieve higher</span> <span style="font-size: 1em;">performance for less power than a DSP, and thus they have a unique</span> <span style="font-size: 1em;">niche in applications such as battery-powered robotics. FPGAs are also</span> <span style="font-size: 1em;">useful for embedded controller applications: A small microprocessor</span> <span style="font-size: 1em;">core, equivalent to or better than a PIC, can easily fit in an FPGA today.</span> <span style="font-size: 1em;">Add all your custom hardware peripherals, such as a serial port and</span> <span style="font-size: 1em;">PWM timing generators, and you’re in business.</span></p>

  <p><span style="font-size: 1em;">FPGAs are also useful in situations where the focus is not on big number</span> <span style="font-size: 1em;">crunching. An FPGA makes a great piece of glue logic in a tight spot,</span> <span style="font-size: 1em;">and well-placed FPGA can save you from having to ever add a wire</span> <span style="font-size: 1em;">jumper to patch a board due to a logic design error. FPGAs also make a</span> <span style="font-size: 1em;">cheap logic analyzer alternative for those of us who cannot afford a</span> <span style="font-size: 1em;">$10,000 Tek TLA mainframe. The high-speed I/O capabilities of the</span> <span style="font-size: 1em;">latest FPGAs combined with large autogenerated FIFO-configured</span> <span style="font-size: 1em;">embedded memories make short work of designing a signal capture and</span> <span style="font-size: 1em;">analysis system.</span></p>

  <p>Finally, FPGAs have applications in mixed-signal situations that are not <span style="font-size: 1em;">immediately obvious. The most common mixed-signal application is</span> <span style="font-size: 1em;">probably using an FPGA to drive the analog signals of a VGA monitor. A</span> <span style="font-size: 1em;">couple of resistive dividers or a well-chosen output driver type is all you need, and al the timing and logic necessary to generate color images can be handled with logic inside the FPGA. FPGAs can also be trivially used as PWM D/A converters, or even as part of a sigma-delta D/A or A/D</span> <span style="font-size: 1em;">converters.</span></p>

  <h3 id="sigil_toc_id_153"><b class="calibre3">Where to Buy</b></h3>

  <p>You’re probably thinking that any tool this versatile and powerful has to <span style="font-size: 1em;">cost a fortune. While that was true about a decade ago, today you can buy</span> <span style="font-size: 1em;">100,000 gate FPGAs for well under $50, and the design tools are often</span> <span style="font-size: 1em;">free for educational users and/or hobbyists.</span></p>

  <p>Of course, an FPGA on its own is not so useful; it needs to be mounted <span style="font-size: 1em;">to a board with the proper connections in order to be used. To this end,</span> <span style="font-size: 1em;">a company cal ed XESS (www.xess.com) makes a line of fairly affordable</span> <span style="font-size: 1em;">FPGA starter kits. Their product line shifts as new FPGAs are intro</span><span style="font-size: 1em;">duced, but the current entry-level FPGA board is the XSA-50 board that</span> <span style="font-size: 1em;">comes with a 50,000 gate FPGA for about $150. The board also includes</span> <span style="font-size: 1em;">a few megabytes of RAM, a parallel port, a VGA port, a PS/2 keyboard</span> <span style="font-size: 1em;">port, and a few other essential items.</span></p>

  <p>The other option is to build your own board from scratch, if you’re <span style="font-size: 1em;">feeling bold. Other appendices in this book describe how to get into</span> <span style="font-size: 1em;">board layout and fabrication and how to attach fine-pitched FPGA</span> <span style="font-size: 1em;">devices to your boards. It is actually quite rewarding to try to build your own boards, and I recommend giving it a try; the cost of fabricating a</span> <span style="font-size: 1em;">board is well below $100 these days, so you don’t lose too much even if</span> <span style="font-size: 1em;">your board doesn’t work in the end.</span></p>

  <p>If you are making your own board, you will need to buy your FPGA <span style="font-size: 1em;">from a Xilinx distributor. The Xilinx webpage (www.xilinx.com) has the</span> <span style="font-size: 1em;">most up-to-date links to distributors. As of this writing, one of the more convenient distributors is NuHorizons (www.nuhorizons.com), as they</span> <span style="font-size: 1em;">offer product availability and pricing information on their webpage</span> <span style="font-size: 1em;">without requiring registration or a special customer account.</span></p>

  <p>FPGA development software can usually be acquired at a low price or <span style="font-size: 1em;">for free. For example, Xilinx offers a free development environment for</span> <span style="font-size: 1em;">its Virtex-II (up to 300K gates), Spartan II-E and CoolRunner lines of</span> <span style="font-size: 1em;">parts. The development environment is called the Xilinx ISE WebPACK,</span> <span style="font-size: 1em;">and it is available for download after registration at www.xilinx.com.</span> <span style="font-size: 1em;">This free environment sports an impressive list of features, including</span> <span style="font-size: 1em;">schematic and HDL input, HDL synthesis, a flooplanner, timing driven</span> <span style="font-size: 1em;">place and route, timing analysis, and power analysis tools.</span></p>

  <p>Xilinx also offers a version of its software called “Xilinx Student <span style="font-size: 1em;">Edition” through Prentice-Hall. This software comes bundled with a</span> <span style="font-size: 1em;">number of tutorials and documentation that can help you get into FPGA</span> <span style="font-size: 1em;">design. You’ll find a wide variety of helpful tutorials and lectures on the Xilinx website under the “Education” tab.</span></p>
</body></html>