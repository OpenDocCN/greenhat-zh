<html><head></head><body><div class="part" title="Part&#xA0;I.&#xA0;The Source"><div class="titlepage"><div><div><h1 class="title"><a id="the_source"/>Part I. The Source</h1></div></div></div><div class="partintro" title="The Source" id="id2730928"><div/><div class="epigraph"><p><span class="emphasis"><em>On the problems that surface long before one sends any information over the network</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div></div></div>
<div class="chapter" title="Chapter&#xA0;1.&#xA0;I Can Hear You Typing"><div class="titlepage"><div><div><h1 class="title"><a id="i_can_hear_you_typing"/>Chapter 1. I Can Hear You Typing</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where we investigate how your keystrokes can be monitored from far, far away</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>From the moment you press the first key on your keyboard, the information you are sending begins a long journey through the virtual world. Microseconds before packets speed through fiber-optic links and bounce off satellite transceivers, a piece of information goes a long way through an amazing maze of circuits. Prior to your keystrokes being received by the operating system and any applications it might be running, many precise and subtle low-level mechanisms are engaged in a process that is of interest to all sorts of hackers and has proven to be of significance to the security crowd as well. The path to user land has many surprises lurking along the way.</p><p>This chapter focuses on these early stages of moving data and on the opportunities that arise for your fellow (and possibly naughty) users to find out way too much about what you are doing in the comfort of your own terminal.</p><p>A prominent example of a potential information disclosure scenario related to the way a computer processes your input is associated with a subject that, at first glance, appears to be unrelated at best: the difficult task of producing random numbers on a machine that behaves in a fully predictable manner. It is difficult to imagine a less obvious connection, yet the problem I mention is very real, and may allow a sneaky observer to deduce much of a user’s activity, from his passwords to private email that he is typing.</p><div class="sect1" title="The Need for Randomness"><div class="titlepage"><div><div><h1 class="title"><a id="the_need_for_randomness"/>The Need for Randomness</h1></div></div></div><p>Computers are completely deterministic. They process data in a way that is governed by a well-defined set of laws. Engineers do their best to compensate for imperfections associated with the manufacturing process and the properties of the electronic components themselves (interference, heat noise, and so on), all to ensure that the systems always follow the same logic and work properly; when, with time and stress, components refuse to act as expected, we consider the computer to be faulty.<a id="IDX-CHP-1-0002" class="indexterm"/><a id="IDX-CHP-1-0003" class="indexterm"/><a id="IDX-CHP-1-0004" class="indexterm"/><a id="IDX-CHP-1-0005" class="indexterm"/><a id="IDX-CHP-1-0006" class="indexterm"/><a id="IDX-CHP-1-0007" class="indexterm"/><a id="IDX-CHP-1-0008" class="indexterm"/><a id="IDX-CHP-1-0009" class="indexterm"/><a id="IDX-CHP-1-0010" class="indexterm"/><a id="IDX-CHP-1-0011" class="indexterm"/><a id="IDX-CHP-1-0012" class="indexterm"/><a id="IDX-CHP-1-0013" class="indexterm"/></p><p>The ability of machines to achieve this level of consistency, combined with their marvelous calculation capabilities, is what makes computers such a great tool for those who manage to master and control them. Naturally, one thing has to be said: not all is roses, and those who complain of computers being unreliable are not all that mistaken. Despite the perfect operation of the equipment, computer programs themselves do misbehave on various occasions. This is because even though computer hardware can be and often is consistent and reliable, you typically can’t make long-term predictions about the behavior of a sufficiently complex computer program, let alone a complex matrix of interdependent programs (such as a typical operating system); this makes validating a computer program quite difficult, even assuming we could come up with a detailed, sufficiently strict and yet flawless hypothetical model of what the program should be doing. Why? Well, in 1936, Alan Turing, the father of modern computing, proved by <span class="emphasis"><em>reductio ad absurdum</em></span> (reduction to the absurd) that there can be no <span class="emphasis"><em>general</em></span> method for determining an outcome of <span class="emphasis"><em>any</em></span> computer procedure, or algorithm, in a finite time (although there may be <span class="emphasis"><em>specific</em></span> methods for <span class="emphasis"><em>some</em></span> algorithms).<sup>[<a href="apb.html#ftn.CHP-1-BIB-1" class="footnoteref">41</a>]</sup></p><p>This in practice means that while you cannot expect your operating system or text editor to ever behave precisely the way you or the author intend it to, you can reasonably expect that two instances of a text editor on systems running on the same hardware will exhibit consistent and identical behavior given the same input (unless, of course, one of the instances gets crushed by a falling piano or is otherwise influenced by other pesky external events). This is great news for software companies, but nevertheless, in some cases we, the security crowd, would prefer that the computer be a bit less deterministic. Not necessarily in how it behaves, but in what it can come up with.</p><p>Take data encryption and especially that mysterious beast, public key cryptography. This novel and brilliant form of encryption (and more), first proposed in the 1970s by Whitfield Diffie and Martin Hellman, and shortly thereafter turned into a full-blown encryption system by Ron Rivest, Adi Shamir, and Len Adleman, is based on a simple concept: some things are more difficult than others. That seems obvious, of course, but just throw in several higher math concepts, and you’re all set for a groundbreaking invention.<a id="IDX-CHP-1-0014" class="indexterm"/><a id="IDX-CHP-1-0015" class="indexterm"/><a id="IDX-CHP-1-0016" class="indexterm"/></p><p>Traditional, symmetrical cryptography called for an identical shared “secret” value (a key) to be distributed among all parties involved in a secret communication. The key is required and sufficient to encrypt and later decrypt the information transferred, so that a third-party observer who knows the encryption method still cannot figure out the message. The need for a shared secret made the entire approach not always practical in terms of computer communications, primarily because the parties had to establish a secure exchange channel prior to communicating; transferring the secret over a nonsecure stream would render the scheme vulnerable to decryption. In the world of computers, you often communicate with systems or people you have never seen before and with whom you have no other affordable and secure communication channel.<a id="IDX-CHP-1-0017" class="indexterm"/></p><p>Public key cryptography, on the other hand, is not based on a shared secret. Each party holds two pieces of information: one (the public key) useful for creating an encrypted message, but next to useless for decryption, and the other (the private key) useful for decrypting a previously encrypted message. The parties can now exchange their public keys using an insecure channel even if it is being snooped. They provide each other with the information (meaningless to an observer) needed to encrypt messages between parties, but they keep the portion needed to access the encrypted data private. All of a sudden, secure communications between complete strangers—such as a customer sitting on a sofa in his apartment and an online shopping server—became closer to reality.</p><p>Fundamentally, the original RSA (Rivest, Shamir, and Adleman) public key cryptosystem is based on the observation that the computational complexity of multiplying two arbitrarily large numbers is fairly low; it is directly proportional to the number of digits to be multiplied. On the other hand, the complexity of finding factors (factorization) of a large number is considerably higher, unless you are a mythical crypto-genius working for the National Security Agency. The RSA algorithm first chooses two arbitrary, very large primes,<sup>[<a id="CHP-1-FN-1" href="#ftn.CHP-1-FN-1" class="footnote">1</a>]</sup> <span class="emphasis"><em>p</em></span> and <span class="emphasis"><em>q</em></span>, and multiplies them. It then uses the product along with a coprime,<sup>[<a id="CHP-1-FN-2" href="#ftn.CHP-1-FN-2" class="footnote">2</a>]</sup> (<span class="emphasis"><em>p-1</em></span>)(<span class="emphasis"><em>q-1</em></span>), to construct a public key. This key can be used to encrypt information, but it alone is not sufficient to decrypt that information without resorting to factorization.</p><p>And the catch: Factorization of products of two large prime numbers is often impractical, foiling such attacks. The fastest universal integer factorization algorithm on traditional computers, general number field sieve (GNFS), would require over a thousand years to find factors of such a 1,024-bit integer, at a rate of one million tests per second. Finding two primes that yield a product that big is, on the other hand, a matter of seconds for an average PC.</p><p>As indicated before, in RSA, in addition to your public key, you also produce a private key. The private key carries an additional piece of information about the primes that can be used to decrypt any information encrypted with your public key. The trick is possible, thanks to the Chinese Remainder Theorem, Euler’s Theorem, and other somewhat scary but fascinating mathematical concepts a particularly curious reader may want to explore on his own.<sup>[<a href="apb.html#ftn.CHP-1-BIB-2" class="footnoteref">42</a>]</sup><a id="IDX-CHP-1-0018" class="indexterm"/><a id="IDX-CHP-1-0019" class="indexterm"/></p><p>Some other public key cryptosystems that rely on other hard problems in mathematics were also devised later on (including elliptic curve cryptosystems and so on), but all share the underlying concept of public and private keys. This method has proved practical for securing email, web transactions, and so forth, even if two parties have never communicated and do not have a secure channel to exchange any additional information prior to establishing a connection.<sup>[<a id="CHP-1-FN-3" href="#ftn.CHP-1-FN-3" class="footnote">3</a>]</sup> Almost every encryption design that we use everyday, from Secure Shell (SSH) and Secure Sockets Layer (SSL) to digitally signed updates or smart cards, are here thanks to the contributions of Diffie, Hellman, Rivest, Shamir, and Adleman.<a id="IDX-CHP-1-0020" class="indexterm"/><a id="IDX-CHP-1-0021" class="indexterm"/></p><div class="sect2" title="Automated Random Number Generation"><div class="titlepage"><div><div><h2 class="title"><a id="automated_random_number_generation"/>Automated Random Number Generation</h2></div></div></div><p>There is only one problem: When implementing RSA on a deterministic machine, the first step is to generate two very large primes, <span class="emphasis"><em>p</em></span> and <span class="emphasis"><em>q</em></span>. It is simple for a computer to find a large prime, but there is a tiny issue: the primes also must be impossible for others to guess, and they cannot be the same on every machine. (If they were, the attack on this algorithm would not require any factorization, and <span class="emphasis"><em>p</em></span> and <span class="emphasis"><em>q</em></span> would be known to anyone who owns a similar computer.)<a id="IDX-CHP-1-0022" class="indexterm"/><a id="IDX-CHP-1-0023" class="indexterm"/><a id="IDX-CHP-1-0024" class="indexterm"/><a id="IDX-CHP-1-0025" class="indexterm"/><a id="IDX-CHP-1-0026" class="indexterm"/><a id="IDX-CHP-1-0027" class="indexterm"/><a id="IDX-CHP-1-0028" class="indexterm"/><a id="IDX-CHP-1-0029" class="indexterm"/></p><p>Many algorithms have been developed over the past few years to quickly find prime number candidates (pseudo-primes) and to perform rapid preliminary primality tests (used to verify pseudo-primes).<sup>[<a href="apb.html#ftn.CHP-1-BIB-3" class="footnoteref">43</a>]</sup> But to generate a truly unpredictable prime, we need to use a good dose of entropy or randomness in order to either blindly choose one of the primes within a range, or start at a random place and pick the first prime we stumble upon.</p><p>Although the need for some randomness at the time of key generation is essential, the demand does not end there. Public key cryptography relies on fairly complex calculations and is thus fairly slow, particularly when compared with the traditional symmetric key cryptography that uses short shared keys and a set of operations machines that are known to execute very fast.</p><p>To implement functionality such as SSH, in which reasonable performance is expected, it is more sensible to establish the initial communication and basic verification using public key algorithms, thus creating a secure channel. The next step is to exchange a compact, perhaps 128-bit symmetric encryption key and continue communicating by switching to old-style symmetric cryptography. The main problem with symmetric cryptography is remedied by creating an initial (and slow) secure stream to exchange a shared secret, and then switching to faster algorithms, hence enabling the user to benefit from the higher performance without sacrificing security. Yet, to use symmetric cryptography in a sensible way, we still need to use a certain amount of entropy in order to generate an unpredictable symmetric session key for every secured communication.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-1-FN-1" href="#CHP-1-FN-1" class="para">1</a>] </sup>A prime number is a positive integer that divides only by 1 and itself.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-1-FN-2" href="#CHP-1-FN-2" class="para">2</a>] </sup>A number that is <span class="emphasis"><em>coprime to x</em></span> (also called <span class="emphasis"><em>relatively prime to x</em></span>) shares no common factors with x, other than 1 and −1. (Their greatest common divisor is 1.)</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-1-FN-3" href="#CHP-1-FN-3" class="para">3</a>] </sup>For the sake of completeness, it should be noted that adhoc public key cryptography is, among other things, vulnerable to “man in the middle” attacks, where an attacker impersonates one of the endpoints and provides its own, fake public key, in order to be able to intercept communications. To prevent such attacks, additional means of verifying the authenticity of a key must be devised, either by arranging a secure exchange or establishing a central authority to issue or certify keys (public key infrastructure, PKI).</p></div></div></div>
<div class="sect1" title="The Security of Random Number Generators"><div class="titlepage"><div><div><h1 class="title"><a id="the_security_of_random_number_generators"/>The Security of Random Number Generators</h1></div></div></div><p>Programmers have invented many ways for computers to generate seemingly random numbers; the general name for these algorithms is pseudorandom number generators (PRNGs).<a id="IDX-CHP-1-0030" class="indexterm"/><a id="IDX-CHP-1-0031" class="indexterm"/><a id="IDX-CHP-1-0032" class="indexterm"/><a id="IDX-CHP-1-0033" class="indexterm"/></p><p>PRNGs suffice for trivial applications, such as generating “random” events for computer games or meaningless subject lines for particularly obtrusive unsolicited bulk mailings. For instance, take the linear congruent (aka power residue) generator,<sup>[<a href="apb.html#ftn.CHP-1-BIB-4" class="footnoteref">44</a>]</sup> a classic example of such an algorithm. Despite its obscure name, this random number generator performs a sequence of simple operations (multiplication, addition, and modulus<sup>[<a id="CHP-1-FN-4" href="#ftn.CHP-1-FN-4" class="footnote">4</a>]</sup>) every time it generates its “random” output. The generator uses its previous output r<sub>t</sub> to calculate the next output value, <span class="emphasis"><em>r</em></span><sub><span class="emphasis"><em>t</em></span>+1</sub> (where <span class="emphasis"><em>t</em></span> denotes time):<a id="IDX-CHP-1-0034" class="indexterm"/></p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>r<sub>t</sub></em></span> + 1 = (<span class="emphasis"><em>a</em></span> × <span class="emphasis"><em>r<sub>t</sub></em></span> + <span class="emphasis"><em>c</em></span>) mod <span class="emphasis"><em>M</em></span></td></tr></table><p>The modulo operator controls the range and prevents overflows, a situation that occurs when the result at some point goes beyond the predefined range of values. If <span class="emphasis"><em>r</em></span><sub><span class="emphasis"><em>0</em></span></sub>, <span class="emphasis"><em>a</em></span>, <span class="emphasis"><em>M</em></span>, and <span class="emphasis"><em>c</em></span>—a set of control variables for the generator—are all positive integers, all results of this equation fall in the range of 0 to <span class="emphasis"><em>M-1</em></span>.</p><p>Yet, while the output of this algorithm may, with some fine-tuning, exhibit statistical properties that make it suitable for generating random number lookalikes, nothing is genuinely unpredictable about its operations. And therein lies the problem: An attacker can easily develop their own copy of the generator and use it to determine any number of results that our generator will produce. Even if we start with an initial generator state (<span class="emphasis"><em>r</em></span><sub><span class="emphasis"><em>0</em></span></sub>) that is unknown to the attacker, they can often successfully deduce important properties of this value by observing subsequent outputs of the victim’s generator and then use this knowledge to tweak their version of it to mimick ours. In fact, a general method to reconstruct and predict all polynomial congruent generators was devised over a decade ago,<sup>[<a href="apb.html#ftn.CHP-1-BIB-5" class="footnoteref">45</a>]</sup> and it would be quite unwise to ignore this little, perhaps somewhat inconvenient detail, as it creates a gaping hole in this algorithm when used for mission-critical purposes.</p><p>Over time, we have realized that the only sane way for a computer to produce practically unpredictable data, short of suffering a massive memory failure or processor meltdown, is to try to gather as much practically unpredictable information from its physical surroundings as possible and then use that as a value passed to any application that demands good randomness. The problem is, an average computer has no “senses” with which it could probe the environment for seemingly random external signals. Nevertheless, we know a fairly good way to work around this inconvenience.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-1-FN-4" href="#CHP-1-FN-4" class="para">4</a>] </sup>The modulo operator returns the remainder of an integer division of two numbers. For example, 7 is divided by 3 yielding an integer result of 2 and a remainder of 1 (7 = 2 * 3 + 1); 7 modulo 3 is thus 1.</p></div></div></div>
<div class="sect1" title="I/O Entropy: This Is Your Mouse Speaking"><div class="titlepage"><div><div><h1 class="title"><a id="i_solidus_o_entropy_colon_this_is_your_m"/>I/O Entropy: This Is Your Mouse Speaking</h1></div></div></div><p>On almost every computer system, external devices communicate relevant asynchronous events, such information being made available from the network card or the keyboard, using a hardware interrupt mechanism. Each device has an assigned hardware interrupt (IRQ) number and reports important developments by changing the voltage on a designated hardware line inside the computer, corresponding to this particular IRQ. The change is then interpreted by a device called a <span class="emphasis"><em>programmable interrupt controller</em></span> (PIC), which serves as a personal butler for the main processor (or processors).<a id="IDX-CHP-1-0038" class="indexterm"/><a id="IDX-CHP-1-0039" class="indexterm"/><a id="IDX-CHP-1-0035" class="indexterm"/><a id="IDX-CHP-1-0036" class="indexterm"/><a id="IDX-CHP-1-0037" class="indexterm"/></p><p>Once instructed by the CPU, the PIC decides if, when, how, and with what priority to deliver requests from the external devices to the main unit, which makes it easier for the processor to manage events in an efficient and reliable manner. Upon receipt of a signal from the PIC, the processor postpones its current task, unless of course the CPU had chosen to ignore all interrupt requests at the moment (if it’s really busy). Next, it invokes a code assigned by your operating system to handle feedback from this device or group of devices. Once the program handles the event, the CPU restores the original process and its context—the information about the state of its environment at the time of the interruption—and continues as if nothing has happened.</p><div class="sect2" title="Delivering Interrupts: A Practical Example"><div class="titlepage"><div><div><h2 class="title"><a id="delivering_interrupts_colon_a_practical"/>Delivering Interrupts: A Practical Example</h2></div></div></div><p>In practice, many additional steps are involved in detecting an external condition and then generating and receiving an IRQ. For example, <a class="xref" href="ch01s03.html#keyboard-to-computer_communications" title="Figure 1-1. Keyboard-to-computer communications">Figure 1-1</a> shows the sequence of events triggered by pressing or releasing a key on the keyboard. Before you even touch a single key, a tiny microcontroller chip inside your keyboard, serving as a keyboard controller, is busy sweeping the keyboard for any changes to its state.<a id="IDX-CHP-1-0040" class="indexterm"/><a id="IDX-CHP-1-0041" class="indexterm"/><a id="IDX-CHP-1-0042" class="indexterm"/><a id="IDX-CHP-1-0043" class="indexterm"/><a id="IDX-CHP-1-0044" class="indexterm"/></p><div class="figure"><a id="keyboard-to-computer_communications"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e622"/><img src="httpatomoreillycomsourcenostarchimages1137996.png.jpg" alt="Keyboard-to-computer communications"/></div></div><p class="title">Figure 1-1. Keyboard-to-computer communications</p></div><p>The keyboard is organized as an array of horizontal and vertical wires. Keys (microswitches or pressure-sensitive membrane switches) are installed at the intersection of each row and column. The controller tests every row and column separately, at very high speed.</p><p>If, for example, the keyboard controller detects a closed circuit when testing row 3, column 5 (which is signified by low resistance when voltage is applied to these lines), it concludes that the key at this particular location (J) is pressed. When the keyboard controller senses a change, it converts row and column coordinates into a scan code, a value that identifies a key by its unique identifier. The scan code information is then queued in the internal buffer of a chip, which then tells the CPU that there’s new data and goes back to minding its own business.</p><p>An input controller chip is the keyboard controller’s counterpart on the motherboard. The input controller usually handles all basic input devices, such as the mouse and keyboard. It receives a single scan code from the keyboard chip and signals an appropriate interrupt to the CPU’s butler, the PIC. As soon as the PIC determines that it can deliver this particular IRQ, the PIC passes this signal to the processor, which then usually interrupts its current task and invokes the interrupt handler installed by the operating system. The handler is expected to read the data and to tell the chip that it has read the scan code successfully. The input controller then resumes its normal operations and eventually reads another scan code from the keyboard if there is any data in the buffer.<sup>[<a id="CHP-1-FN-5" href="#ftn.CHP-1-FN-5" class="footnote">5</a>]</sup></p><p>This scheme is important to random number generation, although its significance is indirect. The computer, using the asynchronous event notification scheme (interrupts), receives almost instantaneous and precise feedback about user activity—perhaps most interestingly, accurately measured delays between keystrokes. Although the information is not always unpredictable, it is perhaps the best source of external, measurable, somewhat indeterministic signal the machine can get. And so, in order to work around the deterministic nature of the computer and to insert randomness in their calculations, authors of secure PRNG implementations resort to gathering entropy from generally unpredictable behavior of certain devices, such as the mouse, keyboard, network interfaces, and sometimes disk drives. To do so, they add an extra code inside an interrupt handler for the operating system that records certain parameters for every acceptable event.</p><p>Although it can be argued that neither of those sources provide truly random feedback all the time—for example, it is likely that after the user types <code class="literal">aardva</code>, the next two characters are going to be <code class="literal">rk</code>—some of the behavior, such as my thinking of aardvarks to begin with, is indeed rather unpredictable, from a practical standpoint (and not getting into an academic discussion of free will and deterministic universes). This method of adding entropy works reasonably well because it incorporates several factors that cannot be reasonably considered and monitored or predicted by an attacker while still maintaining their sanity. By gathering data from all those sources for an extended period of time, the laws of probability tell us that we will collect a certain amount of entropy. By collecting the data in a buffer, we construct an entropy pool that can be full or depleted, depending on the supply and demand for unpredictable data. Unfortunately, these small bits of randomness within the pool—where our typing was influenced by cosmic events—is still mixed with plenty of easily predictable data and as such can’t be immediately used for random number generation.</p><p>To ensure that the amount of actual entropy collected in the process of maintaining and replenishing the entropy pool is spread evenly over all PRNG output bits (with all unpredictable data expended), the pool has to be hashed; that is, it has to be stirred and mixed throughly so that no section of the data is easier to predict than any other. Every bit of the output must depend equally on all the input bits, in a nontrivial way. Achieving this without knowing which pieces of information are predictable and which are not (information that is not readily available to a computer monitoring keystrokes or mouse movements) can be a difficult task.</p></div><div class="sect2" title="One-Way Shortcut Functions"><div class="titlepage"><div><div><h2 class="title"><a id="one-way_shortcut_functions"/>One-Way Shortcut Functions</h2></div></div></div><p>Luckily enough, secure one-way hashing (“message digest”) functions, a flagship product of modern cryptography, can assist us with mixing data to get the most entropy into every bit of output, regardless of how nonuniform the input. These are functions that generate a fixed-length shortcut: a unique identifier of an arbitrary block of input data. But that is not all.<a id="IDX-CHP-1-0045" class="indexterm"/><a id="IDX-CHP-1-0046" class="indexterm"/><a id="IDX-CHP-1-0047" class="indexterm"/><a id="IDX-CHP-1-0048" class="indexterm"/><a id="IDX-CHP-1-0049" class="indexterm"/><a id="IDX-CHP-1-0050" class="indexterm"/></p><p>All one-way hashing functions have two important properties:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>It is easy to calculate the shortcut, but not possible to deduce the original message or any of its properties from the result. Any specific change to the message is just as likely to affect all properties of the output as any other change.</p></li><li class="listitem"><p>The likelihood of two distinct messages having the same shortcut is determined only by the size of the shortcut. With a sufficiently large shortcut (large enough to make exhaustive searches impractical, nowadays set at around 128 to 160 bits, or circa 3.4E+38 to 1.46E+48 combinations), it is not possible to find two messages that would have the same shortcut.</p></li></ul></div><p>As a result, shortcut functions provide a means for distributing entropy present in the input data in a uniform way over the output data. This solves the problem with generally random but locally predictable entropy sources: we gather an approximate amount of entropy from the environment, mixed with predictable data or not, and can generate a shortcut that is guaranteed to be just as unpredictable as the entropy collected in the first place, regardless of how the input entropy was distributed in the input data.</p><p>How do shortcut functions work? Some again rely on mathematical problems that are, as far as we know, very difficult to solve. In fact, any safe symmetrical or public key cryptography algorithm can be easily turned into a secure hashing function. As long as humanity does not come up with a really clever solution to any of these problems, relying on this approach should be fine.</p><p>Yet, by rolling out heavy artillery, we end up with slow and overly complicated tools to generate shortcuts, which is often impractical for compact implementations, particularly when integrating such a solution with an operating system. The alternative is to process the data so that the interdependency between all bits of input and output is sufficiently complex so as to fully obfuscate the input message and hope this is “good enough” to stop known cryptoanalysis techniques. Because “hopefully good enough” is actually the motto for a good chunk of computer science, we gladly accept this as a reasonable approach.</p><p>The advantage of the latter group of algorithms, which includes popular functions such as MD2, MD4, MD5, and SHA-1, is that they are generally much faster and easier to use than their counterparts based on difficult mathematical challenges and, when well designed, are not susceptible to cryptoanalysis tricks of the trade. Their weakness is that they are not provably secure because none of them reduces to a classic, hard-to-solve problem. Indeed, some have been proved to have specific weaknesses.<sup>[<a href="apb.html#ftn.CHP-1-BIB-6" class="footnoteref">46</a>]</sup></p><p>As suggested earlier, a great service of shortcut functions to pseudorandom number generation is that they can be run on a segment of data that contains <span class="emphasis"><em>n</em></span> random bits, and any number of predictable bits, to produce a shortcut that will spread <span class="emphasis"><em>n</em></span> bits of entropy evenly across all bits of the shortcut (thanks to the two fundamental one-way shortcut function properties discussed earlier). As a result, the shortcut function becomes a convenient entropy extractor. By running a sufficient amount of data collected from a generally unpredictable interrupt handler through a shortcut function, we can generate random numbers without disclosing any valuable information about the exact shape of the information used to generate the number, and without the risk of imperfect input affecting the output in any meaningful way. All we need to do is to ensure that there is a sufficient amount of entropy collected and feed into a shortcut function within a chunk of interrupt data, else we risk compromising the entire scheme. If the attacker can predict considerable portions of the data we use for random number generation, and the remainder has only a handful of possible combinations, they can throw a successful brute-force attack against our implementation by simply trying and verifying all possible values. If, for example, we use a shortcut function that produces 128-bit digests, no matter how much data we actually collected, be it 200 bytes or 2 megabytes worth of keyboard tapping, we must be sure that at least 128 of these input bits are unpredictable to the attacker before hashing it.</p></div><div class="sect2" title="The Importance of Being Pedantic"><div class="titlepage"><div><div><h2 class="title"><a id="the_importance_of_being_pedantic"/>The Importance of Being Pedantic</h2></div></div></div><p>As an example of when things can go wrong, consider a user who decides to write a shell script when a system entropy pool is empty, perhaps due to some random number-hungry operation that was performed a while ago. The attacker notices that the user is writing a script because <code class="literal">vi delallusers.sh</code> is being executed; they further assume that the script must have started with something along the lines of <code class="literal">#!/bin/sh</code>. Although they cannot be sure what is coming next, they can reasonably expect that the script will open with an invocation of a shell command and that it is somewhat less likely to continue with a tacky poem about aardvarks.<a id="IDX-CHP-1-0051" class="indexterm"/></p><p>At this point, an encryption utility of some kind suddenly asks the system for a 128-bit random number to be used as a session key to protect communications. However, the system fails to correctly estimate the amount of entropy available in the buffer that recorded the process of writing the first lines of the script, and the attacker now has an easy task. The computer is devoid of the information whether this particular action performed by the user at the very moment is predictable to others or not. It can only speculate (aided by the assumptions made by the programmer) that, over the course of a couple of minutes or hours, users’ actions will sum up to something that could not be precisely predicted and that, on average, this much of the input indeed would depend on factors unpredictable to the attacker.</p><p>The attacker, at this point, knows most of the entropy pool contents and is left with barely thousands of options to choose from when it comes to the unknown part—despite the fact that the operating system is convinced that there is far more entropy in the buffer. These thousands are hardly a big challenge for someone assisted by a computer. Consequently, instead of getting a 128-bit random number, which has a 39-digit number of combinations, an unsuspecting cryptography application ends up with a number generated from input that could have been only one of a couple thousand of options, easily verifiable by the attacker by trial and error, and the attacker can soon decrypt the information that was supposed to remain secure.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-1-FN-5" href="#CHP-1-FN-5" class="para">5</a>] </sup>On many architectures, it is necessary to manually instruct the PIC that the interrupt has been processed and that it should no longer block subsequent interrupts. This is done with the End of Interrupt (EOI) code.</p></div></div></div>
<div class="sect1" title="Entropy Is a Terrible Thing to Waste"><div class="titlepage"><div><div><h1 class="title"><a id="entropy_is_a_terrible_thing_to_waste"/>Entropy Is a Terrible Thing to Waste</h1></div></div></div><p>Because it is next to impossible to accurately predict the amount of entropy collected from a user in a short run, in order to prevent the predictable PRNG output problem discussed previously, all implementations include the shortcut or internal PRNG state in the process of generating new output. The previous output becomes a part of the equation used to calculate the next PRNG value.</p><p>In this design, once a sufficient amount of entropy is initially gathered in the system, the most recent data used to replenish the entropy pool does not need to be fully random at all times in order to ensure basic security.</p><p>Yet, there is another problem. If the implementation runs for a prolonged period of time on old, inherited entropy, only hashed again and again with MD5 or SHA-1, it becomes fully dependent on the security of the shortcut algorithm, which cannot be completely trusted due to the performance and security trade-off discussed before. Moreover, the hashing functions have not necessarily undergone an appropriate evaluation of suitability for this particular use from competent cryptographers. The implementation no longer relies simply on the bit hashing properties of a shortcut function and now fully depends on its invulnerability to cracking attacks. If, with every subsequent step, a small amount of information about the internal state of the generator is disclosed, and no new unpredictable data is added to the pool, in the long run, the data may suffice to reconstruct or guess the internal state with reasonable certainty, which makes it possible to predict the future behavior of the device. On the other hand, if new random data is added at a rate that, at least statistically, prevents a significant reuse of the internal state, the attack becomes much less feasible even if the hashing function is fundamentally broken.<a id="IDX-CHP-1-0052" class="indexterm"/></p><p>Many experts believe this level of trust and reliance on the hashing function should not be exercised for the most demanding applications. Hence, it is important for an implementation to keep track of an estimated amount of entropy collected in the system, which, even if not momentarily correct, reflects a general statistical trend we would expect from the sources used. Minor short-term fluctuations in the availability of external entropy, such as the script editing example discussed previously, may occur and will be compensated for by the output reuse algorithm. Still, it is necessary to make accurate long-term predictions to ensure frequent replenishing of the internal entropy pool and to minimize exposure should the hashing function turn out to leak internal state over time. As such, the implementation has to account for all entropy spent in data supplied to user processes and refuse to supply more random numbers until a sufficient amount of entropy is available.</p><p>A good example of a proper PRNG implementation that takes all the above into account is the excellent system devised and implemented in 1994 by Theodore Ts’o of the Massachusetts Institute of Technology. His mechanism, /dev/random, was first implemented in Linux and later introduced to systems such as FreeBSD, NetBSD, and HP/UX. Ts’o’s mechanism monitors a number of system I/O events, measuring time intervals and other important interrupt characteristics. It also preserves the entropy pool during system shutdowns by saving it to disk, which prevents the system from booting up to a fully predictable state, making it even more difficult to attack.</p></div>
<div class="sect1" title="Attack: The Implications of a Sudden Paradigm Shift"><div class="titlepage"><div><div><h1 class="title"><a id="attack_colon_the_implications_of_a_sudde"/>Attack: The Implications of a Sudden Paradigm Shift</h1></div></div></div><p>What could be the problem with this seemingly fool-proof scheme for supplying unpredictable random numbers to demanding applications? Nothing, at least not where you would expect it. The numbers generated are indeed difficult to predict.<a id="IDX-CHP-1-0055" class="indexterm"/><a id="IDX-CHP-1-0056" class="indexterm"/><a id="IDX-CHP-1-0057" class="indexterm"/><a id="IDX-CHP-1-0058" class="indexterm"/><a id="IDX-CHP-1-0053" class="indexterm"/><a id="IDX-CHP-1-0054" class="indexterm"/></p><p>There is, however, one slight but disastrous mistake in the reasoning of the designer of this technology. Mr. Ts’o’s design assumes that the attacker is interested in predicting random numbers based on knowledge of the machine and its environment. But what if the attacker wants to do quite the opposite?</p><p>The attacker with an account on the machine, even though they have no direct access to the information the user is typing, can deduce the exact moment input activity is occurring in the system by emptying the entropy pool (which can be achieved by simply requesting random data from the system and discarding it) and then monitoring the availability of PRNG output. If there is no I/O activity, the PRNG will not have any new data available, because the entropy estimate won’t change. If a keystroke or a key release occurs, a small amount of information will be available to the attacker, who may then deduce that a key was pressed or released.</p><p>Other events, such as disk activity, also generate some PRNG output, but the amount and timing patterns of entropy gathered this way differ from the characteristics of keyboard interrupt data. As such, it is possible and easy to discern events by the amount of data available at any given time. The data from keystrokes will look different from the data from disk activity.</p><p>In the end, a method for assuring the highest possible level of safety for secure random number generation actually results in degrading the privacy of the user: the availability of this mechanism to estimate the amount of entropy available from an external source can be abused and used to monitor certain aspects of input activities on the system. Although the attacker cannot detect exactly what is being typed, there are strong timing patterns for writing different words on the keyboard, especially if precise key press and release information is present, as it is in this case. By examining those patterns, the attacker can deduce the actual input, or at least guess it more easily.</p><div class="sect2" title="A Closer Look at Input Timing Patterns"><div class="titlepage"><div><div><h2 class="title"><a id="a_closer_look_at_input_timing_patterns"/>A Closer Look at Input Timing Patterns</h2></div></div></div><p>An in-depth analysis led by a team of researchers at the University of California<sup>[<a href="apb.html#ftn.CHP-1-BIB-7" class="footnoteref">47</a>]</sup> indicates that it is possible to deduce certain properties of user input, or even fully reconstruct the data, by looking only at inter-keystroke timing. The research concluded that, for seamless typing and a keyboard-proficient operator, there might be some variation in inter-keystroke timings, but dominant timing patterns for each key-to-key transition are clearly visible.<a id="IDX-CHP-1-0059" class="indexterm"/><a id="IDX-CHP-1-0060" class="indexterm"/><a id="IDX-CHP-1-0061" class="indexterm"/><a id="IDX-CHP-1-0062" class="indexterm"/></p><p>The reason is that our hands lie on the keyboard a certain way and that the key position on the keyboard affects how fast we can reach a key with our fingertips. For example, the interval between pressing e and n is generally different from the interval between m and l. In the first case, because one hand controls the left side of the keyboard, and the other controls the right side (see <a class="xref" href="ch01s05.html#the_usual_territory_for_each_hand._dark" title="Figure 1-2. The usual territory for each hand. Dark-gray keys are usually controlled by the left hand, and white areas are controlled by the right hand.">Figure 1-2</a>), typing both characters requires almost no movement, and both keys are pressed almost simultaneously, with a time interval of less than 100 milliseconds. Typing m and l requires a fairly awkward fingering and takes much longer.</p><div class="figure"><a id="the_usual_territory_for_each_hand._dark"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e804"/><img src="httpatomoreillycomsourcenostarchimages1137998.png.jpg" alt="The usual territory for each hand. Dark-gray keys are usually controlled by the left hand, and white areas are controlled by the right hand."/></div></div><p class="title">Figure 1-2. The usual territory for each hand. Dark-gray keys are usually controlled by the left hand, and white areas are controlled by the right hand.</p></div><p>After analyzing a number of samples, the authors of this research estimate that approximately 1.2 bits of information per key pressed can be acquired from the timing data. By observing sequence delays, it is possible to determine the set of keyboard inputs most likely to generate this pattern, thus making it easier to guess the exact sequence of keys pressed. The idea of counting fractions of bits may sound ridiculous, but what this really means is that the number of possibilities for every key can be reduced by 2<sup>1.2</sup>, or approximately 2.40 times. For a single regular keystroke, which usually carries no more than 6 bits of randomness to begin with, this reduces the option set from about 64 to 26 elements.</p><p>The net effect is that this reduces the level of search space; we can see that there’s a way to limit the number of possibilities if we want to guess at what keys are being typed. Although this reduction may not be particularly impressive on its own, add to this that the data entered from the keyboard is not likely to be just random garbage to start with. The entropy of English text is estimated to be as low as 0.6 to 1.3 bits per character,<sup>[<a href="apb.html#ftn.CHP-1-BIB-8" class="footnoteref">48</a>]</sup> meaning that it on average takes approximately 1.5 to 2.5 attempts to successfully predict the next character. With a method to further reduce the search space, it is possible to find nonambiguous dictionary word matches for almost all the input data.</p><p>To verify their estimates and demonstrate the issue in practice, the researchers used the Hidden Markov Model and Viterbi algorithm to guess keystrokes. A Markov Model is a method for describing a discrete system in which the next value depends only on its current state, and not on the previous values (Markov chain). The Hidden Markov Model is a variant that provides a method for describing a system for which each internal state generates an observation, but for which the actual state is not known. This model is commonly used in applications such as speech recognition, in which the goal is to obtain pure data (a textual representation of the spoken word) from its specific manifestation (sampled waveform).<a id="IDX-CHP-1-0063" class="indexterm"/><a id="IDX-CHP-1-0064" class="indexterm"/></p><p>The authors conclude that the Hidden Markov Model is applicable to keystroke analysis, and they consider the internal state of the system to be the information about keys pressed; the observation in the Hidden Markov Model is the inter-keystroke timing.</p><p>It might be argued that this is an oversimplification, because, most notably in the situation pictured in <a class="xref" href="ch01s05.html#the_need_to_move_the_left_hand_to_a_diff" title="Figure 1-3. The need to move the left hand to a different position in the previous step affects the P-V timing. The Markov Model is unable to take a previous location of the hand on hand-switch scenarios into account.">Figure 1-3</a>, there might be a deeper dependency.</p><div class="figure"><a id="the_need_to_move_the_left_hand_to_a_diff"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e835"/><img src="httpatomoreillycomsourcenostarchimages1138000.png.jpg" alt="The need to move the left hand to a different position in the previous step affects the P-V timing. The Markov Model is unable to take a previous location of the hand on hand-switch scenarios into account."/></div></div><p class="title">Figure 1-3. The need to move the left hand to a different position in the previous step affects the P-V timing. The Markov Model is unable to take a previous location of the hand on hand-switch scenarios into account.</p></div><p>The Viterbi algorithm is one way to solve Hidden Markov Model problems. The algorithm can be used to find the most likely sequence of internal states based on a sequence of observations. In this particular case, we use it to determine the most likely sequence of characters based on a sequence of timings.</p><p>The final result of applying the Viterbi algorithm is a reduction of the search space for nondictionary eight-character passwords by a factor of 50. For reconstruction of typed dictionary-based English text, the factor is likely to be considerably higher.</p><p>Now let’s look at interrupt monitoring. The research we’ve just discussed focused on partial information available by snooping on Secure Shell (SSH) traffic patterns. In the case of interrupt monitoring, the attacker has considerably more information available. For one thing, keystroke duration information is available as well as inter-keystroke timings, with the duration of a single keystroke depending on the finger used. For example the index finger usually makes the shortest contact with the key, the ring finger is probably the slowest, and so on. This is valuable information, which makes it much easier to locate an approximate area of keys on the keyboard.</p><p>Second, the data also enables the attacker to monitor hand transitions, the moment when the first character is typed by the left hand, and the second by the right hand, or vice versa. Because each hand is controlled by a different hemisphere of the brain, almost all proficient keyboard users often press the second key before releasing the first when switching hands. Although key press and release events are indistinguishable as such, a particularly short interval of time between two keyboard events is a clear sign of this phenomenon. In some rare situations, particularly when the typist is in a hurry, the second key press occurs not only before the release, but even before the press of the first key. This results in popular typographic errors such as “teh” instead of “the.”</p><p><a class="xref" href="ch01s05.html#key_press_and_release_timing_for_hand_tr" title="Figure 1-4. Key press and release timing for hand transitions">Figure 1-4</a> shows a capture of sample keyboard timings. The user types the word <span class="emphasis"><em>evil</em></span>. The middle finger of the left hand presses e for a medium period of time. Then, there is a considerable interval before the typist presses v due to the need to move the entire hand in order to reach v with the index finger. (The thumb cannot be used because the spacebar gets in the way.) “The v is pressed for a short period of time, as is i, with both accessed by the index finger. There is also a visible overlap: i is pressed before v is released due to a hand transition. Finally, the ring finger presses l after a while (there is no need to move the hand), and the contact is quite long.</p><div class="figure"><a id="key_press_and_release_timing_for_hand_tr"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject1_d1e858"/><img src="httpatomoreillycomsourcenostarchimages1138002.png.jpg" alt="Key press and release timing for hand transitions"/></div></div><p class="title">Figure 1-4. Key press and release timing for hand transitions</p></div><p>Hence, it is reasonable to expect that it is possible to achieve a much higher success ratio in this attack. (Most of this information was not available in the scenario discussed in the aforementioned white paper.)</p></div><div class="sect2" title="Immediate Defense Tactics"><div class="titlepage"><div><div><h2 class="title"><a id="immediate_defense_tactics"/>Immediate Defense Tactics</h2></div></div></div><p>Now that we know the potential for keyboard sniffing, how do we thwart it? The best way is to employ a separate keyboard entropy buffer of a reasonable size. The buffer is flushed and passed down to the core PRNG implementation only after it overflows or after a time interval considerably larger than the usual inter-keystroke delay (that is, at least several seconds) passes, thus eliminating the attacker’s ability to measure timing.<a id="IDX-CHP-1-0065" class="indexterm"/><a id="IDX-CHP-1-0066" class="indexterm"/><a id="IDX-CHP-1-0067" class="indexterm"/><a id="IDX-CHP-1-0068" class="indexterm"/></p><p>With this solution, only two types of information are available to the attacker. The first results from the flush on overflow procedure and discloses to the attacker that a number of keys (depending on the buffer size) were pressed in a measurable period of time, but does not divulge exact key interval timings. The second possibility is a result of a timed flush sequence, and informs the attacker that a key or several keys were pressed during a fixed time frame, but does not provide any information about the number of events and their precise time of occurrence. The information provided in this way is of a marginal value for timing attacks and can only be used for generating general statistics of keyboard activity, the latter not posing a threat in most multiuser environments.</p></div><div class="sect2" title="Hardware RNG: A Better Solution?"><div class="titlepage"><div><div><h2 class="title"><a id="hardware_rng_colon_a_better_solution_que"/>Hardware RNG: A Better Solution?</h2></div></div></div><p>A number of today’s hardware platforms implement physical random number generators, often referred to as TRNGs, or true random number generators. These devices provide a more reliable way of generating truly unpredictable data, as opposed to gathering information that is merely expected to be difficult to predict, and are a recommended way of acquiring entropy on all machines equipped with this hardware. Two popular solutions, as of this writing, are integrated circuits developed by Intel and VIA.<a id="IDX-CHP-1-0069" class="indexterm"/></p><p>Intel RNG is integrated with chip sets such as i810 and uses a conventional design of two oscillators. The high-frequency oscillator generates a base signal, which is essentially a pattern of alternating logical states (010101010101...). The other oscillator is a low-frequency device, working at a nominal rate of 1/100 the frequency of the high-speed oscillator, but its actual frequency is modulated by a resistor, which serves as a primary source of entropy.</p><p>Certain measurable characteristics of a resistor change as a result of thermal noise and other random material effects. The low-frequency oscillator is used to drive sampling of the alternating signal at now random frequencies (falling edge of the oscillator output). The signal, after some necessary conditioning and “whitening” using von Neumann correction, is then made available to the outside world. A careful analysis of the design and actual output of the generator performed by Benjamin Jun and Paul Kocher of Cryptography Research<sup>[<a href="apb.html#ftn.CHP-1-BIB-9" class="footnoteref">49</a>]</sup> has shown that the quality of the output is consistently high and that the generator provides an estimated 0.999 bits of entropy per output bit.</p><p>VIA C3 “Nehemiah” RNG is based on a slightly different design that uses a set of oscillators, but not a separate source of noise, such as a special resistor hookup. Instead, it relies on the internal jitter of the oscillators, an effect that can be attributed to a number of internal and external factors and additionally controlled by a configurable “bias” setting.</p><p>In this case, a separate analysis led by Cryptography Research<sup>[<a href="apb.html#ftn.CHP-1-BIB-10" class="footnoteref">50</a>]</sup> indicated the generator apparently delivers a lower-quality entropy than its counterpart, ranging from 0.855 to 0.95 bits per output bit. This is a dangerous result if the RNG output is taken as fully random as-is and used for key generation or other critical tasks 1:1, because the amount of actual entropy is reduced accordingly. To solve this problem, we can acquire more data than necessary from the generator and then run the data via a secure hashing function, such as SHA-1, to eliminate any eventual bias or entropy deficiency. The solution is a general good practice for preventing TRNG issues, as long as these undesirable effects are within reasonable limits—that is, each bit still carries some useful entropy.</p><p>Several researchers have also suggested using certain nonspecialized input devices, such as webcams or built-in microphones, as a source of entropy: Charge Coupled Device (CCD) sensors in digital cameras tend to exhibit pixel noise, and a severely overamplified microphone signal is essentially a good source of random noise. However, there is no universal method for setting up such a generator due to the differences in circuits of popular media devices from various manufacturers, and as such the quality of “random” numbers generated this way cannot be assured. In fact, some devices pick up seemingly random but fully predictable radio interference or certain in-circuit signals. Additionally, some devices, in particular CCD sensors, exhibit static noise patterns. While seemingly random, this noise is not changing rapidly and may be dangerous to rely on.</p></div></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought"/>Food for Thought</h1></div></div></div><p>I have decided to omit in-depth discussion of a few interesting concepts, but these may be a valuable inspiration for further explorations.<a id="IDX-CHP-1-0072" class="indexterm"/><a id="IDX-CHP-1-0073" class="indexterm"/><a id="IDX-CHP-1-0074" class="indexterm"/><a id="IDX-CHP-1-0075" class="indexterm"/><a id="IDX-CHP-1-0076" class="indexterm"/><a id="IDX-CHP-1-0070" class="indexterm"/><a id="IDX-CHP-1-0071" class="indexterm"/></p><div class="sect2" title="Remote Timing Attacks"><div class="titlepage"><div><div><h2 class="title"><a id="remote_timing_attacks"/>Remote Timing Attacks</h2></div></div></div><p>In theory, it might be possible to deploy the PRNG timing attack over a network. Certain cryptography-enabled services implement symmetrical cryptography. After establishing a slower asymmetric stream using public key infrastructure and verifying both parties, a symmetrical session key is generated, and both endpoints switch to a faster symmetrical alternative.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>It might be possible to time keystrokes by causing the application to exhaust an existing entropy pool in the system to the point that there is not enough entropy to seed a new session key, but only by a small fraction. The application will then delay generating a symmetrical key until enough entropy to seed the remainder of a key is available, and this will occur, among other possibilities, on the next key press or release.</p></li><li class="listitem"><p>It is my belief that the attack is more likely to succeed in a laboratory setup than in any real-world practical application, although my technical reviewer disagrees with my skepticism, and so, consider it to be merely an opinion. An interesting analysis from the University of Virginia criticized the original SSH timing research discussed in the paper mentioned before on the grounds that network jitter is sufficient to render timing data unusable, although it is worth noting that if a specific activity is repeated over time (for example, the same password is entered upon every login), random network performance fluctuations may very well average out.<sup>[<a href="apb.html#ftn.CHP-1-BIB-11" class="footnoteref">51</a>]</sup></p></li></ul></div></div><div class="sect2" title="Exploiting System Diagnostics"><div class="titlepage"><div><div><h2 class="title"><a id="exploiting_system_diagnostics"/>Exploiting System Diagnostics</h2></div></div></div><p>Some systems have better ways to recover the keystroke information and other timing data. After publishing my PRNG timing research, it was pointed out to me that Linux provides a /proc/interrupts interface that displays interrupt summary statistics, with the intention of providing some useful performance data. By examining interrupt counter changes for IRQ 1, it is possible to obtain the same timing information that is acquired via PRNG, already filtered of any eventual disk and network activity inclusions, thus causing a privacy exposure similar to the one discussed before.<a id="IDX-CHP-1-0077" class="indexterm"/><a id="IDX-CHP-1-0078" class="indexterm"/><a id="IDX-CHP-1-0079" class="indexterm"/><a id="IDX-CHP-1-0080" class="indexterm"/></p></div><div class="sect2" title="Reproducible Unpredictability"><div class="titlepage"><div><div><h2 class="title"><a id="reproducible_unpredictability"/>Reproducible Unpredictability</h2></div></div></div><p>Other issues worth considering are related to the PRNG implementation itself. Buying identical hardware in bulk and installing the same system on each device is a common practice and can be a problem for servers that do not experience heavy console activity. There is also a risk of mirroring an installation using specialized duplication tools and then propagating the image across a number of servers. In all situations, systems can end up with low real entropy for perhaps a bit too long.</p></div></div>
<div class="chapter" title="Chapter&#xA0;2.&#xA0;Extra Efforts Never Go Unnoticed"><div class="titlepage"><div><div><h1 class="title"><a id="extra_efforts_never_go_unnoticed"/>Chapter 2. Extra Efforts Never Go Unnoticed</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where we learn how to build a wooden computer and how to obtain information from watching a real computer run</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>The data you entered is now safe in the hands of the application you chose to run. The program will take its time deciding what to do with the information, how to interpret it, and which actions to take next.</p><p>In this chapter, we examine the low-level mechanics of data processing in detail and explore some of the pitfalls that can lurk deep beneath the heat sink of your processor. We pay particular attention to the information we can deduce simply by observing how a machine executes given programs and how much time it takes to complete certain tasks. As a bonus, we’ll also build a fully functional wooden computer.</p><div class="sect1" title="Boole’s Heritage"><div class="titlepage"><div><div><h1 class="title"><a id="booleas_heritage"/>Boole’s Heritage</h1></div></div></div><p>To understand the design of a processor, we must return to the days when processors had not yet been dreamed of. It all started quite innocently back in the 19th century, when self-taught mathematician George Boole (1815–64) devised a simple binary algebra system intended to provide a framework for understanding and modeling formal calculus. His approach reduced the fundamental concepts of logic to a set of three, simple algebraic operations that could be applied to elements representing two opposite states, true and false. These operations are:<a id="IDX-CHP-2-0081" class="indexterm"/><a id="IDX-CHP-2-0082" class="indexterm"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The disjunction operator, <span class="strong"><strong>OR</strong></span>. This is true when at least one of its operands<sup>[<a id="CHP-2-FN-1" href="#ftn.CHP-2-FN-1" class="footnote">6</a>]</sup> is true.<sup>[<a id="CHP-2-FN-2" href="#ftn.CHP-2-FN-2" class="footnote">7</a>]</sup></p></li><li class="listitem"><p>The conjunction operator, <span class="strong"><strong>AND</strong></span>. This is only true when all its operands are true.</p></li><li class="listitem"><p>The complement (negation) operator, <span class="strong"><strong>NOT</strong></span>. This is true when its only operand is false.</p></li></ul></div><p>Although simple in design, the Boolean algebraic model turned out to be a powerful tool for solving logic problems and certain other mathematical challenges. Ultimately, it made it possible for many brave visionaries to dream of clever analytic machines that would one day change our daily lives.</p><p>Today, Boolean logic is seldom a mystery for the experienced computer user, but the path from this set of trivial operations to today’s computer often is. We’ll begin exploring this path by first attempting to capture the essence of this model at its simplest.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-2-FN-1" href="#CHP-2-FN-1" class="para">6</a>] </sup>The operand is something that is operated on by the operator.</p></div><div class="footnote"><p><sup>[<a id="ftn.CHP-2-FN-2" href="#CHP-2-FN-2" class="para">7</a>] </sup>The meaning of logical OR differs from the common English understanding of this term: the resulting statement remains true both when only one of the OR parameters is true and when all are. In English, “or” typically means that <span class="emphasis"><em>only</em></span> one option is true.</p></div></div></div>
<div class="sect1" title="Toward the Universal Operator"><div class="titlepage"><div><div><h1 class="title"><a id="toward_the_universal_operator"/>Toward the Universal Operator</h1></div></div></div><p>The path to simplicity often leads through a seemingly needless level of complexity—and this case is no exception. To even begin, we must consider the work of another 19th-century mathematician, Augustus DeMorgan (1806–71). DeMorgan’s law states that “a complement of disjunction is the conjunction of complements.” This infamous exercise in obfuscating trivial concepts has some profound consequences for Boolean logic and, ultimately, the design of digital circuits.<a id="IDX-CHP-2-0083" class="indexterm"/><a id="IDX-CHP-2-0084" class="indexterm"/><a id="IDX-CHP-2-0085" class="indexterm"/><a id="IDX-CHP-2-0086" class="indexterm"/><a id="IDX-CHP-2-0087" class="indexterm"/><a id="IDX-CHP-2-0088" class="indexterm"/><a id="IDX-CHP-2-0089" class="indexterm"/><a id="IDX-CHP-2-0090" class="indexterm"/><a id="IDX-CHP-2-0091" class="indexterm"/><a id="IDX-CHP-2-0092" class="indexterm"/></p><p>In plain English, DeMorgan’s law explains that when any (or both) of two conditions is not satisfied, a sentence that claims that both conditions are met (or, in other words, a conjunction of conditions occurs) will be false as well—oh, and vice versa.</p><p>The law concludes that NOT OR (a, b) should be logically equivalent to AND (NOT a, NOT b). Consider a real-world example in which a and b represent the following:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>a = “Bob likes milk”</td></tr><tr><td>b = “Bob likes apples”</td></tr></table><p>The two sides of the DeMorgan’s equation can be now written as:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>OR (NOT a, NOT b) ⇔ Bob does NOT like milk OR does NOT like apples</td></tr><tr><td>NOT AND (a, b) ⇔ It is NOT true that Bob likes both milk AND apples</td></tr></table><p>Both expressions are functionally equivalent. If it is true that Bob dislikes either milk or apples, the first expression is true; it is then also true that he does not like both, which means that the second expression is also true.</p><p>Reversing the situation also results in agreement: If it is not true that Bob dislikes at least one of the choices, he likes both (and the first expression is false). In that case, it is also not true that he does not like both (and the second expression is also false).</p><div class="sect2" title="DeMorgan at Work"><div class="titlepage"><div><div><h2 class="title"><a id="demorgan_at_work"/>DeMorgan at Work</h2></div></div></div><p>To evaluate logic statements beyond appeals to intuition and some hand waving, it helps to construct so-called truth tables that demonstrate all the results that can be calculated from all possible combinations of true and false operators.</p><p>The following two tables represent each expression from the previous example. Each table includes columns for both operators and the corresponding results for all possible true and false combinations. And so, in the first row, you can see that two first columns—both operands to NOT AND(a, b)—are false. This causes AND(a, b) to be false, as well, hence causing NOT AND(a, b) to be true. The outcome is denoted in the third column.</p><p>As you can see, the two expressions behave identically:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="3" valign="bottom"><p>NOT AND(a, b): AND w/Result Negated</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Operand 1 (a)</p></th><th style="text-align: left" valign="bottom"><p>Operand 2 (b)</p></th><th style="text-align: left" valign="bottom"><p>Result</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr></tbody></table></div><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="3" valign="bottom"><p>OR(NOT a, NOT b): OR w/Operands Negated</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Operand 1</p></th><th style="text-align: left" valign="bottom"><p>Operand 2</p></th><th style="text-align: left" valign="bottom"><p>Result</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr></tbody></table></div><p>But why do computer designers care about Bob’s food preferences? Because in the context of Boolean operators, DeMorgan’s law means that the set of basic operations proposed by Boolean algebra is actually partially redundant: a combination of NOT and any of the two other operators (OR and AND) is always sufficient to synthesize the remaining one. For example:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>OR (a, b) ⇔ NOT AND (NOT a, NOT b)</td></tr><tr><td>AND (a, b) ⇔ NOT OR(NOT a, NOT b)</td></tr></table><p>This understanding reduces the set of operators to two, but the Boolean system can be simplified still further.</p></div><div class="sect2" title="Convenience Is a Necessity"><div class="titlepage"><div><div><h2 class="title"><a id="convenience_is_a_necessity"/>Convenience Is a Necessity</h2></div></div></div><p>Several additional operators are not crucial for implementing Boolean logic, but complement the existing set of operations. These additional operators, NAND and NOR, are true only when AND and OR respectively are false:<a id="IDX-CHP-2-0093" class="indexterm"/><a id="IDX-CHP-2-0094" class="indexterm"/></p><table border="0" summary="Simple list" class="simplelist"><tr><td>NAND(a, b) ⇔ NOT AND(a, b) ⇔ OR(NOT a, NOT b)</td></tr><tr><td>NOR(a, b) ⇔ NOT OR(a, b) ⇔ AND(NOT a, NOT b)</td></tr></table><p>These new functions are no more complex than AND and OR. Each has a four-state (four-row) truth table, and hence its value can determined with just as much effort.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>NOR and NAND are not found in the basic set of operands because neither one corresponds to a commonly used, basic type of logical relation between sentences and has no atomic representation in the common language.</p></div><p>I have just introduced a set of new operators, derived from the existing set, that seem to offer nothing but a dubious convenience feature for those wanting to express more bizarre logic dependencies or problems using formal notation. What for?</p><p>The introduction of NAND or NOR alone makes it possible to get rid of AND, OR, and NOT altogether. This furthers our goal of simplicity and affords us the ability to describe the entire Boolean algebra system with fewer elements and operators.</p><p>The importance of those negated auxiliary operators is that you can use any one of them to build a complete Boolean algebra system. In fact, you can construct all basic operators using NAND, as shown here (<span class="emphasis"><em>T</em></span> stands for a true statement, and <span class="emphasis"><em>F</em></span> stands for false<sup>[<a id="CHP-2-FN-3" href="#ftn.CHP-2-FN-3" class="footnote">8</a>]</sup>). How? Well, quite obviously, the following pairs of statements are equivalent:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>NOT a ⇔ NAND(<span class="emphasis"><em>T</em></span>, a)</td></tr><tr><td>AND(a, b) ⇔ NOT NAND(a, b) ⇔ NAND(<span class="emphasis"><em>T</em></span>, NAND(a, b))</td></tr><tr><td>OR(a, b) ⇔ NAND(NOT a, NOT b) ⇔ NAND(NAND(<span class="emphasis"><em>T</em></span>, a), NAND(<span class="emphasis"><em>T</em></span>, b))</td></tr></table><p>or, if we prefer to rely exclusively on NOR, rather than NAND, we can say</p><table border="0" summary="Simple list" class="simplelist"><tr><td>NOT a ⇔ NOR(<span class="emphasis"><em>F</em></span>, a)</td></tr><tr><td>OR(a, b) ⇔ NOT NOR(a, b) ⇔ NOR(<span class="emphasis"><em>F</em></span>, NOR(a, b))</td></tr><tr><td>AND(a, b) ⇔ NOR(NOT a, NOT b) ⇔ NOR(NOR(<span class="emphasis"><em>F</em></span>, a), NOR(<span class="emphasis"><em>F</em></span>, b))</td></tr></table></div><div class="sect2" title="Embracing the Complexity"><div class="titlepage"><div><div><h2 class="title"><a id="embracing_the_complexity"/>Embracing the Complexity</h2></div></div></div><p>It can be hard to believe that the essence of all computing can be captured within one of the universal logic operators. You can implement most complex algorithms, advanced computations, cutting-edge games, and Internet browsing using an array of simple circuits that involve one of the following truth tables, which convert input signals to output signals:<a id="IDX-CHP-2-0095" class="indexterm"/></p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="3" valign="bottom"><p>NAND State Table</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Operand 1</p></th><th style="text-align: left" valign="bottom"><p>Operand 2</p></th><th style="text-align: left" valign="bottom"><p>Result</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr></tbody></table></div><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="3" valign="bottom"><p>NOR State Table</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Operand 1</p></th><th style="text-align: left" valign="bottom"><p>Operand 2</p></th><th style="text-align: left" valign="bottom"><p>Result</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td></tr><tr><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr><tr><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>TRUE</p></td><td style="text-align: left" valign="top"><p>FALSE</p></td></tr></tbody></table></div><p>It would seem we are going nowhere, though. . . . How come this trivial set of dependencies make it possible to build a device capable of solving complex problems, such as rejecting your credit application in a tactful manner? And what does a piece of theory based on the states “true” and “false” have in common with digital circuits?</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-2-FN-3" href="#CHP-2-FN-3" class="para">8</a>] </sup>Purists may want to assume that <span class="emphasis"><em>T</em></span> is equivalent to AND(a, a), for example, which is always true, and <span class="emphasis"><em>F</em></span> is equivalent to NOT AND (a, a), which is always false. In other words, we do not introduce a new concept or equation element—we only simplify the notation a bit at this point.</p></div></div></div>
<div class="sect1" title="Toward the Material World"><div class="titlepage"><div><div><h1 class="title"><a id="toward_the_material_world"/>Toward the Material World</h1></div></div></div><p>There is nothing complex about the mechanism devised by Boole: it calls for two opposite logic states, “true” and “false,” 0 and 1, “cyan” and “purple,” 999 and 999 ½. The actual meaning, the physical representation, and the medium are irrelevant; what matters is the arbitrarily chosen convention that assigns certain states of the medium to a specific set of logic values.</p><p>Computers as we know them use two different voltage levels in an electronic circuit and interpret them as values their designers refer to as 0 and 1. These values, which are carried through the electric circuit, represent two digits in the binary system—but nothing is stopping a person from using just about any method to convey the data, from water flow, to chemical reactions, to smoke signals, to torques transmitted by a set of masterfully crafted wooden gears. The information remains the same, regardless of its carrier.<a id="IDX-CHP-2-0096" class="indexterm"/></p><p>The key to implementing Boolean logic in the physical world is simple, once we agree on the physical representation of logic values. Next, we need only find a way to arrange a set of components to manipulate those values in order to accommodate any task we want our computer to perform (but more about this later). First, let’s try to find out how to manipulate signals and implement real-world logic devices, commonly referred to as gates. Wooden gates, that is.</p></div>
<div class="sect1" title="A Nonelectric Computer"><div class="titlepage"><div><div><h1 class="title"><a id="a_nonelectric_computer"/>A Nonelectric Computer</h1></div></div></div><p>Moving from a set of theoretical operations spawned by the world of pure mathematics to a device that can moderate water flow, torques, or electrical signals in a way that mimics one of the logic operators appears to be a difficult task—but it isn’t.<a id="IDX-CHP-2-0099" class="indexterm"/><a id="IDX-CHP-2-0097" class="indexterm"/><a id="IDX-CHP-2-0098" class="indexterm"/></p><p><a class="xref" href="ch02s04.html#mechanical_nor_gate_design" title="Figure 2-1. Mechanical NOR gate design">Figure 2-1</a> shows a trivial gear set mechanism that implements NOR functionality using torque-based logic. The “output” wheel at idle represents state 0; when a torque is applied to the wheel, its state is 1. The device transmits torque from an external source to the output <span class="emphasis"><em>only</em></span> if no torque is applied to two control “input” wheels. In theory, there is no need for an external source of energy, and the design could be simpler; in practice, however, friction and other problems would make it fairly difficult to build a more complex set of fully self-contained gates.</p><div class="figure"><a id="mechanical_nor_gate_design"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e1491"/><img src="httpatomoreillycomsourcenostarchimages1138004.png.jpg" alt="Mechanical NOR gate design"/></div></div><p class="title">Figure 2-1. Mechanical NOR gate design</p></div><p>Applying a torque to either or both of the inputs will pull out the tiny connector gear and make the “output” gear idle. When inputs go idle, a spring pulls the connector gear back to its position. The truth table for this device is exactly what NOR should be.</p><p>As you will recall, NOR or NAND are all we need to implement any Boolean logic operator. Although adding the ability to implement other operators without recombining NAND and NOR gates would make our device smaller and more efficient, the device does not need this ability in order to work.</p><p>Assuming we skip the pesky detail of making all the gates work together in a way we are accustomed with, we can conclude that computers can be built with almost any technology.<sup>[<a id="CHP-2-FN-4" href="#ftn.CHP-2-FN-4" class="footnote">9</a>]</sup></p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-2-FN-4" href="#CHP-2-FN-4" class="para">9</a>] </sup>And, needless to say, nonelectric computers are not a tall tale. Famous examples of such devices include Charles Babbage’s Analytical Engine, and technologies such as nanotechnology also hold some promise. See Ralph C. Merkle, “Two Types of Mechanical Reversible Logic,” <span class="emphasis"><em>Nanotechnology</em></span> 4 (1993).</p></div></div></div>
<div class="sect1" title="A Marginally More Popular Computer Design"><div class="titlepage"><div><div><h1 class="title"><a id="a_marginally_more_popular_computer_desig"/>A Marginally More Popular Computer Design</h1></div></div></div><p>Although the computer boom of the last several decades sprang from the ingenious transistor, our reliance on it is not associated with any magical value or unique quality. Quite simply, it is the most affordable, usable, and efficient design we have at the moment.<a id="IDX-CHP-2-0100" class="indexterm"/><a id="IDX-CHP-2-0101" class="indexterm"/><a id="IDX-CHP-2-0102" class="indexterm"/><a id="IDX-CHP-2-0103" class="indexterm"/><a id="IDX-CHP-2-0104" class="indexterm"/></p><p>Unlike the possibly far superior wooden gear machine, the electronic computers we use relay electrical signals using transistors, which are tiny devices that let a current flow in one direction between two of their nodes (connection points) when a voltage is applied to the third node. Transistors can be miniaturized quite efficiently, require little power, and are reliable and cheap.</p><div class="sect2" title="Logic Gates"><div class="titlepage"><div><div><h2 class="title"><a id="logic_gates"/>Logic Gates</h2></div></div></div><p>The transistor is simple. In fact, it alone is too simple a device to implement any meaningful Boolean logic. Yet, when properly arranged in logic gates, transistors make it easy to perform all basic and supplementary Boolean algebra operations.<a id="IDX-CHP-2-0105" class="indexterm"/></p><p>The AND gate can be implemented by arranging two transistors serially, so that both must have low resistance (be “on”) before the voltage can flow to the output. Each transistor is controlled (activated) by a separate input line. The output is nominally “pulled down” using a resistor, so that it has the ground voltage 0 (“false”), but will go up past 0 once both transistors switch on and allow a slight current flow.</p><p>The OR gate is implemented by setting up a parallel transistor so that it is sufficient for any of the transistors to enable in order for the output to be set to a nonzero voltage, signifying “truth.”</p><p>The last basic gate, NOT, is implemented using a single transistor and a resistor. “NOT” output is 1 in the idle state (pulled up through the resistor) and gets pulled down to 0 when the transistor opens.</p><p><a class="xref" href="ch02s05.html#transistor-based_logic_gatesmconstructio" title="Figure 2-2. Transistor-based logic gates—construction and symbols">Figure 2-2</a> shows the three most basic transistor gate designs: AND, OR, and NOT.</p><div class="figure"><a id="transistor-based_logic_gatesmconstructio"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e1558"/><img src="httpatomoreillycomsourcenostarchimages1138006.png.jpg" alt="Transistor-based logic gates—construction and symbols"/></div></div><p class="title">Figure 2-2. Transistor-based logic gates—construction and symbols</p></div><div class="note" title="Note"><h3 class="title">Note</h3><p>You might notice that both AND and OR gates can be turned into NAND and NOR without introducing additional components. It is sufficient to use a design observed on the schematics for a NOT gate—that is, by moving the resistor and “output point” toward the supply voltage, thus reverting the output logic.</p></div><p>We have now reached a point where we can combine transistors to implement one of the universal gates, but regardless of how many gates we can build, it is still quite far from real computing.</p><p>The preceding discussion is all well and good, but what makes Boolean logic more than a powerful tool for solving puzzles about Bob’s diet?</p></div></div>
<div class="sect1" title="From Logic Operators to Calculations"><div class="titlepage"><div><div><h1 class="title"><a id="from_logic_operators_to_calculations"/>From Logic Operators to Calculations</h1></div></div></div><p>Combining trivial Boolean logic operations can lead to a number of surprising capabilities, such as the ability to perform arithmetic operations on binary representations of numbers. This is where things get interesting.<a id="IDX-CHP-2-0106" class="indexterm"/><a id="IDX-CHP-2-0107" class="indexterm"/><a id="IDX-CHP-2-0108" class="indexterm"/><a id="IDX-CHP-2-0109" class="indexterm"/><a id="IDX-CHP-2-0110" class="indexterm"/><a id="IDX-CHP-2-0111" class="indexterm"/><a id="IDX-CHP-2-0112" class="indexterm"/><a id="IDX-CHP-2-0113" class="indexterm"/><a id="IDX-CHP-2-0114" class="indexterm"/></p><p>A set of XOR and AND gates, for example, can be used to increase an input number by 1, and this is the first step on our way toward addition. <a class="xref" href="ch02s06.html#trivial_increase-by-one_circuit" title="Figure 2-3. Trivial increase-by-one circuit">Figure 2-3</a> shows a design for a counter, based on this concept.</p><p>Ah, a new term! XOR is yet another “convenient” Boolean logic operator that is true only when one of its operands is true. In this regard, it is closer to the usual meaning of “or” in English. XOR is often used to simplify notation, but otherwise easy to implement by other means, by recombining AND, NOT, and OR. It is defined this way:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>XOR(a, b) ⇔ AND(OR(a, b), NOT AND(a, b))</td></tr></table><p>Back to the circuit of ours . . . what can it do? The device shown in <a class="xref" href="ch02s06.html#trivial_increase-by-one_circuit" title="Figure 2-3. Trivial increase-by-one circuit">Figure 2-3</a> is fed with a number written in binary. In this example, that num-ber is limited to three bits, although this design could easily be extended to allow for a larger number of inputs.</p><div class="figure"><a id="trivial_increase-by-one_circuit"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e1628"/><img src="httpatomoreillycomsourcenostarchimages1138008.png.jpg" alt="Trivial increase-by-one circuit"/></div></div><p class="title">Figure 2-3. Trivial increase-by-one circuit</p></div><p>This simple computation device works the way humans add decimal numbers on a piece of paper—working from right to left, eventually carrying a value to the next column. The only real difference is that it uses binary.</p><p>Let’s see how that would happen. We have a binary number written in a line. We want to increase it by one; we start at the rightmost digit, the way we would do with decimal addition.</p><p>We have a binary digit there; when increasing a binary digit by 1, only two outcomes are possible: if the input digit is 0, the output is 1 (0 + 1 = 1); otherwise, the output is 0, and we need to carry 1 to the next column (1 + 1 = 10). In other words, we do two things: we produce an output that is a negation of the input (1 for 0, 0 for 1), and, if the input digit is 1, we must keep that in mind and include it later.</p><p>The circuit does just that: for the first input, I<sub>0.</sub> The topmost gate processes the input by negating it and supplying it on output O<sub>0</sub> and also feeds the input value itself to the gates that are responsible for handling the next column (O<sub>1</sub>).</p><table border="0" summary="Simple list" class="simplelist"><tr><td>O<sub>0</sub> = NOT I<sub>0</sub></td></tr><tr><td>C<sub>0</sub> = I<sub>0</sub></td></tr></table><p>Well, we have increased the number by one; there is nothing else for us to do in the remaining columns if there is no carry from the previous one. If there is no carry, O<sub>1</sub> should mirror I<sub>1</sub>. If there is a carry value, however, we need to treat the case the same way we handled adding 1 to the previous column: negate the output and carry a value to the next column if applicable.</p><p>From now on, every subsequent output (O<sub>n</sub> for n &gt; 0) will be either copied directly from I<sub>n</sub> if there is no bit carried over from the previous column or increased by 1 (which, again, boils down to negation) due to addition of a carry bit. And so, if I<sub>n</sub> is 1, the carry from this column, C<sub>n</sub>, will also be 1, and O<sub>n</sub> will be 0 (because, in binary, 1 + 1 is 10). As you might notice, the actual output at position <span class="emphasis"><em>n</em></span> is simply a result of XOR of the input value at position <span class="emphasis"><em>n</em></span>, and the carry bit from column <span class="emphasis"><em>n</em></span>−1. Hence, the circuit generates O<sub>n</sub> by XORing the bit carried from C<sub>n−1</sub> with the value of I<sub>n</sub> and then ANDing the carry from O<sub>n−1</sub> with I<sub>n</sub> to determine if there should be a carry to the next column:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>O<sub>n</sub> = XOR(I<sub>n</sub>, C<sub>n−1</sub>)</td></tr><tr><td>C<sub>n</sub> = AND (I<sub>n</sub>, C<sub>n−1</sub>)</td></tr></table><p>Consider the following example. We want to increase an input value, 3 (011 in binary), by 1. Inputs are as follows:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>I<sub>0</sub> = 1</td></tr><tr><td>I<sub>1</sub> = 1</td></tr><tr><td>I<sub>2</sub> = 0</td></tr></table><p>The circuit produces O<sub>0</sub> by negating I<sub>0</sub>; hence O<sub>0</sub> = 0. Because I<sub>0</sub> was nonzero, there is also a carry passed to the next column. In the next column, the XOR gate sets O<sub>1</sub> to 0, because, even though I<sub>1</sub> was 1, there was a carry value from the previous column (1 + 1 = 10). Again, there is a carry to the next column.</p><p>In yet another column, I<sub>2</sub> = 0, but the AND gate indicates a carry value from the previous row, because two previous inputs were both set to 1. Hence, the output is 1. There will be no carry to the last column. The output is:</p><table border="0" summary="Simple list" class="simplelist"><tr><td>O<sub>0</sub> = 0</td></tr><tr><td>O<sub>1</sub> = 0</td></tr><tr><td>O<sub>2</sub> = 1</td></tr><tr><td>O<sub>0</sub> = 0</td></tr><tr><td>. . . or 0100, which, quite incidentally, is 4 when converted to decimal numbers.</td></tr></table><p>And voilà—that’s +1, written in binary.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>We have just expressed the first computing problem in terms of Boolean algebra. You might be tempted to extend the design to be able to sum two arbitrary numbers, rather than just one number and the number 1. Nonetheless, this basic circuitry is much where computing starts and ends.</p></div><p>Digital arithmetic circuitry works by running certain input data through an array of cleverly arranged logic gates that, in turn, add, subtract, multiply, or perform other trivial modifications on an array of bits. Little magic is involved.</p><p>So far, I have explained the ability of silicon chips or crafted wood to perform certain fixed, basic operations such as integer arithmetics. Yet, something is missing from this picture: computers do not come with text editors, games, and peer-to-peer software hard-coded in a painstakingly complex array of gates inside the CPU. Where is the software kept?</p></div>
<div class="sect1" title="From Electronic Egg Timer to Computer"><div class="titlepage"><div><div><h1 class="title"><a id="from_electronic_egg_timer_to_computer"/>From Electronic Egg Timer to Computer</h1></div></div></div><p>The true value of a computer lies in its ability to be programmed to act in a specific way—to execute a sequence of software commands according to some plan.<a id="IDX-CHP-2-0115" class="indexterm"/><a id="IDX-CHP-2-0116" class="indexterm"/><a id="IDX-CHP-2-0117" class="indexterm"/><a id="IDX-CHP-2-0118" class="indexterm"/><a id="IDX-CHP-2-0119" class="indexterm"/></p><p><a class="xref" href="ch02s07.html#flip-flop_memory_with_a_practical_interf" title="Figure 2-4. Flip-flop memory with a practical interface">Figure 2-4</a> illustrates the next step on our way toward developing a flexible machine that can do more than just a single, hard-wired task: data storage and memory. In this figure, we see a type of memory storage unit known as a <span class="emphasis"><em>flip-flop design</em></span>. This memory cell has two control lines, “set” and “reset.” When both are down, the gate maintains its current state, thanks to a feedback connection between its input and output to the OR gate. Previous output from OR is passed through an AND gate because its other line is set to 1 (negated “reset”), and through OR once again, because its other input is 0 (“set”). The state of the output is sustained for as long as the gates are powered.</p><div class="figure"><a id="flip-flop_memory_with_a_practical_interf"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e1854"/><img src="httpatomoreillycomsourcenostarchimages1138010.png.jpg" alt="Flip-flop memory with a practical interface"/></div></div><p class="title">Figure 2-4. Flip-flop memory with a practical interface</p></div><p>When “set” goes high, the OR gate is forced to output 1 and will retain this value when “set” goes back down. When “reset” line goes high, the AND gate is forced to output 0 and break the feedback loop, thus forcing the circuit to output 0. Once “reset” goes down, the output remains 0. When both control lines are up, the circuit becomes unstable—something not quite pretty, especially when the computer in question is mechanical.</p><p>The truth table for this design is as follows (<span class="emphasis"><em>V</em></span> denotes an arbitrary logic value):</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="4" valign="bottom"><p>Flip-Flop Truth Table</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Set</p></th><th style="text-align: left" valign="bottom"><p>Reset</p></th><th style="text-align: left" valign="bottom"><p>Q<sub>t-1</sub></p></th><th style="text-align: left" valign="bottom"><p>Q<sub>t</sub></p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p><span class="emphasis"><em>V</em></span></p></td><td style="text-align: left" valign="top"><p><span class="emphasis"><em>V</em></span></p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>-</p></td><td style="text-align: left" valign="top"><p>1</p></td></tr><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>-</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>-</p></td><td style="text-align: left" valign="top"><p>unstable</p></td></tr></tbody></table></div><p>A more practical variant of a flip-flop circuit, which incorporates an “update interface” (see <a class="xref" href="ch02s07.html#flip-flop_memory_with_a_practical_interf" title="Figure 2-4. Flip-flop memory with a practical interface">Figure 2-4</a>), uses two AND gates and one NOT gate so that the state of an input line is captured (sampled and held) whenever an external “strobe” control signal occurs. This design eliminates unstable combinations of inputs and makes this sort of memory easier to use for storing information.</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="4" valign="bottom"><p>Improved Flip-Flop Truth Table</p></th></tr><tr><th style="text-align: left" valign="bottom"><p>Input</p></th><th style="text-align: left" valign="bottom"><p>Strobe</p></th><th style="text-align: left" valign="bottom"><p>Q<sub>t-1</sub></p></th><th style="text-align: left" valign="bottom"><p>Q<sub>t</sub></p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>-</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p><span class="emphasis"><em>V</em></span></p></td><td style="text-align: left" valign="top"><p><span class="emphasis"><em>V</em></span></p></td></tr><tr><td style="text-align: left" valign="top"><p><span class="emphasis"><em>S</em></span></p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>-</p></td><td style="text-align: left" valign="top"><p><span class="emphasis"><em>S</em></span></p></td></tr></tbody></table></div><p>This trivial gate configuration exhibits an important property: it can store data. A single cell can store only a single bit, but combining a number of flip-flops can extend the storage capacity. Although today’s memory designs vary, the significance of this functionality remains the same: it allows programs to execute. But how?</p><p>In the basic design, the chip stores a special value, usually called the <span class="emphasis"><em>instruction pointer</em></span>, in an internal on-chip memory latch (register) consisting of several flip-flops. Because popular computers work synchronously, with all processes timed by a clock signal generator working at a high frequency, the pointer selects a memory cell from the main memory on every clock cycle. The control data retrieved this way then selects and activates the appropriate arithmetic circuit to process the input data.</p><p>For some control data, our hypothetical chip performs addition; for others, it gets involved in an input-output operation. After fetching each piece of control data (every machine instruction), the chip has to advance its internal instruction pointer so that it will be prepared to read the next command in the next cycle. Thanks to this functionality, we can use the chip to execute a sequence of machine instructions, or a program.</p><p>It is now time to find out which operations the chip has to implement in order for it to be usable.</p></div>
<div class="sect1" title="Turing and Instruction Set Complexity"><div class="titlepage"><div><div><h1 class="title"><a id="turing_and_instruction_set_complexity"/>Turing and Instruction Set Complexity</h1></div></div></div><p>As it turns out, the processor does not have to be complex. In fact, the set of instructions required for a chip to be able to execute just about any task is surprisingly small. The Church-Turing thesis states that every real-world computation can be carried out by a Turing machine, which is a primitive model of a computer. The Turing machine, named after its inventor, is a trivial device that operates on a potentially infinite tape consisting of single cells, a hypothetical, purely abstract storage medium. Each cell can store a single character from a machine “alphabet,” which is simply a name for a finite ordered set of possible values. (This alphabet has absolutely nothing to do with human alphabets; it was named this way to promote a healthy dose of confusion among the laity.)<a id="IDX-CHP-2-0120" class="indexterm"/><a id="IDX-CHP-2-0121" class="indexterm"/><a id="IDX-CHP-2-0122" class="indexterm"/><a id="IDX-CHP-2-0123" class="indexterm"/><a id="IDX-CHP-2-0124" class="indexterm"/></p><p>The device is also equipped with an internal register that can hold a finite number of equally internal states. A Turing machine starts at a certain position on the tape, in a given state, and then reads a character from a cell on the tape. Every automaton has an associated set of transition patterns that describe how to modify its internal state, what to store on the tape based on the situation after the read, and how to (optionally) move the tape either way by one cell. Such a set of transitions defines the rules for calculating the system’s next state based on its current characteristics. These rules are often documented using a <span class="emphasis"><em>state transition table</em></span> like this.</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/><col/><col/></colgroup><thead><tr><th style="text-align: center" colspan="5" valign="bottom"><p>State Transition Table</p></th></tr><tr><th style="text-align: center" colspan="2" valign="bottom"><p>Current State</p></th><th style="text-align: center" colspan="3" valign="bottom"><p>New State/Action</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>C<sub>t</sub></p></td><td style="text-align: left" valign="top"><p>S<sub>t</sub></p></td><td style="text-align: left" valign="top"><p>C<sub>t+1</sub></p></td><td style="text-align: left" valign="top"><p>S<sub>t+1</sub></p></td><td style="text-align: left" valign="top"><p>MOVE</p></td></tr><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>S0</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>S1</p></td><td style="text-align: left" valign="top"><p>-</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>S0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>S0</p></td><td style="text-align: left" valign="top"><p>LEFT</p></td></tr></tbody></table></div><p>The table tells us that, if the current value of a cell under which the machine is currently positioned is 0, and the machine’s internal state at that moment is S0, the device will alter the state of C to 1, will alter its internal state to S1, and will not move the reading head.</p><p><a class="xref" href="ch02s08.html#sample_turing_machine_execution_stages" title="Figure 2-5. Sample Turing machine execution stages">Figure 2-5</a> shows an example of a Turing machine positioned at cell C with internal state S.</p><div class="figure"><a id="sample_turing_machine_execution_stages"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e2134"/><img src="httpatomoreillycomsourcenostarchimages1138012.png.jpg" alt="Sample Turing machine execution stages"/></div></div><p class="title">Figure 2-5. Sample Turing machine execution stages</p></div><p>Let’s walk through this. As you can see in <a class="xref" href="ch02s08.html#sample_turing_machine_execution_stages" title="Figure 2-5. Sample Turing machine execution stages">Figure 2-5</a>, the machine uses an alphabet of two characters, 0 and 1, and has two internal states, S0 and S1. It starts with S0. (Starting conditions can be defined arbitrarily; I chose to start it there for no particular reason.) When positioned at the end (the least significant bit) of a binary number stored on the tape (C<sub>0</sub>), the machine follows this logic:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>If the character under the machine head is 0, it is changed to 1, and the state of the machine is changed to S1, according to the first transition rule documented in the table preceding. Because there is no transition rule from S1, the machine stops in the next cycle.</p></li><li class="listitem"><p>If the character read from beneath the head is 1, it changes to 0, and the state remains the same. The machine also moves the reading head on the tape to the left, per the second transition rule. The entire process then repeats, starting at the new location, because the machine remains in its current state, for which further transition rules are defined.</p></li></ul></div><div class="sect2" title="Functionality, at Last"><div class="titlepage"><div><div><h2 class="title"><a id="functionality_comma_at_last"/>Functionality, at Last</h2></div></div></div><p>Although this may come as a surprise, this particular machine is actually useful and implements a task that can be of more than theoretical value: it performs basic arithmetic. It does precisely the same thing as our increase-by-one circuit discussed earlier in this chapter. In fact, it implements the same algorithm: bits on the tape, starting at the rightmost position, are inverted until after 0 is encountered (and also inverted).<a id="IDX-CHP-2-0125" class="indexterm"/><a id="IDX-CHP-2-0126" class="indexterm"/></p><p>This is, naturally, just the tip of the iceberg. A proper Turing machine can implement any algorithm ever conceived. The only problem is that every algorithm requires the implementation of a separate set of transition rules and internal states; in other words, we need to build a new Turing machine for every new task, which is not quite practical in the long run.</p><p>Thankfully, a special type of such a machine, a Universal Turing Machine (UTM), has an instruction set that is advanced enough to implement all specific Turing machines and to execute any algorithm without the need to alter the transition table.</p><p>This über-machine is neither particularly abstract nor complex. Its existence is guaranteed because a specific Turing machine can be devised to perform any finite algorithm (according to the aforementioned Church-Turing thesis). Because the method for “running” a Turing machine is itself a finite algorithm, a machine can be devised to execute it.<a id="IDX-CHP-2-0127" class="indexterm"/></p><p>As to the complexity of this machine, a one-bit, two-element alphabet machine (the smallest UTM devised) requires 22 internal states and instructions describing state transitions, in order to execute algorithms on a sequential infinite memory tape.<sup>[<a href="apb.html#ftn.CHP-2-BIB-1" class="footnoteref">52</a>]</sup> That’s not that big a deal.</p></div><div class="sect2" title="Holy Grail: The Programmable Computer"><div class="titlepage"><div><div><h2 class="title"><a id="holy_grail_colon_the_programmable_comput"/>Holy Grail: The Programmable Computer</h2></div></div></div><p>The Turing machine is also far more than just a hypothetical abstract device that mathematicians use to entertain themselves. It is a construct that begs to be implemented using a specially designed, Boolean, logic-based electronic (or mechanical) device and perhaps extended to make it far more useful, which brings us one step closer to useful computing. The only problem is that the prerequisite for an infinitely long input tape cannot be satisfied in the real world. Nevertheless, we can provide plenty of it, making such a hardware Turing machine quite usable for most of our everyday problems. Enter the universal computer.<a id="IDX-CHP-2-0130" class="indexterm"/><a id="IDX-CHP-2-0128" class="indexterm"/><a id="IDX-CHP-2-0129" class="indexterm"/></p><p>Real computers, of course, go far beyond the sequential access single-bit memory, thus significantly reducing the set of instructions required to achieve Turing completeness. A UTM with an alphabet of 18 characters requires only two internal states in order to work. Real computers, on the other hand, usually operate on an “alphabet” of at least 4,294,967,296 characters (32 bits), and often far more, which allows for nonsequential memory access and for the use of a large number of registers with an astronomical number of possible internal states.</p><p>In the end, the UTM model proves and everyday practice confirms that it is possible to build a flexible, programmable processing unit using only a handful of features, composed of two or three internal registers (instruction pointer, data read/write pointer, and perhaps an accumulator) and a small set of instructions. It is perfectly feasible to assemble such a device with just hundreds of logic gates, even though today’s designs may use many more.</p><p>As you can see, the notion of building a computer from scratch is not so absurd—even a wooden one.</p></div><div class="sect2" title="Advancement through Simplicity"><div class="titlepage"><div><div><h2 class="title"><a id="advancement_through_simplicity"/>Advancement through Simplicity</h2></div></div></div><p>Coming up with such an unimpressive set of instructions is, of course, not going to make the device fast or easy to program. Universal Turing Machines can do just about everything (in many cases, by virtue of their simplicity), but they are painfully slow and difficult to program, to a degree that even implementing machine-assisted translation from more human-readable languages to machine code is difficult, at least without driving the programmer clinically insane.</p><p>Architectures or languages that come too close to implementing bare-bones Turing completeness are often referred to as <span class="emphasis"><em>Turing tarpits</em></span>. This means that, while it is theoretically possible to carry out just about any task with their help, in practice, it is barely feasible, too time-consuming, and too burdensome to actually try. Even simpler tasks such as integer multiplication or moving the contents of memory can take forever to set up, and twice as long to execute. The less effort and time required to complete simple and repetitive tasks, and the fewer the tasks that have to be accomplished by software using a number of separate instructions, the better.<a id="IDX-CHP-2-0131" class="indexterm"/></p><p>One popular way to improve the functionality and performance of a processing unit is to implement certain common tasks in the hardware that would be quite annoying to perform in software. These tasks are implemented using an array of specialized circuits (and include multiplication and home-loan-rejection processing), thus adding convenient extensions to the architecture and enabling the faster and saner deployment of programs, while still enabling the system to execute those functions in a programmed, flexible order.</p><p>Surprisingly, beyond the few initial steps, it is not always desirable when designing a processor to linearly increase the complexity of the circuitry in order to make processors achieve higher speeds, be more energy efficient, and provide a better feature set. You can, of course, build a large number of circuits to handle just about any frequently used complex operation imaginable. However, this won’t be practical until the architecture is truly mature, and your budget allows you to invest additional effort and resources in making a chip. Although programs on such a platform indeed require less time to execute and are easier to write, the device itself is far more difficult to build, requires more power, and could become too bulky or expensive for routine use. Complex algorithms such as division or floating-point operations require an insanely large array of usually idle gates to complete such a task in a single step.</p></div><div class="sect2" title="Split the Task"><div class="titlepage"><div><div><h2 class="title"><a id="split_the_task"/>Split the Task</h2></div></div></div><p>Rather than following this expensive and possibly naive path of building blocks to carry out entire instructions at once, it is best to abandon the single-cycle execution model until you have a working design and plenty of time to improve it. A better way to achieve complex functionality in hardware is to hack the job into tiny bits and execute advanced tasks in a number of cycles.<a id="IDX-CHP-2-0132" class="indexterm"/><a id="IDX-CHP-2-0133" class="indexterm"/><a id="IDX-CHP-2-0134" class="indexterm"/><a id="IDX-CHP-2-0135" class="indexterm"/></p><p>In such a multicycle design, the processor goes through a number of internal stages, much like the add-one Turing machine example. It runs the data through simple circuits in the right order, thus implementing a more complex functionality step by step, which relies on more basic components. Rather than use a complex device to do all the math at once, it might use a circuit to multiply subsequent bits of 32-bit integers and track carry values and then produce a final result in the 33rd cycle. Or, it could perform certain independent, preparation tasks that precede the actual operation. This would free us from having to design dozens of circuits for every variant of an opcode, depending on where it should get its operands or store results.<a id="IDX-CHP-2-0136" class="indexterm"/></p><p>The added benefit of this approach is that it enables more efficient hardware resource management: for trivial operands; a variable-complexity algorithm can complete sooner, taking only as many cycles as absolutely necessary. For example, division by 1 is likely to require less time than division by 187,371.</p><p>A simple, cheap circuit, with maximum usage and a variable execution time could quite easily be more cost efficient than a complex and power-consuming one with a constant execution time. Although some of today’s processors have attempted to use a fixed number of cycles to complete more and more tasks, virtually all began as multicycle architectures. Even for these big boys, the model seldom remains truly single cycle, as you’ll see in a moment.</p><p>But first, let’s take a look at how this very advantage of simplicity through multicycle execution can backfire.</p></div><div class="sect2" title="Execution Stages"><div class="titlepage"><div><div><h2 class="title"><a id="execution_stages"/>Execution Stages</h2></div></div></div><p>One of the variations of multicycle execution is a method that splits a task not into a number of repetitive steps, but rather into a number of distinct yet generic preparation and execution stages. This method, called <span class="emphasis"><em>staging</em></span>, is used in today’s processors to make them perform better without necessarily becoming linearly more complex. Execution staging has become one of a processor’s more important features.<a id="IDX-CHP-2-0138" class="indexterm"/><a id="IDX-CHP-2-0139" class="indexterm"/><a id="IDX-CHP-2-0140" class="indexterm"/><a id="IDX-CHP-2-0137" class="indexterm"/></p><p>Today’s processors can translate every instruction into a set of largely independent small steps. Certain steps can be achieved using generic circuits shared by all instructions, thus contributing to the overall simplicity. For example, the circuitry specific to a given task (our favorite multiplication comes to mind once more) can be made more universal and reusable as a part of various advanced instructions by separating it from any generic I/O handling tasks, and so on. The set of execution stages and transitions depends on the architecture, but it is usually similar to the scheme shown in <a class="xref" href="ch02s08.html#baseline_instruction_execution_stages" title="Figure 2-6. Baseline instruction execution stages">Figure 2-6</a>.</p><div class="figure"><a id="baseline_instruction_execution_stages"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e2284"/><img src="httpatomoreillycomsourcenostarchimages1138014.png.jpg" alt="Baseline instruction execution stages"/></div></div><p class="title">Figure 2-6. Baseline instruction execution stages</p></div><p><a class="xref" href="ch02s08.html#baseline_instruction_execution_stages" title="Figure 2-6. Baseline instruction execution stages">Figure 2-6</a> shows the following stages:</p><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>Instruction fetch/decode</strong></span></span></dt><dd><p>The processor retrieves an instruction from memory, translates it to a low-level sequence, and decides how to proceed and which data to pass to all subsequent stages. The circuit is shared for all operations.</p></dd><dt><span class="term"><span class="strong"><strong>Operand fetch/decode</strong></span></span></dt><dd><p>The processor uses a generic circuit to fetch operands from sources for this particular instruction (for example, from specified internal registers) so that the main circuit does not have to support all possible operand combinations and fetch strategies.</p></dd><dt><span class="term"><span class="strong"><strong>ALU</strong></span></span></dt><dd><p>An arithmetic logic unit (ALU) tailored to perform this particular operation, perhaps in a number of steps, is invoked to perform a specified arithmetic task. For nonarithmetic (memory transfer) instructions, generic or dedicated ALU circuits are sometimes used to calculate source and destination addresses.</p></dd><dt><span class="term"><span class="strong"><strong>Memory store</strong></span></span></dt><dd><p>The result is stored at its destination. For nonarithmetic operations, the memory is copied between calculated locations.</p></dd></dl></div><p>This, alone, may appear to be merely a variation of regular multicycle execution and a circuit reuse measure—one that is prevalent in most of today’s CPU designs. But as you will see, it is also of utmost importance to execution speed.</p></div><div class="sect2" title="The Lesser Memory"><div class="titlepage"><div><div><h2 class="title"><a id="the_lesser_memory"/>The Lesser Memory</h2></div></div></div><p>The simplicity of circuitry is not where this story ends. One additional advantage to the multicycle design is that the processor speed is no longer limited by the memory, the slowest component of the system. Consumer-grade external memory is considerably slower than today’s processors and has a high access and write latency. A single-cycle processor can be no faster than it takes to reliably access memory, even though it is not accessing memory all the time. It needs to be slow simply because one of the single-cycle instructions it could encounter <span class="emphasis"><em>might</em></span> require memory access; and hence, there must be enough time to accomplish this. Multicycle designs, on the other hand, allow the CPU to take its time and even idle for a couple of cycles as necessary (during memory I/O, for example), but run at full speed when performing internal computations. Too, when using multicycle designs, its easier to speed up memory-intensive operations without having to invest in faster main memory.<a id="IDX-CHP-2-0141" class="indexterm"/><a id="IDX-CHP-2-0142" class="indexterm"/><a id="IDX-CHP-2-0143" class="indexterm"/><a id="IDX-CHP-2-0144" class="indexterm"/><a id="IDX-CHP-2-0145" class="indexterm"/><a id="IDX-CHP-2-0146" class="indexterm"/><a id="IDX-CHP-2-0147" class="indexterm"/><a id="IDX-CHP-2-0148" class="indexterm"/><a id="IDX-CHP-2-0149" class="indexterm"/></p><p>The flip-flop design, commonly referred to as SRAM (static RAM), offers low-access latency and consumes little power. Current designs require about 5 nanoseconds, which is comparable to the cycle interval of some processors. Unfortunately, the design also requires a considerable number of components per flip-flop, typically about six transistors per bit.<a id="IDX-CHP-2-0150" class="indexterm"/></p><p>Unlike SRAM, DRAM, (dynamic RAM) the other memory design popular today, uses an array of capacitors to store the information. Capacitors, however, tend to discharge and need to be refreshed regularly. DRAM requires more power than SRAM and has a considerably higher access and modification latency, as high as 50 nanoseconds. On the upside, DRAM is much cheaper to manufacture than SRAM.</p><p>The use of SRAM for main memory is practically unheard of because its cost is prohibitive. Besides, we would have trouble using all that increase in performance, which would require us to run the memory at nearly the same speed as the CPU. Alas, because main memory is sizable and designed to be extensible, it must be placed outside the CPU. Although the CPU core can usually run at a speed much higher than the world around it, serious reliability issues (such as track capacitance on the motherboard, interference, costs of high-speed peripheral chips, and so on) arise when data must be transferred over longer distances.</p><p>Rather than take the cost-prohibitive routes of using faster external memory or integrating all memory with the CPU, manufacturers usually adopt a more reasonable approach. Advanced CPUs are equipped with fast but considerably smaller in-core memory, SRAM or some derivative, that caches the most frequently accessed memory regions and sometimes stores certain additional CPU-specific data. Thus, whenever a chunk of memory is found in cache <span class="emphasis"><em>(cache hit)</em></span>, it can be accessed rapidly. Only when a chunk of memory has to be fetched from the main memory <span class="emphasis"><em>(cache miss)</em></span> can there be a considerable delay, at which point the processor has to postpone some of its operations for some time. (Single-cycle processors cannot take full advantage of internal caching.)</p></div><div class="sect2" title="Do More at Once: Pipelining"><div class="titlepage"><div><div><h2 class="title"><a id="do_more_at_once_colon_pipelining"/>Do More at Once: Pipelining</h2></div></div></div><p>As I have mentioned, staging offers a considerable performance advantage that goes far beyond a traditional multicycle approach. There is one major difference between them, though: because many of the stages are shared by various instructions, there is no reason not to optimize execution a bit.<a id="IDX-CHP-2-0153" class="indexterm"/><a id="IDX-CHP-2-0154" class="indexterm"/><a id="IDX-CHP-2-0155" class="indexterm"/><a id="IDX-CHP-2-0156" class="indexterm"/><a id="IDX-CHP-2-0157" class="indexterm"/><a id="IDX-CHP-2-0151" class="indexterm"/><a id="IDX-CHP-2-0152" class="indexterm"/></p><p><a class="xref" href="ch02s08.html#baseline_instruction_execution_stages" title="Figure 2-6. Baseline instruction execution stages">Figure 2-6</a> shows that, with separate stages executing separately, only a specific part of the device is used in every cycle. Even though the instruction currently executed has already passed the first stages, it blocks the entire CPU until it completes. For systems with a high number of execution stages (the count often reaches or exceeds 10 on today’s chips, with the Pentium 4 exceeding 20) this proves to be a terrible waste of computing power.</p><p>One solution is to let the next instruction enter the execution pipeline as soon as the previous one moves to the following stage, as shown in <a class="xref" href="ch02s08.html#pipeline_execution_model" title="Figure 2-7. Pipeline execution model">Figure 2-7</a>. As soon as a particular stage of the first instruction is finished, and the execution moves to the next stage, the previous stage is fed with a portion of the subsequent instruction, and so forth. By the time the first instruction completes, the next is only one stage from being completed, and the third instruction is two stages apart. Execution time is thus decreased rather dramatically, and chip usage becomes optimal, using this cascading method.</p><div class="figure"><a id="pipeline_execution_model"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e2426"/><img src="httpatomoreillycomsourcenostarchimages1138016.png.jpg" alt="Pipeline execution model"/></div></div><p class="title">Figure 2-7. Pipeline execution model</p></div><p>Pipelining works fine as long as the instructions are not interdependent and neither operates on the output of its predecessor still in the pipeline. If the instructions do depend on each other, serious problems are bound to ensue. As such, a special circuit must be implemented to supervise the pipeline and to prevent such interlocking situations.</p><p>There are more challenges when it comes to pipelining. For example, on some processors, the set of stages may be different for distinct operations. Not all stages are always applicable, and it might be more optimal to skip some. Certain simple operations could conceivably be run through the pipeline much faster, because there are no operands to be fetched or stored. In addition, some stages can take a variable number of cycles, which contributes to the risk of collisions when two instructions reach the same execution stage at the same point. To prevent this, certain additional mechanisms such as pipeline “bubbles,” no-op stages designed to introduce ephemeral delays when necessary, must be devised.</p></div><div class="sect2" title="The Big Problem with Pipelines"><div class="titlepage"><div><div><h2 class="title"><a id="the_big_problem_with_pipelines"/>The Big Problem with Pipelines</h2></div></div></div><p>Traditional pipelines are a great tool for achieving high performance with simple, multistaged chip design, by reducing the latency of subsequent instructions and ensuring optimal circuit usage, but they are not without concerns: it is not possible to pipeline instructions past a conditional branch instruction if those instructions could alter further program execution.</p><p>In fact, it often is possible, but the processor has no idea which execution path to follow, and if an incorrect decision is made, the entire pipeline has to be flushed down immediately after a branch instruction. (The CPU must also delay committing any changes made by these instructions that, after all, were not to be executed.) Dumping the pipeline introduces an additional delay.</p><p>And, unfortunately for this design, many CPU-intensive tasks, including plenty of video and audio algorithms, rely on small conditional-exit loops executed millions of times in sequence, thus inflicting a terrible performance impact on the pipelined architecture.<a id="IDX-CHP-2-0158" class="indexterm"/></p><p>The answer to this problem is <span class="emphasis"><em>branch prediction</em></span>. Branch predictors are usually fairly simple counter circuits that track the most recent code execution and maintain a small history buffer to make educated guesses about the most likely outcome of a conditional branch operation (although more complex designs are also often deployed<sup>[<a href="apb.html#ftn.CHP-2-BIB-2" class="footnoteref">53</a>]</sup>).<a id="IDX-CHP-2-0159" class="indexterm"/></p><p>All branch predictors employ a strategy that is designed to offer the best pipelining performance for a given code: if a specific branch instruction is executed more often than it is skipped, it is better to fetch and pipeline instructions. Of course, the prediction can fail, in which case, the entire queue must be dropped. However, today’s predictors achieve up to 90 percent success rates in typical code.</p></div></div>
<div class="sect1" title="Implications: Subtle Differences"><div class="titlepage"><div><div><h1 class="title"><a id="implications_colon_subtle_differences"/>Implications: Subtle Differences</h1></div></div></div><p>The advanced set of optimizations employed in today’s processors results in an interesting set of consequences. We observe that execution times depend on the following characteristics, which can be divided into three groups:<a id="IDX-CHP-2-0162" class="indexterm"/><a id="IDX-CHP-2-0163" class="indexterm"/><a id="IDX-CHP-2-0164" class="indexterm"/><a id="IDX-CHP-2-0160" class="indexterm"/><a id="IDX-CHP-2-0161" class="indexterm"/></p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="strong"><strong>Type of instruction and the complexity of the operation</strong></span>. Some operations execute much faster than others.</td></tr><tr><td><span class="strong"><strong>Operand values</strong></span>. Certain multiple cycle algorithms prove faster for trivial inputs. For example, multiplying a value by 0 is generally rather trivial and can be done quickly.</td></tr><tr><td><span class="strong"><strong>The memory location from which the data needed for the instruction must be retrieved</strong></span>. Cached memory is available sooner.</td></tr></table><p>The importance, prevalence, and impact of each of these characteristics depends on the exact nature of the CPU architecture in question. The first characteristic—variable instruction execution times—is shared by all multi-cycle architectures, but might be absent on some basic chips. The second—dependence on operands—is increasingly extinct in top-of-the-line processors.</p><p>In top-end devices, ALU and Floating Point Unit (FPU) components sometimes work at a speed higher than the CPU itself. Hence, even if there are computation speed differences, they cannot be precisely measured because much of the arithmetic is done within one CPU clock tick.</p><p>The last group of timing patterns—memory location dependence—is, for a change, exclusive to today’s, high-performance computers and is unheard of in low-end controllers and various embedded designs.</p><p>The first two timing pattern groups—operation complexity and operand value dependences—can also manifest themselves on a level slightly higher than the CPU itself, namely software. Processors feature arithmetic units that deal well with fairly small integers (usually from 8 to 128 bits) and some floating-point numbers, but today’s cryptography and many other applications require the manipulation of large numbers (often hundreds or thousands of digits), high-precision floats, or various mathematic operations that are not implemented in hardware. Therefore, this functionality is commonly implemented in software libraries. Algorithms in those libraries are again likely to take variable time, depending on the specifics of the operation and operands.</p><div class="sect2" title="Using Timing Patterns to Reconstruct Data"><div class="titlepage"><div><div><h2 class="title"><a id="using_timing_patterns_to_reconstruct_dat"/>Using Timing Patterns to Reconstruct Data</h2></div></div></div><p>It can be argued that an attacker could deduce certain properties of the operands or of an operation performed by monitoring how long it takes for a program to process data. This poses a potential security risk because in several scenarios, at least one of the operands can be a secret value that is not supposed to be disclosed to a third party.<a id="IDX-CHP-2-0165" class="indexterm"/><a id="IDX-CHP-2-0166" class="indexterm"/><a id="IDX-CHP-2-0167" class="indexterm"/><a id="IDX-CHP-2-0168" class="indexterm"/><a id="IDX-CHP-2-0169" class="indexterm"/></p><p>Although the concept of recovering data by watching someone with a stopwatch in your hand might sound surreal, today’s CPUs offer precise counters that allow parties to determine exact time intervals. Too, some operations can be considerably more time-consuming, with certain advanced opcodes on the Intel platform taking as much as thousands of cycles to complete. With ever-increasing network throughput and ever-improving response times, it is not entirely impossible to deduce this information, even from a remote system.</p><p>The nature of information leaked as computation complexity measurements may not be immediately clear. If so, Paul Kocher from Cryptography Research demonstrated a great example of this attack last century (that is, back in the ’90s<sup>[<a href="apb.html#ftn.CHP-2-BIB-3" class="footnoteref">54</a>]</sup>), using an example of the RSA algorithm we discussed in <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a>.<a id="IDX-CHP-2-0170" class="indexterm"/></p></div><div class="sect2" title="Bit by Bit . . ."><div class="titlepage"><div><div><h2 class="title"><a id="bit_by_bit"/>Bit by Bit . . .</h2></div></div></div><p>Kocher observed that the process of decrypting data in the RSA algorithm is rather simple and is based on solving the following equation:<a id="IDX-CHP-2-0171" class="indexterm"/></p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>T</em></span> = <span class="emphasis"><em>c</em></span><sup><span class="emphasis"><em>k</em></span></sup> mod <span class="emphasis"><em>M</em></span></td></tr></table><p>in which <span class="emphasis"><em>T</em></span> is the decrypted message, <span class="emphasis"><em>c</em></span> is the encrypted message, <span class="emphasis"><em>k</em></span> is the secret key, and <span class="emphasis"><em>M</em></span> is a moduli, which are a part of the key pair.</p><p>A trivial integer modulo exponentiation algorithm used in a typical implementation has an important property: if a specific bit of the exponent is one, a portion of the result is calculated by performing modulo multiplication on a portion of the base (some bits of <span class="emphasis"><em>c</em></span>). If the bit is 0, the step is skipped. Even when the step is not actually skipped, the time needed by software to carry out multiplication varies, as indicated earlier. Most trivial cases—such as multiplying by a power of 2—are solved more quickly than others.<a id="IDX-CHP-2-0172" class="indexterm"/></p><p>Hence, on such a system, it would appear that we can determine plenty of information about the key (<span class="emphasis"><em>k</em></span>) by repeatedly checking to see how long it takes to decrypt a piece of information. Even on platforms on which hardware multiplication takes a fixed amount of time, a timing pattern often results from the use of software multiplication algorithms (such as Karatsuba multiplication algorithm) that are needed for processing large numbers such as the ones used by public key cryptography. Subsequent bits of the exponent make the private key, whereas the base is a representation of the message supplied or visible to the curious bystander.</p><p>The attack is rather trivial. The villain sends the attacker two similar but slightly different portions of encrypted data. They differ in a section <span class="emphasis"><em>X</em></span>, so that decrypting that section would presumably take a different amount of time to decrypt. One of the variants of <span class="emphasis"><em>X</em></span>, as far as the villain’s idea of victim’s modulo multiplication implementation goes, is a trivial case that would hence make the task of decrypting <span class="emphasis"><em>X</em></span> fast. The other variant is expected to take more time.</p><p>If it takes the same amount of time for the attacker to decode and respond to both sequences, the attacker can safely assume that the part of the key that was used to decode section <span class="emphasis"><em>X</em></span> consisted of zeros. They can also assume that the multiplication algorithm took the early optimization path, that of not performing any multiplication at all.</p><p>If, on the other hand, one of the scenarios takes more time, it’s obvious that in both cases, the multiplication was carried out, with one case being simpler to solve. The corresponding part of the secret key bit must have been set to a nonzero value.</p><p>By following this procedure, treating subsequent bits of the encrypted message as our “section <span class="emphasis"><em>X</em></span>” and generating, or even (if one has more time) simply waiting for encrypted messages that will happen to work with this scenario, it is possible to reconstruct every bit of the key.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Research suggests that this approach can be successfully extended to just about any algorithm that is carried out in a variable time and discusses some practical optimizations for the attack, such as the ability to deploy limited error detection and correction functionality.</p></div></div></div>
<div class="sect1" title="In Practice"><div class="titlepage"><div><div><h1 class="title"><a id="in_practice"/>In Practice</h1></div></div></div><p>The ability to deduce tangible properties of operands for arithmetic instructions based solely on timing information is the most obvious, effective, and interesting vector for performing computational complexity attacks. Other techniques, such as cache hit and miss timing, usually require considerably more detailed analysis and reveal less information in every cycle.<a id="IDX-CHP-2-0175" class="indexterm"/><a id="IDX-CHP-2-0176" class="indexterm"/><a id="IDX-CHP-2-0177" class="indexterm"/><a id="IDX-CHP-2-0173" class="indexterm"/><a id="IDX-CHP-2-0174" class="indexterm"/></p><p>It is clear that this problem would, to a degree, affect many software algorithms, such as large-number arithmetic libraries commonly used in cryptographic applications. But software algorithms and theory aside, a couple of important questions remain: how real is the execution time dependency on the hardware level, and how can it be measured?</p><p>An example is well within reach. At least a portion of the Intel IA32 architecture exhibits this behavior. The <span class="emphasis"><em>80386 Programmer’s Reference Manual</em></span><sup>[<a href="apb.html#ftn.CHP-2-BIB-4" class="footnoteref">55</a>]</sup> describes an integer-signed multiplication opcode, denoted by the mnemonic IMUL. The opcode, in its basic form, multiplies the value stored in the <span class="emphasis"><em>accumulator</em></span> (a multipurpose working register going by the name [E]AX on this platform), by a value stored in another register. The result is then stored back in the accumulator.</p><p>The documentation further explains:</p><div class="blockquote"><blockquote class="blockquote"><p>The 80386 uses an early-out multiply algorithm. The actual number of clocks depends on the position of the most significant bit in the optimizing multiplier [...]. The optimization occurs for positive and negative values. Because of the early-out algorithm, clock counts given are minimum to maximum. To calculate the actual clocks, use the following formula:<a id="IDX-CHP-2-0178" class="indexterm"/></p><p>Actual clock = if m &lt;&gt; 0 then max(ceiling(log2(m)), 3) + 6 clocks</p><p>Actual clock = if m = 0 then 9 clocks</p></blockquote></div><p>Although this may look cryptic, its meaning is simple: The processor optimizes multiplication based on the value of the multiplier. Instead of multiplying the multiplicand until all bits of the multiplier are exhausted, it skips zeros at the beginning of the operand.</p><div class="sect2" title="Early-Out Optimization"><div class="titlepage"><div><div><h2 class="title"><a id="early-out_optimization"/>Early-Out Optimization</h2></div></div></div><p>To understand the relevance of this tactic to integer multiplication, imagine a traditional iterative multiplication method taught in schools, except this time in binary. A hypothetical “dumb” implementation of this algorithm performs the following set of operations.</p><a id="I_programlisting2_d1e2667"/><pre class="programlisting">00000000 00000000 11001010 11111110     Multiplicand (P)
* 00000000 00000000 00000000 00000110     Multiplier (R)
 -------------------------------------
  00000000 00000000 00000000 00000000     P * R[0] = P * 0
  00000000 00000001 10010101 1111110      P * R[1] = P * 1
  00000000 00000011 00101011 111110       P * R[2] = P * 1
  00000000 00000000 00000000 00000        P * R[3] = P * 0
  00000000 00000000 00000000 0000         P * R[4] = P * 0
  00000000 00000000 00000000 000          P * R[5] = P * 0
  ...
+ 0                                       P * R[31] = P * 0
 -------------------------------------
  00000000 00000100 11000001 11110100</pre><p>It should be obvious that a large number of these operations are completely unnecessary and unwarranted and that continuing the operation once nothing but zeros remain at subsequent bits of the multiplier is simply pointless. A more reasonable approach is to skip them:</p><a id="I_programlisting2_d1e2671"/><pre class="programlisting">00000000 00000000 11001010 11111110      Multiplicand (P)
* 00000000 00000000 00000000 00000110      Multiplier (R) - optimizing
 -------------------------------------
  00000000 00000000 00000000 00000000      P * R[0] = P * 0
  00000000 00000001 10010101 1111110       P * R[1] = P * 1
+ 00000000 00000011 00101011 111110        P * R[2] = P * 1
  ...Bail out − ignore leading zeros of R!
 -------------------------------------
  00000000 00000100 11000001 11110100</pre><p>And this is, in essence, the nature of the <span class="emphasis"><em>early-out optimization</em></span> that Intel deployed.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>This optimization makes multiplication nonsymmetrical in time. 2*100 will compute more slowly than 100*2 (!), even though the result is obviously the same.</p></div><p>With early-out optimization, Intel processors require a variable number of cycles to perform multiplication, and the length is directly proportional to the location of the oldest (most significant) bit set in the second operand. By applying the clock count algorithm provided in the documentation, it is possible to determine the correlation between the multiplier and IMUL time, as shown here:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Multiplier Value Range</p></th><th style="text-align: left" valign="bottom"><p>Cycles to Complete</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0 – 7</p></td><td style="text-align: left" valign="top"><p>9</p></td></tr><tr><td style="text-align: left" valign="top"><p>8 – 15</p></td><td style="text-align: left" valign="top"><p>10</p></td></tr><tr><td style="text-align: left" valign="top"><p>16 – 31</p></td><td style="text-align: left" valign="top"><p>11</p></td></tr><tr><td style="text-align: left" valign="top"><p>32 – 63</p></td><td style="text-align: left" valign="top"><p>12</p></td></tr><tr><td style="text-align: left" valign="top"><p>64 – 127</p></td><td style="text-align: left" valign="top"><p>13</p></td></tr><tr><td style="text-align: left" valign="top"><p>128 – 255</p></td><td style="text-align: left" valign="top"><p>14</p></td></tr><tr><td style="text-align: left" valign="top"><p>256 – 1,023</p></td><td style="text-align: left" valign="top"><p>15</p></td></tr><tr><td style="text-align: left" valign="top"><p>1,024 – 2,047</p></td><td style="text-align: left" valign="top"><p>16</p></td></tr><tr><td style="text-align: left" valign="top"><p>2,048 – 4,095</p></td><td style="text-align: left" valign="top"><p>17</p></td></tr><tr><td style="text-align: left" valign="top"><p>4,096 – 8,191</p></td><td style="text-align: left" valign="top"><p>18</p></td></tr><tr><td style="text-align: left" valign="top"><p>8,192 – 16,383</p></td><td style="text-align: left" valign="top"><p>19</p></td></tr><tr><td style="text-align: left" valign="top"><p>16,384 – 32,767</p></td><td style="text-align: left" valign="top"><p>20</p></td></tr><tr><td style="text-align: left" valign="top"><p>32,768 – 65,535</p></td><td style="text-align: left" valign="top"><p>21</p></td></tr><tr><td style="text-align: left" valign="top"><p>65,536 – 131,071</p></td><td style="text-align: left" valign="top"><p>22</p></td></tr><tr><td style="text-align: left" valign="top"><p>131,072 – 262,143</p></td><td style="text-align: left" valign="top"><p>23</p></td></tr><tr><td style="text-align: left" valign="top"><p>262,144 – 524,287</p></td><td style="text-align: left" valign="top"><p>24</p></td></tr><tr><td style="text-align: left" valign="top"><p>524,288 – 1,048,575</p></td><td style="text-align: left" valign="top"><p>25</p></td></tr><tr><td style="text-align: left" valign="top"><p>1,048,576 – 2,097,151</p></td><td style="text-align: left" valign="top"><p>26</p></td></tr><tr><td style="text-align: left" valign="top"><p>2,097,152 – 4,194,303</p></td><td style="text-align: left" valign="top"><p>27</p></td></tr><tr><td style="text-align: left" valign="top"><p>4,194,304 – 8,388,607</p></td><td style="text-align: left" valign="top"><p>28</p></td></tr><tr><td style="text-align: left" valign="top"><p>8,388,608 – 16,777,215</p></td><td style="text-align: left" valign="top"><p>29</p></td></tr><tr><td style="text-align: left" valign="top"><p>16,777,216 – 33,554,431</p></td><td style="text-align: left" valign="top"><p>30</p></td></tr><tr><td style="text-align: left" valign="top"><p>33,554,432 – 67,108,863</p></td><td style="text-align: left" valign="top"><p>31</p></td></tr><tr><td style="text-align: left" valign="top"><p>67,108,864 – 134,217,727</p></td><td style="text-align: left" valign="top"><p>32</p></td></tr><tr><td style="text-align: left" valign="top"><p>134,217,728 – 268,435,455</p></td><td style="text-align: left" valign="top"><p>33</p></td></tr><tr><td style="text-align: left" valign="top"><p>268,435,456 – 536,870,911</p></td><td style="text-align: left" valign="top"><p>34</p></td></tr><tr><td style="text-align: left" valign="top"><p>536,870,912 – 1,073,741,823</p></td><td style="text-align: left" valign="top"><p>35</p></td></tr><tr><td style="text-align: left" valign="top"><p>1,073,741,824 – 2,147,483,647</p></td><td style="text-align: left" valign="top"><p>36</p></td></tr></tbody></table></div><p>A similar dependency exists for negative multiplier values.</p></div><div class="sect2" title="Working Code—Do It Yourself"><div class="titlepage"><div><div><h2 class="title"><a id="working_codemdo_it_yourself"/>Working Code—Do It Yourself</h2></div></div></div><p>The following code listing shows a practical implementation in C for Unix-type systems that can be used to confirm and measure differences in timing patterns. The program is invoked with two parameters: <span class="emphasis"><em>multiplicand</em></span> (which should not affect performance in any way) and <span class="emphasis"><em>multiplier</em></span> (presumably used in early-out optimizations and hence impacting the speed of the entire operation). The program performs 256 tests of 500 subsequent multiplications with the chosen parameters and returns the shortest measured time.<a id="IDX-CHP-2-0179" class="indexterm"/><a id="IDX-CHP-2-0180" class="indexterm"/></p><p>We run 256 tests and select the best result in order to compensate for cases in which execution is interrupted by the system for some period of time, a condition fairly common in multitasking environments. Although a single test can be affected by such an event, at least some of the test in a rapid sequence of short tests can be expected to complete without interruption.</p><p>The code uses the system clock to measure execution time in micro-seconds.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>Several of today’s Intel chips feature a precise timing mechanism available through RDTSC opcode. This method for accessing the internal clock cycle counter is not available on older platforms, and so we will not rely on it.</p></div><a id="I_programlisting2_d1e2920"/><pre class="programlisting">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;limits.h&gt;

int main(int argc,char** argv) {

  int shortest = INT_MAX;
  int i,p,r;

  if (argc != 3) {
    printf("Usage: %s multiplicand multiplier\n",argv[0]);
    exit(1);
  }

  p=atoi(argv[1]);
  r=atoi(argv[2]);

  for (i=0;i&lt;256;i++) {
    int ct;
    struct timeval s;
    struct timeval e;

    gettimeofday(&amp;s,NULL);

    asm(

      "  movl $500,%%ecx    \n"  /* Loop repetition counter (R) */
      "imul_loop:           \n"
      "  movl %%esi,%%eax   \n"
      "  movl %%edi,%%edx   \n"
      "  imul %%edx,%%eax   \n"        /* Comment out for first run */
      "  loop imul_loop     \n"
        :
        : "S" (p), "D" (r)
        : "ax", "cx", "dx", "cc");

    gettimeofday(&amp;e,NULL);

    ct = ( e.tv_usec - s.tv_usec ) +
         ( e.tv_sec - s.tv_sec ) * 1000000;

    if (ct &lt; shortest) shortest = ct;

  }

  printf("T[%d,%d] = %d usec\n",p,r,shortest);
  return 0;
}</pre><p>By compiling the code with the IMUL instruction initially commented out and invoking the program with arbitrary parameters, we can estimate the timing code overhead (T<sub>idle</sub>). If the value falls outside the range of 10 to 100 microseconds—which is high enough to provide a fine-grained readout, but low enough to maximize the chance of not being interrupted by the operating system—readjust the loop repetition counter R, which is set to 500 by default.</p><p>After restoring the IMUL instruction and recompiling and running the program with a chosen multiplicand D and repetition counter R, it is possible to use the returned time approximation T<sub>D,R</sub> to estimate the number of CPU cycles spent on IMUL operation (C<sub>D,R</sub>), as long as the operating frequency of the processor (F<sub>MHz</sub>) is known:</p><table border="0" summary="Simple list" class="simplelist"><tr><td><span class="emphasis"><em>C</em></span><sub><span class="emphasis"><em>D, R</em></span></sub> = (<span class="emphasis"><em>T</em></span><sub><span class="emphasis"><em>D, R</em></span></sub> − <span class="emphasis"><em>T</em></span><sub><span class="emphasis"><em>idle</em></span></sub>) · <span class="emphasis"><em>F</em></span><sub><span class="emphasis"><em>MHz</em></span></sub>/<span class="emphasis"><em>R</em></span></td></tr></table><p>As expected, pipelining and branch predictors on newer and more advanced chips will kick in and skew the result slightly, but a good estimate can be made.</p><div class="note" title="Note"><h3 class="title">Note</h3><p>On newer Intel processors, the time needed to complete multiplication is already constant.</p></div></div></div>
<div class="sect1" title="Prevention"><div class="titlepage"><div><div><h1 class="title"><a id="prevention"/>Prevention</h1></div></div></div><p>You can take a number of approaches to protect against computational effort analysis. The most obvious is to make all operations take the same amount of time to execute. However, this is difficult and often results in severe performance penalties because the time taken by all computations would have to be extended to match that of the slowest one.<a id="IDX-CHP-2-0181" class="indexterm"/><a id="IDX-CHP-2-0182" class="indexterm"/><a id="IDX-CHP-2-0183" class="indexterm"/></p><p>Introducing random delays sometimes appears to be an acceptable defense tactic for applications if latency is not critical, in particular many noninteractive network services, and puts less stress on the processor itself. However, this random noise can be effectively filtered out if the attack can be carried out repeatedly.</p><p>Another approach, known as <span class="emphasis"><em>blinding</em></span>, relies on introducing a certain amount of noise in the system by running random or otherwise bogus and unpredictable data combined with the actual input to the algorithm in order to make it impossible for the attacker to deduct meaningful properties of the input even if the encryption algorithm is vulnerable to timing attacks—then discarding the surplus information we did not intend to send out. Although the performance penalty is considerably lower in this scenario, it is difficult to perform blinding well.</p></div>
<div class="sect1" title="Food for Thought"><div class="titlepage"><div><div><h1 class="title"><a id="food_for_thought-id1"/>Food for Thought</h1></div></div></div><p>I’ve taken you on a long ride, but I hope it was worth it. As usual, I will leave you several possibly quite interesting problems to consider:<a id="IDX-CHP-2-0184" class="indexterm"/><a id="IDX-CHP-2-0185" class="indexterm"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>First, although I have focused on the impact that computational complexity attacks have on cryptography-related application, the problem is not strictly limited to this area, and often manifests itself whenever private or confidential information is processed. Certainly, various basic information about HTTP requests or SMTP traffic can be deduced by carefully observing the appropriate service on a system; can you think of any more practical scenarios?</p></li><li class="listitem"><p>Second, even if no secret data is being processed by a service, computational complexity information may be of some use. Consider applications such as network daemons that prevent disclosure of secrets by providing perhaps overly generic error or success messages, with the goal of, for example, making it difficult for an attacker to find out whether he is getting “login incorrect” because of a mistyped password or a non-existent user. However, depending on the time it takes to receive this message, a careful observer may determine which path in the code was indeed executed, and whether the error occurred earlier (when just checking for a valid username), or later on (when verifying the password). I encourage you to experiment with common network services such as SSH, POP3, and Telnet to see whether there is a measurable and consistent difference.</p></li><li class="listitem"><p>As always, even the best defenses against information disclosure tend to fail unexpectedly. Too, computational complexity is not the only way to determine what’s going on inside a silicon chip. Consider this example: Biham and Shamir<sup>[<a href="apb.html#ftn.CHP-2-BIB-5" class="footnoteref">56</a>]</sup> have devised a brilliant scheme for cracking “secure” chip designs used in smart cards. Smart cards are designed to securely store a piece of information such as personal identification data or cryptographic keys and to divulge it only to certain authentication services and trusted clients. As it turns out, you can deduce the properties of the guarded data or the protection mechanism by abusing the device and inducing faults due to mechanical stress, high-energy radiation, overheating, or similar external factors that cause the device to misbehave.<a id="IDX-CHP-2-0186" class="indexterm"/></p></li></ul></div><p>Just thought I’d share.</p></div>
<div class="chapter" title="Chapter&#xA0;3.&#xA0;Ten Heads of the Hydra"><div class="titlepage"><div><div><h1 class="title"><a id="ten_heads_of_the_hydra"/>Chapter 3. Ten Heads of the Hydra</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where we explore several other tempting scenarios that occur very early on in the process of communications</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>In <a class="xref" href="ch01.html" title="Chapter 1. I Can Hear You Typing">Chapter 1</a> and <a class="xref" href="ch02.html" title="Chapter 2. Extra Efforts Never Go Unnoticed">Chapter 2</a>, I discussed two distinct information disclosure scenarios that occur as a result of brilliant, but in the end poorly thought out, attempts to make computers either more functional or easier to maintain. The passive snooping vectors these design decisions open are buried deep beneath the actual implementation and provide a fascinating insight into the earliest threats to processed information.</p><p>On the other hand, the exposure is naturally limited to the physical or logical proximity of the environment monitored. Although a nearly endless number of information disclosure possibilities arise early along the route of a portion of information, I’ve chosen to single out these two cases for their uniqueness, beauty, and the relative ease with which a potential attack can be carried out by a determined attacker. The other scenarios are also worth mentioning, though, and in this chapter, I touch on some of the more interesting possibilities that may not warrant a detailed discussion but that you might want to explore in more detail on your own.</p><div class="sect1" title="Revealing Emissions: TEMPEST in the TV"><div class="titlepage"><div><div><h1 class="title"><a id="revealing_emissions_colon_tempest_in_the"/>Revealing Emissions: TEMPEST in the TV</h1></div></div></div><p>In the 1950s, researchers concluded that electromagnetic radiation (EMR) can often be practically and easily used to recover or reconstruct information about the behavior of the device emitting it. EMR is undesirable noise caused by virtually all electronic, electromechanical, and electric devices, regardless of their design and intended purpose, and often propagated over considerable distances via power lines or by air.<a id="IDX-CHP-3-0187" class="indexterm"/><a id="IDX-CHP-3-0188" class="indexterm"/><a id="IDX-CHP-3-0189" class="indexterm"/><a id="IDX-CHP-3-0190" class="indexterm"/><a id="IDX-CHP-3-0191" class="indexterm"/><a id="IDX-CHP-3-0192" class="indexterm"/><a id="IDX-CHP-3-0193" class="indexterm"/><a id="IDX-CHP-3-0194" class="indexterm"/><a id="IDX-CHP-3-0195" class="indexterm"/></p><p>Prior to their findings, the problem of EMR was believed to be relevant to engineering due to a risk of unexpected interference between separate devices or circuits, but not confirmed to be of any value to a person monitoring the radio frequencies polluted by the device. However, with the world on the brink of the era of information warfare, and with the development and increasing deployment of electronic data processing and telecommunications devices (some used to transfer or store classified or sensitive information), the conclusion that a remote observer can reconstruct some of the information processed by a system by merely listening to a specific frequency became quite worrisome for governments of the free (or not so free) world.</p><p>The term TEMPEST (Transient Electromagnetic Pulse Emanation Standard) originated from a classified EMR emissions study commissioned for the U.S. military in the 1960s and was originally used to denote a set of practices to prevent revealing emissions in electronic circuits processing sensitive data. It later became just a buzzword for describing a general class of problems and techniques related to intercepting and reconstructing radio frequency (RF) emissions.<a id="IDX-CHP-3-0196" class="indexterm"/></p><p>Although this risk initially sounded more like bad science-fiction than an actual threat in the ears of skeptics, an important research paper released in 1985 by Wim van Eck,<sup>[<a href="apb.html#ftn.CHP-3-BIB-1" class="footnoteref">57</a>]</sup> demonstrated that it would be—and in fact is—quite easy to reconstruct the image displayed on a CRT monitor by intercepting radio frequency signals generated by high-voltage circuits inside such a device.</p><p>A typical CRT (see <a class="xref" href="ch03.html#a_crt_display_image_scan_and_the_buildup" title="Figure 3-1. A CRT display image scan and the buildup process">Figure 3-1</a>)builds its display by illuminating every pixel of the image in sequence, line by line and then row by row, at very high speed, and modulating the strength of the signal depending on the location of the screen that is lit up at any moment. To achieve this, a narrow beam of electrons is emitted from a cathode gun in the back of the device. This electron beam hits the anode (a conductive layer of material on the display), which, in turn, emits photons of visible light that we see. The electron beam is modulated by a special circuit, but also positioned by a set of electro-magnets that cause it to sweep the entire display area from left to right and top to bottom to produce and update the image on the screen. Wim noted that the oscillators controlling the electromagnets and the electron gun electronics emit several types of characteristic signals at standard frequencies. It is rather trivial to spot these signals in the radio spectrum,<sup>[<a id="CHP-3-FN-1" href="#ftn.CHP-3-FN-1" class="footnote">10</a>]</sup> and each of the signals is usually clear and strong enough to make it easy to build a fairly inexpensive device that can snoop on CRT displays, even from a considerable distance.</p><div class="figure"><a id="a_crt_display_image_scan_and_the_buildup"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject3_d1e3091"/><img src="httpatomoreillycomsourcenostarchimages1138018.png.jpg" alt="A CRT display image scan and the buildup process"/></div></div><p class="title">Figure 3-1. A CRT display image scan and the buildup process</p></div><div class="note" title="Note"><h3 class="title">Note</h3><p>Emissions are, of course, not limited to CRT screens and are just as common in LCD (TFT, or thin film transistor) displays and any computer circuitry. They are also just as common on databuses, where the information between separate chips is carried over a large set of usually fairly long and sharply cornered conductive tracks laid out on the main board that, among other things, serve as a great antenna (although the ease of extracting and interpreting a specific signal, as well as the range of an emission, can vary rather significantly).</p></div><p>Although there are no verifiable accounts of emission attacks being carried out in the wild, other than for military and intelligence applications (particularly during the Cold War<sup>[<a href="apb.html#ftn.CHP-3-BIB-2" class="footnoteref">58</a>]</sup>), some anecdotal accounts of industrial espionage can be found in the literature.<sup>[<a href="apb.html#ftn.CHP-3-BIB-3" class="footnoteref">59</a>]</sup></p><p>Obviously, this kind of attack has its limitations: The attacker must be near the target. Too, except when snooping on analog CRT displays, the attacker must be armed with expensive and nontrivial equipment, especially when snooping on today’s low-interference displays and higher CPU and bus speeds. Still, any such attack is difficult and costly to prevent.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.CHP-3-FN-1" href="#CHP-3-FN-1" class="para">10</a>] </sup>For this reason, and because of power line interference, “nature radio” enthusiasts who want to listen to earth’s ultra-low frequency signals must often travel with their recording equipment to distant, secluded areas.</p></div></div></div>
<div class="sect1" title="Privacy, Limited"><div class="titlepage"><div><div><h1 class="title"><a id="privacy_comma_limited"/>Privacy, Limited</h1></div></div></div><p>The exposure scenarios discussed so far can be classified as the undesired or unexpected results of the way a specific technology was designed and deployed, despite the identical goals or expectations of both the developer and the end user. In some cases, however, the exposure results in small differences in the goals and expectations of the two groups. Although software-level privacy problems resulting from the incompetence or malice of a programmer are notorious and usually pervasive, more subtle design problems that are not a flaw per se are also being seen. Some of the more interesting groups of problems in this area fall into the category of data disclosure in electronic documents.</p><p>We naturally assume when authoring a document that all information not related to the document’s contents (and in particular, any information that uniquely identifies the originator) is hidden from other parties able to access the document, unless specifically disclosed by the author. But the days of plain-text editors are long gone. Today’s document formats support extensive meta-information storage functionality, in an effort to make it easier to uniquely tag and later index, search, and track documents. What is worrisome, though, is that the designers of authoring tools often decide to fill in certain information automatically, frequently giving the author little or no control over the process and without making them immediately aware of this practice. Although the practice can be considered just another exercise in making the environment more user friendly and transparent to the user, the lack of widespread awareness of this process is appreciated only by a few.<a id="IDX-CHP-3-0197" class="indexterm"/></p><div class="sect2" title="Tracking the Source: “He Did It!”"><div class="titlepage"><div><div><h2 class="title"><a id="tracking_the_source_colon_lhe_did_it_exc"/>Tracking the Source: “He Did It!”</h2></div></div></div><p>One common problem with authoring software is that certain applications store unique identification tags that make it possible to correlate a document with its source. In particular, Microsoft Word long used the hardware address of a computer’s network card (if the computer had one) to construct a Globally Unique Identifier (GUID) field in a document—be it a cookie recipe or a terrorist’s handbook. Although the problem has been fixed in the most recent versions of Microsoft’s Office suite of applications, the practice has had some interesting implications:<a id="IDX-CHP-3-0199" class="indexterm"/><a id="IDX-CHP-3-0200" class="indexterm"/><a id="IDX-CHP-3-0201" class="indexterm"/><a id="IDX-CHP-3-0202" class="indexterm"/><a id="IDX-CHP-3-0198" class="indexterm"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Every device has a unique hardware card address. Because hardware addresses are used to locate a specific device on a local network, this uniqueness is necessary in order to prevent problems that would arise were two computers with the same hardware address to connect to the same network. As such, the number recorded in the GUID field of a Microsoft Word document can be used to uniquely identify the document’s author, whether that person wrote the document anonymously or signed it. This can serve both as a valuable forensics investigation tool and as an effective way to suppress the freedom of speech in certain situations (by an employer hunting down whistle-blowers, for example).<a id="IDX-CHP-3-0203" class="indexterm"/></p></li><li class="listitem"><p>Hardware addresses are assigned in batches to a specific manufacturer. Furthermore, in many cases, network cards are manufactured with numbers in sequence and then sold in batches to computer manufacturers. Thus, a knowledgeable person can determine not only who made a specific card, but also who sold it and to whom. In many situations, it can be possible to actually track a specific hardware address to an individual machine and, effectively, to a private entity or a particular corporation. This might then make it possible for a determined investigator to figure out the origin of a specific document.</p></li><li class="listitem"><p>Because hardware addresses are assigned in batches, it might also be possible to draw limited conclusions as to the hardware configuration of the system on which a document was authored. Although this poses a mild threat, it can be an interesting source of information for the easily amused or particularly curious.</p></li></ul></div><p>Some functionality, although accessible to the user, is buried deep enough within the interface that a typical user is unaware of what is being saved and how to change these defaults. Productivity software such as Microsoft Word and <a class="ulink" href="http://openoffice.org">OpenOffice.org</a> are notorious for inserting “default author” information. This information is usually taken from the data provided with the software license or automatically stored after the first run, deep inside the metadata in the document where most users do not bother to look. Although this is a mildly useful feature that comes in handy when sharing documents, its privacy implications usually far outweigh any eventual benefit for an end user.</p><p>Another example is the “user-friendly” practice of automatically filling the “title” field in metaheaders of a document based on the first sentence in the document. This is a nice touch, but the selection is often permanent, meaning that even if the first paragraph is changed later (so that, for example, the new business offer is now addressed to a competitor), the original contents can be deduced by a careful observer. This “feature” once again exposes more than the author expected to be revealed to the recipient of a document.</p><p>Older versions of Microsoft Word also saved documents without properly clearing out all the data that had been edited out, effectively providing undo information, and recording all previous revisions of the text. This information could easily be recovered later by any sufficiently skilled attacker with software to parse object linking and embedding (OLE) containers, the format in which the editor stores all its data. The problem is particularly severe when a previous version of a document is reused as a template and sent to another party, perhaps a competitor. The ability to recover the previous version of an offer, a motivation letter, or an official response to a customer is definitely entertaining and enlightening, but not always desirable for the sender.</p><p>Of course, with the recent push for trusted computing and increased “accountability” for the purpose of reducing piracy, it is reasonable to expect that it will become commonplace to tag all documents so that they can be traced to their originator.</p></div><div class="sect2" title="“Oops” Exposure: *_~1q'@@ . . . and the Password Is . . ."><div class="titlepage"><div><div><h2 class="title"><a id="loopsr_exposure_colon__asterisk_undersco"/>“Oops” Exposure: *_~1q'@@ . . . and the Password Is . . .</h2></div></div></div><p>The last group of problems shared by a variety of text editors is that of leaking random memory. This type of disclosure is the result of sheer incompetence or insufficient testing, but it differs from other coding flaws in that it doesn’t so much render the code vulnerable to an attack, as it divulges some useful hints to a careful observer. Whether this problem is limited to the program alone or is caused by systemwide leaks (the latter on systems with poor memory protection, such as Windows 3.<span class="emphasis"><em>x</em></span> or 9<span class="emphasis"><em>x</em></span>), this leaked data can include such sensitive information as other documents, browse history, email contents, or even passwords.<a id="IDX-CHP-3-0204" class="indexterm"/><a id="IDX-CHP-3-0205" class="indexterm"/><a id="IDX-CHP-3-0206" class="indexterm"/><a id="IDX-CHP-3-0207" class="indexterm"/><a id="IDX-CHP-3-0208" class="indexterm"/><a id="IDX-CHP-3-0209" class="indexterm"/><a id="IDX-CHP-3-0210" class="indexterm"/><a id="IDX-CHP-3-0211" class="indexterm"/><a id="IDX-CHP-3-0212" class="indexterm"/><a id="IDX-CHP-3-0213" class="indexterm"/><a id="IDX-CHP-3-0214" class="indexterm"/><a id="IDX-CHP-3-0215" class="indexterm"/><a id="IDX-CHP-3-0216" class="indexterm"/></p><p>The problem occurs when an application allocates a chunk of memory (to an editing buffer, for example), perhaps used previously for some other task, and forgets to clear it before reusing it for a wholly different purpose. For performance reasons, the memory is not always zeroed before being granted to an application. The application can then operate on and overwrite only a small portion of the chunk of memory, but write the entire allocated block of data when saving the file, storing both the data it wanted to and some leftover contents from who knows how long ago. And, not surprisingly, older versions of Microsoft Word were once notorious for dumping sizable chunks of random memory within almost every document produced.</p><p>This problem has surfaced a number of times in Microsoft Windows, first in 1998 on all systems, and then on Mac OS only in 2001. Some anecdotal evidence suggests other sightings, but those are rather poorly documented.</p></div></div>
<div class="chapter" title="Chapter&#xA0;4.&#xA0;Working for the Common Good"><div class="titlepage"><div><div><h1 class="title"><a id="working_for_the_common_good"/>Chapter 4. Working for the Common Good</h1></div></div></div><div class="epigraph"><p><span class="emphasis"><em>Where a question of how the computer may determine the intent of its user is raised and left unanswered</em></span></p><div class="attribution"><span>—<span class="attribution"/></span></div></div><p>The beauty of, but also one of the biggest problems with, any sufficiently extensive and diverse computer network is that you cannot blindly trust any connected party to be who they claim to be, and it is impossible to determine their intentions or the real driving force behind their actions.</p><p>I’ll discuss the issue of confirming the identity of a source in the third part of this book, when I dissect the architecture of the network and explore the risks that result from the way a network is built. However, the issue of the originator’s intentions is a separate and fascinating aspect of computer security, with often serious and far-fetched social and judicial implications that extend beyond the world of computing. As we make computers better and better at predicting what their users want to do (itself a means of achieving intuitiveness and ease of use) and give them more autonomy, it becomes increasingly easy to trick machines into becoming a tool to be used by someone else, instead of helping the user.</p><p>A long river of words has been written on the subject, followed by a number of heated disputes about where to put the blame and whom to sue when things go wrong. I believe it is important to tackle the problem but not appropriate to impose any particular viewpoint on you. As such, I will close this section of the book with a short and mostly technical paper that I originally published in 2001 in <span class="emphasis"><em>Phrack</em></span> magazine, vol. 57. I’ve made some minor edits to it and will refrain from further commentary.</p><p>Let me dig it up . . . /me searches for paper . . . Ah, here it is:</p><a id="I_programlisting4_d1e3246"/><pre class="programlisting">==Phrack Inc.==
                  Volume 0x0b, Issue 0x39, Phile #0x0a of 0x12
|=---------------=[ Against the System: Rise of the Robots ]=----------------=|
|=---------------------------------------------------------------------------=|
|=---=[ (C)Copyright 2001 by Michal Zalewski &lt;lcamtuf@bos.bindview.com&gt; ]=---=|


-- [1] Introduction -----------------------------------------------------------

" . . . [the] big difference between the Web and traditional well-controlled
 collections is that there is virtually no control over what people can put on
 the Web. Couple this flexibility to publish anything with the enormous
 influence of search engines to route traffic, and companies that deliberately
 manipulate [sic] search engines for profit become a serious problem."

                                    -- Sergey Brin, Lawrence Page [A]

Consider a remote attacker who can compromise a remote system without sending
 any traffic to his victim. Consider an attack that relies on simply creating a
 file to compromise thousands of computers and that does not require any local
 resources to carry it out. Welcome to the world of zero-effort exploit
 techniques, automation, and anonymous as well as virtually unstoppable attacks
 that result from the ever-increasing complexity of the Internet.

Zero-effort exploits create their wish list and leave it somewhere in
 cyberspace where others can find it. The utility workers of the Internet [B] --
 hundreds of tireless, never-sleeping robots, information browsers, search
 engines, intelligent agents -- come to pick up the information and,
 unknowingly, become a tool in the hands of the attacker. You can stop one of
 them, but you cannot stop them all. You can find out what their orders are, but
 you cannot guess what these orders will be tomorrow, lurking somewhere in the
 abyss of not-yet-indexed cyberspace.

Your private army, close at hand, is picking up the orders you left for them on
 their way. You exploit them without having to compromise them. They do what
 they are designed to do the best they can. Welcome to the new reality, in which
 our AI machines can rise against us.

Consider a worm. Consider a worm that does nothing. It is carried and injected by
 others, but does not infect them. This worm creates a list of 10,000 random
 addresses with specific orders. And waits. Intelligent agents pick up this
list, and with their united forces they try to attack the targets. Imagine that
 they are not too lucky and achieve a 0.1% success ratio. Ten new hosts are now
 infected. On every single one of them, the worm does exactly the same thing-
prepares a list. Now the agents come back to infect 100 new hosts. And so the
 story goes (or crawls, if you wish).

Agents are virtually unnoticeable, as people are now accustomed to their
 presence and persistence. Agents just slowly move ahead in a never-ending loop.
 They work systematically. They do not choke connections with excessive data,
 and there are no network meltdowns, traffic spikes, or telltale signs of
 disease. Week after week they try new hosts, carefully, and their exploration
 never ends. Is it possible to notice that they carry a worm? Possibly . . .

-- [2] An example -------------------------------------------------------------

When this idea came to mind, I tried to use the simplest test just to see if I
 was right. I targeted, if that is the correct word, several general-purpose
 web-indexing crawlers. I created a very short HTML document and put it
 somewhere on my home page and then waited for a couple of weeks. And they came
 -- AltaVista, Lycos, and dozens of others. They found new links, picked them up
 enthusiastically, and then disappeared for days.

  bigip1-snat.sv.av.com:
    GET /indexme.html HTTP/1.0

  sjc-fe5-1.sjc.lycos.com:
    GET /indexme.html HTTP/1.0

  [...]

They came back later to see what I had given them to parse.

    http://somehost/cgi-bin/script.pl?p1=../../../../attack
    http://somehost/cgi-bin/script.pl?p1=;attack
    http://somehost/cgi-bin/script.pl?p1=|attack
    http://somehost/cgi-bin/script.pl?p1=`attack`
    http://somehost/cgi-bin/script.pl?p1=$(attack)
    http://somehost:54321/attack?`id`
    http://somehost/AAAAAAAAAAAAAAAAAAAAA...

The bots followed the links, each of the links simulating vulnerabilities.
 Although these exploits did not affect my server, they could easily compromise
 specific scripts or the entire web server on a remote system by causing the
 script to execute arbitrary commands, to write to arbitrary files, or, better
 yet, to suffer a buffer overflow problem:

  sjc-fe6-1.sjc.lycos.com:
    GET /cgi-bin/script.pl?p1=;attack HTTP/1.0

  212.135.14.10:
    GET /cgi-bin/script.pl?p1=$(attack) HTTP/1.0
bigip1-snat.sv.av.com:
    GET /cgi-bin/script.pl?p1=../../../../attack HTTP/1.0

  [...]

Bots also happily connected to the non-HTTP ports I prepared for them and
 started a conversation by sending the data I supplied in URLs, thus making it
 possible to attack even services other than just web servers:

  GET /attack?`id` HTTP/1.0
  Host: somehost
  Pragma: no-cache
  Accept: text/*
  User-Agent: Scooter/1.0
  From: scooter@pa.dec.com

  GET /attack?`id` HTTP/1.0
  User-agent: Lycos_Spider_(T-Rex)
  From: spider@lycos.com
  Accept: */*
  Connection: close
  Host: somehost:54321

  GET /attack?`id` HTTP/1.0
  Host: somehost:54321
  From: crawler@fast.no
  Accept: */*
  User-Agent: FAST-WebCrawler/2.2.6 (crawler@fast.no; [...])
  Connection: close

  [...]


Other than the well-known set of web search engines, a bunch of other, private,
 crawl bots and agents run by specific organizations and companies also
 responded. Bots from ecn.purdue.edu, visual.com, poly.edu, inria.fr,
 powerinter.net, xyleme.com, and even more unidentified engines found this page
 and enjoyed it. Although some robots did not pick all addresses (some crawlers
 do not index CGI scripts at all, while others would not use nonstandard ports),
 the majority of the most powerful bots did attack virtually all vectors I
 supplied; and even those that were more careful always got tricked into
 performing at least some.

The experiment could be modified to use a set of real vulnerabilities in the
 form of thousands and thousands of web server overflows, Unicode problems in
 servers such as Microsoft IIS, or script problems. Instead of pointing to my
 own server, the bots could point to a list of randomly generated IP addresses
 or a random selection of .com, .org, or .net servers. Or, you could point the
 bots to a service that could be attacked by supplying a specific input string.
There is an army of robots encompassing a wide range of species, functions, and
 levels of intelligence. And these robots will do whatever you tell them to do.

-- [3] Social considerations --------------------------------------------------

Who is guilty if a "possessed" web crawler compromises your system? The most
 obvious answer is: the author of the original web page the crawler visited. But
 web page authors are hard to trace, and a web crawler indexing cycle takes
 weeks. It is hard to determine when a specific page was put on the Net because
 pages can be delivered in so many ways or even produced by other robots. There
 is no tracking mechanism for the Web that provides functionality similar to
 that implemented in the SMTP protocol. Moreover, many crawlers do not remember
 where they "learned" new URLs. Additional problems are caused by indexing
 flags, such as "noindex" without the "nofollow" option. In many cases, an
 author's identity and attack origin can never be fully determined.

By analogy to other cases, it is reasonable to expect that intelligent bot
 developers would be forced to implement specific filters or to pay enormous
 compensation to victims suffering from bot abuse, should this kind of attack
 become a reality. On the other hand, when you consider the number and wide
 variety of known vulnerabilities, it seems almost impossible to successfully
 filter contents to eliminate malicious code. And so the problem persists. (An
 additional issue is that not all crawler bots are under U.S. jurisdiction,
 which differs significantly from some of their counterparts when it comes to
 computer abuse regulations.)

-- [4] Defense ----------------------------------------------------------------

As mentioned earlier, web crawlers themselves have limited defense and
 avoidance possibilities, due to a wide variety of web-based vulnerabilities. It
 is impossible to simply ban all malicious sequences, and heuristic
 investigation is risky: input that is valid and expected for one script may be
 enough to attack another. One reasonable defense tactic is for all potential
 victims to use secure and up-to-date software, but this concept is extremely
 unpopular for some reason. (A quick and nonscientific test: A search at http://
www.google.com with the unique documents filter enabled returns 62,100 matches
 for "CGI vulnerability" query [C].) Another line of defense against infected
 bots is to use the standard /robots.txt exclusion mechanism [D]. The price you
 pay, though, is the partial or complete exclusion of your site from search
 engines, which in most cases is undesirable and unacceptable. Also, some robots
 are broken or intentionally designed to ignore /robots.txt when following a
 direct link to new websites.

-- [5] References -------------------------------------------------------------

[A] "The Anatomy of a Large-Scale Hypertextual Web Search Engine"
    Googlebot concept, Sergey Brin, Lawrence Page, Stanford University
    URL: http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm

[B] "The Web Robots Database"
    URL: http://www.robotstxt.org/wc/active.html

[C] "Web Security FAQ", Lincoln D. Stein
    URL: http://www.w3.org/Security/Faq/www-security-faq.html

[D] "A Standard for Robot Exclusion", Martijn Koster
    URL: http://info.webcrawler.com/mak/projects/robots/norobots.html

|=[ EOF ]=-------------------------------------------------------------------=|</pre><p>It appears nearly impossible to fully prevent the automated abuse without the ability to anticipate and classify the actual intent behind a particular user action, which is not likely to happen any time soon. Meanwhile, the number of systems that rely on automated interaction with other entities increases every year, making this issue perhaps even more interesting than when I originally wrote this article, particularly with more and more sophisticated and populous worms hitting the Internet in the past several years.</p><p>Is there a moral to this story or a clear conclusion we should be drawing? Not really. It is, however, important to remember that machines do not always act on behalf of their operators, even when they are not clearly compromised or downright abused to become hostile. Determining the intent and the place where the desire to carry out a malicious action originated may be a tremendous challenge, as you’ll see in later chapters.</p></div></body></html>