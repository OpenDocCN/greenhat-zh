- en: Chapter 1. Security in the World of Web Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To provide proper context for the technical discussions later in the book, it
    seems prudent to first of all explain what the field of security engineering tries
    to achieve and then to outline why, in this otherwise well-studied context, web
    applications deserve special treatment. So, shall we?
  prefs: []
  type: TYPE_NORMAL
- en: Information Security in a Nutshell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On the face of it, the field of information security appears to be a mature,
    well-defined, and accomplished branch of computer science. Resident experts eagerly
    assert the importance of their area of expertise by pointing to large sets of
    neatly cataloged security flaws, invariably attributed to security-illiterate
    developers, while their fellow theoreticians note how all these problems would
    have been prevented by adhering to this year’s hottest security methodology. A
    commercial industry thrives in the vicinity, offering various nonbinding security
    assurances to everyone, from casual computer users to giant international corporations.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, for several decades, we have in essence completely failed to come up with
    even the most rudimentary usable frameworks for understanding and assessing the
    security of modern software. Save for several brilliant treatises and limited-scale
    experiments, we do not even have any real-world success stories to share. The
    focus is almost exclusively on reactive, secondary security measures (such as
    vulnerability management, malware and attack detection, sandboxing, and so forth)
    and perhaps on selectively pointing out flaws in somebody else’s code. The frustrating,
    jealously guarded secret is that when it comes to enabling others to develop secure
    systems, we deliver far less value than should be expected; the modern Web is
    no exception.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some of the most alluring approaches to ensuring information security
    and try to figure out why they have not made a difference so far.
  prefs: []
  type: TYPE_NORMAL
- en: Flirting with Formal Solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Perhaps the most obvious tool for building secure programs is to algorithmically
    prove they behave just the right way. This is a simple premise that intuitively
    should be within the realm of possibility—so why hasn’t this approach netted us
    much?
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, let’s start with the adjective *secure* itself: What is it supposed to
    convey, precisely? Security seems like an intuitive concept, but in the world
    of computing, it escapes all attempts to usefully define it. Sure, we can restate
    the problem in catchy yet largely unhelpful ways, but you know there’s a problem
    when one of the definitions most frequently cited by practitioners^([[2](#ftn.CHP-1-FN-1)])
    is this:'
  prefs: []
  type: TYPE_NORMAL
- en: A system is secure if it behaves precisely in the manner intended—and does nothing
    more.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This definition is neat and vaguely outlines an abstract goal, but it tells
    very little about how to achieve it. It’s computer science, but in terms of specificity,
    it bears a striking resemblance to a poem by Victor Hugo:'
  prefs: []
  type: TYPE_NORMAL
- en: Love is a portion of the soul itself, and it is of the same nature as the celestial
    breathing of the atmosphere of paradise.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One could argue that practitioners are not the ones to be asked for nuanced
    definitions, but go ahead and pose the same question to a group of academics and
    they’ll offer you roughly the same answer. For example, the following common academic
    definition traces back to the Bell-La Padula security model, published in the
    1960s. (This was one of about a dozen attempts to formalize the requirements for
    secure systems, in this case in terms of a finite state machine;^([[86](pr03.html#ftn.CHP-1-FT-1)])
    it is also one of the most notable ones.)
  prefs: []
  type: TYPE_NORMAL
- en: A system is secure if and only if it starts in a secure state and cannot enter
    an insecure state.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Definitions along these lines are fundamentally true, of course, and may serve
    as the basis for dissertations or even a couple of government grants. But in practice,
    models built on these foundations are bound to be nearly useless for generalized,
    real-world software engineering for at least three reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**There is no way to define desirable behavior for a sufficiently complex computer
    system**. No single authority can define what the “intended manner” or “secure
    states” should be for an operating system or a web browser. The interests of users,
    system owners, data providers, business process owners, and software and hardware
    vendors tend to differ significantly and shift rapidly—when the stakeholders are
    capable and willing to clearly and honestly disclose their interests to begin
    with. To add insult to injury, sociology and game theory suggest that computing
    a simple sum of these particular interests may not actually result in a beneficial
    outcome. This dilemma, known as “the tragedy of the commons,” is central to many
    disputes over the future of the Internet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wishful thinking does not automatically map to formal constraints**. Even
    if we can reach a perfect, high-level agreement about how the system should behave
    in a subset of cases, it is nearly impossible to formalize such expectations as
    a set of permissible inputs, program states, and state transitions, which is a
    prerequisite for almost every type of formal analysis. Quite simply, intuitive
    concepts such as “I do not want my mail to be read by others,” do not translate
    to mathematical models particularly well. Several exotic approaches will allow
    such vague requirements to be at least partly formalized, but they put heavy constraints
    on software-engineering processes and often result in rulesets and models that
    are far more complicated than the validated algorithms themselves. And, in turn,
    they are likely to need their own correctness to be proven . . . *ad infinitum*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software behavior is very hard to conclusively analyze**. Static analysis
    of computer programs with the intent to prove that they will always behave according
    to a detailed specification is a task that no one has managed to believably demonstrate
    in complex, real-world scenarios (though, as you might expect, limited success
    in highly constrained settings or with very narrow goals is possible). Many cases
    are likely to be impossible to solve in practice (due to computational complexity)
    and may even turn out to be completely undecidable due to the halting problem.^([[3](#ftn.CHP-1-FN-2)])'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps more frustrating than the vagueness and uselessness of the early definitions
    is that as the decades have passed, little or no progress has been made toward
    something better. In fact, an academic paper released in 2001 by the Naval Research
    Laboratory backtracks on some of the earlier work and arrives at a much more casual,
    enumerative definition of software security—one that explicitly disclaims its
    imperfection and incompleteness.^([[87](pr03.html#ftn.CHP-1-FT-2)])
  prefs: []
  type: TYPE_NORMAL
- en: A system is secure if it adequately protects information that it processes against
    unauthorized disclosure, unauthorized modification, and unauthorized withholding
    (also called denial of service). We say “adequately” because no practical system
    can achieve these goals without qualification; security is inherently relative.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The paper also provides a retrospective assessment of earlier efforts and the
    unacceptable sacrifices made to preserve the theoretical purity of said models:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Experience has shown that, on one hand, the axioms of the Bell-La Padula model
    are overly restrictive: they disallow operations that users require in practical
    applications. On the other hand, trusted subjects, which are the mechanism provided
    to overcome some of these restrictions, are not restricted enough. . . . Consequently,
    developers have had to develop ad hoc specifications for the desired behavior
    of trusted processes in each individual system.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the end, regardless of the number of elegant, competing models introduced,
    all attempts to understand and evaluate the security of real-world software using
    algorithmic foundations seem bound to fail. This leaves developers and security
    experts with no method to make authoritative, future-looking statements about
    the quality of produced code. So, what other options are on the table?
  prefs: []
  type: TYPE_NORMAL
- en: Enter Risk Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the absence of formal assurances and provable metrics, and given the frightening
    prevalence of security flaws in key software relied upon by modern societies,
    businesses flock to another catchy concept: *risk management*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of risk management, applied successfully to the insurance business
    (with perhaps a bit less success in the financial world), simply states that system
    owners should learn to live with vulnerabilities that cannot be addressed in a
    cost-effective way and, in general, should scale efforts according to the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '| *risk* = *probability of an event* × *maximum loss* |'
  prefs: []
  type: TYPE_TB
- en: For example, according to this doctrine, if having some unimportant workstation
    compromised yearly won’t cost the company more than $1,000 in lost productivity,
    the organization should just budget for this loss and move on, rather than spend
    say $100,000 on additional security measures or contingency and monitoring plans
    to prevent the loss. According to the doctrine of risk management, the money would
    be better spent on isolating, securing, and monitoring the mission-critical mainframe
    that churns out billing records for all customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, it’s prudent to prioritize security efforts. The problem is that
    when risk management is done strictly by the numbers, it does little to help us
    to understand, contain, and manage real-world problems. Instead, it introduces
    a dangerous fallacy: that structured inadequacy is almost as good as adequacy
    and that underfunded security efforts *plus* risk management are about as good
    as properly funded security work.'
  prefs: []
  type: TYPE_NORMAL
- en: Guess what? No dice.
  prefs: []
  type: TYPE_NORMAL
- en: '**In interconnected systems, losses are not capped and are not tied to an asset**.
    Strict risk management depends on the ability to estimate typical and maximum
    cost associated with the compromise of a resource. Unfortunately, the only way
    to do this is to overlook the fact that many of the most spectacular security
    breaches—such as the attacks on TJX^([[4](#ftn.CHP-1-FN-3)]) or Microsoft^([[5](#ftn.CHP-1-FN-4)])—began
    at relatively unimportant and neglected entry points. These initial intrusions
    soon escalated and eventually resulted in the nearly complete compromise of critical
    infrastructure, bypassing any superficial network compartmentalization on their
    way. In typical by-the-numbers risk management, the initial entry point is assigned
    a lower weight because it has a low value when compared to other nodes. Likewise,
    the internal escalation path to more sensitive resources is downplayed as having
    a low probability of ever being abused. Still, neglecting them both proves to
    be an explosive mix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The nonmonetary costs of intrusions are hard to offset with the value contributed
    by healthy systems**. Loss of user confidence and business continuity, as well
    as the prospect of lawsuits and the risk of regulatory scrutiny, are difficult
    to meaningfully insure against. These effects can, at least in principle, make
    or break companies or even entire industries, and any superficial valuations of
    such outcomes are almost purely speculative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Existing data is probably not representative of future risks**. Unlike the
    participants in a fender bender, attackers will not step forward to helpfully
    report break-ins and will not exhaustively document the damage caused. Unless
    the intrusion is painfully evident (due to the attacker’s sloppiness or disruptive
    intent), it will often go unnoticed. Even though industry-wide, self-reported
    data may be available, there is simply no reliable way of telling how complete
    it is or how much extra risk one’s current business practice may be contributing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Statistical forecasting is not a robust predictor of individual outcomes**.
    Simply because on average people in cities are more likely to be hit by lightning
    than mauled by a bear does not mean you should bolt a lightning rod to your hat
    and then bathe in honey. The likelihood that a compromise will be associated with
    a particular component is, on an individual scale, largely irrelevant: Security
    incidents are nearly certain, but out of thousands of exposed nontrivial resources,
    any service can be used as an attack vector—and no one service is likely to see
    a volume of events that would make statistical forecasting meaningful within the
    scope of a single enterprise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enlightenment Through Taxonomy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The two schools of thought discussed above share something in common: Both
    assume that it is possible to define security as a set of computable goals and
    that the resulting unified theory of a secure system or a model of acceptable
    risk would then elegantly trickle down, resulting in an optimal set of low-level
    actions needed to achieve perfection in application design.'
  prefs: []
  type: TYPE_NORMAL
- en: Some practitioners preach the opposite approach, which owes less to philosophy
    and more to the natural sciences. These practitioners argue that, much like Charles
    Darwin of the information age, by gathering sufficient amounts of low-level, experimental
    data, we will be able to observe, reconstruct, and document increasingly more
    sophisticated laws in order to arrive some sort of a unified model of secure computing.
  prefs: []
  type: TYPE_NORMAL
- en: 'This latter worldview brings us projects like the Department of Homeland Security-funded
    Common Weakness Enumeration (CWE), the goal of which, in the organization’s own
    words, is to develop a unified “Vulnerability Theory”; “improve the research,
    modeling, and classification of software flaws”; and “provide a common language
    of discourse for discussing, finding and dealing with the causes of software security
    vulnerabilities.” A typical, delightfully baroque example of the resulting taxonomy
    may be this:'
  prefs: []
  type: TYPE_NORMAL
- en: Improper Enforcement of Message or Data Structure
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Failure to Sanitize Data into a Different Plane
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Improper Control of Resource Identifiers
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Insufficient Filtering of File and Other Resource Names for Executable Content
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Today, there are about 800 names in the CWE dictionary, most of which are as
    discourse-enabling as the one quoted here.
  prefs: []
  type: TYPE_NORMAL
- en: 'A slightly different school of naturalist thought is manifested in projects
    such as the Common Vulnerability Scoring System (CVSS), a business-backed collaboration
    that aims to strictly quantify known security problems in terms of a set of basic,
    machine-readable parameters. A real-world example of the resulting vulnerability
    descriptor may be this:'
  prefs: []
  type: TYPE_NORMAL
- en: AV:LN / AC:L / Au:M / C:C / I:N / A:P / E:F / RL:T / RC:UR / CDP:MH / TD:H /
    CR:M / IR:L / AR:M
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Organizations and researchers are expected to transform this 14-dimensional
    vector in a carefully chosen, use-specific way in order to arrive at some sort
    of objective, verifiable, numerical conclusion about the significance of the underlying
    bug (say, “42”), precluding the need to judge the nature of security flaws in
    any more subjective fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Yes, I am poking gentle fun at the expense of these projects, but I do not mean
    to belittle their effort. CWE, CVSS, and related projects serve noble goals, such
    as bringing a more manageable dimension to certain security processes implemented
    by large organizations. Still, none has yielded a grand theory of secure software,
    and I doubt such a framework is within sight.
  prefs: []
  type: TYPE_NORMAL
- en: Toward Practical Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All signs point to security being largely a nonalgorithmic problem for now.
    The industry is understandably reluctant to openly embrace this notion, because
    it implies that there are no silver bullet solutions to preach (or better yet,
    commercialize); still, when pressed hard enough, eventually everybody in the security
    field falls back to a set of rudimentary, empirical recipes. These recipes are
    deeply incompatible with many business management models, but they are all that
    have really worked for us so far. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning from (preferably other people’s) mistakes**. Systems should be designed
    to prevent known classes of bugs. In the absence of automatic (or even just elegant)
    solutions, this goal is best achieved by providing ongoing design guidance, ensuring
    that developers know what could go wrong, and giving them the tools to carry out
    otherwise error-prone tasks in the simplest manner possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Developing tools to detect and correct problems**. Security deficiencies
    typically have no obvious side effects until they’re discovered by a malicious
    party: a pretty costly feedback loop. To counter this problem, we create security
    quality assurance (QA) tools to validate implementations and perform audits periodically
    to detect casual mistakes (or systemic engineering deficiencies).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Planning to have everything compromised**. History teaches us that major
    incidents will occur despite our best efforts to prevent them. It is important
    to implement adequate component separation, access control, data redundancy, monitoring,
    and response procedures so that service owners can react to incidents before an
    initially minor hiccup becomes a disaster of biblical proportions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all cases, a substantial dose of patience, creativity, and real technical
    expertise is required from all the information security staff.
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, even such simple, commonsense rules—essentially basic engineering
    rigor—are often dressed up in catchphrases, sprinkled liberally with a selection
    of acronyms (such as *CIA*: *confidentiality*, *integrity*, *availability*), and
    then called “methodologies.” Frequently, these methodologies are thinly veiled
    attempts to pass off one of the most frustrating failures of the security industry
    as yet another success story and, in the end, sell another cure-all product or
    certification to gullible customers. But despite claims to the contrary, such
    products are no substitute for street smarts and technical prowess—at least not
    today.'
  prefs: []
  type: TYPE_NORMAL
- en: In any case, through the remainder of this book, I will shy away from attempts
    to establish or reuse any of the aforementioned grand philosophical frameworks
    and settle for a healthy dose of anti-intellectualism instead. I will review the
    exposed surface of modern browsers, discuss how to use the available tools safely,
    which bits of the Web are commonly misunderstood, and how to control collateral
    damage when things go boom.
  prefs: []
  type: TYPE_NORMAL
- en: And that is, pretty much, the best take on security engineering that I can think
    of.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[2](#CHP-1-FN-1)]) The quote is attributed originally to Ivan Arce, a renowned
    vulnerability hunter, circa 2000; since then, it has been used by Crispin Cowan,
    Michael Howard, Anton Chuvakin, and scores of other security experts.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[3](#CHP-1-FN-2)]) In 1936, Alan Turing showed that (paraphrasing slightly)
    it is not possible to devise an algorithm that can generally decide the outcome
    of other algorithms. Naturally, some algorithms are very much decidable by conducting
    case-specific proofs, just not all of them.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[4](#CHP-1-FN-3)]) Sometime in 2006, several intruders, allegedly led by
    Albert Gonzalez, attacked an unsecured wireless network at a retail location and
    subsequently made their way through the corporate networks of the retail giant.
    They copied the credit card data of about 46 million customers and the Social
    Security numbers, home addresses, and so forth of about 450,000 more. Eleven people
    were charged in connection with the attack, one of whom committed suicide.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[5](#CHP-1-FN-4)]) Microsoft’s formally unpublished and blandly titled presentation
    *Threats Against and Protection of Microsoft’s Internal Network* outlines a 2003
    attack that began with the compromise of an engineer’s home workstation that enjoyed
    a long-lived VPN session to the inside of the corporation. Methodical escalation
    attempts followed, culminating with the attacker gaining access to, and leaking
    data from, internal source code repositories. At least to the general public,
    the perpetrator remains unknown.
  prefs: []
  type: TYPE_NORMAL
- en: A Brief History of the Web
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Web has been plagued by a perplexing number, and a remarkable variety, of
    security issues. Certainly, some of these problems can be attributed to one-off
    glitches in specific client or server implementations, but many are due to capricious,
    often arbitrary design decisions that govern how the essential mechanisms operate
    and mesh together on the browser end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our empire is built on shaky foundations—but why? Perhaps due to simple shortsightedness:
    After all, back in the innocent days, who could predict the perils of contemporary
    networking and the economic incentives behind today’s large-scale security attacks?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, while this explanation makes sense for truly ancient mechanisms
    such as SMTP or DNS, it does not quite hold water here: The Web is relatively
    young and took its current shape in a setting not that different from what we
    see today. Instead, the key to this riddle probably lies in the tumultuous and
    unusual way in which the associated technologies have evolved.'
  prefs: []
  type: TYPE_NORMAL
- en: So, pardon me another brief detour as we return to the roots. The prehistory
    of the Web is fairly mundane but still worth a closer look.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tales of the Stone Age: 1945 to 1994'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computer historians frequently cite a hypothetical desk-sized device called
    the Memex as one of the earliest fossil records, postulated in 1945 by Vannevar
    Bush.^([[88](pr03.html#ftn.CHP-1-FT-3)]) Memex was meant to make it possible to
    create, annotate, and follow cross-document links in microfilm, using a technique
    that vaguely resembled modern-day bookmarks and hyperlinks. Bush boldly speculated
    that this simple capability would revolutionize the field of knowledge management
    and data retrieval (amusingly, a claim still occasionally ridiculed as uneducated
    and naïve until the early 1990s). Alas, any useful implementation of the design
    was out of reach at that time, so, beyond futuristic visions, nothing much happened
    until transistor-based computers took center stage.
  prefs: []
  type: TYPE_NORMAL
- en: The next tangible milestone, in the 1960s, was the arrival of IBM’s Generalized
    Markup Language (GML), which allowed for the annotation of documents with machine-readable
    directives indicating the function of each block of text, effectively saying “this
    is a header,” “this is a numbered list of items,” and so on. Over the next 20
    years or so, GML (originally used by only a handful of IBM text editors on bulky
    mainframe computers) became the foundation for Standard Generalized Markup Language
    (SGML), a more universal and flexible language that traded an awkward colon- and
    period-based syntax for a familiar angle-bracketed one.
  prefs: []
  type: TYPE_NORMAL
- en: While GML was developing into SGML, computers were growing more powerful and
    user friendly. Several researchers began experimenting with Bush’s cross-link
    concept, applying it to computer-based document storage and retrieval, in an effort
    to determine whether it would be possible to cross-reference large sets of documents
    based on some sort of key. Adventurous companies and universities pursued pioneering
    projects such as ENQUIRE, NLS, and Xanadu, but most failed to make a lasting impact.
    Some common complaints about the various projects revolved around their limited
    practical usability, excess complexity, and poor scalability.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the decade, two researchers, Tim Berners-Lee and Dan Connolly,
    had begun working on a new approach to the cross-domain reference challenge—one
    that focused on simplicity. They kicked off the project by drafting HyperText
    Markup Language (HTML), a bare-bones descendant of SGML, designed specifically
    for annotating documents with hyperlinks and basic formatting. They followed their
    work on HTML with the development of HyperText Transfer Protocol (HTTP), an extremely
    basic, dedicated scheme for accessing HTML resources using the existing concepts
    of Internet Protocol (IP) addresses, domain names, and file paths. The culmination
    of their work, sometime between 1991 and 1993, was Tim Berners-Lee’s World Wide
    Web ([Figure 1-1](ch01s02.html#tim_berners-leeas_world_wide_web "Figure 1-1. Tim
    Berners-Lee’s World Wide Web")), a rudimentary browser that parsed HTML and allowed
    users to render the resulting data on the screen, and then navigate from one page
    to another with a mouse click.
  prefs: []
  type: TYPE_NORMAL
- en: '![Tim Berners-Lee’s World Wide Web](httpatomoreillycomsourcenostarchimages949987.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1. Tim Berners-Lee’s World Wide Web
  prefs: []
  type: TYPE_NORMAL
- en: To many people, the design of HTTP and HTML must have seemed a significant regression
    from the loftier goals of competing projects. After all, many of the earlier efforts
    boasted database integration, security and digital rights management, or cooperative
    editing and publishing; in fact, even Berners-Lee’s own project, ENQUIRE, appeared
    more ambitious than his current work. Yet, because of its low entry requirements,
    immediate usability, and unconstrained scalability (which happened to coincide
    with the arrival of powerful and affordable computers and the expansion of the
    Internet), the unassuming WWW project turned out to be a sudden hit.
  prefs: []
  type: TYPE_NORMAL
- en: All right, all right, it turned out to be a “hit” by the standards of the mid-1990s.
    Soon, there were no fewer than dozens of web servers running on the Internet.
    By 1993, HTTP traffic accounted for 0.1 percent of all bandwidth in the National
    Science Foundation backbone network. The same year also witnessed the arrival
    of Mosaic, the first reasonably popular and sophisticated web browser, developed
    at the University of Illinois. Mosaic extended the original World Wide Web code
    by adding features such as the ability to embed images in HTML documents and submit
    user data through forms, thus paving the way for the interactive, multimedia applications
    of today.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mosaic made browsing prettier, helping drive consumer adoption of the Web.
    And through the mid-1990s, it served as the foundation for two other browsers:
    Mosaic Netscape (later renamed Netscape Navigator) and Spyglass Mosaic (ultimately
    acquired by Microsoft and renamed Internet Explorer). A handful of competing non-Mosaic
    engines emerged as well, including Opera and several text-based browsers (such
    as Lynx and w3m). The first search engines, online newspapers, and dating sites
    followed soon after.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The First Browser Wars: 1995 to 1999'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By the mid-1990s, it was clear that the Web was here to stay and that users
    were willing to ditch many older technologies in favor of the new contender. Around
    that time, Microsoft, the desktop software behemoth that had been slow to embrace
    the Internet before, became uncomfortable and began to allocate substantial engineering
    resources to its own browser, eventually bundling it with the Windows operating
    system in 1996.^([[6](#ftn.CHP-1-FN-5)]) Microsoft’s actions sparked a period
    colloquially known as the “browser wars.”
  prefs: []
  type: TYPE_NORMAL
- en: The resulting arms race among browser vendors was characterized by the remarkably
    rapid development and deployment of new features in the competing products, a
    trend that often defied all attempts to standardize or even properly document
    all the newly added code. Core HTML tweaks ranged from the silly (the ability
    to make text blink, a Netscape invention that became the butt of jokes and a telltale
    sign of misguided web design) to notable ones, such as the ability to change typefaces
    or embed external documents in so-called frames. Vendors released their products
    with embedded programming languages such as JavaScript and Visual Basic, plug-ins
    to execute platform-independent Java or Flash applets on the user’s machine, and
    useful but tricky HTTP extensions such as cookies. Only a limited degree of superficial
    compatibility, sometimes hindered by patents and trademarks,^([[7](#ftn.CHP-1-FN-6)])
    would be maintained.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the Web grew larger and more diverse, a sneaky disease spread across browser
    engines under the guise of fault tolerance. At first, the reasoning seemed to
    make perfect sense: If browser A could display a poorly designed, broken page
    but browser B refused to (for any reason), users would inevitably see browser
    B’s failure as a bug in that product and flock in droves to the seemingly more
    capable client, browser A. To make sure that their browsers could display almost
    any web page correctly, engineers developed increasingly complicated and undocumented
    heuristics designed to second-guess the intent of sloppy webmasters, often sacrificing
    security and occasionally even compatibility in the process. Unfortunately, each
    such change further reinforced bad web design practices^([[8](#ftn.CHP-1-FN-7)])
    and forced the remaining vendors to catch up with the mess to stay afloat. Certainly,
    the absence of sufficiently detailed, up-to-date standards did not help to curb
    the spread of this disease.'
  prefs: []
  type: TYPE_NORMAL
- en: In 1994, in order to mitigate the spread of engineering anarchy and govern the
    expansion of HTML, Tim Berners-Lee and a handful of corporate sponsors created
    the World Wide Web Consortium (W3C). Unfortunately for this organization, for
    a long while it could only watch helplessly as the format was randomly extended
    and tweaked. Initial W3C work on HTML 2.0 and HTML 3.2 merely tried to catch up
    with the status quo, resulting in half-baked specs that were largely out-of-date
    by the time they were released to the public. The consortium also tried to work
    on some novel and fairly well-thought-out projects, such as Cascading Style Sheets,
    but had a hard time getting buy-in from the vendors.
  prefs: []
  type: TYPE_NORMAL
- en: Other efforts to standardize or improve already implemented mechanisms, most
    notably HTTP and JavaScript, were driven by other auspices such as the European
    Computer Manufacturers Association (ECMA), the International Organization for
    Standardization (ISO), and the Internet Engineering Task Force (IETF). Sadly,
    the whole of these efforts was seldom in sync, and some discussions and design
    decisions were dominated by vendors or other stakeholders who did not care much
    about the long-term prospects of the technology. The results were a number of
    dead standards, contradictory advice, and several frightening examples of harmful
    cross-interactions between otherwise neatly designed protocols—a problem that
    will be particularly evident when we discuss a variety of content isolation mechanisms
    in [Chapter 9](ch09.html "Chapter 9. Content Isolation Logic").
  prefs: []
  type: TYPE_NORMAL
- en: 'The Boring Period: 2000 to 2003'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the efforts to wrangle the Web floundered, Microsoft’s dominance grew as
    a result of its operating system-bundling strategy. By the beginning of the new
    decade, Netscape Navigator was on the way out, and Internet Explorer held an impressive
    80 percent market share—a number roughly comparable to what Netscape had held
    just five years before. On both sides of the fence, security and interoperability
    were the two most notable casualties of the feature war, but one could hope now
    that the fighting was over, developers could put differences aside and work together
    to fix the mess.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, dominance bred complacency: Having achieved its goals brilliantly,
    Microsoft had little incentive to invest heavily in its browser. Although through
    version 5, major releases of Internet Explorer (IE) arrived yearly, it took two
    years for version 6 to surface, then five full years for Internet Explorer 6 to
    be updated to Internet Explorer 7\. Without Microsoft’s interest, other vendors
    had very little leverage to make disruptive changes; most sites were unwilling
    to make improvements that would work for only a small fraction of their visitors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the upside, the slowdown in browser development allowed the W3C to catch
    up and to carefully explore some new concepts for the future of the Web. New initiatives
    finalized around the year 2000 included HTML 4 (a cleaned-up language that deprecated
    or banned many of the redundant or politically incorrect features embraced by
    earlier versions) and XHTML 1.1 (a strict and well-structured XML-based format
    that was easier to unambiguously parse, with no proprietary heuristics allowed).
    The consortium also made significant improvements to JavaScript’s Document Object
    Model and to Cascading Style Sheets. Regrettably, by the end of the century, the
    Web was too mature to casually undo some of the sins of the old, yet too young
    for the security issues to be pressing and evident enough for all to see. Syntax
    was improved, tags were deprecated, validators were written, and deck chairs were
    rearranged, but the browsers remained pretty much the same: bloated, quirky, and
    unpredictable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But soon, something interesting happened: Microsoft gave the world a seemingly
    unimportant, proprietary API, confusingly named *XMLHttpRequest*. This trivial
    mechanism was meant to be of little significance, merely an attempt to scratch
    an itch in the web-based version of Microsoft Outlook. But *XMLHttpRequest* turned
    out to be far more, as it allowed for largely unconstrained asynchronous HTTP
    communications between client-side JavaScript and the server without the need
    for time-consuming and disruptive page transitions. In doing so, the API contributed
    to the emergence of what would later be dubbed *web 2.0—*a range of complex, unusually
    responsive, browser-based applications that enabled users to operate on complex
    data sets, collaborate and publish content, and so on, invading the sacred domain
    of “real,” installable client software in the process. Understandably, this caused
    quite a stir.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Web 2.0 and the Second Browser Wars: 2004 and Beyond'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*XMLHttpRequest*, in conjunction with the popularity of the Internet and the
    broad availability of web browsers, pushed the Web to some new, exciting frontiers—and
    brought us a flurry of security bugs that impacted both individual users and businesses.
    By about 2002, worms and browser vulnerabilities had emerged as a frequently revisited
    theme in the media. Microsoft, by virtue of its market dominance and a relatively
    dismissive security posture, took much of the resulting PR heat. The company casually
    downplayed the problem, but the trend eventually created an atmosphere conducive
    to a small rebellion.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In 2004, a new contender in the browser wars emerged: Mozilla Firefox (a community-supported
    descendant of Netscape Navigator) took the offensive, specifically targeting Internet
    Explorer’s poor security track record and standards compliance. Praised by both
    IT journalists and security experts, Firefox quickly secured a 20 percent market
    share. While the newcomer soon proved to be nearly as plagued by security bugs
    as its counterpart from Redmond, its open source nature and the freedom from having
    to cater to stubborn corporate users allowed developers to fix issues much faster.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Why would vendors compete so feverishly? Strictly speaking, there is no money
    to be made by having a particular market share in the browser world. That said,
    pundits have long speculated that it is a matter of power: By bundling, promoting,
    or demoting certain online services (even as simple as the default search engine),
    whoever controls the browser controls much of the Internet.'
  prefs: []
  type: TYPE_NORMAL
- en: Firefox aside, Microsoft had other reasons to feel uneasy. Its flagship product,
    the Windows operating system, was increasingly being used as an (expendable?)
    launch pad for the browser, with more and more applications (from document editors
    to games) moving to the Web. This could not be good.
  prefs: []
  type: TYPE_NORMAL
- en: These facts, combined with the sudden emergence of Apple’s Safari browser and
    perhaps Opera’s advances in the world of smartphones, must have had Microsoft
    executives scratching their heads. They had missed the early signs of the importance
    of the Internet in the 1990s; surely they couldn’t afford to repeat the mistake.
    Microsoft put some steam behind Internet Explorer development again, releasing
    drastically improved and somewhat more secure versions 7, 8, and 9 in rapid succession.
  prefs: []
  type: TYPE_NORMAL
- en: Competitors countered with new features and claims of even better (if still
    superficial) standards compliance, safer browsing, and performance improvements.
    Caught off guard by the unexpected success of *XMLHttpRequest* and quick to forget
    other lessons from the past, vendors also decided to experiment boldly with new
    ideas, sometimes unilaterally rolling out half-baked or somewhat insecure designs
    like *globalStorage* in Firefox or *httponly* cookies in Internet Explorer, just
    to try their luck.
  prefs: []
  type: TYPE_NORMAL
- en: To further complicate the picture, frustrated by creative differences with W3C,
    a group of contributors created a wholly new standards body called the Web Hypertext
    Application Technology Working Group (WHATWG). The WHATWG has been instrumental
    in the development of HTML5, the first holistic and security-conscious revision
    of existing standards, but it is reportedly shunned by Microsoft due to patent
    policy disputes.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout much of its history, the Web has enjoyed a unique, highly competitive,
    rapid, often overly political, and erratic development model with no unifying
    vision and no one set of security principles. This state of affairs has left a
    profound mark on how browsers operate today and how secure the user data handled
    by browsers can be.
  prefs: []
  type: TYPE_NORMAL
- en: Chances are, this situation is not going to change anytime soon.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[6](#CHP-1-FN-5)]) Interestingly, this decision turned out to be a very controversial
    one. On one hand, it could be argued that in doing so, Microsoft contributed greatly
    to the popularization of the Internet. On the other, it undermined the position
    of competing browsers and could be seen as anticompetitive. In the end, the strategy
    led to a series of protracted legal battles over the possible abuse of monopoly
    by the company, such as *United States v. Microsoft*.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[7](#CHP-1-FN-6)]) For example, Microsoft did not want to deal with Sun to
    license a trademark for JavaScript (a language so named for promotional reasons
    and not because it had anything to do with Java), so it opted to name its almost-but-not-exactly-identical
    version “JScript.” Microsoft’s official documentation still refers to the software
    by this name.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[8](#CHP-1-FN-7)]) Prime examples of misguided and ultimately lethal browser
    features are content and character set-sniffing mechanisms, both of which will
    be discussed in [Chapter 13](ch13.html "Chapter 13. Content Recognition Mechanisms").
  prefs: []
  type: TYPE_NORMAL
- en: The Evolution of a Threat
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clearly, web browsers, and their associated document formats and communication
    protocols, evolved in an unusual manner. This evolution may explain the high number
    of security problems we see, but by itself it hardly proves that these problems
    are unique or noteworthy. To wrap up this chapter, let’s take a quick look at
    the very special characteristics behind the most prevalent types of online security
    threats and explore why these threats had no particularly good equivalents in
    the years before the Web.
  prefs: []
  type: TYPE_NORMAL
- en: The User as a Security Flaw
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perhaps the most striking (and entirely nontechnical) property of web browsers
    is that most people who use them are overwhelmingly unskilled. Sure, nonproficient
    users have been an amusing, fringe problem since the dawn of computing. But the
    popularity of the Web, combined with its remarkably low barrier to entry, means
    we are facing a new foe: Most users simply don’t know enough to stay safe.'
  prefs: []
  type: TYPE_NORMAL
- en: For a long time, engineers working on general-purpose software have made seemingly
    arbitrary assumptions about the minimal level of computer proficiency required
    of their users. Most of these assumptions have been without serious consequences;
    the incorrect use of a text editor, for instance, would typically have little
    or no impact on system security. Incompetent users simply would not be able to
    get their work done, a wonderfully self-correcting issue.
  prefs: []
  type: TYPE_NORMAL
- en: Web browsers do not work this way, however. Unlike certain complicated software,
    they can be *successfully* used by people with virtually no computer training,
    people who may not even know how to use a text editor. But at the same time, browsers
    can be operated *safely* only by people with a pretty good understanding of computer
    technology and its associated jargon, including topics such as Public-Key Infrastructure.
    Needless to say, this prerequisite is not met by most users of some of today’s
    most successful web applications.
  prefs: []
  type: TYPE_NORMAL
- en: Browsers still look and feel as if they were designed by geeks and for geeks,
    complete with occasional cryptic and inconsistent error messages, complex configuration
    settings, and a puzzling variety of security warnings and prompts. A notable study
    by Berkeley and Harvard researchers in 2006 demonstrated that casual users are
    almost universally oblivious to signals that surely make perfect sense to a developer,
    such as the presence or absence of lock icons in the status bar.^([[89](pr03.html#ftn.CHP-1-FT-4)])
    In another study, Stanford and Microsoft researchers reached similar conclusions
    when they examined the impact of the modern “green URL bar” security indicator.
    The mechanism, designed to offer a more intuitive alternative to lock icons, actually
    made it easier to trick users by teaching the audience to trust a particular shade
    of green, no matter where this color appeared.^([[90](pr03.html#ftn.CHP-1-FT-5)])
  prefs: []
  type: TYPE_NORMAL
- en: 'Some experts argue that the ineptitude of the casual user is not the fault
    of software vendors and hence not an engineering problem at all. Others note that
    when creating software so easily accessible and so widely distributed, it is irresponsible
    to force users to make security-critical decisions that depend on technical prowess
    not required to operate the program in the first place. To blame browser vendors
    alone is just as unfair, however: The computing industry as a whole has no robust
    answers in this area, and very little research is available on how to design comparably
    complex user interfaces (UIs) in a bulletproof way. After all, we barely get it
    right for ATMs.'
  prefs: []
  type: TYPE_NORMAL
- en: The Cloud, or the Joys of Communal Living
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another peculiar characteristic of the Web is the dramatically understated separation
    between unrelated applications and the data they process.
  prefs: []
  type: TYPE_NORMAL
- en: In the traditional model followed by virtually all personal computers over the
    last 15 years or so, there are very clear boundaries between high-level data objects
    (documents), user-level code (applications), and the operating system kernel that
    arbitrates all cross-application communications and hardware input/output (I/O)
    and enforces configurable security rules should an application go rogue. These
    boundaries are well studied and useful for building practical security schemes.
    A file opened in your text editor is unlikely to be able to steal your email,
    unless a really unfortunate conjunction of implementation flaws subverts all these
    layers of separation at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the browser world, this separation is virtually nonexistent: Documents and
    code live as parts of the same intermingled blobs of HTML, isolation between completely
    unrelated applications is partial at best (with all sites nominally sharing a
    global JavaScript environment), and many types of interaction between sites are
    implicitly permitted with few, if any, flexible, browser-level security arbitration
    frameworks.'
  prefs: []
  type: TYPE_NORMAL
- en: In a sense, the model is reminiscent of CP/M, DOS, and other principally nonmultitasking
    operating systems with no robust memory protection, CPU preemption, or multiuser
    features. The obvious difference is that few users depended on these early operating
    systems to simultaneously run multiple untrusted, attacker-supplied applications,
    so there was no particular reason for alarm.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, the seemingly unlikely scenario of a text file stealing your email
    is, in fact, a frustratingly common pattern on the Web. Virtually all web applications
    must heavily compensate for unsolicited, malicious cross-domain access and take
    cumbersome steps to maintain at least some separation of code and the displayed
    data. And sooner or later, virtually all web applications fail. Content-related
    security issues, such as cross-site scripting or cross-site request forgery, are
    extremely common and have very few counterparts in dedicated, compartmentalized
    client architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Nonconvergence of Visions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fortunately, the browser security landscape is not entirely hopeless, and despite
    limited separation between web applications, several selective security mechanisms
    offer rudimentary protection against the most obvious attacks. But this brings
    us to another characteristic that makes the Web such an interesting subject: There
    is no shared, holistic security model to grasp and live by. We are not looking
    for a grand vision for world peace, mind you, but simply a common set of flexible
    paradigms that would apply to most, if not all, of the relevant security logic.
    In the Unix world, for example, the *rwx* user/group permission model is one such
    strong unifying theme. But in the browser realm?'
  prefs: []
  type: TYPE_NORMAL
- en: In the browser realm, a mechanism called *same-origin policy* could be considered
    a candidate for a core security paradigm, but only until one realizes that it
    governs a woefully small subset of cross-domain interactions. That detail aside,
    even within its scope, it has no fewer than seven distinct varieties, each of
    which places security boundaries between applications in a slightly different
    place.^([[9](#ftn.CHP-1-FN-8)]) Several dozen additional mechanisms, with no relation
    to the same-origin model, control other key aspects of browser behavior (essentially
    implementing what each author considered to be the best approach to security controls
    that day).
  prefs: []
  type: TYPE_NORMAL
- en: As it turns out, hundreds of small, clever hacks do not necessarily add up to
    a competent security opus. The unusual lack of integrity makes it very difficult
    even to decide where a single application ends and a different one begins. Given
    this reality, how does one assess attack surfaces, grant or take away permissions,
    or accomplish just about any other security-minded task? Too often, “by keeping
    your fingers crossed” is the best response we can give.
  prefs: []
  type: TYPE_NORMAL
- en: Curiously, many well-intentioned attempts to improve security by defining new
    security controls only make the problem worse. Many of these schemes create new
    security boundaries that, for the sake of elegance, do not perfectly align with
    the hairy juxtaposition of the existing ones. When the new controls are finer
    grained, they are likely to be rendered ineffective by the legacy mechanisms,
    offering a false sense of security; when they are more coarse grained, they may
    eliminate some of the subtle assurances that the Web depends on right now. (Adam
    Barth and Collin Jackson explore the topic of destructive interference between
    browser security policies in their academic work.)^([[91](pr03.html#ftn.CHP-1-FT-6)])
  prefs: []
  type: TYPE_NORMAL
- en: 'Cross-Browser Interactions: Synergy in Failure'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The overall susceptibility of an ecosystem composed of several different software
    products could be expected to be equal to a simple sum of the flaws contributed
    by each of the applications. In some cases, the resulting exposure may be less
    (diversity improves resilience), but one would not expect it to be more.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Web is once again an exception to the rule. The security community has
    discovered a substantial number of issues that cannot be attributed to any particular
    piece of code but that emerge as a real threat when various browsers try to interact
    with each other. No particular product can be easily singled out for blame: They
    are all doing their thing, and the only problem is that no one has bothered to
    define a common etiquette for all of them to obey.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, one browser may assume that, in line with its own security model,
    it is safe to pass certain URLs to external applications or to store or read back
    certain types of data from disk. For each such assumption, there likely exists
    at least one browser that strongly disagrees, expecting other parties to follow
    its rules instead. The exploitability of these issues is greatly aggravated by
    vendors’ desire to get their foot in the door and try to allow web pages to switch
    to their browser on the fly without the user’s informed consent. For example,
    Firefox allows pages to be opened in its browser by registering a *firefoxurl:*
    protocol; Microsoft installs its own .NET gateway plug-in in Firefox; Chrome does
    the same to Internet Explorer via a protocol named *cf:*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Especially in the case of such interactions, pinning the blame on any particular
    party is a fool’s errand. In a recent case of a bug related to *firefoxurl:*,
    Microsoft and half of the information security community blamed Mozilla, while
    Mozilla and the other half of experts blamed Microsoft.^([[92](pr03.html#ftn.CHP-1-FT-7)])
    It did not matter who was right: The result was still a very real mess.'
  prefs: []
  type: TYPE_NORMAL
- en: Another set of closely related problems (practically unheard of in the days
    before the Web) are the incompatibilities in superficially similar security mechanisms
    implemented in each browser. When the security models differ, a sound web application–engineering
    practice in one product may be inadequate and misguided in another. In fact, several
    classes of rudimentary tasks, such as serving a user-supplied plaintext file,
    cannot be safely implemented in certain browsers at all. This fact, however, will
    not be obvious to developers unless they are working in one of the affected browsers—and
    even then, they need to hit just the right spot.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, all the characteristics outlined in this section contribute to a
    whole new class of security vulnerabilities that a taxonomy buff might call a
    *failure to account for undocumented diversity*. This class is very well populated
    today.
  prefs: []
  type: TYPE_NORMAL
- en: The Breakdown of the Client-Server Divide
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Information security researchers enjoy the world of static, clearly assigned
    roles, which are a familiar point of reference when mapping security interactions
    in the otherwise complicated world. For example, we talk about Alice and Bob,
    two wholesome, hardworking users who want to communicate, and Mallory, a sneaky
    attacker who is out to get them. We then have client software (essentially dumb,
    sometimes rogue I/O terminals that frivolously request services) and humble servers,
    carefully fulfilling the clients’ whim. Developers learn these roles and play
    along, building fairly comprehensible and testable network-computing environments
    in the process.
  prefs: []
  type: TYPE_NORMAL
- en: The Web began as a classical example of a proper client-server architecture,
    but the functional boundaries between client and server responsibilities were
    quickly eroded. The culprit is JavaScript, a language that offers the HTTP servers
    a way to delegate application logic to the browser (“client”) side and gives them
    two very compelling reasons to do so. First, such a shift often results in more
    responsive user interfaces, as servers do not need to synchronously participate
    in each tiny UI state change imaginable. Second, server-side CPU and memory requirements
    (and hence service-provisioning costs) can decrease drastically when individual
    workstations across the globe chip in to help with the bulk of the work.
  prefs: []
  type: TYPE_NORMAL
- en: The client-server diffusion process began innocently enough, but it was only
    a matter of time before the first security mechanisms followed to the client side
    too, along with all the other mundane functionality. For example, what was the
    point of carefully scrubbing HTML on the server side when the data was only dynamically
    rendered by JavaScript on the client machine?
  prefs: []
  type: TYPE_NORMAL
- en: In some applications, this trend was taken to extremes, eventually leaving the
    server as little more than a dumb storage device and moving almost all the parsing,
    editing, display, and configuration tasks into the browser itself. In such designs,
    the dependency on a server could even be fully severed by using offline web extensions
    such as HTML5 persistent storage.
  prefs: []
  type: TYPE_NORMAL
- en: A simple shift in where the entire application magic happens is not necessarily
    a big deal, but not all security responsibilities can be delegated to the client
    as easily. For example, even in the case of a server acting as dumb storage, clients
    cannot be given indiscriminate access to all the data stored on the server for
    other users, and they cannot be trusted to enforce access controls. In the end,
    because it was not desirable to keep all the application security logic on the
    server side, and it was impossible to migrate it fully to the client, most applications
    ended up occupying some arbitrary middle ground instead, with no easily discernible
    and logical separation of duties between the client and server components. The
    resulting unfamiliar designs and application behaviors simply had no useful equivalents
    in the elegant and wholesome world of security role-play.
  prefs: []
  type: TYPE_NORMAL
- en: The situation has resulted in more than just a design-level mess; it has led
    to irreducible complexity. In a traditional client-server model with well-specified
    APIs, one can easily evaluate a server’s behavior without looking at the client,
    and vice versa. Moreover, within each of these components, it is possible to easily
    isolate smaller functional blocks and make assumptions about their intended operation.
    With the new model, coupled with the opaque, one-off application APIs common on
    the Web, these analytical tools, and the resulting ease of reasoning about the
    security of a system, have been brutally taken away.
  prefs: []
  type: TYPE_NORMAL
- en: The unexpected failure of standardized security modeling and testing protocols
    is yet another problem that earns the Web a very special—and scary—place in the
    universe of information security.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[9](#CHP-1-FN-8)]) The primary seven varieties, as discussed throughout [Part II](pt02.html
    "Part II. Browser Security Features") of this book, include the security policy
    for JavaScript DOM access; *XMLHttpRequest* API; HTTP cookies; local storage APIs;
    and plug-ins such as Flash, Silverlight, or Java.
  prefs: []
  type: TYPE_NORMAL
- en: Global browser market share, May 2011
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| Vendor | Browser Name | Market Share |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Microsoft | Internet Explorer 6 | 10% | 52% |'
  prefs: []
  type: TYPE_TB
- en: '| Internet Explorer 7 | 7% |'
  prefs: []
  type: TYPE_TB
- en: '| Internet Explorer 8 | 31% |'
  prefs: []
  type: TYPE_TB
- en: '| Internet Explorer 9 | 4% |'
  prefs: []
  type: TYPE_TB
- en: '| Mozilla | Firefox 3 | 12% | 22% |'
  prefs: []
  type: TYPE_TB
- en: '| Firefox 4+ | 10% |'
  prefs: []
  type: TYPE_TB
- en: '| Google | Chrome | 13% |'
  prefs: []
  type: TYPE_TB
- en: '| Apple | Safari | 7% |'
  prefs: []
  type: TYPE_TB
- en: '| Opera Software | Opera | 3% |'
  prefs: []
  type: TYPE_TB
- en: '*Source*: Data drawn from public Net Applications reports.^([[93](pr03.html#ftn.CHP-1-FT-8)])'
  prefs: []
  type: TYPE_NORMAL
