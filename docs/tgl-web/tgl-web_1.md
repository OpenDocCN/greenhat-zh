# 第一章. Web 应用程序世界中的安全

为了为书中稍后技术讨论提供适当的背景，首先解释安全工程领域试图实现的目标，然后概述为什么在这个其他方面已经得到充分研究的背景下，Web 应用程序值得特别对待似乎是明智的。那么，我们就这样做吗？

# 信息安全概述

表面上看，信息安全领域似乎是一个成熟、定义明确且成就显著的计算机科学分支。驻场专家们通过指出大量精心分类的安全漏洞来热情地宣称他们专业领域的重要性，这些漏洞不可避免地归因于缺乏安全知识的开发者，而他们的同行理论家则指出，所有这些问题本可以通过遵循今年最热门的安全方法来预防。一个商业产业在附近蓬勃发展，向所有人提供各种非约束性的安全保证，从普通计算机用户到大型国际公司。

然而，几十年来，我们基本上完全未能提出甚至最基础的、可用的框架来理解和评估现代软件的安全性。除了几篇杰出的论文和有限的实验之外，我们甚至没有可以分享的真实世界成功案例。重点几乎完全集中在反应性、次要的安全措施（如漏洞管理、恶意软件和攻击检测、沙箱等）以及可能是有选择地指出他人代码中的缺陷。令人沮丧的是，这个秘密被嫉妒地保守着：当涉及到使他人能够开发安全系统时，我们提供的价值远低于预期；现代网络也不例外。

让我们来看看确保信息安全的一些最吸引人的方法，并试图弄清楚为什么它们至今没有产生任何影响。

## 与形式化解决方案调情

建立安全程序的最明显工具可能是通过算法证明它们的行为完全正确。这是一个简单的假设，直观上应该属于可能性的范畴——那么为什么这种方法没有给我们带来太多成果呢？

好吧，让我们从形容词*安全*本身开始：它究竟要传达什么？安全似乎是一个直观的概念，但在计算的世界里，它逃避了所有试图有用地定义它的尝试。当然，我们可以用吸引人的方式重述问题，但你知道当从业者最常引用的定义之一是这样的：

> 一个系统是安全的，如果它的行为完全符合预期——并且不做任何其他事情。

这个定义简洁明了，模糊地概述了一个抽象的目标，但它很少讲述如何实现它。这是计算机科学，但在具体性方面，它与维克多·雨果的一首诗有着惊人的相似之处：

> 爱是灵魂的一部分，它与天堂之气的天体呼吸具有相同的本质。

可以争论说，从业者不是被要求提供细微定义的人，但即使向一群学者提出相同的问题，他们也会给出大致相同的答案。例如，以下常见的学术定义可以追溯到 20 世纪 60 年代发表的贝尔-拉帕杜拉安全模型。（这是大约十几次尝试形式化安全系统要求之一的尝试；^([86])它也是最引人注目的一次之一。）

> 一个系统只有在它从安全状态开始并且不能进入不安全状态时才是安全的。

沿着这些定义路线，当然基本上是真实的，可能作为论文或甚至几项政府拨款的基础。但在实践中，建立在这些基础上的模型注定对于广义、现实世界的软件工程几乎毫无用处，至少有三个原因：

+   **为足够复杂的计算机系统定义理想行为是没有办法的**。没有任何单一权威机构可以定义操作系统或网络浏览器的“预期方式”或“安全状态”应该是什么。用户、系统所有者、数据提供者、业务流程所有者以及软件和硬件供应商的利益往往差异很大，并且迅速变化——当利益相关者能够并且愿意清楚地、诚实地披露他们的利益时。更糟糕的是，社会学和博弈论表明，计算这些特定利益的简单总和可能实际上不会产生有益的结果。这个被称为“公地悲剧”的困境是许多关于互联网未来争议的核心。

+   **愿望思维并不自动映射到形式约束**。即使我们可以在某些情况下就系统的行为达成完美、高级的协议，但将这种期望形式化为允许的输入、程序状态和状态转换的集合，这对于几乎每种形式分析都是先决条件，这几乎是不可能的。简单地说，像“我不想让我的邮件被他人阅读”这样的直观概念并不特别适合转化为数学模型。几种异质的方法至少可以部分地形式化这样的模糊要求，但它们对软件工程过程施加了沉重的约束，并且往往导致规则集和模型比经过验证的算法本身更加复杂。而且，反过来，它们可能还需要证明它们自己的正确性……无穷无尽。

+   **软件行为很难进行最终分析**。以证明计算机程序将始终按照详细规范行事为目的的静态分析是一项没有人能够在复杂、现实场景中可信地证明的任务（尽管，正如你所期望的，在高度受限的环境或非常狭窄的目标下取得有限的成就是可能的）。许多案例在实践中可能无法解决（由于计算复杂性），甚至可能因为停机问题而完全不可解。（^[3]）

比早期定义的模糊和无用性更令人沮丧的是，随着几十年的过去，在向更好的方向取得进展方面几乎没有任何进展。事实上，2001 年海军研究实验室发布的一篇学术论文对早期工作进行了回顾，并得出了一种更为随意、列举式的软件安全定义——该定义明确否认其不完善和不完整。（^[87]）

> 一个系统如果能够充分保护其处理的信息免受未经授权的披露、修改和保留（也称为服务拒绝），则该系统是安全的。我们说“充分”，因为没有任何实际系统能够在没有任何限制的情况下实现这些目标；安全性本质上是相对的。

该论文还对早期努力进行了回顾性评估，以及为了保持这些模型的理论纯洁性所做出的不可接受牺牲：

> 经验表明，一方面，Bell-La Padula 模型的公理过于严格：它们禁止用户在实际应用中需要的操作。另一方面，受信任的主体，这是为了克服这些限制而提供的机制，限制不足。因此，开发人员不得不为每个系统中的受信任进程的期望行为制定专门的规范。

最后，无论引入了多少优雅、竞争的模型，所有试图使用算法基础来理解和评估现实世界软件安全性的尝试似乎注定会失败。这使开发人员和安全专家没有方法来做出权威、前瞻性的声明，关于所产生代码的质量。那么，还有什么其他选择呢？

## 进入风险管理

在没有正式保证和可证明的指标的情况下，考虑到现代社会所依赖的关键软件中存在令人担忧的安全漏洞，企业纷纷转向另一个吸引人的概念：*风险管理*。

风险管理的理念，成功应用于保险业（在金融世界中可能稍逊一筹），简单地说，就是系统所有者应该学会与无法以成本效益的方式解决的安全漏洞共存，并且通常应根据以下公式调整努力：

| *风险* = *事件发生的概率* × *最大损失* |
| --- |

例如，根据这一教条，如果每年有一些不重要的工作站被破坏不会使公司损失超过 1000 美元的生产力，那么该组织应该只是为这种损失进行预算并继续前进，而不是花费比如说 10 万美元在额外的安全措施或应急和监控计划上以防止损失。根据风险管理教条，这笔钱最好用于隔离、保护和监控为所有客户生成账单记录的至关重要的主机的安全。

自然，优先考虑安全工作是很谨慎的。问题是，当风险管理严格按数字进行时，它对我们理解、控制和处理现实世界问题帮助甚微。相反，它引入了一个危险的谬误：结构性的不足几乎和充足一样好，而且资金不足的安全努力*加上*风险管理几乎和充分资金的安全工作一样好。

猜猜看？没有用。

+   **在互联系统中，损失没有上限，也不与任何资产挂钩**。严格的风险管理依赖于估计与资源妥协相关的典型和最大成本的能力。不幸的是，唯一的方法是忽略这样一个事实：许多最引人注目的安全漏洞——例如对 TJX^([4])或 Microsoft^([5])的攻击——都是从相对不重要且被忽视的入口点开始的。这些初始入侵很快升级，最终导致关键基础设施几乎完全被破坏，绕过了它们在路上的任何表面网络隔离。在典型的按数字进行的风险管理中，初始入口点被赋予较低的权重，因为它与其他节点相比价值较低。同样，通往更敏感资源的内部升级路径被轻视，因为它被低估为被滥用的可能性很低。然而，忽视这两者都证明是一个爆炸性的组合。

+   **入侵的非货币成本很难通过健康系统的价值来抵消**。用户信心丧失、业务连续性中断，以及诉讼前景和监管审查的风险，都难以进行有意义的保险。这些影响，至少在原则上，可以使公司或整个行业陷入困境，或者甚至完全崩溃，而对这些结果的任何表面评估几乎纯粹是投机性的。

+   **现有数据可能并不代表未来的风险**。与轻微碰撞的参与者不同，攻击者不会主动报告入侵，也不会详尽地记录造成的损害。除非入侵令人痛苦地明显（由于攻击者的粗心大意或破坏意图），否则它通常会被忽视。尽管行业范围内的自报数据可能可用，但根本无法可靠地判断其完整性或当前业务实践可能增加多少额外风险。

+   **统计预测并不是个体结果的稳健预测器**。仅仅因为平均而言，城市中的人被雷击的可能性比被熊袭击的可能性更大，并不意味着你应该在你的帽子上安装避雷针，然后泡在蜜里。在个体层面上，与特定组件相关的妥协的可能性在很大程度上是不相关的：安全事件几乎是必然发生的，但在数千个暴露的非平凡资源中，任何服务都可以被用作攻击向量——而且没有任何一种服务可能会看到足以在单个企业范围内使统计预测有意义的事件量。

## 通过分类学获得启迪

上文讨论的两种思想流派有一些共同之处：两者都假设可以将安全定义为可计算的目标的集合，并且由此产生的安全系统统一理论或可接受风险模型将优雅地向下渗透，从而产生实现应用设计完美所需的底层行动的最优集合。

一些从业者宣扬相反的方法，这种方法与其说是基于哲学，不如说是基于自然科学。这些从业者认为，就像信息时代的查尔斯·达尔文一样，通过收集足够的低级实验数据，我们将能够观察、重建和记录越来越复杂的法则，以便达到某种统一的计算安全模型。

这种世界观带来了像国土安全部资助的通用弱点枚举（CWE）这样的项目，该项目的目标，用组织自己的话说，是开发一个统一的“漏洞理论”；“改进软件缺陷的研究、建模和分类”；以及“提供一个共同的语言来讨论、发现和处理软件安全漏洞的原因。”一个典型的、令人愉快的巴洛克式分类学例子可能是这个：

> 信息或数据结构执行不当
> 
> 未将数据净化到不同的平面
> 
> 资源标识符控制不当
> 
> 对可执行内容中的文件和其他资源名称过滤不足

今天，CWE 词典中有大约 800 个名称，其中大多数与这里引用的名称一样，具有促进对话的能力。

自然主义思想的一个略有不同的学派在诸如通用漏洞评分系统（CVSS）等项目中表现出来，这是一个由企业支持的协作项目，旨在通过一组基本、机器可读的参数严格量化已知的安全问题。一个现实世界的漏洞描述符示例可能是这样的：

> AV:LN / AC:L / Au:M / C:C / I:N / A:P / E:F / RL:T / RC:UR / CDP:MH / TD:H / CR:M / IR:L / AR:M

组织和研究人员预计将以一种精心选择、用途特定的方式转换这个 14 维向量，以便得出关于潜在错误（例如，“42”）重要性的某种客观、可验证、数值结论，从而避免以任何更主观的方式判断安全漏洞的性质。

是的，我在这些项目的费用上轻轻开了一个玩笑，但我的意思并不是贬低他们的努力。CWE、CVSS 和相关项目服务于崇高的目标，例如为大型组织实施的一些安全流程带来更可管理的维度。然而，没有一个产生了关于安全软件的伟大理论，我怀疑这样的框架在眼前。

## 向实用方法迈进

所有迹象都表明，目前安全问题在很大程度上是一个非算法问题。行业可以理解地不愿意公开接受这一观点，因为这暗示了没有银弹解决方案可以宣扬（或者更好的是，商业化）；然而，当压力足够大时，最终安全领域的每个人都会退回到一套基本的、经验性的食谱。这些食谱与许多商业模式深深不兼容，但它们是我们迄今为止真正有效的方法。它们如下：

+   **从（最好是别人的）错误中学习**。系统应该被设计成预防已知的错误类别。在没有自动（或者甚至只是优雅）解决方案的情况下，这个目标最好通过提供持续的设计指导来实现，确保开发者知道可能出错的地方，并给他们提供以最简单的方式执行可能出错的任务的工具。

+   **开发用于检测和纠正问题的工具**。安全缺陷通常在恶意方发现之前没有明显的副作用：一个相当昂贵的反馈循环。为了解决这个问题，我们创建了安全质量保证（QA）工具来验证实施情况，并定期进行审计以检测偶然的错误（或系统性的工程缺陷）。

+   **计划让一切都被破坏**。历史告诉我们，尽管我们尽了最大的努力来预防，但重大事件仍会发生。实施适当的组件分离、访问控制、数据冗余、监控和响应程序非常重要，这样服务所有者可以在一个最初微不足道的小故障变成圣经般规模的灾难之前对事件做出反应。

在所有情况下，所有信息安全人员都需要大量的耐心、创造力和真正的技术专长。

自然地，即使这样简单、常识性的规则——本质上是一种基本的工程严谨性——也常常被包装成口号，大量使用各种缩写（例如 *CIA*：*保密性*、*完整性*、*可用性*），然后被称为“方法论”。通常，这些方法论只是试图将安全行业最令人沮丧的失败之一作为另一个成功故事来推销，最终向易受骗的客户出售另一种万能产品或认证。但尽管有相反的声明，这样的产品并不能替代街头智慧和技术专长——至少不是在今天。

在任何情况下，在这本书的剩余部分，我将避免尝试建立或重新使用上述任何宏伟的哲学框架，而是满足于适量的反智主义。我将回顾现代浏览器暴露的表面，讨论如何安全地使用可用的工具，哪些 Web 部分通常被误解，以及当事情变得糟糕时如何控制附带损害。

这基本上是我能想到的关于安全工程的最佳看法。

* * *

^([2]) 这句话最初归功于伊万·阿尔塞，一位著名的漏洞猎人，大约在 2000 年左右；从那时起，它被 Crispin Cowan、Michael Howard、Anton Chuvakin 和其他众多安全专家所使用。

^([3]) 1936 年，艾伦·图灵表明（略有引申）不可能设计出一个算法，可以一般性地决定其他算法的结果。当然，有些算法可以通过进行特定案例的证明而被决定，但并非所有算法都可以。

^([4]) 大约在 2006 年，一些入侵者，据称由阿尔伯特·冈萨雷斯领导，攻击了一个零售场所未加密的无线网络，并随后进入了零售巨头的企业网络。他们复制了约 4600 万客户的信用卡数据，以及约 45 万人的社会保障号码、家庭地址等。与攻击有关的 11 人被起诉，其中一人自杀。

^([5]) 微软正式未公开且平淡无奇的演示文稿《针对和保护微软内部网络威胁》概述了 2003 年的一次攻击，该攻击始于一名工程师的家庭工作站被入侵，该工作站与公司内部保持了长期的 VPN 会话。随后进行了有计划的升级尝试，最终攻击者获得了对内部源代码存储库的访问权限，并泄露了数据。至少对公众来说，肇事者仍然是个谜。

# 网络简史

互联网一直受到大量令人困惑的安全问题的困扰，这些问题种类繁多。当然，其中一些问题可以归因于特定客户端或服务器实现中的一时疏忽，但许多问题是由于任性的、通常是任意的设计决策造成的，这些决策决定了基本机制在浏览器端的操作和协同工作方式。

我们的帝国建立在摇摇欲坠的基础上——但为什么呢？或许是因为简单的短视：毕竟，在那些天真无邪的日子里，谁会预测到当代网络的风险以及今天大规模安全攻击背后的经济激励呢？

不幸的是，虽然这种解释对于像 SMTP 或 DNS 这样真正古老的机制是有道理的，但它在这里并不完全适用：互联网相对较年轻，并在与我们今天所看到的环境不太不同的环境中形成了目前的形状。相反，这个谜题的关键可能在于相关技术演变过程中的动荡和异常方式。

因此，请原谅我再次短暂地偏离主题，当我们回到根源时。网络的史前时期相当平凡，但仍值得仔细研究。

## 石器时代的故事：1945 年至 1994 年

计算机历史学家经常引用一个假设的桌面大小的设备，称为 Memex，作为最早的化石记录之一，这是 1945 年由范内瓦·布什提出的。^([[88)](https://wiki.example.org/feynmans_learning_method) Memex 旨在通过一种类似于现代书签和超链接的技术，使创建、注释和跟踪缩微胶片中的跨文档链接成为可能。布什大胆地预测，这种简单的功能将彻底改变知识管理和数据检索领域（有趣的是，这种说法直到 20 世纪 90 年代初偶尔还会被嘲笑为无知的和天真的）。然而，任何有用的设计实现在当时都遥不可及，因此，除了未来主义的愿景之外，直到基于晶体管的计算机成为主流之前，并没有发生太多的事情。

下一个有形的里程碑是在 20 世纪 60 年代，IBM 推出了通用标记语言（GML），它允许使用机器可读的指令对文档进行注释，指示每块文本的功能，实际上是在说“这是一个标题”，“这是一个项目编号列表”，等等。在接下来的 20 年左右，GML（最初仅由少数 IBM 文本编辑器在笨重的主机计算机上使用）成为了标准通用标记语言（SGML）的基础，这是一种更通用、更灵活的语言，它用熟悉的尖括号语法取代了笨拙的冒号和句点语法。

当 GML 发展成 SGML 时，计算机变得更加强大和用户友好。几位研究人员开始尝试布什的交叉链接概念，将其应用于基于计算机的文档存储和检索，试图确定是否有可能基于某种关键字来交叉引用大量文档。一些冒险的公司和大学追求了开创性的项目，如 ENQUIRE、NLS 和 Xanadu，但大多数未能产生持久的影响。关于这些项目的常见抱怨围绕着它们的有限实用性、过度复杂性和较差的可扩展性。

到了十年末，两位研究人员，蒂姆·伯纳斯-李和丹·康诺利，开始致力于解决跨领域引用挑战的新方法——该方法侧重于简单性。他们通过起草超文本标记语言（HTML），一个 SGML 的基本后代，专门设计用于通过超链接和基本格式化标注文档，启动了这个项目。他们随后继续开发超文本传输协议（HTTP），这是一个极其基本的、专门用于使用现有的互联网协议（IP）地址、域名和文件路径概念访问 HTML 资源的方案。他们工作的成果，在 1991 年和 1993 年之间，是蒂姆·伯纳斯-李的世界万维网（图 1-1

图 1-1.蒂姆·伯纳斯-李的世界万维网

对于许多人来说，HTTP 和 HTML 的设计似乎是对竞争项目更高目标的重大倒退。毕竟，许多早期的努力都吹嘘数据库集成、安全性和数字版权管理，或者协作编辑和发布；事实上，甚至伯纳斯-李自己的项目 ENQUIRE，似乎也比他目前的工作更有雄心。然而，由于其低门槛要求、即时可用性和不受限制的可扩展性（这恰好与强大且价格合理的计算机的问世以及互联网的扩张相吻合），这个不起眼的万维网项目意外地成为了一项热门。

好吧，好吧，按照 1990 年代中期的标准，这显然是一个“热门”产品。很快，互联网上就有数十个网络服务器在运行。到 1993 年，HTTP 流量占美国国家科学基金会骨干网络的 0.1%带宽。同年，也见证了 Mosaic 的到来，这是第一个相对流行且复杂的网络浏览器，由伊利诺伊大学开发。Mosaic 通过添加将图像嵌入 HTML 文档和通过表单提交用户数据等功能，扩展了原始万维网代码，从而为今天的交互式、多媒体应用铺平了道路。

Mosaic 让浏览变得更加美观，有助于推动消费者对网络的采用。到 1990 年代中期，它成为其他两个浏览器的基石：Mosaic Netscape（后来更名为 Netscape Navigator）和 Spyglass Mosaic（最终被微软收购并更名为 Internet Explorer）。还出现了一些竞争的非 Mosaic 引擎，包括 Opera 和几个基于文本的浏览器（如 Lynx 和 w3m）。第一个搜索引擎、在线报纸和约会网站紧随其后。

## 第一次浏览器战争：1995 年至 1999 年

到 1990 年代中期，很明显，网络将长期存在，并且用户愿意放弃许多旧技术，转而选择新的竞争者。在那个时期，微软，这个之前对互联网反应迟缓的桌面软件巨头，开始感到不舒服，并开始为其自己的浏览器分配大量的工程资源，最终在 1996 年将其捆绑到 Windows 操作系统上.^([6])微软的行动引发了一个被俗称为“浏览器战争”的时期。

浏览器供应商之间由此产生的军备竞赛，其特点是在竞争产品中迅速发展和部署新功能，这一趋势往往违背了所有试图标准化或甚至正确记录所有新增代码的尝试。核心 HTML 调整从愚蠢的（使文本闪烁的能力，这是网景的一个发明，成为笑柄，也是错误网络设计的明显标志）到显著的，例如改变字体或在外部框架中嵌入外部文档的能力。供应商发布了包含嵌入式编程语言（如 JavaScript 和 Visual Basic）、用于在用户机器上执行平台无关的 Java 或 Flash 小程序的插件，以及如 cookies 之类的有用但棘手的 HTTP 扩展。只有有限程度的表面兼容性，有时受到专利和商标的限制，^([7])才能得到维持。

随着网络的日益庞大和多样化，一种狡猾的疾病在浏览器引擎中以容错为幌子传播开来。起初，这种推理似乎完全合理：如果浏览器 A 能够显示一个设计糟糕、损坏的页面，而浏览器 B 拒绝显示（无论什么原因），用户必然会将浏览器 B 的失败视为该产品的缺陷，并成群结队地涌向看似更强大的客户端，即浏览器 A。为了确保他们的浏览器能够正确显示几乎任何网页，工程师们开发了越来越复杂且未经文档记录的启发式方法，旨在猜测马虎的网站管理员的本意，在这个过程中往往牺牲了安全性和偶尔甚至兼容性。不幸的是，每一次这样的改变都进一步强化了不良的网页设计实践^([8])，并迫使剩余的厂商跟上混乱的局面以保持浮出水面。当然，缺乏足够详细、最新的标准并没有帮助遏制这种疾病的传播。

1994 年，为了减轻工程无序的传播并管理 HTML 的扩展，蒂姆·伯纳斯-李和少数几家企业赞助商创建了万维网联盟（W3C）。不幸的是，对于这个组织来说，在很长的一段时间里，它只能无助地旁观格式被随意扩展和调整。W3C 对 HTML 2.0 和 HTML 3.2 的最初工作仅仅试图跟上现状，结果产生了半成品规范，这些规范在发布给公众时已经很大程度上过时了。该联盟还试图从事一些新颖且相当周密考虑的项目，例如层叠样式表（Cascading Style Sheets），但很难获得厂商的支持。

其他旨在标准化或改进已实施机制的尝试，最显著的是 HTTP 和 JavaScript，是由欧洲计算机制造商协会（ECMA）、国际标准化组织（ISO）和互联网工程任务组（IETF）等其他机构推动的。遗憾的是，这些努力很少同步进行，有些讨论和设计决策被厂商或其他不太关心技术长期前景的利益相关者主导。结果是产生了一系列死标准、相互矛盾的建议，以及几个令人担忧的例子，展示了原本设计精良的协议之间有害的交叉交互——当我们在第九章（ch09.html "第九章。内容隔离逻辑"）讨论各种内容隔离机制时，这个问题将尤为明显。

## 无聊时期：2000 至 2003 年

随着努力控制网络的努力失败，微软凭借其操作系统捆绑策略的统治地位日益增强。到新世纪的开始，网景导航器正在走向尽头，而互联网浏览器占据了令人印象深刻的 80%市场份额——这个数字大约与五年前网景所持有的市场份额相当。在双方阵营，安全和互操作性是特征战争中最显著的受害者，但现在人们可以希望战斗已经结束，开发者可以放下分歧，共同努力修复混乱。

相反，主导地位滋生了自满：微软在出色地实现了其目标后，几乎没有动力在浏览器上大量投资。尽管从第五版开始，互联网浏览器（IE）的主要版本每年都会发布，但第六版的出现却花了两年时间，然后又用了整整五年时间才将互联网浏览器 6 更新到互联网浏览器 7。没有微软的兴趣，其他供应商几乎没有能力进行颠覆性的改变；大多数网站都不愿意进行改进，这些改进只能为极少数访客带来好处。

从积极的一面来看，浏览器开发的放缓使得万维网联盟（W3C）能够赶上并仔细探索一些关于网络未来的新概念。在 2000 年左右完成的新举措包括 HTML 4（一种清理过的语言，废弃或禁止了早期版本中许多冗余或政治上不正确的特性）和 XHTML 1.1（一种严格且结构良好的基于 XML 的格式，更容易明确解析，不允许使用专有启发式方法）。联盟还对 JavaScript 的文档对象模型和层叠样式表（CSS）进行了重大改进。遗憾的是，到世纪末，网络已经足够成熟，可以随意纠正一些旧时代的错误，但还太年轻，安全问题并不紧迫，也不够明显，以至于所有人都看得见。语法得到了改进，标签被废弃，编写了验证器，甲板椅被重新排列，但浏览器基本上还是老样子：臃肿、古怪、不可预测。

但不久之后，发生了一件有趣的事情：微软向世界提供了一个看似微不足道、名为*XMLHttpRequest*的专有 API，名称令人困惑。这个微不足道的机制原本意义不大，仅仅是为了解决微软 Outlook 网络版的一个小问题。但*XMLHttpRequest*最终证明意义非凡，它允许客户端 JavaScript 与服务器之间进行大量不受约束的异步 HTTP 通信，而无需进行耗时且破坏性的页面转换。在这个过程中，该 API 促进了后来被称为*Web 2.0*的出现——一系列复杂、响应速度异常快、基于浏览器的应用程序，使用户能够操作复杂的数据集、协作和发布内容等，在这个过程中侵入了“真实”的、可安装的客户端软件的神圣领域。可以理解，这引起了很大的轰动。

## Web 2.0 和第二次浏览器战争：2004 年及以后

*XMLHttpRequest*，结合互联网的普及和浏览器的广泛可用性，推动了网络走向一些新的、令人兴奋的领域——并带来了一系列影响个人用户和企业的安全漏洞。大约在 2002 年，蠕虫和浏览器漏洞成为媒体上经常讨论的主题。凭借其市场主导地位和相对轻视的安全态度，微软承担了大部分由此产生的公关压力。公司轻描淡写地贬低问题，但这一趋势最终营造了一种有利于小规模反抗的氛围。

2004 年，浏览器战争中出现了一位新的竞争者：Mozilla Firefox（Netscape Navigator 的社区支持后代）发起了攻势，特别针对 Internet Explorer 糟糕的安全记录和标准合规性。Firefox 受到了 IT 记者和安全专家的赞扬，迅速占据了 20%的市场份额。尽管这位新来者很快证明其同样受到安全漏洞的困扰，但其开源性质和无需迎合固执的 corporate users 的自由使得开发者能够更快地修复问题。

### 备注

为什么供应商会如此激烈地竞争呢？严格来说，在浏览器世界中拥有特定的市场份额并不能赚钱。然而，专家们长期以来一直猜测，这关乎权力：通过捆绑、推广或降低某些在线服务（甚至像默认搜索引擎这样简单的东西），控制浏览器的人就能在很大程度上控制互联网。

除了 Firefox 之外，微软还有其他原因感到不安。其旗舰产品 Windows 操作系统越来越多地被用作浏览器的（可消耗的？）发射台，越来越多的应用程序（从文档编辑到游戏）转移到网络上。这可不是什么好事。

这些事实，加上苹果 Safari 浏览器的突然出现，以及可能在智能手机领域取得进展的 Opera，肯定让微软的高管们感到困惑。他们在 20 世纪 90 年代错过了互联网重要性的早期迹象；当然，他们不能犯同样的错误。微软再次加大了对 Internet Explorer 开发的力度，迅速发布了大幅改进且相对更安全的版本 7、8 和 9。

竞争对手通过新增功能和声称更好的（尽管仍然表面化）标准合规性、更安全的浏览和性能改进来反击。在*XMLHttpRequest*意外成功面前措手不及，并且很快忘记了过去的教训，供应商们也大胆地尝试新想法，有时甚至单方面推出半成品或有些不安全的方案，如 Firefox 中的*globalStorage*或 Internet Explorer 中的*httponly* cookies，只是为了试试运气。

为了进一步复杂化情况，由于与 W3C 在创意上的分歧，一群贡献者创建了一个全新的标准机构，称为 Web 超文本应用技术工作组（WHATWG）。WHATWG 在 HTML5 的发展中发挥了关键作用，这是现有标准的第一次全面和注重安全的修订，但据报道，由于专利政策争议，它被微软所排斥。

在其大部分历史中，网络都享有一种独特、高度竞争、快速、往往过于政治化和反复无常的发展模式，没有统一的愿景和一套固定的安全原则。这种状况对浏览器当前的运作方式以及浏览器处理用户数据的安全性留下了深刻的印记。

很有可能，这种情况不会很快改变。

* * *

^([6]) 有趣的是，这个决定最终证明是非常有争议的。一方面，可以认为，通过这样做，微软极大地促进了互联网的普及。另一方面，它削弱了竞争对手浏览器的地位，可能被视为反竞争。最终，这种策略导致了一系列关于公司可能滥用垄断地位的长期法律斗争，例如*美国诉微软*。

^([7]) 例如，微软不想与 Sun 协商 JavaScript（这种语言之所以这样命名是为了促销目的，而不是因为它与 Java 有任何关系）的商标许可，因此它选择了将其几乎但并不完全相同的版本命名为“JScript”。微软的官方文档仍然使用这个名字。

^([8]) 一些被误导且最终致命的浏览器功能例子是内容识别和字符集嗅探机制，这两者都将在第十三章（内容识别机制）中讨论。

# 威胁的演变

显然，网络浏览器及其相关的文档格式和通信协议是以一种非常规的方式演化的。这种演化可能解释了我们看到的大量安全问题，但仅凭这一点几乎无法证明这些问题是独特或值得注意的。为了总结本章，让我们快速看一下最常见的在线安全威胁背后的非常特殊的特点，并探讨为什么这些威胁在互联网出现之前并没有特别好的对应物。

## 用户作为安全漏洞

也许网络浏览器最引人注目（而且完全是技术性的）的特性是，使用它们的大多数人都是技能不足的。当然，非熟练用户自从计算机诞生以来一直是一个有趣且边缘的问题。但互联网的普及，加上其惊人的低门槛，意味着我们面临一个新的敌人：大多数用户对安全的了解不足，无法保持安全。

很长一段时间以来，从事通用软件开发的工程师们对于用户所需的最基本的计算机技能水平做出了看似随意的假设。这些假设中的大多数都没有产生严重的后果；例如，文本编辑器的错误使用通常对系统安全的影响微乎其微。能力不足的用户根本无法完成他们的工作，这是一个美妙的自纠正问题。

然而，网络浏览器并不是这样工作的。与某些复杂的软件不同，它们可以被几乎没有计算机培训的人成功使用，这些人甚至可能不知道如何使用文本编辑器。但与此同时，只有对计算机技术和相关术语有相当了解的人才能安全地操作浏览器，包括诸如公钥基础设施等主题。不用说，大多数今天最成功的网络应用的用户都没有达到这个先决条件。

浏览器仍然看起来和感觉像是被极客们为极客们设计的，包括偶尔出现的晦涩和不一致的错误信息、复杂的配置设置，以及令人困惑的安全警告和提示。2006 年，加州大学伯克利分校和哈佛大学的研究人员进行的一项显著研究表明，普通用户几乎普遍对那些对开发者来说肯定是有意义的信号视而不见，例如状态栏中是否存在锁形图标。^([[89]) 在另一项研究中，斯坦福大学和微软的研究人员在对现代“绿色 URL 栏”安全指示符的影响进行了考察后，得出了相似的结论。该机制旨在提供一种更直观的替代锁形图标的方案，但实际上它通过教会观众信任特定色调的绿色，无论这种颜色出现在哪里，都使得欺骗用户变得更加容易。^([[90])

一些专家认为，普通用户的无能不是软件供应商的过错，因此根本不是工程问题。其他人指出，在创建如此易于访问和广泛分布的软件时，强迫用户做出依赖于技术专长（而这些技术专长原本不是操作程序所必需的）的安全关键决策是不负责任的。然而，仅仅责怪浏览器供应商也是不公平的：整个计算行业在这个领域没有强大的答案，而且关于如何以安全的方式设计类似复杂用户界面（UI）的研究非常少。毕竟，我们连 ATM 机都很难做到完全正确。

## 云端，或集体生活的乐趣

网络的另一个奇特特征是无关应用程序及其处理的数据之间戏剧性地低估的分离。

在过去 15 年左右几乎所有个人计算机遵循的传统模型中，高级数据对象（文档）、用户级代码（应用程序）和仲裁所有跨应用程序通信以及硬件输入/输出（I/O）的操作系统内核之间有非常清晰的边界，并在应用程序出现异常时强制执行可配置的安全规则。这些边界得到了很好的研究，并且对于构建实用的安全方案很有用。在你文本编辑器中打开的文件不太可能窃取你的电子邮件，除非非常不幸的实现缺陷同时破坏了所有这些分离层。

在浏览器世界中，这种分离几乎不存在：文档和代码作为同一混合的 HTML 块的一部分存在，完全无关的应用程序之间的隔离最多是部分的（所有网站名义上共享一个全局 JavaScript 环境），并且网站之间的大多数交互都是隐式允许的，几乎没有灵活的、浏览器级别的安全仲裁框架。

在某种意义上，这种模式让人联想到 CP/M、DOS 以及其他主要非多任务操作系统，它们没有强大的内存保护、CPU 抢占或多用户功能。明显的区别是，很少有用户依赖于这些早期的操作系统来同时运行多个不受信任、由攻击者提供的应用程序，因此没有特别的理由感到恐慌。

最后，看似不可能的文本文件窃取你的电子邮件的情况，实际上在网络上是一个令人沮丧的常见模式。几乎所有的网络应用程序都必须大量补偿未经请求、恶意的跨域访问，并采取繁琐的步骤来保持代码和显示数据之间至少有一些分离。而且迟早，几乎所有的网络应用程序都会失败。与内容相关的安全问题，如跨站脚本或跨站请求伪造，非常普遍，在专门的、分区的客户端架构中几乎没有对应的例子。

## 视野的非收敛

幸运的是，浏览器安全领域并非完全无望，尽管网络应用程序之间的分离有限，但一些选择性的安全机制为最明显的攻击提供了基本的保护。但这又引出了使网络成为一个有趣主题的另一个特征：没有共享的、整体的安全模型可以把握和遵循。请注意，我们不是在寻找世界和平的宏伟愿景，而只是寻找一套适用于大多数，如果不是所有相关安全逻辑的灵活范式。例如，在 Unix 世界中，*rwx* 用户/组权限模型就是这样一种强大的统一主题。但在浏览器领域呢？

在浏览器领域，一种称为*同源策略*的机制可以被认为是一个核心安全范式的候选，但只有直到人们意识到它只控制了跨域交互的一个非常小的子集。抛开这个细节不谈，即使在它的范围内，它也有不少于七种不同的类型，每种类型都在应用程序之间以略微不同的位置设置安全边界。^([9]) 与同源模型无关的数十种其他机制控制着浏览器行为的其他关键方面（本质上实现了每个作者认为当天最佳的安全控制方法）。

事实上，数百个小巧的漏洞并不一定能够组合成一个合格的安全作品。这种异常缺乏完整性使得甚至很难决定一个应用程序的结束和另一个应用程序的开始。考虑到这一现实，一个人如何评估攻击面、授予或撤销权限，或者完成几乎任何其他以安全为导向的任务？太经常了，“只靠交叉手指”是我们能给出的最佳回应。

奇怪的是，许多出于好意的尝试通过定义新的安全控制措施来提高安全性，反而使问题变得更糟。许多这样的方案创建了新的安全边界，为了追求优雅，它们并不完美地与现有的复杂边界对齐。当新的控制措施更加细粒度时，它们很可能会被遗留机制所削弱，从而产生一种虚假的安全感；而当它们更加粗粒度时，它们可能会消除网络目前所依赖的一些微妙的安全保证。（亚当·巴思和柯林·杰克逊在他们学术工作中探讨了浏览器安全策略之间破坏性干扰的话题。）^([91])

## 跨浏览器交互：失败的协同

由多个不同的软件产品组成的生态系统的整体易受攻击性可能预期等于每个应用程序贡献的缺陷的简单总和。在某些情况下，由此产生的暴露可能更少（多样性提高了弹性），但人们不会期望它更多。

Web 再次成为规则的例外。安全社区已经发现了一系列问题，这些问题不能归因于任何特定的代码片段，但当各种浏览器尝试相互交互时，它们会成为一个真正的威胁。无法轻易将责任归咎于任何特定产品：它们都在做自己的事情，唯一的问题是没有人费心为它们定义一个共同的行为准则。

例如，一个浏览器可能认为，根据其自身的安全模型，将某些 URL 传递给外部应用程序或从磁盘存储或读取某些类型的数据是安全的。对于这样的假设，很可能至少存在一个浏览器强烈反对，期望其他方遵循其规则。由于供应商希望打开市场并尝试在用户知情同意的情况下动态切换网页到他们的浏览器，这些问题可利用性大大加剧。例如，Firefox 允许通过注册*firefoxurl:*协议在浏览器中打开页面；Microsoft 在 Firefox 中安装了自己的.NET 网关插件；Chrome 通过名为*cf:*的协议以同样的方式对 Internet Explorer 进行操作。

### 注意

尤其是在这种交互的情况下，将责任归咎于任何特定的一方都是徒劳的。在最近一个与*firefoxurl:*相关的错误案例中，Microsoft 和一半的信息安全社区指责 Mozilla，而 Mozilla 和另一半专家则指责 Microsoft.^([92]) 谁对谁错并不重要：结果仍然是一个非常真实的混乱局面。

另一组与之密切相关的问题（在 Web 出现之前几乎闻所未闻）是每个浏览器中实施的表面上类似的安全机制的不兼容性。当安全模型不同时，一个产品中的良好网络应用程序工程实践可能在另一个产品中不足且误导。实际上，一些基本任务，如提供用户提供的明文文件，在某些浏览器中根本无法安全实现。然而，除非开发者在受影响的浏览器中工作，否则这一事实对他们来说可能并不明显——即使如此，他们也需要恰好击中正确的位置。

最后，本节中概述的所有特征共同导致了一种全新的安全漏洞类别，一个分类学爱好者可能会称之为“未能考虑未记录的多样性”。这个类别在今天非常丰富。

## 客户端-服务器分界的崩溃

信息安全研究人员喜欢静态、明确分配的角色世界，这在映射复杂世界中安全交互时是一个熟悉的知识点。例如，我们谈论 Alice 和 Bob，两位诚实、勤奋的用户想要进行通信，以及 Mallory，一个狡猾的攻击者，他想要对他们下手。然后我们有客户端软件（本质上是无知的、有时是恶意 I/O 终端，随意请求服务）和谦逊的服务器，小心翼翼地满足客户端的愿望。开发者学习这些角色并参与其中，在这个过程中构建了相当可理解和可测试的网络计算环境。

互联网最初是一个典型的客户端-服务器架构的例子，但客户端和服务器之间的功能边界很快就被侵蚀了。罪魁祸首是 JavaScript，这种语言为 HTTP 服务器提供了一种将应用程序逻辑委托给浏览器（“客户端”）的方法，并给了它们两个非常有说服力的理由去做这件事。首先，这样的转变通常会导致用户界面更加响应迅速，因为服务器不需要同步参与每个可想象的微小 UI 状态变化。其次，当全球各地的个人工作站共同分担大量工作时，服务器端的 CPU 和内存需求（以及因此提供服务的成本）可以大幅降低。

客户端-服务器扩散过程开始时相当无辜，但很快，第一个安全机制也跟随到了客户端，以及其他所有平凡的功能。例如，当数据仅在客户端机器上通过 JavaScript 动态渲染时，在服务器端仔细清洗 HTML 有什么意义呢？

在某些应用程序中，这种趋势被推向了极端，最终服务器几乎只是一个哑存储设备，几乎所有解析、编辑、显示和配置任务都移到了浏览器本身。在这种设计中，甚至可以通过使用离线 Web 扩展（如 HTML5 持久存储）完全切断对服务器的依赖。

整个应用程序魔法发生位置的简单转变并不一定是件大事，但并非所有的安全责任都可以轻易地委托给客户端。例如，即使是在服务器作为哑存储的情况下，客户端也不能无差别地访问服务器上存储的其他用户的所有数据，也不能信任它们执行访问控制。最终，由于不希望将所有应用程序安全逻辑保留在服务器端，并且完全迁移到客户端又是不可能的，大多数应用程序最终占据了某种任意的中间地带，客户端和服务器组件之间没有明显的和逻辑上的职责分离。由此产生的不熟悉的设计和应用行为在优雅和纯洁的安全角色扮演世界中没有任何有用的对应物。

这种情况不仅仅导致了设计层面的混乱；它还导致了不可还原的复杂性。在传统的客户端-服务器模型中，具有明确指定的 API，人们可以很容易地评估服务器的行为，而不必查看客户端，反之亦然。此外，在每一个这些组件内部，可以轻松地隔离更小的功能块，并对它们的预期操作做出假设。在新模型中，结合 Web 上常见的模糊的、一次性的应用程序 API，这些分析工具以及由此产生的关于系统安全性的推理便利性，都被残酷地剥夺了。

标准化安全建模和测试协议的意外失败是另一个问题，这使得 Web 在信息安全领域占据了非常特殊——并且令人恐惧——的位置。

* * *

^(9]) 本书第二部分“浏览器安全特性”中讨论的主要七种类型包括 JavaScript DOM 访问的安全策略；*XMLHttpRequest* API；HTTP cookies；本地存储 API；以及 Flash、Silverlight 或 Java 等插件。

# 全球浏览器市场份额，2011 年 5 月

| 供应商 | 浏览器名称 | 市场份额 |
| --- | --- | --- |
| Microsoft | Internet Explorer 6 | 10% | 52% |
| Internet Explorer 7 | 7% |
| Internet Explorer 8 | 31% |
| Internet Explorer 9 | 4% |
| Mozilla | Firefox 3 | 12% | 22% |
| Firefox 4+ | 10% |
| Google | Chrome | 13% |
| Apple | Safari | 7% |
| Opera Software | Opera | 3% |

*来源*：数据来源于公开的 Net Applications 报告。^([93)]
